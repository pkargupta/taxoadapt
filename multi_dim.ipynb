{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Setup**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "os.environ['HF_HOME'] = '/shared/data3/pk36/.cache'\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "!export HF_HOME=/shared/data3/pk36/.cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model_definitions import initializeLLM, promptLLM, constructPrompt\n",
    "import json\n",
    "from utils import clean_json_string\n",
    "from collections import deque\n",
    "from taxonomy import Node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args:\n",
    "    def __init__(self):\n",
    "        \n",
    "        self.topic = \"natural language processing\"\n",
    "        self.init_dims = 2\n",
    "        self.llm = 'samba'\n",
    "\n",
    "        self.dataset = \"ner_event_kgc\"\n",
    "        self.data_dir = f\"datasets/gen_kgc/{self.dataset}/\"\n",
    "        self.internal = f\"{self.dataset}.txt\"\n",
    "        self.external = f\"{self.dataset}_external.txt\"\n",
    "        self.groundtruth = \"groundtruth.txt\"\n",
    "        \n",
    "        self.length = 512\n",
    "        self.dim = 768\n",
    "\n",
    "        self.iters = 4\n",
    "\n",
    "args = Args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pk36/Comparative-Summarization/taxoadapt/env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "initializeLLM(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Construct a 2-Level Multi-Dimensional Taxonomy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prompts import multi_dim_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_topic = args.topic.replace(' ', '_').lower()\n",
    "root = Node(\n",
    "        id=0,\n",
    "        label=mod_topic\n",
    "    )\n",
    "id2node = {0:root}\n",
    "# we want to make this a directed acyclic graph (DAG) so maintain a list of the nodes\n",
    "label2node = {mod_topic:root}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "queue = deque([root])\n",
    "\n",
    "while queue:\n",
    "    curr_node = queue.popleft()\n",
    "    label = curr_node.label\n",
    "    # expand\n",
    "    system_instruction, main_prompt, json_output_format = multi_dim_prompt(curr_node)\n",
    "    prompts = [constructPrompt(args, system_instruction, main_prompt + \"\\n\\n\" + json_output_format)]\n",
    "    outputs = promptLLM(args=args, prompts=prompts, max_new_tokens=2000, json_mode=True, temperature=0.1, top_p=0.99)[0]\n",
    "    outputs = json.loads(clean_json_string(outputs)) if \"```\" in outputs else json.loads(outputs.strip())\n",
    "    outputs = outputs[label]\n",
    "\n",
    "    # add all children\n",
    "    for key, value in outputs.items():\n",
    "        key = key.replace(' ', '_').lower()\n",
    "        if key not in label2node:\n",
    "            child_node = Node(\n",
    "                    id=len(id2node),\n",
    "                    label=key,\n",
    "                    description=value['description'],\n",
    "                    datasets=value['datasets'],\n",
    "                    methodologies=value['methodologies'],\n",
    "                    evaluation_methods=value['evaluation_methods'],\n",
    "                    applications=value['applications'],\n",
    "                    parents=[curr_node]\n",
    "                )\n",
    "            curr_node.add_child(key, child_node)\n",
    "            id2node[child_node.id] = child_node\n",
    "            label2node[key] = child_node\n",
    "            if child_node.level < args.init_dims:\n",
    "                queue.append(child_node)\n",
    "        else:\n",
    "            child_node = label2node[key]\n",
    "            child_node.add_parent(curr_node)\n",
    "            child_node.add_dataset(value['datasets'])\n",
    "            child_node.add_methodology(value['methodologies'])\n",
    "            child_node.add_evaluation_method(value['evaluation_methods'])\n",
    "            child_node.add_application(value['applications'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: natural_language_processing\n",
      "Description: None\n",
      "Level: 0\n",
      "----------------------------------------\n",
      "Children:\n",
      "     Label: text_classification\n",
      "     Description: The task of assigning predefined categories to text based on its content.\n",
      "     Level: 1\n",
      "     Datasets: ['A dataset of labeled text from news articles for training text classification models.', 'A collection of news articles categorized by topic', 'A dataset of labeled product reviews for sentiment analysis', 'A dataset of text from product reviews for training sentiment analysis models.']\n",
      "     Methodologies: ['Convolutional Neural Networks (CNNs)', 'Supervised learning with convolutional neural networks', 'Support Vector Machines (SVMs)', 'Random Forests', 'Transfer learning with pre-trained language models']\n",
      "     Evaluation Methods: ['A metric to evaluate the robustness of text classification models to adversarial attacks.', 'Precision and recall for topic modeling', 'Accuracy metric to evaluate the performance of text classification models.', 'Accuracy and F1-score for sentiment analysis']\n",
      "     Applications: ['Sentiment analysis for product reviews and feedback.', 'Sentiment analysis for customer feedback', 'Spam detection and filtering for emails and messages.', 'Topic modeling for news article categorization']\n",
      "     ----------------------------------------\n",
      "     Children:\n",
      "          Label: text_classification_for_low_resource_languages\n",
      "          Description: Classifying text in low-resource languages with limited labeled data.\n",
      "          Level: 2\n",
      "          Datasets: ['A dataset of text in a low-resource language (e.g. Swahili, Amharic) with limited labeled data', 'A dataset of text in a low-resource language with labeled data augmented through machine translation']\n",
      "          Methodologies: ['Transfer learning from high-resource languages', 'Few-shot learning with meta-learning algorithms']\n",
      "          Evaluation Methods: ['Accuracy, precision, recall, F1-score for text classification', 'Cross-lingual evaluation for text classification']\n",
      "          Applications: ['Language preservation for endangered languages', 'Multilingual text analysis for global communication']\n",
      "          ----------------------------------------\n",
      "          Label: multimodal_text_classification\n",
      "          Description: Classifying text with multimodal inputs (e.g. images, audio, video).\n",
      "          Level: 2\n",
      "          Datasets: ['A dataset of text with images (e.g. memes, infographics) for multimodal classification', 'A dataset of text with audio (e.g. podcasts, audiobooks) for multimodal classification']\n",
      "          Methodologies: ['Multimodal fusion with deep learning models (e.g. CNN, RNN)', 'Multimodal attention with transformer models']\n",
      "          Evaluation Methods: ['Accuracy, precision, recall, F1-score for multimodal text classification', 'Multimodal evaluation metrics (e.g. multimodal accuracy, multimodal F1-score)']\n",
      "          Applications: ['Multimodal sentiment analysis for social media monitoring', 'Multimodal text analysis for multimedia content analysis']\n",
      "          ----------------------------------------\n",
      "     ----------------------------------------\n",
      "     Label: language_modeling\n",
      "     Description: The task of predicting the next word in a sequence of text given the context.\n",
      "     Level: 1\n",
      "     Datasets: ['A dataset of text from social media platforms for training language models on informal language.', 'A large-scale dataset of books from the internet archive for training language models.', 'A large corpus of text from the internet for training language models', 'A dataset of conversations for dialogue generation']\n",
      "     Methodologies: ['Recurrent neural networks with long short-term memory', 'Recurrent Neural Networks (RNNs)', 'Transformers', 'Long Short-Term Memory (LSTM) Networks', 'Transformers with self-attention mechanisms']\n",
      "     Evaluation Methods: ['Perplexity for language model evaluation', 'A human evaluation metric to assess the coherence and fluency of generated text.', 'BLEU score for dialogue generation', 'Perplexity metric to evaluate the performance of language models.']\n",
      "     Applications: ['Text summarization and generation for news articles.', 'Chatbots and conversational AI', 'Chatbots and conversational AI systems.', 'Language translation and generation']\n",
      "     ----------------------------------------\n",
      "     Children:\n",
      "          Label: language_understanding\n",
      "          Description: The ability of a model to comprehend the meaning of text, including syntax, semantics, and pragmatics.\n",
      "          Level: 2\n",
      "          Datasets: ['A dataset of annotated text for sentiment analysis, including nuanced sentiment labels and contextual information.', 'A multilingual dataset for machine translation, with parallel text in multiple languages and varying levels of formality.']\n",
      "          Methodologies: ['Attention-based neural networks for machine translation', 'Graph-based neural networks for semantic role labeling']\n",
      "          Evaluation Methods: ['A metric for evaluating the accuracy of sentiment analysis models on nuanced sentiment labels', 'A framework for evaluating the robustness of machine translation models to adversarial attacks']\n",
      "          Applications: ['Sentiment analysis for customer service chatbots', 'Machine translation for international business communication']\n",
      "          ----------------------------------------\n",
      "          Label: language_generation\n",
      "          Description: The ability of a model to generate coherent and natural-sounding text, including text summarization, dialogue generation, and language translation.\n",
      "          Level: 2\n",
      "          Datasets: ['A dataset of paired text summaries and original articles for training and evaluating text summarization models', 'A dataset of human-generated dialogue responses to prompts, for training and evaluating dialogue generation models']\n",
      "          Methodologies: ['Sequence-to-sequence neural networks for text summarization', 'Generative adversarial networks for dialogue generation']\n",
      "          Evaluation Methods: ['A metric for evaluating the coherence and fluency of generated text', 'A framework for evaluating the diversity and creativity of generated text']\n",
      "          Applications: ['Text summarization for news articles and academic papers', 'Dialogue generation for virtual assistants and chatbots']\n",
      "          ----------------------------------------\n",
      "          Label: conversational_ai\n",
      "          Description: The ability of a model to engage in natural-sounding conversation, including dialogue management, intent recognition, and response generation.\n",
      "          Level: 2\n",
      "          Datasets: ['A dataset of human-human conversations, annotated with dialogue acts and intent labels', 'A dataset of customer service interactions, including transcripts and outcome labels']\n",
      "          Methodologies: ['Reinforcement learning for dialogue management', 'Deep learning for intent recognition and response generation']\n",
      "          Evaluation Methods: ['A metric for evaluating the effectiveness of conversational AI models in customer service scenarios', 'A framework for evaluating the user experience of conversational AI interfaces']\n",
      "          Applications: ['Virtual assistants for customer service and tech support', 'Chatbots for e-commerce and online shopping']\n",
      "          ----------------------------------------\n",
      "          Label: multimodal_language_modeling\n",
      "          Description: The ability of a model to process and generate text and other modalities, such as images, audio, and video.\n",
      "          Level: 2\n",
      "          Datasets: ['A dataset of images and captions, for training and evaluating image captioning models', 'A dataset of audio recordings and transcripts, for training and evaluating speech recognition models']\n",
      "          Methodologies: ['Multimodal neural networks for image captioning and speech recognition', 'Transfer learning for adapting language models to new modalities']\n",
      "          Evaluation Methods: ['A metric for evaluating the accuracy of image captioning models', 'A framework for evaluating the robustness of speech recognition models to noise and variability']\n",
      "          Applications: ['Image captioning for accessibility and search', 'Speech recognition for voice assistants and transcription services']\n",
      "          ----------------------------------------\n",
      "          Label: explainable_language_modeling\n",
      "          Description: The ability of a model to provide insights and explanations for its predictions and decisions, including model interpretability and transparency.\n",
      "          Level: 2\n",
      "          Datasets: ['A dataset of annotated text for explainability, including explanations and justifications for model predictions', 'A dataset of model predictions and explanations, for evaluating the effectiveness of explainability methods']\n",
      "          Methodologies: ['Attention-based neural networks for model interpretability', 'Model-agnostic explainability methods for language models']\n",
      "          Evaluation Methods: ['A metric for evaluating the effectiveness of explainability methods for language models', 'A framework for evaluating the transparency and trustworthiness of language models']\n",
      "          Applications: ['Explainable AI for high-stakes decision-making, such as healthcare and finance', 'Transparent language models for education and research']\n",
      "          ----------------------------------------\n",
      "     ----------------------------------------\n",
      "     Label: named_entity_recognition\n",
      "     Description: The task of identifying and categorizing named entities in text.\n",
      "     Level: 1\n",
      "     Datasets: ['A dataset of news articles with named entity labels (e.g. person, organization, location)', 'A collection of news articles with annotated entities', 'A dataset of social media posts with named entity labels (e.g. person, organization, location)', 'A dataset of labeled text with named entities for training']\n",
      "     Methodologies: ['Supervised learning with conditional random fields', 'Supervised learning with machine learning algorithms (e.g. SVM, Random Forest)', 'Deep learning with recurrent neural networks (RNN) or transformers', 'Deep learning with recurrent neural networks']\n",
      "     Evaluation Methods: ['Entity-level accuracy for named entity recognition', 'Precision and recall for entity recognition', 'F1-score for entity classification', 'Precision, recall, F1-score for named entity recognition']\n",
      "     Applications: ['Question answering and entity disambiguation', 'Question answering for chatbots or virtual assistants', 'Information extraction for data mining', 'Information extraction and knowledge graph construction']\n",
      "     ----------------------------------------\n",
      "     Children:\n",
      "          Label: entity_extraction\n",
      "          Description: Identifying and extracting specific entities from unstructured text.\n",
      "          Level: 2\n",
      "          Datasets: ['A dataset of annotated news articles for extracting entities related to politics and economics.', 'A dataset of biomedical texts for extracting entities related to genes and proteins.']\n",
      "          Methodologies: ['Rule-based approaches using regular expressions and gazetteers', 'Machine learning-based approaches using supervised learning and deep learning']\n",
      "          Evaluation Methods: ['Precision, recall, and F1-score for evaluating entity extraction accuracy', 'A metric that measures the overlap between extracted entities and gold standard entities']\n",
      "          Applications: ['Information retrieval and search engines', 'Text summarization and question answering']\n",
      "          ----------------------------------------\n",
      "          Label: entity_disambiguation\n",
      "          Description: Resolving ambiguity between entities with similar names or contexts.\n",
      "          Level: 2\n",
      "          Datasets: ['A dataset of news articles with ambiguous entity mentions', 'A dataset of social media posts with entities that require disambiguation']\n",
      "          Methodologies: ['Graph-based approaches using entity co-occurrence and context', 'Deep learning-based approaches using attention mechanisms and contextualized embeddings']\n",
      "          Evaluation Methods: ['Accuracy and F1-score for evaluating entity disambiguation performance', 'A metric that measures the consistency of entity disambiguation across different contexts']\n",
      "          Applications: ['Entity linking and knowledge graph construction', 'Question answering and text summarization']\n",
      "          ----------------------------------------\n",
      "          Label: entity_linking\n",
      "          Description: Linking extracted entities to a knowledge base or ontology.\n",
      "          Level: 2\n",
      "          Datasets: ['A dataset of annotated texts with entity links to Wikipedia', 'A dataset of biomedical texts with entity links to a knowledge graph']\n",
      "          Methodologies: ['Rule-based approaches using string matching and dictionary lookup', 'Machine learning-based approaches using supervised learning and graph-based methods']\n",
      "          Evaluation Methods: ['Precision, recall, and F1-score for evaluating entity linking accuracy', 'A metric that measures the coverage of entity links in a knowledge graph']\n",
      "          Applications: ['Knowledge graph construction and completion', 'Question answering and text summarization']\n",
      "          ----------------------------------------\n",
      "          Label: entity_typing\n",
      "          Description: Assigning a type or category to an extracted entity.\n",
      "          Level: 2\n",
      "          Datasets: ['A dataset of annotated texts with entity types', 'A dataset of social media posts with entities that require typing']\n",
      "          Methodologies: ['Rule-based approaches using gazetteers and lexical resources', 'Machine learning-based approaches using supervised learning and deep learning']\n",
      "          Evaluation Methods: ['Accuracy and F1-score for evaluating entity typing performance', 'A metric that measures the consistency of entity typing across different contexts']\n",
      "          Applications: ['Entity recognition and information extraction', 'Text classification and sentiment analysis']\n",
      "          ----------------------------------------\n",
      "          Label: entity_coreference_resolution\n",
      "          Description: Resolving coreference between entities in a text.\n",
      "          Level: 2\n",
      "          Datasets: ['A dataset of annotated texts with coreference annotations', 'A dataset of dialogues with entities that require coreference resolution']\n",
      "          Methodologies: ['Rule-based approaches using string matching and syntactic parsing', 'Machine learning-based approaches using supervised learning and deep learning']\n",
      "          Evaluation Methods: ['Precision, recall, and F1-score for evaluating coreference resolution accuracy', 'A metric that measures the consistency of coreference resolution across different contexts']\n",
      "          Applications: ['Text summarization and question answering', 'Dialogue systems and conversational AI']\n",
      "          ----------------------------------------\n",
      "     ----------------------------------------\n",
      "     Label: machine_translation\n",
      "     Description: The task of translating text from one language to another.\n",
      "     Level: 1\n",
      "     Datasets: ['A dataset of translated text with annotations', 'A dataset of text from books and articles in multiple languages for training machine translation models.', 'A large-scale dataset of paired text in multiple languages for training machine translation models.', 'A parallel corpus of text in multiple languages']\n",
      "     Methodologies: ['Attention-based Models', 'Neural machine translation with sequence-to-sequence models', 'Statistical machine translation with phrase-based models', 'Graph-based Models', 'Sequence-to-Sequence Models']\n",
      "     Evaluation Methods: ['METEOR score for translation quality', 'BLEU score metric to evaluate the performance of machine translation models.', 'BLEU score for translation evaluation', 'A human evaluation metric to assess the fluency and accuracy of translated text.']\n",
      "     Applications: ['Translation systems for languages with limited resources.', 'Cross-lingual information retrieval', 'Language translation and localization', 'Multilingual chatbots and conversational AI systems.']\n",
      "     ----------------------------------------\n",
      "     Children:\n",
      "          Label: neural_machine_translation\n",
      "          Description: Using neural networks to improve machine translation\n",
      "          Level: 2\n",
      "          Datasets: ['Multilingual dataset for low-resource languages', 'Large-scale dataset for domain adaptation in NMT', 'Dataset with human-annotated error analysis for NMT']\n",
      "          Methodologies: ['Sequence-to-sequence models with attention', 'Transformer-based models', 'Recurrent neural network-based models']\n",
      "          Evaluation Methods: ['BLEU score with linguistic features', 'Human evaluation with fluency and adequacy metrics', 'Automated evaluation with contextualized embeddings']\n",
      "          Applications: ['Real-time translation for chatbots and virtual assistants', 'Document translation for international business', 'Subtitling and closed captions for multimedia content']\n",
      "          ----------------------------------------\n",
      "          Label: statistical_machine_translation\n",
      "          Description: Using statistical models to improve machine translation\n",
      "          Level: 2\n",
      "          Datasets: ['Large-scale parallel corpus for phrase-based SMT', 'Dataset with syntactic and semantic annotations for SMT', 'Multilingual dataset for hierarchical phrase-based SMT']\n",
      "          Methodologies: ['Phrase-based models with n-gram language models', 'Syntax-based models with dependency parsing', 'Hierarchical phrase-based models with semantic roles']\n",
      "          Evaluation Methods: ['BLEU score with n-gram precision and recall', 'Human evaluation with ranking and preference metrics', 'Automated evaluation with perplexity and entropy']\n",
      "          Applications: ['Document translation for government and education', 'Website translation for e-commerce and tourism', 'Speech recognition and translation for voice assistants']\n",
      "          ----------------------------------------\n",
      "          Label: hybrid_machine_translation\n",
      "          Description: Combining multiple approaches to improve machine translation\n",
      "          Level: 2\n",
      "          Datasets: ['Multimodal dataset for image and text translation', 'Dataset with human-annotated error analysis for hybrid MT', 'Large-scale dataset for transfer learning in hybrid MT']\n",
      "          Methodologies: ['Combining NMT and SMT with ensemble methods', 'Using transfer learning with pre-trained language models', 'Integrating rule-based and statistical MT approaches']\n",
      "          Evaluation Methods: ['Human evaluation with ranking and preference metrics', 'Automated evaluation with contextualized embeddings', 'BLEU score with linguistic features and n-gram precision']\n",
      "          Applications: ['Real-time translation for social media and online forums', 'Document translation for international business and law', 'Subtitling and closed captions for multimedia content']\n",
      "          ----------------------------------------\n",
      "          Label: multimodal_machine_translation\n",
      "          Description: Using multiple modalities to improve machine translation\n",
      "          Level: 2\n",
      "          Datasets: ['Multimodal dataset for image and text translation', 'Dataset with audio and text for speech-to-text translation', 'Large-scale dataset for video and text translation']\n",
      "          Methodologies: ['Using visual features with NMT models', 'Integrating audio and text features with SMT models', 'Combining multiple modalities with ensemble methods']\n",
      "          Evaluation Methods: ['Human evaluation with ranking and preference metrics', 'Automated evaluation with multimodal embeddings', 'BLEU score with linguistic features and multimodal precision']\n",
      "          Applications: ['Real-time translation for multimedia content', 'Document translation for international business and education', 'Subtitling and closed captions for multimedia content']\n",
      "          ----------------------------------------\n",
      "     ----------------------------------------\n",
      "     Label: question_answering\n",
      "     Description: The task of answering questions based on the content of text.\n",
      "     Level: 1\n",
      "     Datasets: ['A dataset of questions and answers for training', 'A collection of text passages with annotated answers']\n",
      "     Methodologies: ['Information retrieval with keyword matching', 'Deep learning with attention-based models']\n",
      "     Evaluation Methods: ['Accuracy and F1-score for answer extraction', 'Precision and recall for question answering']\n",
      "     Applications: ['Virtual assistants and chatbots', 'Search engines and information retrieval']\n",
      "     ----------------------------------------\n",
      "     Children:\n",
      "          Label: open_domain_question_answering\n",
      "          Description: The task of answering questions without any specific domain or context.\n",
      "          Level: 2\n",
      "          Datasets: ['A large-scale dataset of open-domain questions with answers from various sources.', 'A dataset of open-domain questions with a focus on common sense and world knowledge.']\n",
      "          Methodologies: ['Retrieval-based models', 'Generative models', 'Hybrid models']\n",
      "          Evaluation Methods: ['BLEU score for answer generation', 'ROUGE score for answer ranking', 'Human evaluation for answer relevance']\n",
      "          Applications: ['Virtual assistants', 'Chatbots', 'Search engines']\n",
      "          ----------------------------------------\n",
      "          Label: reading_comprehension\n",
      "          Description: The task of answering questions based on a given text or passage.\n",
      "          Level: 2\n",
      "          Datasets: ['A dataset of news articles with questions and answers.', \"A dataset of children's stories with questions and answers.\"]\n",
      "          Methodologies: ['Attention-based models', 'Graph-based models', 'Memory-augmented models']\n",
      "          Evaluation Methods: ['Exact match score for answer selection', 'F1 score for answer extraction', 'Human evaluation for answer accuracy']\n",
      "          Applications: ['Text summarization', 'Sentiment analysis', 'Information extraction']\n",
      "          ----------------------------------------\n",
      "          Label: conversational_question_answering\n",
      "          Description: The task of answering questions in a conversational setting.\n",
      "          Level: 2\n",
      "          Datasets: ['A dataset of conversations with questions and answers.', 'A dataset of dialogues with questions and answers.']\n",
      "          Methodologies: ['Sequence-to-sequence models', 'Memory-augmented models', 'Graph-based models']\n",
      "          Evaluation Methods: ['Perplexity score for response generation', 'BLEU score for response ranking', 'Human evaluation for response relevance']\n",
      "          Applications: ['Chatbots', 'Virtual assistants', 'Customer service']\n",
      "          ----------------------------------------\n",
      "          Label: visual_question_answering\n",
      "          Description: The task of answering questions based on visual information.\n",
      "          Level: 2\n",
      "          Datasets: ['A dataset of images with questions and answers.', 'A dataset of videos with questions and answers.']\n",
      "          Methodologies: ['Attention-based models', 'Graph-based models', 'Multimodal fusion models']\n",
      "          Evaluation Methods: ['Accuracy score for answer classification', 'F1 score for answer extraction', 'Human evaluation for answer accuracy']\n",
      "          Applications: ['Image captioning', 'Object detection', 'Scene understanding']\n",
      "          ----------------------------------------\n",
      "          Label: multitask_question_answering\n",
      "          Description: The task of answering questions across multiple domains or tasks.\n",
      "          Level: 2\n",
      "          Datasets: ['A dataset of questions and answers across multiple domains.', 'A dataset of tasks with questions and answers.']\n",
      "          Methodologies: ['Multitask learning models', 'Transfer learning models', 'Meta-learning models']\n",
      "          Evaluation Methods: ['Average score across tasks', 'Weighted score across tasks', 'Human evaluation for task-specific performance']\n",
      "          Applications: ['General-purpose AI', 'Transfer learning', 'Meta-learning']\n",
      "          ----------------------------------------\n",
      "     ----------------------------------------\n",
      "     Label: text_generation\n",
      "     Description: The task of generating text based on a prompt or input.\n",
      "     Level: 1\n",
      "     Datasets: ['A dataset of text prompts with corresponding generated text', 'A collection of text passages with annotated styles']\n",
      "     Methodologies: ['Language models with generative adversarial networks', 'Deep learning with variational autoencoders']\n",
      "     Evaluation Methods: ['Perplexity for generated text evaluation', 'BLEU score for text generation quality']\n",
      "     Applications: ['Language translation and generation', 'Chatbots and conversational AI']\n",
      "     ----------------------------------------\n",
      "     Children:\n",
      "          Label: text_generation_from_non_text_data\n",
      "          Description: The task of generating text from non-text data such as images, audio, or video.\n",
      "          Level: 2\n",
      "          Datasets: ['A dataset of images with corresponding captions for training image-to-text models.', 'A dataset of audio recordings with corresponding transcripts for training speech-to-text models.']\n",
      "          Methodologies: ['Multimodal Neural Networks', 'Attention-based Models', 'Generative Adversarial Networks (GANs)']\n",
      "          Evaluation Methods: ['A metric to evaluate the relevance and accuracy of generated text.', 'A human evaluation metric to assess the coherence and fluency of generated text.']\n",
      "          Applications: ['Image and video captioning systems.', 'Speech-to-text systems for voice assistants and transcription services.']\n",
      "          ----------------------------------------\n",
      "          Label: style_transfer_and_paraphrasing\n",
      "          Description: The task of transferring the style of one piece of text to another while preserving the original content.\n",
      "          Level: 2\n",
      "          Datasets: ['A dataset of text with corresponding style labels for training style transfer models.', 'A dataset of text with corresponding paraphrases for training paraphrasing models.']\n",
      "          Methodologies: ['Sequence-to-Sequence Models', 'Attention-based Models', 'Generative Adversarial Networks (GANs)']\n",
      "          Evaluation Methods: ['A metric to evaluate the style similarity between the original and transferred text.', 'A human evaluation metric to assess the coherence and fluency of transferred text.']\n",
      "          Applications: ['Text rewriting and editing tools.', 'Chatbots and conversational AI systems with personalized tone and style.']\n",
      "          ----------------------------------------\n",
      "     ----------------------------------------\n",
      "     Label: sentiment_analysis\n",
      "     Description: The task of determining the sentiment or emotional tone of text.\n",
      "     Level: 1\n",
      "     Datasets: ['A dataset of movie reviews with sentiment labels (positive, negative, neutral)', 'A dataset of labeled text with sentiment annotations', 'A dataset of tweets with sentiment labels (positive, negative, neutral) related to a specific event', 'A collection of product reviews with sentiment ratings']\n",
      "     Methodologies: ['Deep learning with convolutional neural networks (CNN) or recurrent neural networks (RNN)', 'Supervised learning with machine learning algorithms (e.g. SVM, Random Forest)', 'Supervised learning with machine learning algorithms', 'Deep learning with convolutional neural networks']\n",
      "     Evaluation Methods: ['Accuracy and F1-score for sentiment classification', 'Mean squared error (MSE) or mean absolute error (MAE) for sentiment regression', 'Accuracy, precision, recall, F1-score for sentiment classification', 'Precision and recall for sentiment detection']\n",
      "     Applications: ['Social media monitoring for brand reputation management', 'Customer feedback analysis and sentiment monitoring', 'Product review analysis for e-commerce websites', 'Opinion mining and sentiment analysis']\n",
      "     ----------------------------------------\n",
      "     Children:\n",
      "          Label: aspect_based_sentiment_analysis\n",
      "          Description: Identify sentiment towards specific aspects or features of a product or service\n",
      "          Level: 2\n",
      "          Datasets: ['AspectOpinionDataset: A dataset of customer reviews with annotated aspects and opinions', 'AspectSentimentDataset: A dataset of product reviews with sentiment labels for specific aspects']\n",
      "          Methodologies: ['Rule-based approach using part-of-speech tagging and dependency parsing', 'Deep learning approach using convolutional neural networks (CNNs) and recurrent neural networks (RNNs)']\n",
      "          Evaluation Methods: ['Aspect-level sentiment accuracy: Evaluate the accuracy of sentiment classification for each aspect', 'Aspect-level sentiment F1-score: Evaluate the F1-score of sentiment classification for each aspect']\n",
      "          Applications: ['Product review analysis: Analyze customer reviews to identify strengths and weaknesses of a product', 'Customer feedback analysis: Analyze customer feedback to identify areas for improvement']\n",
      "          ----------------------------------------\n",
      "          Label: multimodal_sentiment_analysis\n",
      "          Description: Analyze sentiment from multiple sources, such as text, images, and audio\n",
      "          Level: 2\n",
      "          Datasets: ['Multimodal Sentiment Dataset: A dataset of videos with annotated sentiment labels', 'Multimodal Opinion Dataset: A dataset of product reviews with images and text']\n",
      "          Methodologies: ['Early fusion approach: Combine features from multiple modalities early in the analysis process', 'Late fusion approach: Combine features from multiple modalities late in the analysis process']\n",
      "          Evaluation Methods: ['Multimodal sentiment accuracy: Evaluate the accuracy of sentiment classification using multiple modalities', 'Multimodal sentiment F1-score: Evaluate the F1-score of sentiment classification using multiple modalities']\n",
      "          Applications: ['Social media analysis: Analyze sentiment from social media posts with images and text', 'Customer service analysis: Analyze sentiment from customer service interactions with audio and text']\n",
      "          ----------------------------------------\n",
      "          Label: sentiment_analysis_for_low_resource_languages\n",
      "          Description: Develop sentiment analysis models for languages with limited resources\n",
      "          Level: 2\n",
      "          Datasets: ['Low Resource Sentiment Dataset: A dataset of text with sentiment labels for a low-resource language', 'Multilingual Sentiment Dataset: A dataset of text with sentiment labels for multiple languages']\n",
      "          Methodologies: ['Transfer learning approach: Use pre-trained models for high-resource languages and fine-tune for low-resource languages', 'Multilingual approach: Train a single model on multiple languages']\n",
      "          Evaluation Methods: ['Sentiment accuracy for low-resource languages: Evaluate the accuracy of sentiment classification for low-resource languages', 'Sentiment F1-score for low-resource languages: Evaluate the F1-score of sentiment classification for low-resource languages']\n",
      "          Applications: ['Language translation: Improve language translation by incorporating sentiment analysis', 'Cross-lingual sentiment analysis: Analyze sentiment across multiple languages']\n",
      "          ----------------------------------------\n",
      "          Label: explainable_sentiment_analysis\n",
      "          Description: Develop models that provide insights into the sentiment analysis process\n",
      "          Level: 2\n",
      "          Datasets: ['Explainable Sentiment Dataset: A dataset of text with annotated explanations for sentiment labels', 'Attention-based Sentiment Dataset: A dataset of text with attention weights for sentiment analysis']\n",
      "          Methodologies: ['Attention-based approach: Use attention mechanisms to highlight important words or phrases for sentiment analysis', 'Model interpretability approach: Use techniques such as feature importance and partial dependence plots to interpret the model']\n",
      "          Evaluation Methods: ['Explainability metrics: Evaluate the explainability of the model using metrics such as faithfulness and stability', 'Sentiment accuracy with explanations: Evaluate the accuracy of sentiment classification with explanations']\n",
      "          Applications: ['Model debugging: Use explainability techniques to debug and improve the model', \"Model transparency: Provide insights into the model's decision-making process for transparency and accountability\"]\n",
      "          ----------------------------------------\n",
      "     ----------------------------------------\n",
      "     Label: topic_modeling\n",
      "     Description: The task of discovering underlying topics or themes in a collection of text.\n",
      "     Level: 1\n",
      "     Datasets: ['A dataset of research papers with topic labels (e.g. machine learning, natural language processing)', 'A dataset of news articles from various sources with topic labels (e.g. politics, sports, entertainment)', 'A collection of news articles with topic labels', 'A dataset of text documents with annotated topics']\n",
      "     Methodologies: ['Non-negative matrix factorization with topic modeling', 'Latent Dirichlet Allocation (LDA) for topic modeling', 'Non-negative Matrix Factorization (NMF) for topic modeling', 'Latent Dirichlet allocation with Gibbs sampling']\n",
      "     Evaluation Methods: ['Topic coherence score for topic quality', 'Perplexity for topic model evaluation', 'Perplexity score for topic modeling', 'Topic coherence score using word embeddings (e.g. Word2Vec, GloVe)']\n",
      "     Applications: ['Information retrieval for document search', 'Information retrieval and document clustering', 'Text summarization for news articles or research papers', 'Text classification and topic modeling']\n",
      "     ----------------------------------------\n",
      "     Children:\n",
      "          Label: unsupervised_topic_modeling\n",
      "          Description: Discovering hidden topics in a corpus without labeled data\n",
      "          Level: 2\n",
      "          Datasets: ['A large-scale dataset of news articles for topic modeling evaluation', 'A dataset of social media posts for analyzing topic evolution over time']\n",
      "          Methodologies: ['Latent Dirichlet Allocation (LDA)', 'Non-Negative Matrix Factorization (NMF)', 'Gaussian Mixture Model (GMM)']\n",
      "          Evaluation Methods: ['Perplexity-based evaluation for topic model quality', 'Topic coherence score using word embeddings', 'Human evaluation of topic interpretability']\n",
      "          Applications: ['Information retrieval and filtering', 'Text summarization and clustering', 'Opinion mining and sentiment analysis']\n",
      "          ----------------------------------------\n",
      "          Label: supervised_topic_modeling\n",
      "          Description: Learning topics from labeled data for specific tasks\n",
      "          Level: 2\n",
      "          Datasets: ['A dataset of labeled documents for topic modeling-based text classification', 'A dataset of annotated topics for evaluating supervised topic modeling']\n",
      "          Methodologies: ['Supervised Latent Dirichlet Allocation (sLDA)', 'Label Regularized Latent Dirichlet Allocation (L-LDA)', 'Discriminative Topic Model (DTM)']\n",
      "          Evaluation Methods: ['Classification accuracy for topic modeling-based text classification', 'Topic-based clustering evaluation using labeled data', 'Evaluation of topic model interpretability using labeled data']\n",
      "          Applications: ['Text classification and clustering', 'Sentiment analysis and opinion mining', 'Information retrieval and filtering']\n",
      "          ----------------------------------------\n",
      "          Label: multimodal_topic_modeling\n",
      "          Description: Modeling topics from multimodal data (text, images, etc.)\n",
      "          Level: 2\n",
      "          Datasets: ['A dataset of multimodal documents (text and images) for topic modeling', 'A dataset of social media posts with images and text for multimodal topic analysis']\n",
      "          Methodologies: ['Multimodal Latent Dirichlet Allocation (mLDA)', 'Multimodal Non-Negative Matrix Factorization (mNMF)', 'Deep multimodal topic modeling using neural networks']\n",
      "          Evaluation Methods: ['Multimodal topic coherence score using word and image embeddings', 'Evaluation of multimodal topic model interpretability', 'Multimodal topic-based clustering evaluation']\n",
      "          Applications: ['Multimodal information retrieval and filtering', 'Multimodal text and image summarization', 'Multimodal opinion mining and sentiment analysis']\n",
      "          ----------------------------------------\n",
      "          Label: dynamic_topic_modeling\n",
      "          Description: Modeling topics that evolve over time\n",
      "          Level: 2\n",
      "          Datasets: ['A dataset of news articles for analyzing topic evolution over time', 'A dataset of social media posts for dynamic topic modeling']\n",
      "          Methodologies: ['Dynamic Latent Dirichlet Allocation (dLDA)', 'Dynamic Non-Negative Matrix Factorization (dNMF)', 'State-space models for dynamic topic modeling']\n",
      "          Evaluation Methods: ['Evaluation of topic evolution using time-stamped data', 'Dynamic topic coherence score using word embeddings', 'Human evaluation of dynamic topic model interpretability']\n",
      "          Applications: ['Time-series analysis and forecasting', 'Dynamic information retrieval and filtering', 'Dynamic opinion mining and sentiment analysis']\n",
      "          ----------------------------------------\n",
      "     ----------------------------------------\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "root.display(0, indent_multiplier=5, simple=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: Node(label=natural_language_processing, description=None, level=0),\n",
       " 1: Node(label=text_classification, description=The task of assigning predefined categories to text based on its content., level=1),\n",
       " 2: Node(label=language_modeling, description=The task of predicting the next word in a sequence of text given the context., level=1),\n",
       " 3: Node(label=named_entity_recognition, description=The task of identifying and categorizing named entities in text into predefined categories., level=1),\n",
       " 4: Node(label=machine_translation, description=The task of translating text from one language to another., level=1),\n",
       " 5: Node(label=question_answering, description=The task of answering questions based on the content of a given text., level=1),\n",
       " 6: Node(label=text_summarization, description=The task of summarizing a long piece of text into a shorter summary., level=1),\n",
       " 7: Node(label=dialogue_systems, description=The task of generating responses to user input in a conversational setting., level=1),\n",
       " 8: Node(label=sentiment_analysis, description=The task of determining the sentiment or emotional tone of a piece of text., level=1),\n",
       " 9: Node(label=sentiment_analysis, description=Determining the emotional tone or sentiment behind a piece of text., level=2),\n",
       " 10: Node(label=topic_modeling, description=Identifying underlying topics or themes in a large corpus of text., level=2),\n",
       " 11: Node(label=named_entity_recognition, description=Identifying and categorizing named entities in text, such as people, places, and organizations., level=2),\n",
       " 12: Node(label=text_classification_for_low_resource_languages, description=Classifying text in low-resource languages with limited training data., level=2),\n",
       " 13: Node(label=multimodal_text_classification, description=Classifying text with multimodal inputs, such as images or audio., level=2),\n",
       " 14: Node(label=language_understanding, description=The ability of a model to comprehend the meaning of text, including entities, relationships, and context., level=2),\n",
       " 15: Node(label=language_generation, description=The ability of a model to generate coherent and natural-sounding text, including text summarization, machine translation, and chatbots., level=2),\n",
       " 16: Node(label=language_translation, description=The ability of a model to translate text from one language to another, including machine translation and cross-lingual language understanding., level=2),\n",
       " 17: Node(label=multimodal_language_modeling, description=The ability of a model to process and generate text and other modalities, such as images and audio, including multimodal machine translation and multimodal dialogue systems., level=2),\n",
       " 18: Node(label=named_entity_disambiguation, description=Identifying the correct entity from a set of candidates based on the context., level=2),\n",
       " 19: Node(label=named_entity_recognition_in_low_resource_languages, description=Developing NER models for languages with limited annotated data., level=2),\n",
       " 20: Node(label=named_entity_recognition_in_noisy_text, description=Developing NER models that can handle noisy or unstructured text data., level=2),\n",
       " 21: Node(label=named_entity_normalization, description=Normalizing entity mentions to a standard form., level=2),\n",
       " 22: Node(label=named_entity_relation_extraction, description=Extracting relationships between entities in text., level=2),\n",
       " 23: Node(label=neural_machine_translation, description=Using neural networks to improve machine translation, level=2),\n",
       " 24: Node(label=statistical_machine_translation, description=Using statistical models to improve machine translation, level=2),\n",
       " 25: Node(label=hybrid_machine_translation, description=Combining multiple approaches for machine translation, level=2),\n",
       " 26: Node(label=low_resource_machine_translation, description=Improving machine translation for low-resource languages, level=2),\n",
       " 27: Node(label=multimodal_machine_translation, description=Using multimodal data for machine translation, level=2),\n",
       " 28: Node(label=extractive_question_answering, description=Extractive question answering involves identifying the relevant information in a given text to answer a question., level=2),\n",
       " 29: Node(label=generative_question_answering, description=Generative question answering involves generating answers to questions based on the context, without relying on explicit extraction from the text., level=2),\n",
       " 30: Node(label=open_domain_question_answering, description=Open-domain question answering involves answering questions that require knowledge from a wide range of topics and domains., level=2),\n",
       " 31: Node(label=visual_question_answering, description=Visual question answering involves answering questions about images or videos., level=2),\n",
       " 32: Node(label=multimodal_question_answering, description=Multimodal question answering involves answering questions that require information from multiple sources, such as text, images, and audio., level=2),\n",
       " 33: Node(label=extractive_summarization, description=Extractive summarization involves selecting the most relevant sentences or phrases from the original text to create a summary., level=2),\n",
       " 34: Node(label=abstractive_summarization, description=Abstractive summarization involves generating a summary that is not necessarily present in the original text, but rather a paraphrased version of it., level=2),\n",
       " 35: Node(label=query-focused_summarization, description=Query-focused summarization involves generating a summary that is relevant to a specific query or topic., level=2),\n",
       " 36: Node(label=multi-document_summarization, description=Multi-document summarization involves generating a summary from multiple documents., level=2),\n",
       " 37: Node(label=task_oriented_dialogue_systems, description=Dialogue systems designed to accomplish a specific task, such as booking a flight or making a reservation., level=2),\n",
       " 38: Node(label=conversational_dialogue_systems, description=Dialogue systems designed to engage in natural-sounding conversations, often without a specific task in mind., level=2),\n",
       " 39: Node(label=emotional_dialogue_systems, description=Dialogue systems designed to recognize and respond to emotions, empathizing with users., level=2),\n",
       " 40: Node(label=multimodal_dialogue_systems, description=Dialogue systems that incorporate multiple modalities, such as text, speech, and vision., level=2),\n",
       " 41: Node(label=aspect_based_sentiment_analysis, description=Identify sentiment towards specific aspects or features of a product or service, level=2),\n",
       " 42: Node(label=multimodal_sentiment_analysis, description=Analyze sentiment from multiple sources such as text, images, and audio, level=2),\n",
       " 43: Node(label=sentiment_analysis_for_low_resource_languages, description=Develop sentiment analysis models for languages with limited resources, level=2),\n",
       " 44: Node(label=explainable_sentiment_analysis, description=Develop models that provide insights into the sentiment analysis process, level=2)}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id2node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['Supervised learning with conditional random fields',\n",
       "  'Deep learning with recurrent neural networks'],\n",
       " ['Supervised learning with conditional random fields',\n",
       "  'Unsupervised learning with clustering algorithms'])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id2node[3].methodologies, id2node[11].methodologies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
