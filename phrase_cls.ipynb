{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0,1,6,7\"\n",
    "os.environ['HF_HOME'] = '/shared/data3/pk36/.cache'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "!export HF_HOME=/shared/data3/pk36/.cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7b116aa8c2a40478d8d1df582d56d42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "/home/pk36/inverse_knowledge_search/inverse/lib/python3.8/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from collections import Counter\n",
    "from taxonomy import Taxonomy, Paper\n",
    "from utils import filter_phrases, cosine_similarity_embeddings, average_with_harmonic_series, rank_by_significance, rank_by_discriminative_significance, rank_by_relation\n",
    "from model_definitions import sentence_model\n",
    "import subprocess\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import pickle as pk\n",
    "import hdbscan\n",
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args:\n",
    "    def __init__(self):\n",
    "        self.track = \"Question Answering\"\n",
    "        self.dim = \"Methodology\"\n",
    "        self.dataset = \"qa_papers\"\n",
    "        self.input_file = \"datasets/phrase_emnlp.txt\"\n",
    "        self.iters = 4\n",
    "        self.model = \"bert_full_ft\"\n",
    "        self.override = True\n",
    "\n",
    "args = Args()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pre-Processing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datasets/phrase_emnlp.txt\n"
     ]
    }
   ],
   "source": [
    "print(args.input_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m===Corpus Pre-processing===\u001b[m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 287/287 [00:08<00:00, 33.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m===Compilation===\u001b[m\n",
      "\u001b[32m===Tokenization===\u001b[m\n",
      "Current step: Tokenizing input file...\u001b[0K\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "real\t0m2.342s\n",
      "user\t0m19.168s\n",
      "sys\t0m1.422s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected Language: EN\u001b[0K\n",
      "Current step: Tokenizing wikipedia phrases...\u001b[0K\n",
      "No provided expert labels.\u001b[0K\n",
      "\u001b[32m===Part-Of-Speech Tagging===\u001b[m\n",
      "Current step: Merging...\u001b[0Ks...\u001b[0K\n",
      "\u001b[32m===AutoPhrasing===\u001b[m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "=== Current Settings ===\n",
      "Iterations = 2\n",
      "Minimum Support Threshold = 10\n",
      "Maximum Length Threshold = 6\n",
      "POS-Tagging Mode Enabled\n",
      "Number of threads = 10\n",
      "Labeling Method = DPDN\n",
      "\tAuto labels from knowledge bases\n",
      "\tMax Positive Samples = -1\n",
      "=======\n",
      "Loading data...\n",
      "# of total tokens = 2088439\n",
      "max word token id = 66199\n",
      "# of documents = 287\n",
      "# of distinct POS tags = 57\n",
      "Mining frequent phrases...\n",
      "selected MAGIC = 66221\n",
      "# of frequent phrases = 87032\n",
      "Extracting features...\n",
      "Constructing label pools...\n",
      "\tThe size of the positive pool = 3873\n",
      "\tThe size of the negative pool = 82754\n",
      "# truth patterns = 75189\n",
      "Estimating Phrase Quality...\n",
      "Segmenting...\n",
      "Rectifying features...\n",
      "Estimating Phrase Quality...\n",
      "Segmenting...\n",
      "Dumping results...\n",
      "Done.\n",
      "\n",
      "real\t0m6.444s\n",
      "user\t0m31.714s\n",
      "sys\t0m2.139s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m===Saving Model and Results===\u001b[m\n",
      "\u001b[32m===Generating Output===\u001b[m\n",
      "\u001b[32m===Tokenization===\u001b[m\n",
      "Current step: Tokenizing input file...\u001b[0K\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "real\t0m2.087s\n",
      "user\t0m17.306s\n",
      "sys\t0m0.813s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected Language: EN\u001b[0K\n",
      "\u001b[32m===Part-Of-Speech Tagging===\u001b[m\n",
      "Current step: Merging...\u001b[0Ks...\u001b[0K\n",
      "\u001b[32m===Phrasal Segmentation===\u001b[m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "=== Current Settings ===\n",
      "Segmentation Model Path = models/NEW/segmentation.model\n",
      "After the phrasal segmentation, only following phrases will be highlighted with <phrase> and </phrase>\n",
      "\tQ(multi-word phrases) >= 0.700000\n",
      "\tQ(single-word phrases) >= 1.000000\n",
      "=======\n",
      "POS guided model loaded.\n",
      "# of loaded patterns = 21920\n",
      "# of loaded truth patterns = 79062\n",
      "POS transition matrix loaded\n",
      "Phrasal segmentation finished.\n",
      "   # of total highlighted quality phrases = 161016\n",
      "   # of total processed sentences = 316830\n",
      "   avg highlights per sentence = 0.508209\n",
      "\n",
      "real\t0m2.945s\n",
      "user\t0m2.778s\n",
      "sys\t0m0.040s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m===Generating Output===\u001b[m\n",
      "\u001b[32m===Segmented Corpus Post-processing===\u001b[m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "287it [00:00, 1900.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phrase segmented corpus written to ../datasets/qa_papers/phrase_qa_papers.txt\n"
     ]
    }
   ],
   "source": [
    "if args.override or (not os.path.exists(f\"datasets/{args.dataset}/phrase_{args.dataset}.txt\")):\n",
    "    # pre-process\n",
    "    os.chdir(\"./preprocessing\")\n",
    "    subprocess.check_call(['./auto_phrase.sh', args.dataset])\n",
    "    os.chdir(\"../\")\n",
    "else:\n",
    "    print(\"already pre-processed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Base Taxonomy Construction & Reading in Papers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'datasets/phrase_emnlp.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[64], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# input: track, dimension -> get base taxonomy (2 levels) -> Class Tree, Class Node (description, seed words)\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m taxo \u001b[38;5;241m=\u001b[39m \u001b[43mTaxonomy\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrack\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput_file\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m base_taxo \u001b[38;5;241m=\u001b[39m taxo\u001b[38;5;241m.\u001b[39mbuildBaseTaxo(levels\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, num_terms\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(base_taxo)\n",
      "File \u001b[0;32m~/Comparative-Summarization/taxoadapt/taxonomy.py:359\u001b[0m, in \u001b[0;36mTaxonomy.__init__\u001b[0;34m(self, track, dimen, input_file)\u001b[0m\n\u001b[1;32m    357\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m input_file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    358\u001b[0m     \u001b[38;5;28mid\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m--> 359\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43minput_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m    360\u001b[0m         papers \u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39mread()\u001b[38;5;241m.\u001b[39mstrip()\u001b[38;5;241m.\u001b[39msplitlines()\n\u001b[1;32m    361\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m papers:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'datasets/phrase_emnlp.txt'"
     ]
    }
   ],
   "source": [
    "# input: track, dimension -> get base taxonomy (2 levels) -> Class Tree, Class Node (description, seed words)\n",
    "\n",
    "taxo = Taxonomy(args.track, args.dim, args.input_file)\n",
    "base_taxo = taxo.buildBaseTaxo(levels=1, k=5, num_terms=20)\n",
    "\n",
    "print(base_taxo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Types of Methodology Proposed in Text Classification Research Papers'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "taxo.root.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# format the input keywords file for seetopic -> get phrases -> filter using LLM\n",
    "dir_name = (args.track + \"_\" + args.dim).lower().replace(\" \", \"_\")\n",
    "\n",
    "if not os.path.exists(f\"SeeTopic/{dir_name}\"):\n",
    "    os.makedirs(f\"SeeTopic/{dir_name}\")\n",
    "\n",
    "with open(f\"SeeTopic/{dir_name}/{dir_name}.txt\", \"w\") as f:\n",
    "    for p in taxo.collection:\n",
    "        f.write(f\"{p.text}\\n\")\n",
    "\n",
    "\n",
    "## get first level of children\n",
    "children_with_terms = taxo.root.getChildren(terms=True)\n",
    "with open(f\"SeeTopic/{dir_name}/keywords_0.txt\", \"w\") as f:\n",
    "    for idx, c in enumerate(children_with_terms):\n",
    "        str_c = \",\".join(c[1])\n",
    "        f.write(f\"{idx}:{c[0]},{str_c}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Phrase Mining for Level 1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m===Get PLM Embeddings===\u001b[m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertModel were not initialized from the model checkpoint at /home/pk36/Comparative-Summarization/bert_full_ft/checkpoint-8346/ and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####### CONSTRUCTING AND TOKENIZING VOCAB #######\n",
      "####### COMPUTING STATIC EMBEDDINGS #######\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5349/5349 [00:41<00:00, 130.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m===Iter 0: PLM Module===\u001b[m\n",
      "\u001b[32m===Iter 1: PLM Module===\u001b[m\n",
      "\u001b[32m===Iter 1: Local Module===\u001b[m\n",
      "make: 'cate' is up to date.\n",
      "Starting training using file ../text_classification_methodology/text_classification_methodology.txt\n",
      "Reading topics from file text_classification_methodology_1/keywords.txt\n",
      "Vocab size: 5313\n",
      "Words in train file: 186360\n",
      "Read 5 topics\n",
      "naive_bayes\tdecision_trees\trandom_forest\t\n",
      "non_negative_matrix_factorization\tlatent_semantic_analysis\ttopic_modeling\t\n",
      "self_training\tco_training\ttransfer_learning\t\n",
      "convolutional_neural_networks\trecurrent_neural_networks\tlong_short_term_memory\t\n",
      "bagging\tstacking\tvoting\t\n",
      "Pre-training for 2 epochs, in total 2 + 10 = 12 epochs\n",
      "Topic mining results written to file text_classification_methodology_1/res_cate.txt\n",
      "\u001b[32m===Iter 1: Ensemble===\u001b[m\n",
      "\u001b[32m===Iter 2: PLM Module===\u001b[m\n",
      "\u001b[32m===Iter 2: Local Module===\u001b[m\n",
      "make: 'cate' is up to date.\n",
      "Starting training using file ../text_classification_methodology/text_classification_methodology.txt\n",
      "Reading topics from file text_classification_methodology_2/keywords.txt\n",
      "Vocab size: 5313\n",
      "Words in train file: 186360\n",
      "Read 5 topics\n",
      "supervised_learning\tnaive_bayes\tdecision_trees\trandom_forest\tsupport_vector_machines\tlogistic_regression\t\n",
      "unsupervised_learning\tnon_negative_matrix_factorization\tlatent_semantic_analysis\ttopic_modeling\tclassic_feature_selection\tclustering_algorithm\t\n",
      "semi_supervised_learning\tself_training\tco_training\ttransfer_learning\tmulti_task_learning\tfew_shot_learning\t\n",
      "deep_learning\tconvolutional_neural_networks\trecurrent_neural_networks\tlong_short_term_memory\tattention_mechanism\ttransformers\t\n",
      "bagging\tstacking\tvoting\trandom_forest\tgradient_boosting\tcross_validation\t\n",
      "Pre-training for 2 epochs, in total 2 + 10 = 12 epochs\n",
      "Topic mining results written to file text_classification_methodology_2/res_cate.txt\n",
      "\u001b[32m===Iter 2: Ensemble===\u001b[m\n",
      "\u001b[32m===Iter 3: PLM Module===\u001b[m\n",
      "\u001b[32m===Iter 3: Local Module===\u001b[m\n",
      "make: 'cate' is up to date.\n",
      "Starting training using file ../text_classification_methodology/text_classification_methodology.txt\n",
      "Reading topics from file text_classification_methodology_3/keywords.txt\n",
      "Vocab size: 5313\n",
      "Words in train file: 186360\n",
      "Read 5 topics\n",
      "supervised_learning\tnaive_bayes\tdecision_trees\trandom_forest\tsupport_vector_machines\tlogistic_regression\tk_nearest_neighbors\tgradient_boosting\tneural_networks\t\n",
      "unsupervised_learning\tnon_negative_matrix_factorization\tlatent_semantic_analysis\ttopic_modeling\tclustering_algorithm\tclassic_feature_selection\tself_organizing_map\tsimilarity_measure\tfeature_transformation\t\n",
      "semi_supervised_learning\tself_training\tco_training\ttransfer_learning\tmulti_task_learning\tfew_shot_learning\tactive_learning\tcurriculum_learning\tmeta_learning\t\n",
      "deep_learning\tconvolutional_neural_networks\trecurrent_neural_networks\tlong_short_term_memory\tattention_mechanism\ttransformers\tword_embeddings\tlanguage_models\tpre_trained_word_embeddings\t\n",
      "bagging\tstacking\tvoting\trandom_forest\tgradient_boosting\tcross_validation\trandom_forests\tensemble_learning\tbase_learners\t\n",
      "Pre-training for 2 epochs, in total 2 + 10 = 12 epochs\n",
      "Topic mining results written to file text_classification_methodology_3/res_cate.txt\n",
      "\u001b[32m===Iter 3: Ensemble===\u001b[m\n",
      "\u001b[32m===Iter 4: PLM Module===\u001b[m\n",
      "\u001b[32m===Iter 4: Local Module===\u001b[m\n",
      "make: 'cate' is up to date.\n",
      "Starting training using file ../text_classification_methodology/text_classification_methodology.txt\n",
      "Reading topics from file text_classification_methodology_4/keywords.txt\n",
      "Vocab size: 5313\n",
      "Words in train file: 186360\n",
      "Read 5 topics\n",
      "supervised_learning\tnaive_bayes\tdecision_trees\trandom_forest\tsupport_vector_machines\tlogistic_regression\tk_nearest_neighbors\tgradient_boosting\tneural_networks\tfeature_selection\tfeature_engineering\tdata_augmentation\t\n",
      "unsupervised_learning\tnon_negative_matrix_factorization\tlatent_semantic_analysis\ttopic_modeling\tclustering_algorithm\tsimilarity_measure\tself_organizing_map\tclassic_feature_selection\tfeature_transformation\tstring_vectors\tfaceted_classification\tnumerical_vectors\t\n",
      "semi_supervised_learning\tself_training\tco_training\ttransfer_learning\tmulti_task_learning\tfew_shot_learning\tactive_learning\tcurriculum_learning\tmeta_learning\tmeta-learning\ttraining_examples\tstance_classification\t\n",
      "deep_learning\tconvolutional_neural_networks\trecurrent_neural_networks\tlong_short_term_memory\tattention_mechanism\ttransformers\tword_embeddings\tlanguage_models\tpre_trained_word_embeddings\tfine_tuning\ttransfer_learning\tmulti_task_learning\t\n",
      "bagging\tstacking\tvoting\trandom_forest\tgradient_boosting\tcross_validation\tbase_learners\trandom_forests\tensemble_learning\tcluster_based\tensemble_models\tensemble_techniques\t\n",
      "Pre-training for 2 epochs, in total 2 + 10 = 12 epochs\n",
      "Topic mining results written to file text_classification_methodology_4/res_cate.txt\n",
      "\u001b[32m===Iter 4: Ensemble===\u001b[m\n"
     ]
    }
   ],
   "source": [
    "os.chdir(\"./SeeTopic\")\n",
    "subprocess.check_call(['./seetopic.sh', dir_name, str(args.iters), args.model])\n",
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2emb = {}\n",
    "with open(f'./SeeTopic/{dir_name}/embedding_{args.model}.txt') as fin:\n",
    "\tfor line in fin:\n",
    "\t\tdata = line.strip().split()\n",
    "\t\tif len(data) != 769:\n",
    "\t\t\tcontinue\n",
    "\t\tword = data[0]\n",
    "\t\temb = np.array([float(x) for x in data[1:]])\n",
    "\t\temb = emb / np.linalg.norm(emb)\n",
    "\t\tword2emb[word] = emb\n",
    "\n",
    "taxo.word2emb = word2emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(os.path.join(f'SeeTopic/{dir_name}', 'static_emb.pk')):\n",
    "\twith open(os.path.join(f'SeeTopic/{dir_name}', 'static_emb.pk'), \"rb\") as f:\n",
    "\t\tsaved_emb = pk.load(f)\n",
    "\t\tstatic_emb = saved_emb[\"static_emb\"]\n",
    "\t\ttoken_lens = saved_emb[\"token_lens\"]\n",
    "\t\ttokenized_sents = saved_emb[\"tokenized_sents\"]\n",
    "\t\ttokenized_docs = saved_emb[\"tokenized_docs\"]\n",
    "\n",
    "\tfor p_id, paper in enumerate(taxo.collection):\n",
    "\t\tpaper.sentences = tokenized_docs[p_id]\n",
    "\t\tpaper.tokenized = tokenized_sents[p_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[supervised_learning,\n",
       " unsupervised_learning,\n",
       " semi_supervised_learning,\n",
       " deep_learning,\n",
       " ensemble_methods]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "taxo.static_emb = static_emb\n",
    "taxo.root.children"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "supervised_learning_filtering_explanation:'supervised_learning' is redundant and 'naive_bayes', 'decision_trees', 'random_forest','support_vector_machines', 'logistic_regression', 'k_nearest_neighbors', 'gradient_boosting', 'neural_networks', 'feature_selection', 'feature_engineering', 'data_augmentation', 'cross_validation', 'bagging','stacking', 'voting', 'feature_space', 'capsule_network', 'projection_method', 'knn', 'feature_weighting', 'dimensionality_reduction', 'tc', 'text_categorization', 'feature_representations', 'weights','snad', 'alleviate','multi-grained','statistical_methods', 'ontology-based', 'tackling', 'higher_education', 'epat-bert', 'document-level', 'aspect-level_sentiment_classification', 'feature_mapping', 'climate_change_denial', 'digitalization', 'classification_algorithms', 'commentary', 'feature_vectors','specialized', 'parameterization', 'arises', 'tried', 'domain_knowledge', 'feature_weights', 'conceptum','mlm', 'feature_extraction', 'external','maintained', 'bug_triaging', 'numerical_features','si-gcn','maximum_entropy', 'experiments_prove', 'data_mining', 'feature_weight', 'ambiguities', 'feature_vector', 'english_language', 'pseudo', 'optimization_problem', 'catastrophic_forgetting', 'dqd','re', 'error_propagation', 'department', 'higher-order', 'bivalency', 'feature_values', 'albert', 'accumulation','multi-channel', 'aim', 'generalization', 'attention_network','multi-lingual', 'genre', 'topic_models', 'existing_works', 'administrative', 'user_experience', 'allowed','regularization', 'automatically_extract', 'great_progress','sufficiently','memes', 'feature_reduction','suffers', 'ega', 'entity', 'drifting', 'er-hg', 'genetic_algorithm', 'knowledge_base', 'expert_knowledge', 'thesis', 'weapon','search_engines', 'cross_language' were filtered because they are irrelevant to'supervised_learning' or can be subtopics of other parent topics.\n",
      "supervised_learning_filtered: ['naive_bayes', 'decision_trees', 'random_forest','support_vector_machines', 'logistic_regression', 'k_nearest_neighbors', 'gradient_boosting', 'neural_networks']\n",
      "---\n",
      "---\n",
      "unsupervised_learning_filtering_explanation: 'unsupervised_learning', 'unsupervised_learning', 'bee', 'road', 'particle','swarm', 'engine', 'preserved','microblog', 'pathways' were filtered because they are irrelevant to 'unsupervised_learning' or can be subtopics of other parent topics like'supervised_learning','semi_supervised_learning', 'deep_learning', and 'ensemble_methods'.\n",
      "unsupervised_learning_filtered: ['non_negative_matrix_factorization', 'latent_semantic_analysis', 'topic_modeling','similarity_measure', 'clustering_algorithm','string_vectors', 'faceted_classification','self_organizing_map', 'numerical_vectors', 'feature_transformation', 'classic_feature_selection','string_vector', 'dependency_graph', 'weight_matrix', 'gibbs_sampling','supervised_topic_model','sentence_representation','vectorization', '1d-som', 'orthogonality', 'feature_representation', 'hownet', 'tokenization', 'auto-tagging', 'pattern_matching', 'latent_semantic_indexing','string_matching', 'rough_set', 'term_distribution', 'paragraphs', 'neighboring', 'cbr', 'grouping','misl', 'text_representation', 'calculating', 'term_weighting', 'case-based_reasoning', 'key_concepts', 'automatically_constructed', 'text_generation', 'transformed','som', 'implied', 'nonparametric','smoothing', 'gene_expression', 'knowledge-based', 'thereafter', 'word_vectors','sparseness', 'textural', 'gini_index','sharpness', 'text_mining', 'rough_sets','sentence_similarity','simulated_annealing', 'accidentology', 'word_vector', 'characterizes','supervised_term_weighting', 'co-occurrence', 'directly_affects', 'term_weighting_method', 'local_binary_pattern', 'essence','semantic-interactive', 'generalization_ability','readability_assessment', 'projection','multi-layered', 'vsm', 'text_classification', 'approximation', 'assignment','sequential_minimization', 'posteriori', 'binary_classification', 'latent_dirichlet_allocation', 'cdw', 'permits', 'icvs', 'transforming', 'anomaly_detection','social_event', 'library', 'term_frequency_-_inverse_document_frequency', 'constriction', 'accomplish', 'twd']\n",
      "---\n",
      "---\n",
      "semi_supervised_learning_filtering_explanation:'semi_supervised_learning','semi_supervised_learning','meta-learning','meta-learning','stance_classification','supervised_learning', 'out-of-distribution', 'deep_learning','supervised_learning', 'unsupervised_learning', 'deep_learning', 'ensemble_methods' were filtered because they are either irrelevant to'semi_supervised_learning', or they can also be parents of'semi_supervised_learning', or they are subtopics of other parent topics.\n",
      "semi_supervised_learning_filtered: ['self_training', 'co_training', 'transfer_learning','multi_task_learning', 'few_shot_learning', 'active_learning', 'curriculum_learning', 'contrastive_learning','representation_learning', 'rule_induction', 'classifier_ensemble', 'query_strategies', 'joint_modeling','simulated', 'error_reduction','relation_classification', 'textual_representation', 'pseudo-labeling', 'uncertainty-based', 'irm','metamorphic']\n",
      "---\n",
      "---\n",
      "deep_learning_filtering_explanation:'supervised_learning', 'unsupervised_learning','semi_supervised_learning', 'ensemble_methods','machine_learning', 'artificial_neural_networks','statistical_machine_translation','machine_reading_comprehension', 'topic_model', 'paraphrasing', 'parsing', 'primarily', 'defect_text' were filtered because they are not specific to deep learning, can be parents of deep learning, or are subtopics of other parent topics.\n",
      "deep_learning_filtered: ['convolutional_neural_networks','recurrent_neural_networks', 'long_short_term_memory', 'attention_mechanism', 'transformers', 'word_embeddings', 'language_models', 'pre_trained_word_embeddings', 'fine_tuning', 'transfer_learning','multi_task_learning','masked_language_model','sentence_classification', 'gated_recurrent_unit','mlcnn', 'context-aware','speech-to-intent_classification', 'attention_based', 'dmix','state-of-art', 'bidirectional_long_short-term_memory', 'pre-trained_transformer', 'topfuzz4sa','stacked', 'extensive_evaluation', 'neural_network', 'xlnet', 'low-resource_languages', 'neural_architecture', 'gcn', 'word_representation','sequence-based', 'generative_model', 'pretrained_models', 'deep_neural_network', 'bi-directional_lstm', 'deepmoji','resource-poor', 'deep_neural_networks', 'transformer-based', 'hisans', 'leopard', 'architectures', 'generative_models', 'deep_belief_network', 'offensive_language', 'gru', 'word_representations', 'joint_training', 'low-cost', 'contextualized','mbert','vector_space_model', 'bidirectional_encoder_representations_from_transformers', 'distilbert', 'losses', 'latent_variable', 'plms', 'projecting', 'bigru','model-agnostic', 'pre-trained_language_models', 'graph_convolutional_network', 'isomer','spurious_correlations', 'literature-mining','marbert','multi-classifier','seq2seq', 'bae', 'flaubert', 'bert', 'dc', 'decoding', 'vanilla', 'warranty']\n",
      "---\n",
      "---\n",
      "ensemble_methods_filtering_explanation: The following subtopics were filtered because they are not relevant to 'ensemble_methods' or can be subtopics of other parent topics: 'c4.5', 'c5.0','mnb','multinomial_logistic_regression','multinomial_naive_bayes', 'nb','svm-rfe','svm', 'turing_machine', 'well-established', 'again', 'ac', 'pre-trained_word_embedding', 'document_vectors','sentence_vectors', 'feed-forward', 'hidden_layer','master-slaves','morphological_analysis','response_generation', 'thresholding'.\n",
      "ensemble_methods_filtered: ['ensemble_methods', 'bagging','stacking', 'voting', 'random_forest', 'gradient_boosting', 'cross_validation', 'base_learners', 'cluster_based', 'random_forests', 'ensemble_learning', 'ensemble_models', 'ensemble_techniques', 'attention_layer', 'base_classifiers', 'dt', 'k-nearest_neighbour', 'radial_basis_function', 'complement', 'distance_measure','substantial_improvement', 'labeling_cost', 'c1', 'partitioning','symbolic', 'pooling','mlp-based', 'channeling', 'firebert', 'unbalanced_data', 'zoning', 'cso-lstmnn', 'd1','squares', 'optimally', 'chi', 'essa-acnn','macro-averaged','scgru', 'non-symmetrical', 'k10','mfom','me','manuscript', 'bottleneck', 'decreasing', 'adaptive_neuro-fuzzy', 'gss', 'best-performing', 'nearest_neighbor', 'em_algorithm', 'emotional_states', 'polarity_detection', 'ensemble_classifier']\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "with open(f\"./SeeTopic/{dir_name}/keywords_seetopic.txt\", \"r\") as f:\n",
    "    children_phrases = [i.strip().split(\":\")[1].split(\",\") for i in f.readlines()]\n",
    "    filtered_children_phrases = []\n",
    "    for c_id, c in enumerate(taxo.root.children):\n",
    "        # other parents\n",
    "        other_parents = \"\\n\".join([f\"Sibling topic: {i.label}; Description: {i.desc}\" for i in taxo.root.children if i != c])\n",
    "        other_terms = [p for child in children_phrases[:c_id] + children_phrases[c_id+1:] for p in child]\n",
    "        # filter the child phrases\n",
    "        child_phrases = filter_phrases(c, children_phrases[c_id], word2emb, other_parents, other_terms)\n",
    "        # child_phrases = filter_phrases(c, children_phrases[c_id], other_parents=other_parents)\n",
    "        filtered_children_phrases.append(child_phrases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c_id, c in enumerate(taxo.root.children):\n",
    "    c.addTerms(filtered_children_phrases[c_id], mined=True, addToParent=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Get initial, exact-matching pool of papers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "supervised_learning 58\n",
      "unsupervised_learning 132\n",
      "semi_supervised_learning 28\n",
      "deep_learning 111\n",
      "ensemble_methods 29\n"
     ]
    }
   ],
   "source": [
    "for c in taxo.root.children:\n",
    "    print(c.label, len(c.papers))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Node-Oriented Sentence Representations**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_phrase_reprs = taxo.getClassReprs(taxo.root.children, phrase=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:29<00:00,  5.99s/it]\n"
     ]
    }
   ],
   "source": [
    "for c in tqdm(taxo.root.children):\n",
    "    c.rankPapers(class_phrase_reprs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_reprs = taxo.getClassReprs(taxo.root.children, phrase=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "paper_reprs = []\n",
    "for p in taxo.root.papers:\n",
    "    if p.emb is None:\n",
    "        paper_reprs.append(p.computePaperEmb(class_reprs, phrase=False))\n",
    "    else:\n",
    "        paper_reprs.append(p.emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_labels, mapping = taxo.mapPapers(paper_reprs, taxo.root.children, class_reprs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in taxo.root.children:\n",
    "    c.density = len(c.papers)/(len(c.parent.papers)/(1 + len(c.parent.children)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unmapped: 216, 1.296\n",
      "supervised_learning: 193, 1.1580000000000001\n",
      "unsupervised_learning: 201, 1.206\n",
      "semi_supervised_learning: 468, 2.8080000000000003\n",
      "deep_learning: 212, 1.272\n",
      "ensemble_methods: 225, 1.35\n"
     ]
    }
   ],
   "source": [
    "print(f\"unmapped: {len(mapping[-1])}, {len(mapping[-1])/(len(taxo.root.papers)/(1 + len(taxo.root.children)))}\")\n",
    "for k in taxo.root.children:\n",
    "    print(f\"{k.label}: {len(k.papers)}, {k.density}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Depth Expansion**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pk36/inverse_knowledge_search/inverse/lib/python3.8/site-packages/transformers/generation/configuration_utils.py:515: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/home/pk36/inverse_knowledge_search/inverse/lib/python3.8/site-packages/transformers/generation/configuration_utils.py:520: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "curr_node = taxo.root\n",
    "global_taxo = taxo.toDict()\n",
    "\n",
    "for c in curr_node.children:\n",
    "    if c.density >= 1:\n",
    "        c.genCommonSenseChildren(global_taxo, k=2, num_terms=20)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bagging, boosting, stacking, voting, hybrid'"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\", \".join([l.label for l in taxo.root.children[4].children])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# format the input keywords file for seetopic -> get phrases -> filter using LLM\n",
    "dir_name = (args.track + \"_\" + args.dim).lower().replace(\" \", \"_\")\n",
    "\n",
    "if not os.path.exists(f\"SeeTopic/{dir_name}\"):\n",
    "    os.makedirs(f\"SeeTopic/{dir_name}\")\n",
    "\n",
    "with open(f\"SeeTopic/{dir_name}/{dir_name}.txt\", \"w\") as f:\n",
    "    for p in curr_node.papers:\n",
    "        f.write(f\"{p.text}\\n\")\n",
    "\n",
    "\n",
    "## get first level of children\n",
    "children_with_terms = curr_node.getChildren(terms=True)\n",
    "with open(f\"SeeTopic/{dir_name}/keywords_0.txt\", \"w\") as f:\n",
    "    for idx, c in enumerate(children_with_terms):\n",
    "        str_c = \",\".join(c[1])\n",
    "        f.write(f\"{idx}:{c[0]},{str_c}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "308"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(taxo.root.papers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_repr = taxo.root.updateNodeEmb(phrase=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unmapped: 185\n",
      "supervised_learning: 659\n",
      "unsupervised_learning: 26\n",
      "semi_supervised_learning: 86\n",
      "deep_learning: 308\n",
      "ensemble_methods: 73\n"
     ]
    }
   ],
   "source": [
    "for k, v in mapping.items():\n",
    "    if k == -1:\n",
    "        print(f\"unmapped: {len(v)}\")\n",
    "    else:\n",
    "        print(f\"{taxo.root.children[k]}: {len(v)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shapes (5215,768) and (1,) not aligned: 768 (dim 1) != 1 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[134], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m potential_siblings \u001b[38;5;241m=\u001b[39m \u001b[43mtaxo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msiblingExpansion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtaxo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mroot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapping\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Comparative-Summarization/taxoadapt/taxonomy.py:461\u001b[0m, in \u001b[0;36mTaxonomy.siblingExpansion\u001b[0;34m(self, parent_node, mapping)\u001b[0m\n\u001b[1;32m    459\u001b[0m phrase_reprs \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstatic_emb[w] \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m unmapped_vocab]\n\u001b[1;32m    460\u001b[0m \u001b[38;5;66;03m# terms should be relevant to the parent node\u001b[39;00m\n\u001b[0;32m--> 461\u001b[0m parent_ranks \u001b[38;5;241m=\u001b[39m \u001b[43mrank_by_significance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mphrase_reprs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mparent_node\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mphrase_emb\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    463\u001b[0m \u001b[38;5;66;03m# terms should be similar to terms from existing sibling nodes\u001b[39;00m\n\u001b[1;32m    464\u001b[0m sib_ranks \u001b[38;5;241m=\u001b[39m rank_by_significance(phrase_reprs, [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstatic_emb[c\u001b[38;5;241m.\u001b[39mlabel] \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m parent_node\u001b[38;5;241m.\u001b[39mchildren])\n",
      "File \u001b[0;32m~/Comparative-Summarization/taxoadapt/utils.py:111\u001b[0m, in \u001b[0;36mrank_by_significance\u001b[0;34m(embeddings, class_embeddings)\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrank_by_significance\u001b[39m(embeddings, class_embeddings):\n\u001b[0;32m--> 111\u001b[0m     similarities \u001b[38;5;241m=\u001b[39m \u001b[43mcosine_similarity_embeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclass_embeddings\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    112\u001b[0m     significance_score \u001b[38;5;241m=\u001b[39m [np\u001b[38;5;241m.\u001b[39mmax(similarity) \u001b[38;5;28;01mfor\u001b[39;00m similarity \u001b[38;5;129;01min\u001b[39;00m similarities]\n\u001b[1;32m    113\u001b[0m     significance_ranking \u001b[38;5;241m=\u001b[39m {i: r \u001b[38;5;28;01mfor\u001b[39;00m r, i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(np\u001b[38;5;241m.\u001b[39margsort(\u001b[38;5;241m-\u001b[39mnp\u001b[38;5;241m.\u001b[39marray(significance_score)))}\n",
      "File \u001b[0;32m~/Comparative-Summarization/taxoadapt/utils.py:101\u001b[0m, in \u001b[0;36mcosine_similarity_embeddings\u001b[0;34m(emb_a, emb_b)\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcosine_similarity_embeddings\u001b[39m(emb_a, emb_b):\n\u001b[0;32m--> 101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[43memb_a\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtranspose\u001b[49m\u001b[43m(\u001b[49m\u001b[43memb_b\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m/\u001b[39m np\u001b[38;5;241m.\u001b[39mouter(np\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39mnorm(emb_a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m), np\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39mnorm(emb_b, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m))\n",
      "File \u001b[0;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36mdot\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: shapes (5215,768) and (1,) not aligned: 768 (dim 1) != 1 (dim 0)"
     ]
    }
   ],
   "source": [
    "potential_siblings = taxo.siblingExpansion(taxo.root, mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning': (0, 365845168),\n",
       " 'phrase': (1, 1024959936),\n",
       " 'graph': (2, 1615149900),\n",
       " 'deep_learning': (3, 1698770700),\n",
       " 'models': (4, 2831294100),\n",
       " 'fusion': (5, 3547610640),\n",
       " 'fuzzy': (6, 3946380102),\n",
       " 'model': (7, 6582211200),\n",
       " 'machine': (8, 6842318000),\n",
       " 'academy': (9, 8327732224),\n",
       " 'linear': (10, 10512634170),\n",
       " 'optimization': (11, 10868002320),\n",
       " 'hierarchical': (12, 11764767168),\n",
       " 'neural': (13, 12319519744),\n",
       " 'supervised_learning': (14, 12370806720),\n",
       " 'algorithms': (15, 12546031680),\n",
       " 'sampling': (16, 13347406368),\n",
       " 'deep_belief_network': (17, 14062305852),\n",
       " 'network': (18, 14796022164),\n",
       " 'ctas': (19, 16306138212),\n",
       " 'pivotal': (20, 17494725600),\n",
       " 'algorithm': (21, 18272217600),\n",
       " 'deep': (22, 18588007440),\n",
       " 'technique': (23, 19392854737),\n",
       " 'classification': (24, 19428041880),\n",
       " 'architecture': (25, 20834904200),\n",
       " 'ensemble_learning': (26, 22131726120),\n",
       " 'supervised_machine_learning': (27, 23189579800),\n",
       " 'machine_learning': (28, 23568924464),\n",
       " 'posing': (29, 26935359616),\n",
       " 'supervised_topic_model': (30, 27373046400),\n",
       " 'supervised_machine_learning_algorithms': (31, 29005389630),\n",
       " 'methods': (32, 31561745600),\n",
       " 'language': (33, 34683389028),\n",
       " 'based': (34, 35086425738),\n",
       " 'dan': (35, 35148500544),\n",
       " 'sequence': (36, 36507839280),\n",
       " 'deep_neural_network': (37, 37591349760),\n",
       " 'search': (38, 39701070000),\n",
       " 'statistical': (39, 40657911840),\n",
       " 'approaches': (40, 41351963400),\n",
       " 'complexity-based': (41, 43564946040),\n",
       " 'rule': (42, 45685035792),\n",
       " 'techniques': (43, 46105394832),\n",
       " 'mary': (44, 49693961536),\n",
       " 'representations': (45, 51902910150),\n",
       " 'representation': (46, 51965900600),\n",
       " 'k-bert': (47, 52313509248),\n",
       " 'semantic': (48, 53602027584),\n",
       " 'ranking': (49, 54873785520),\n",
       " 'fasttext': (50, 55034369280),\n",
       " 'historically': (51, 64276860804),\n",
       " '84.4': (52, 64742344128),\n",
       " 'component': (53, 67698941454),\n",
       " 'decision_tree': (54, 68323931676),\n",
       " 'modeling': (55, 69349966070),\n",
       " 'path-lexicalization': (56, 70089104520),\n",
       " 'strengthen': (57, 71993501184),\n",
       " '0.59': (58, 72250728300),\n",
       " 'unsupervised_learning': (59, 74680490976),\n",
       " 'retrieval': (60, 80252967600),\n",
       " 'linguistic': (61, 83497638336),\n",
       " 'framework': (62, 84169998710),\n",
       " 'approach': (63, 89733804800),\n",
       " 'shallow': (64, 89902908095),\n",
       " 'concept': (65, 92996377680),\n",
       " 'tree': (66, 93455965512),\n",
       " 'feature': (67, 93548612520),\n",
       " 'method': (68, 97298288640),\n",
       " 'emotion': (69, 101336400000),\n",
       " 'petersburg': (70, 101667067700),\n",
       " 'stemming': (71, 102188744952),\n",
       " 'regression': (72, 102778106850),\n",
       " 'hybrid': (73, 103128556050),\n",
       " 'map': (74, 106091344242),\n",
       " 'supervised': (75, 109369237520),\n",
       " 'label': (76, 110807386872),\n",
       " 'catalogue': (77, 113673421472),\n",
       " 'classifications': (78, 118396961280),\n",
       " 'artificial_neural_network': (79, 120473816496),\n",
       " 'transitivity': (80, 121559792508),\n",
       " 'mining': (81, 121798120752),\n",
       " 'divisions': (82, 126629070848),\n",
       " 'strategy': (83, 127786647744),\n",
       " 'highlighting': (84, 129457821105),\n",
       " 'artificial_intelligence': (85, 135008710200),\n",
       " 'machine_learning-based': (86, 140571222714),\n",
       " 'bayesian': (87, 143238660180),\n",
       " 'machine-learning': (88, 143294257152),\n",
       " 'binary': (89, 146532907008),\n",
       " 'technology': (90, 148618138032),\n",
       " 'conditional': (91, 148779709650),\n",
       " 'modelling': (92, 149299054432),\n",
       " 'curvature-based': (93, 156113529264),\n",
       " 'unsupervised_clustering': (94, 161312533382),\n",
       " 'repeatedly': (95, 161472351180),\n",
       " 'attracts': (96, 161650457280),\n",
       " 'matching': (97, 161818596720),\n",
       " 'features': (98, 164368766700),\n",
       " 'setting': (99, 169399440000),\n",
       " 'adaptive': (100, 177853995852),\n",
       " 'strategies': (101, 179479960380),\n",
       " 'bringing': (102, 179780123040),\n",
       " 'interactional': (103, 180302163678),\n",
       " 'mapping': (104, 182521805088),\n",
       " 'unsupervised': (105, 198431726976),\n",
       " 'acoustic': (106, 201613501440),\n",
       " 'rules': (107, 201629194416),\n",
       " 'attention-mechanism-based': (108, 205819796442),\n",
       " 'trajectory': (109, 205837758576),\n",
       " 'gcc': (110, 205970410100),\n",
       " 'spie': (111, 211686918612),\n",
       " 'textual': (112, 214397981460),\n",
       " 'pattern': (113, 214769244456),\n",
       " 'syndromes': (114, 215281366200),\n",
       " 'structure': (115, 215381717040),\n",
       " 'relation': (116, 215482468500),\n",
       " 'labeling': (117, 219582306352),\n",
       " 'networks': (118, 221261793200),\n",
       " 'european': (119, 228144923370),\n",
       " 'knowledge': (120, 229799172096),\n",
       " 'slavic_languages': (121, 230357407488),\n",
       " 'semi-supervised': (122, 233400012120),\n",
       " 'gradient': (123, 233405156640),\n",
       " 'vector': (124, 235170791856),\n",
       " 'embedded': (125, 236337594990),\n",
       " 'traditional_machine_learning': (126, 236558463570),\n",
       " 'mlp-based': (127, 247515547500),\n",
       " 'softmax': (128, 248817972740),\n",
       " 'transformations': (129, 250070714880),\n",
       " 'reinforcement_learning': (130, 257585935776),\n",
       " 'greedy': (131, 260633712960),\n",
       " 'harms': (132, 264428782080),\n",
       " 'temporal': (133, 268921680426),\n",
       " 'rule-based': (134, 268942233392),\n",
       " 'local': (135, 269182731168),\n",
       " 'biomedical': (136, 273365384754),\n",
       " 'infers': (137, 274314637296),\n",
       " 'geometric': (138, 276052550400),\n",
       " 'selection': (139, 279972992862),\n",
       " 'generation': (140, 280365314432),\n",
       " 'featured': (141, 283147224360),\n",
       " 'eastern': (142, 285971215552),\n",
       " 'darkness': (143, 288355285152),\n",
       " 'weakly_supervised': (144, 291527913600),\n",
       " 'random': (145, 293547879375),\n",
       " 'dialogue': (146, 294759599400),\n",
       " '450': (147, 295941562488),\n",
       " 'dynamic': (148, 296642831400),\n",
       " 'weighted': (149, 297709850880),\n",
       " 'felicity': (150, 298739129724),\n",
       " 'salle': (151, 300060533520),\n",
       " 'inc.': (152, 310156861784),\n",
       " 'mechanism': (153, 311073541506),\n",
       " 'along': (154, 311754445200),\n",
       " 'scheme': (155, 312337898400),\n",
       " 'semantic-embedding_vectors': (156, 313291524000),\n",
       " 'global': (157, 314089112796),\n",
       " 'pulling': (158, 327397766720),\n",
       " 'x-vector': (159, 331495836672),\n",
       " 'filtering': (160, 339100130160),\n",
       " 'conversely': (161, 347734060410),\n",
       " 'hie': (162, 355095700960),\n",
       " 'recurrent_neural_network': (163, 356959444800),\n",
       " 'fine': (164, 360098430848),\n",
       " 'succeeding': (165, 365201366400),\n",
       " 'module': (166, 367005250920),\n",
       " 'using': (167, 368869606560),\n",
       " 'buy/sell': (168, 375081395040),\n",
       " 'inference': (169, 385468812000),\n",
       " 'partially_supervised': (170, 389656809600),\n",
       " 'enriched': (171, 396579643200),\n",
       " 'schemes': (172, 415743525120),\n",
       " 'yielding': (173, 418330140732),\n",
       " 'training': (174, 420541214964),\n",
       " 'emotional': (175, 426843531660),\n",
       " 'non-grounded': (176, 429654544704),\n",
       " 'character': (177, 431582142600),\n",
       " 'transcriptional': (178, 431795024100),\n",
       " 'learned': (179, 433637709120),\n",
       " 'topic_modelling': (180, 435369633072),\n",
       " 'teacher': (181, 439445298600),\n",
       " 'integrated': (182, 442204358400),\n",
       " 'two-teacher': (183, 445604718650),\n",
       " 'residual': (184, 447667166940),\n",
       " 'feature-based': (185, 455975108820),\n",
       " 'incompatible': (186, 457872942060),\n",
       " 'joint': (187, 460834874792),\n",
       " '1988': (188, 468531408675),\n",
       " '280': (189, 477178162020),\n",
       " 'spikes': (190, 481104624000),\n",
       " 'portfolio': (191, 481106202450),\n",
       " 'resumption': (192, 482611654752),\n",
       " 'r-cnn': (193, 488088108760),\n",
       " 'contrastive_learning': (194, 488413199872),\n",
       " 'computing': (195, 497891605680),\n",
       " '1992': (196, 498583661004),\n",
       " 'phenotypes': (197, 501196324167),\n",
       " 'term': (198, 506034760000),\n",
       " 'big_data': (199, 512527727382),\n",
       " 'multimedia': (200, 515957405184),\n",
       " 'som-based': (201, 516633390000),\n",
       " 'distant_supervised': (202, 518859268488),\n",
       " 'scoring': (203, 520638932736),\n",
       " 'variational_bayes': (204, 520771330816),\n",
       " 'communication_studies': (205, 523325471760),\n",
       " '1dsom': (206, 526317392475),\n",
       " 'attack': (207, 529727904000),\n",
       " 'k-means': (208, 533034884250),\n",
       " ',': (209, 544981829840),\n",
       " 'text-guided': (210, 545219683605),\n",
       " 'design': (211, 549440199308),\n",
       " 'wilson': (212, 551609747240),\n",
       " 'extraction': (213, 553459903920),\n",
       " 'attractive': (214, 561556724400),\n",
       " 'advancing': (215, 563872075488),\n",
       " 'construction': (216, 566203341830),\n",
       " 'quran': (217, 570904819892),\n",
       " 'systematization': (218, 574607018160),\n",
       " 'alternate': (219, 596808089178),\n",
       " 'relation_facts': (220, 599185844244),\n",
       " 'attention': (221, 607425751296),\n",
       " 'text': (222, 607679439486),\n",
       " 'theory': (223, 609223645680),\n",
       " '(': (224, 610414618716),\n",
       " 'formulation': (225, 618441143040),\n",
       " 'americans': (226, 623692882800),\n",
       " 'analysis': (227, 624658950324),\n",
       " 'compa-rable': (228, 625599802800),\n",
       " 'neural_network-based': (229, 626768285500),\n",
       " 'signs': (230, 627477717440),\n",
       " 'leeuwen': (231, 631058179752),\n",
       " 'multi-question_classification': (232, 636624978528),\n",
       " 'averages': (233, 640925737056),\n",
       " 'conservation': (234, 644648274536),\n",
       " 'could': (235, 648785014944),\n",
       " '22': (236, 650498748480),\n",
       " 'interrogation': (237, 651253757700),\n",
       " 'god': (238, 653740170600),\n",
       " 'dictionary': (239, 656896004235),\n",
       " 'servicing': (240, 657877609368),\n",
       " 'function': (241, 660472923072),\n",
       " 'accusative': (242, 664861081500),\n",
       " '*': (243, 664915260936),\n",
       " 'graphs': (244, 668195975160),\n",
       " 'visual': (245, 668639890800),\n",
       " 'softmax_classifier': (246, 670994274208),\n",
       " 'international_classification_of_diseases': (247, 674603846400),\n",
       " 'morphological': (248, 675796704660),\n",
       " 'psycinfo': (249, 676345901184),\n",
       " 'tools': (250, 687020352480),\n",
       " 'multi-agent': (251, 689755602580),\n",
       " 'xenophobic': (252, 690145545250),\n",
       " 'word': (253, 691506449700),\n",
       " 'statistical_tests': (254, 694738057860),\n",
       " 'gan-based': (255, 700698206208),\n",
       " 'standard': (256, 701030125824),\n",
       " 'reimers': (257, 711411382800),\n",
       " 'unableto': (258, 711916358912),\n",
       " 'xml': (259, 712599439140),\n",
       " 'natural_language': (260, 719615013075),\n",
       " 'loss': (261, 721061663580),\n",
       " 'classifiers': (262, 724821467412),\n",
       " 'system': (263, 726288724728),\n",
       " 'information': (264, 731208392750),\n",
       " 'grammar': (265, 742444103940),\n",
       " 'adaptation': (266, 748102852448),\n",
       " 'distribution': (267, 751619013354),\n",
       " 'paradigm': (268, 751725212616),\n",
       " 'procedure': (269, 753174258872),\n",
       " 'presumably': (270, 759191596128),\n",
       " 'classifier': (271, 764393742112),\n",
       " 'layer': (272, 764968127448),\n",
       " '1237': (273, 766281733632),\n",
       " 'community': (274, 767334204960),\n",
       " 'processes': (275, 773697847380),\n",
       " 'transformer-based': (276, 774277948620),\n",
       " '2.131': (277, 776951357952),\n",
       " 'alexnet-l': (278, 780346027032),\n",
       " 'sample': (279, 780390914940),\n",
       " 'weights': (280, 781877386752),\n",
       " 'evaluation': (281, 785679591424),\n",
       " 'sellers': (282, 791246170089),\n",
       " 'data': (283, 791794472352),\n",
       " 'healthy_subjects': (284, 791841503892),\n",
       " 'decision_level': (285, 791893575000),\n",
       " 'attesting': (286, 805590568608),\n",
       " 'topic_models': (287, 805592027296),\n",
       " 'solutions': (288, 818703705870),\n",
       " 'sift': (289, 825519090024),\n",
       " 'image_analysis': (290, 826308980016),\n",
       " 'lda-based': (291, 826841806830),\n",
       " 'diffusion': (292, 833420663640),\n",
       " 'machine-learning-based': (293, 841994067864),\n",
       " 'error': (294, 842546019000),\n",
       " 'distance': (295, 844576595200),\n",
       " 'utilizing': (296, 846974910600),\n",
       " 'charge': (297, 851330689300),\n",
       " '1987': (298, 854822481760),\n",
       " 'fuzzy_set': (299, 859166152488),\n",
       " 'ss': (300, 859575931200),\n",
       " 'methodology': (301, 866498321427),\n",
       " 'performs': (302, 869038478880),\n",
       " 'classifier-free': (303, 871535801160),\n",
       " 'parameters': (304, 874879429105),\n",
       " 'rights_reserved': (305, 894849282404),\n",
       " 'porto': (306, 897557091102),\n",
       " 'rtsl': (307, 899958058272),\n",
       " '664': (308, 911975334656),\n",
       " 'enhanced': (309, 913706820000),\n",
       " 'artificial': (310, 918064728724),\n",
       " 'without': (311, 920586380000),\n",
       " '246': (312, 922310316720),\n",
       " 'bilingual': (313, 923134680000),\n",
       " 'embed-dings': (314, 929768446800),\n",
       " 'joint-entity-sentiment-topic': (315, 930205087500),\n",
       " 'grounds': (316, 939725197488),\n",
       " 'archival': (317, 943048629600),\n",
       " '579199': (318, 944237390250),\n",
       " 'topology-based': (319, 955345934250),\n",
       " '-word': (320, 962932481280),\n",
       " 'shark': (321, 968319349920),\n",
       " 'variant': (322, 973452662000),\n",
       " 'cnn-based': (323, 977703686505),\n",
       " 'shapes': (324, 978027340320),\n",
       " 'instruction': (325, 981036087776),\n",
       " 'misunderstanding': (326, 984071908875),\n",
       " 'acoustic-textual': (327, 986688423630),\n",
       " 'filter': (328, 999575187912),\n",
       " 'eleven': (329, 1000365009840),\n",
       " 'prediction': (330, 1003201203942),\n",
       " 'inquiry': (331, 1003506893415),\n",
       " 'pipeline': (332, 1007969054400),\n",
       " 'interfering': (333, 1008965295600),\n",
       " 'complementary': (334, 1021470495320),\n",
       " 'moan': (335, 1021642790400),\n",
       " 'automated': (336, 1022793780324),\n",
       " '9945': (337, 1028611620960),\n",
       " 'whereas': (338, 1031516386056),\n",
       " 'literary_texts': (339, 1032812839665),\n",
       " 'south_wales': (340, 1034641814528),\n",
       " 'june': (341, 1039941885000),\n",
       " 'whatever': (342, 1040842032640),\n",
       " 'criterion': (343, 1040875652520),\n",
       " 'la-gan': (344, 1048417841600),\n",
       " 'sentiment': (345, 1049224707440),\n",
       " 'janda': (346, 1049301205940),\n",
       " 'character_segmentation': (347, 1055270802600),\n",
       " 'measures': (348, 1060188191964),\n",
       " 'works': (349, 1060465341600),\n",
       " 'combined': (350, 1071166464000),\n",
       " '—': (351, 1071568620000),\n",
       " 'node': (352, 1073081309040),\n",
       " 'ethnicity-related': (353, 1074937608000),\n",
       " '378': (354, 1105949749248),\n",
       " 'active': (355, 1108263377664),\n",
       " 'medical': (356, 1109301519690),\n",
       " 'cnn': (357, 1111333279140),\n",
       " 'functions': (358, 1112892834000),\n",
       " 'operators': (359, 1114188433050),\n",
       " 'fictional': (360, 1116149649030),\n",
       " 'encoding': (361, 1120950133740),\n",
       " 'compression': (362, 1137732099504),\n",
       " 'bottle': (363, 1141239493324),\n",
       " '375': (364, 1141477722112),\n",
       " '1266': (365, 1142010389376),\n",
       " 'soft_label': (366, 1150269120000),\n",
       " 'argument': (367, 1150985733380),\n",
       " '12,13': (368, 1159632676080),\n",
       " 'listings': (369, 1164990945888),\n",
       " 'ref': (370, 1174364697600),\n",
       " 'reasoning': (371, 1176222625776),\n",
       " 'light': (372, 1183132749375),\n",
       " 'produced': (373, 1189175648850),\n",
       " '94.8': (374, 1190975385600),\n",
       " 'examples': (375, 1194876977928),\n",
       " 'git': (376, 1200270052800),\n",
       " 'principle': (377, 1203130978140),\n",
       " 'mapbox': (378, 1210875221094),\n",
       " 'functional_analysis': (379, 1223677597824),\n",
       " 'semantic-interactive': (380, 1233176712768),\n",
       " 'irrespective': (381, 1246217236056),\n",
       " '0.25': (382, 1246438240425),\n",
       " 'scale_invariant_feature_transform': (383, 1247395444200),\n",
       " '.': (384, 1250783955120),\n",
       " 'multi-hop': (385, 1251475013040),\n",
       " ';': (386, 1256521663272),\n",
       " 'sequential': (387, 1258422261096),\n",
       " 'text-projection': (388, 1259479696860),\n",
       " 'volatility': (389, 1277989826256),\n",
       " 'uncertainty': (390, 1299737003040),\n",
       " 'decomposition': (391, 1308496870080),\n",
       " 'mathematical': (392, 1313190278400),\n",
       " 'external_knowledge-base': (393, 1328042007360),\n",
       " 'hmm': (394, 1329492231288),\n",
       " 'baudouin': (395, 1335402769824),\n",
       " 'cnnbatsk': (396, 1336394459556),\n",
       " 'human': (397, 1336417284960),\n",
       " 'subtlety': (398, 1342126279080),\n",
       " 'across': (399, 1346461551720),\n",
       " 'density': (400, 1353008843208),\n",
       " 'atec': (401, 1355502500968),\n",
       " 'post-purchase': (402, 1370930736738),\n",
       " 'prior': (403, 1374570933120),\n",
       " 'category': (404, 1389674724000),\n",
       " '62.74': (405, 1407883474788),\n",
       " 'labels': (406, 1411325723808),\n",
       " 'invested': (407, 1412693663472),\n",
       " 'group': (408, 1415420889984),\n",
       " 'processing': (409, 1428876261120),\n",
       " 'interaction': (410, 1433582222709),\n",
       " 'wall': (411, 1438646950944),\n",
       " 'measure': (412, 1449604111428),\n",
       " 'computational': (413, 1450301641250),\n",
       " '0.530': (414, 1453801431040),\n",
       " 'prompt': (415, 1454444072445),\n",
       " 'scream': (416, 1457057565600),\n",
       " 'down-sampled': (417, 1459029501072),\n",
       " 'augmented_data': (418, 1460613108402),\n",
       " 'la_nación': (419, 1461952138725),\n",
       " 'distributions': (420, 1465830590400),\n",
       " 'sbnn': (421, 1469417443200),\n",
       " 'soft': (422, 1471576337144),\n",
       " 'voicing': (423, 1478699987400),\n",
       " 'ā': (424, 1485373848000),\n",
       " '”': (425, 1498926209280),\n",
       " 'gives': (426, 1508972526600),\n",
       " 'delineates': (427, 1510225572936),\n",
       " 'resistance': (428, 1512507118150),\n",
       " 'naïve_bayes': (429, 1517163509400),\n",
       " 'š': (430, 1520376610896),\n",
       " 'block': (431, 1525667173632),\n",
       " 'gcn-based': (432, 1544531330160),\n",
       " 'dbn': (433, 1550572277760),\n",
       " 'north_africa': (434, 1551324574800),\n",
       " 'engineering': (435, 1551917475000),\n",
       " 'mono-objective': (436, 1552812847886),\n",
       " 'evoke': (437, 1557019665600),\n",
       " 'consistently_improves': (438, 1557737638842),\n",
       " 'usage': (439, 1570045635600),\n",
       " 'deep‐learning‐based': (440, 1570047649920),\n",
       " 'parallel': (441, 1571113368000),\n",
       " 'late_fusion': (442, 1571314168512),\n",
       " '2011': (443, 1573101113472),\n",
       " 'e2e-asr': (444, 1577485554120),\n",
       " 'connections': (445, 1581290284248),\n",
       " 'othering': (446, 1584889212672),\n",
       " 'unhappy': (447, 1593916300800),\n",
       " 'job_interview': (448, 1595324074840),\n",
       " 'conversations': (449, 1609366143744),\n",
       " 'gun': (450, 1611996182784),\n",
       " 'learningsetting': (451, 1613296868025),\n",
       " 'prepares': (452, 1619752592640),\n",
       " 'transform': (453, 1627470651696),\n",
       " 'vectors': (454, 1631231768096),\n",
       " 'resumed': (455, 1633372277000),\n",
       " 'college': (456, 1645764951411),\n",
       " 'perspective': (457, 1664867590650),\n",
       " 'soundly': (458, 1675635359100),\n",
       " 'traces': (459, 1684580026688),\n",
       " 'back-propagation': (460, 1685382408000),\n",
       " 'manner': (461, 1686468341760),\n",
       " 'operation': (462, 1690785425664),\n",
       " 'dual-view': (463, 1710797942700),\n",
       " 'rankings': (464, 1711770258588),\n",
       " 'simple': (465, 1716977570664),\n",
       " 'functional': (466, 1724736640704),\n",
       " 'bot': (467, 1735960750080),\n",
       " 'requirements': (468, 1737375108480),\n",
       " 'heritability': (469, 1744323876675),\n",
       " 'generative_model': (470, 1749063788910),\n",
       " 'adapted': (471, 1754917249536),\n",
       " 'knowledge-based': (472, 1758287556168),\n",
       " 'metric-learning-based': (473, 1760665330730),\n",
       " 'distant_supervision': (474, 1763920194582),\n",
       " 'transfer': (475, 1772799459633),\n",
       " 'cifar-10': (476, 1812052547487),\n",
       " 'simultaneously': (477, 1824079379520),\n",
       " 'open': (478, 1824281733120),\n",
       " 'submodular': (479, 1824501813750),\n",
       " 'independent': (480, 1828759422060),\n",
       " 'theories': (481, 1831932012978),\n",
       " 'fuzzy_rules': (482, 1840116820500),\n",
       " 'disadvantage': (483, 1842848628894),\n",
       " 'systems': (484, 1844082408663),\n",
       " '102': (485, 1844153036754),\n",
       " 'controlled': (486, 1845268926480),\n",
       " 'multiple': (487, 1846808030280),\n",
       " 'signers': (488, 1856229129000),\n",
       " 'homogenous': (489, 1864060846496),\n",
       " 'reviewing': (490, 1865453942475),\n",
       " 'correlation': (491, 1877730818556),\n",
       " 'centuries': (492, 1878342313950),\n",
       " 'may': (493, 1883171392209),\n",
       " 'la': (494, 1885270314400),\n",
       " 'al.': (495, 1887613147680),\n",
       " 'discovery': (496, 1887716000560),\n",
       " 'flowing': (497, 1891132503600),\n",
       " 'beforethe': (498, 1893399257088),\n",
       " 'together': (499, 1895793869952),\n",
       " 'fatal': (500, 1898557603272),\n",
       " 'müller': (501, 1901966234760),\n",
       " 'improved': (502, 1904290454664),\n",
       " 'tool': (503, 1906896416280),\n",
       " 'lexicalization': (504, 1910573848260),\n",
       " \"'flower\": (505, 1911667665600),\n",
       " 'expert': (506, 1920430470720),\n",
       " 'tasks': (507, 1921204471464),\n",
       " 'regular_expression': (508, 1921756700424),\n",
       " 'job_seekers': (509, 1923289816320),\n",
       " 'uncover': (510, 1932195492096),\n",
       " 'machine_translation': (511, 1941802983640),\n",
       " 'advanced': (512, 1943483103144),\n",
       " 'decision': (513, 1944896976360),\n",
       " 'concepts': (514, 1957991344650),\n",
       " 'intelligence': (515, 1958156217600),\n",
       " 'ii': (516, 1958865916280),\n",
       " 'referendum': (517, 1961604983520),\n",
       " 'test': (518, 1962305461935),\n",
       " 'ccl': (519, 1962726205440),\n",
       " 'process': (520, 1966237555968),\n",
       " 'constrained': (521, 1971070358400),\n",
       " 'perceiver': (522, 1982650636512),\n",
       " \"'big_data\": (523, 1990933749000),\n",
       " 'phonological': (524, 1994157827200),\n",
       " 'distributed': (525, 2003327646012),\n",
       " 'presentation': (526, 2004548810208),\n",
       " 'integration': (527, 2010208154292),\n",
       " 'synthetic': (528, 2013048591190),\n",
       " '1d-som': (529, 2021783502200),\n",
       " 'corpus-based': (530, 2028756928968),\n",
       " 'visual-semantic': (531, 2043826476384),\n",
       " '1990': (532, 2048682411360),\n",
       " 'topic': (533, 2061081603000),\n",
       " 'coarse_grained': (534, 2061413172000),\n",
       " 'multi-label': (535, 2066034948705),\n",
       " 'consequences': (536, 2069607763520),\n",
       " 'weakly-supervised': (537, 2073526400400),\n",
       " 'combining': (538, 2082519482728),\n",
       " 'effortlessly': (539, 2083444741728),\n",
       " 'working': (540, 2089200411900),\n",
       " 'several': (541, 2091570104520),\n",
       " 'architectural': (542, 2097213564538),\n",
       " 'evolutionary': (543, 2106424047336),\n",
       " 'lakoff': (544, 2107144955520),\n",
       " 'supports': (545, 2112470952165),\n",
       " 'justification': (546, 2127097800000),\n",
       " 'vehicle': (547, 2127783121200),\n",
       " 'multi-scale': (548, 2130193812824),\n",
       " 'urban_areas': (549, 2140073070575),\n",
       " 'improves': (550, 2141080373965),\n",
       " 'computer': (551, 2147594911616),\n",
       " 'competing': (552, 2158965762840),\n",
       " 'panel': (553, 2163325913280),\n",
       " 'maximum': (554, 2164133581740),\n",
       " 'completely': (555, 2181339205584),\n",
       " 'suggesting': (556, 2184702422435),\n",
       " 'restriction': (557, 2186709423360),\n",
       " 'student': (558, 2204809370280),\n",
       " 'multi-level': (559, 2215458642540),\n",
       " 'crypto-currency': (560, 2229414197472),\n",
       " 'augmentation-agnostic': (561, 2233659228528),\n",
       " 'dcgan-based': (562, 2234596071070),\n",
       " 'menu': (563, 2234942380125),\n",
       " 'glove': (564, 2237164400640),\n",
       " 'interestingness': (565, 2248600033872),\n",
       " 'requirements_management': (566, 2249500356096),\n",
       " 'supervisory': (567, 2253036593808),\n",
       " 'samples': (568, 2264448083040),\n",
       " 'weight_distribution': (569, 2273096034027),\n",
       " '0.97': (570, 2274172785600),\n",
       " 'entropy': (571, 2283823603776),\n",
       " 'spatial': (572, 2285356290000),\n",
       " 'abusive': (573, 2292719867776),\n",
       " 'tests': (574, 2300457650400),\n",
       " '©2004': (575, 2301207222600),\n",
       " 'structures': (576, 2302717082850),\n",
       " 'continuous': (577, 2306693007255),\n",
       " 'sensitive_words': (578, 2315239394832),\n",
       " 'translation': (579, 2324619610480),\n",
       " 'underexplored': (580, 2327588263728),\n",
       " 'count': (581, 2333014363680),\n",
       " 'conversion': (582, 2337178733847),\n",
       " 'common': (583, 2339842867200),\n",
       " 'publics': (584, 2340778568040),\n",
       " 'devil': (585, 2348460188928),\n",
       " 'end-users': (586, 2354990645568),\n",
       " 'patterns': (587, 2355724073625),\n",
       " 'edge-reasoning': (588, 2357366893248),\n",
       " '39': (589, 2361318844500),\n",
       " 'smote': (590, 2365273713312),\n",
       " 'extractions': (591, 2367762107686),\n",
       " 'classification_scheme': (592, 2380703861206),\n",
       " 'recent_spanbert': (593, 2386679139792),\n",
       " 'within-': (594, 2417652950412),\n",
       " 'dna': (595, 2422137806928),\n",
       " 'sarcasm': (596, 2424726427770),\n",
       " 'speaker': (597, 2435735712410),\n",
       " 'combination': (598, 2436729039360),\n",
       " 'advancement': (599, 2440169620032),\n",
       " '2012': (600, 2445934522230),\n",
       " 'vowel': (601, 2455939193344),\n",
       " 'rendering': (602, 2470705086150),\n",
       " 'previously': (603, 2472033648128),\n",
       " 'municipality': (604, 2484531163296),\n",
       " '2003': (605, 2493675524800),\n",
       " 'lsi-1dsom': (606, 2497900546386),\n",
       " 'labeled': (607, 2500791536640),\n",
       " '81.51': (608, 2500991875382),\n",
       " 'class_label': (609, 2505551638772),\n",
       " 'implementation': (610, 2509049434164),\n",
       " 'image': (611, 2519941526520),\n",
       " 'fused': (612, 2521305004000),\n",
       " 'instances': (613, 2528797031552),\n",
       " 'policy_makers': (614, 2535061003398),\n",
       " 'properties': (615, 2539632494294),\n",
       " 'rating': (616, 2539839722805),\n",
       " 'alone': (617, 2541311475780),\n",
       " 'indus': (618, 2542924487265),\n",
       " 'modified': (619, 2544751250118),\n",
       " 'italic': (620, 2547963928182),\n",
       " 'hamza': (621, 2552030081775),\n",
       " 'rising': (622, 2555559936000),\n",
       " 'baseline': (623, 2562366668400),\n",
       " 'anchor-based': (624, 2572163818400),\n",
       " '-': (625, 2576409066000),\n",
       " 'augmented': (626, 2580052788144),\n",
       " '23.3': (627, 2590683067980),\n",
       " 'dravidian': (628, 2600896500384),\n",
       " 'f1m': (629, 2608951742775),\n",
       " 'classic': (630, 2611880343666),\n",
       " 'equivalents': (631, 2615113894800),\n",
       " 'de-arteaga': (632, 2616699108240),\n",
       " 'related': (633, 2624645214400),\n",
       " 'intelligent': (634, 2627437867488),\n",
       " 'hour': (635, 2636707952700),\n",
       " '2006': (636, 2656242168768),\n",
       " 'nightclub': (637, 2663946898272),\n",
       " 'sequence_alignment': (638, 2680726497750),\n",
       " 'thai-japanese': (639, 2687726626200),\n",
       " '71.0': (640, 2692531688080),\n",
       " 'explanations': (641, 2693864600000),\n",
       " 'preventive': (642, 2695899804786),\n",
       " 'translations': (643, 2697441671322),\n",
       " 'static': (644, 2698864609110),\n",
       " 'leaders': (645, 2707476892144),\n",
       " 'insurance-based': (646, 2714239712520),\n",
       " 'matrix': (647, 2721262521978),\n",
       " 'data-deficient': (648, 2730346920000),\n",
       " 'referring': (649, 2743495413480),\n",
       " 'diagnostic': (650, 2749474592928),\n",
       " 'apa': (651, 2749744473840),\n",
       " 'failure_modes': (652, 2754000307476),\n",
       " 'relational': (653, 2754062113920),\n",
       " 'assistant': (654, 2758411912284),\n",
       " 'analog': (655, 2760266265606),\n",
       " '2009': (656, 2775293672580),\n",
       " 'ganter': (657, 2778866342525),\n",
       " 'patent': (658, 2780191389960),\n",
       " 'inquiries': (659, 2785958313600),\n",
       " 'pertaining': (660, 2790723685008),\n",
       " 'polynomial': (661, 2793933285000),\n",
       " 'insignificance': (662, 2798001146430),\n",
       " 'polite-rl': (663, 2798004615008),\n",
       " 'class': (664, 2802398711266),\n",
       " 'informing': (665, 2814064474200),\n",
       " 'transitions': (666, 2825876232000),\n",
       " 'acoustic_scene_classification': (667, 2832544183904),\n",
       " 'outline': (668, 2834222043120),\n",
       " 'tamil_language': (669, 2838133519488),\n",
       " 'advocates': (670, 2846638878600),\n",
       " 'manually': (671, 2850694421652),\n",
       " 'task': (672, 2854389979584),\n",
       " 'database': (673, 2856372192000),\n",
       " 'user-interfaces': (674, 2863254217740),\n",
       " 'recognition': (675, 2866766605920),\n",
       " 'canada': (676, 2869246797186),\n",
       " 'doctor–patient': (677, 2880118443840),\n",
       " 'topic_model': (678, 2886843235584),\n",
       " 'connectionist': (679, 2887019420940),\n",
       " 'various': (680, 2887540771500),\n",
       " 'holding_companies': (681, 2889141156160),\n",
       " 'aspect': (682, 2901860636220),\n",
       " 'escaping': (683, 2904409100340),\n",
       " 'handshape': (684, 2904421925888),\n",
       " 'human_rights': (685, 2908089854700),\n",
       " '26.4': (686, 2911560595038),\n",
       " 'space': (687, 2918533584512),\n",
       " 'spend': (688, 2925974570324),\n",
       " 'military': (689, 2935885712940),\n",
       " 'wishes': (690, 2961952371378),\n",
       " '©_2010_springer-verlag_berlin_heidelberg': (691, 2969109727920),\n",
       " 'charles': (692, 2972410156800),\n",
       " 'relations': (693, 2978382177540),\n",
       " '“': (694, 2982138848000),\n",
       " 'retrieval-based': (695, 2994993334508),\n",
       " 'marginalize': (696, 2997126630432),\n",
       " 'paris': (697, 3006650006360),\n",
       " 'overcoming': (698, 3007115890000),\n",
       " 'morbidity': (699, 3010879872000),\n",
       " 'faults': (700, 3020566489920),\n",
       " 'mythology': (701, 3022625411316),\n",
       " '65.97': (702, 3028523291640),\n",
       " 'information-theoretic': (703, 3028763109680),\n",
       " 'itemization': (704, 3036520274920),\n",
       " 'calculation': (705, 3064443804000),\n",
       " 'operator/': (706, 3070286198784),\n",
       " 'minds': (707, 3073991452560),\n",
       " 'presumptive': (708, 3077295370240),\n",
       " 'gaussians': (709, 3088797594480),\n",
       " '27': (710, 3104728486640),\n",
       " 'use/cover': (711, 3121129241340),\n",
       " 'auxiliary': (712, 3122346755934),\n",
       " 'nineteen': (713, 3122458467840),\n",
       " '52.5': (714, 3131163420000),\n",
       " 'solution': (715, 3136389734400),\n",
       " 'type': (716, 3143516608512),\n",
       " 'back': (717, 3150203040000),\n",
       " 'cbms': (718, 3160355047344),\n",
       " 'compression-based': (719, 3164873293824),\n",
       " 'american': (720, 3171111232800),\n",
       " 'modules': (721, 3179320014080),\n",
       " 'gmail': (722, 3181771599930),\n",
       " 'outdated': (723, 3182990786112),\n",
       " 'capability': (724, 3190669996800),\n",
       " 'incompleteness': (725, 3191025058795),\n",
       " 'automatic': (726, 3209296293931),\n",
       " 'bias': (727, 3215325355200),\n",
       " '1995': (728, 3217427962800),\n",
       " 'ambiguity': (729, 3218505282240),\n",
       " 'reclassifying': (730, 3219470284800),\n",
       " 'signifies': (731, 3219634678464),\n",
       " 'logic': (732, 3229815743964),\n",
       " 'semantics': (733, 3238469648370),\n",
       " 'query': (734, 3242754126360),\n",
       " 'conception': (735, 3251718726300),\n",
       " 'application': (736, 3260217417600),\n",
       " 'sacrificing': (737, 3260981718480),\n",
       " 'analytical': (738, 3261311259000),\n",
       " 'hlspc': (739, 3261942810672),\n",
       " 'aphasia': (740, 3267004554432),\n",
       " 'operator': (741, 3271198744344),\n",
       " 'metric': (742, 3287523705480),\n",
       " 'content-based': (743, 3291386089515),\n",
       " 'declension': (744, 3302571328441),\n",
       " 'domain_adaptation': (745, 3304509015500),\n",
       " 'universal': (746, 3309267502926),\n",
       " 'latch': (747, 3310172025600),\n",
       " 'smart': (748, 3317519489328),\n",
       " 'among': (749, 3321886038016),\n",
       " 'fraud': (750, 3329595146576),\n",
       " 'hesitant_fuzzy': (751, 3330167168125),\n",
       " 'attribute': (752, 3335988938436),\n",
       " 'predictions': (753, 3337113600000),\n",
       " 'polygonal': (754, 3338462499840),\n",
       " 'facial': (755, 3346775095968),\n",
       " 'qas': (756, 3348265427280),\n",
       " 'image_processing': (757, 3355871574528),\n",
       " '93.6': (758, 3362868601560),\n",
       " 'associate': (759, 3363971705280),\n",
       " 'cgdialog': (760, 3378046875000),\n",
       " 'shared': (761, 3390446241000),\n",
       " 'bias-corrected': (762, 3407589223560),\n",
       " 'algebra': (763, 3408380352300),\n",
       " 'calzolari': (764, 3418314665220),\n",
       " 'gigantic': (765, 3421531348301),\n",
       " 'tommola': (766, 3430750562400),\n",
       " 'nle-alone': (767, 3437710533180),\n",
       " 'downstream_classification_tasks': (768, 3438154075860),\n",
       " 'generic': (769, 3439435757688),\n",
       " 'ascending': (770, 3443348594736),\n",
       " 'long': (771, 3451073615850),\n",
       " 'collection': (772, 3455507136600),\n",
       " 'single-datset': (773, 3455736453000),\n",
       " 'sense_disambiguation': (774, 3464690178768),\n",
       " 'formal': (775, 3490465645425),\n",
       " 'approached': (776, 3494286390700),\n",
       " 'till': (777, 3498496037850),\n",
       " 'weight': (778, 3508375225896),\n",
       " 'me/cfs': (779, 3517108671440),\n",
       " 'generative': (780, 3526385448432),\n",
       " 'image_editing': (781, 3531912575760),\n",
       " '6.9': (782, 3533602154460),\n",
       " 'ribonucleic': (783, 3535436709900),\n",
       " 'image-class-tags': (784, 3536325990912),\n",
       " 'synthesizing': (785, 3538596445020),\n",
       " 'april': (786, 3544640838648),\n",
       " '232': (787, 3547522182960),\n",
       " 'efficient': (788, 3550252448728),\n",
       " 'trending_topics': (789, 3551822208792),\n",
       " 'variational_inference': (790, 3552730200000),\n",
       " 'nationality': (791, 3553443382104),\n",
       " 'gene': (792, 3553835774400),\n",
       " 'multi-label_classification': (793, 3555049212288),\n",
       " 'pretrained_language_model': (794, 3561743343984),\n",
       " 'gender': (795, 3575805975500),\n",
       " '2014': (796, 3587157745380),\n",
       " 'directly': (797, 3588016647744),\n",
       " 'type-matching': (798, 3593948684040),\n",
       " 'discussions': (799, 3596548546250),\n",
       " 'evidence': (800, 3606090637968),\n",
       " 'deaf': (801, 3606473325240),\n",
       " 'mirnas': (802, 3617013917853),\n",
       " 'set': (803, 3618540521600),\n",
       " 'typing': (804, 3620340595872),\n",
       " 'automatically': (805, 3624768941472),\n",
       " '0.5': (806, 3624893113798),\n",
       " 'va': (807, 3625929189696),\n",
       " '92.2': (808, 3631244005360),\n",
       " 'hours': (809, 3634613013654),\n",
       " 'gt': (810, 3635337623400),\n",
       " 'discourse_analysis': (811, 3645777945810),\n",
       " 'separate': (812, 3648102007550),\n",
       " 'quality_assessment': (813, 3651277129500),\n",
       " 'culturology': (814, 3663082619196),\n",
       " 'conformance': (815, 3675187251288),\n",
       " 'generated': (816, 3675688010280),\n",
       " 'relationships': (817, 3678597111168),\n",
       " 'trained': (818, 3687278671272),\n",
       " 'corpus': (819, 3702583884000),\n",
       " 'arabic': (820, 3709007786880),\n",
       " 'a.k.a': (821, 3714276888000),\n",
       " 'named': (822, 3718854205440),\n",
       " 'supposing': (823, 3729204133560),\n",
       " 'dynamical_systems': (824, 3748942852452),\n",
       " 'symmetry': (825, 3751300916352),\n",
       " 'like': (826, 3763270736400),\n",
       " 'abstract': (827, 3772698615000),\n",
       " 'insurance_companies': (828, 3776313956700),\n",
       " 'document': (829, 3792045304320),\n",
       " 'backing': (830, 3796505124084),\n",
       " 'index': (831, 3796633916370),\n",
       " 'moral': (832, 3801143712960),\n",
       " 'studies': (833, 3809217162166),\n",
       " 'justifying': (834, 3810215331936),\n",
       " 'provides': (835, 3815006711100),\n",
       " 'sirnas': (836, 3824573931000),\n",
       " 'semi-structured': (837, 3832265880240),\n",
       " 'social': (838, 3834850861017),\n",
       " '3d-cnn': (839, 3836198689344),\n",
       " 'limiting': (840, 3863316206610),\n",
       " 'holy_quran': (841, 3868075112616),\n",
       " 'trees': (842, 3877408861248),\n",
       " 'brexit': (843, 3878583435072),\n",
       " 'non-function': (844, 3881904136074),\n",
       " 'racial': (845, 3885082897104),\n",
       " 'numerous': (846, 3886175422080),\n",
       " 'explicated': (847, 3895358105912),\n",
       " 'post-transcriptional': (848, 3896950596000),\n",
       " 'message': (849, 3902923446480),\n",
       " 'selections': (850, 3926595133098),\n",
       " '592': (851, 3928150090800),\n",
       " 'aesthetic': (852, 3929285850756),\n",
       " 'classroom': (853, 3931245964800),\n",
       " 'structural': (854, 3933120777600),\n",
       " 'gc': (855, 3935929367250),\n",
       " 'capabilities': (856, 3936235050048),\n",
       " 'yields': (857, 3937606187200),\n",
       " 'compilers': (858, 3940186493880),\n",
       " 'software': (859, 3942418178160),\n",
       " 'components': (860, 3945102289362),\n",
       " 'two-level': (861, 3949332961200),\n",
       " 'coordinates': (862, 3952914802816),\n",
       " 'artificially': (863, 3955899001600),\n",
       " 'privacy-centric': (864, 3957170020730),\n",
       " 'rent': (865, 3967806919482),\n",
       " 'intervention': (866, 3969747155790),\n",
       " '59.4': (867, 3972652705632),\n",
       " 'text_classification-based': (868, 3974859637980),\n",
       " 'grammars': (869, 3978036562500),\n",
       " 'review': (870, 3987143309580),\n",
       " 'network_architecture': (871, 3991467936600),\n",
       " 'inventories': (872, 3999885746670),\n",
       " 'dms': (873, 4005690071040),\n",
       " 'neuroscience': (874, 4012408698880),\n",
       " 'requires': (875, 4024087841280),\n",
       " 'segment': (876, 4039824159000),\n",
       " '1980': (877, 4043873326752),\n",
       " 'kept': (878, 4048592549736),\n",
       " 'longest_common': (879, 4055844830128),\n",
       " 'link': (880, 4055955328656),\n",
       " 'debiasing': (881, 4078272285360),\n",
       " 'classification_task': (882, 4079625593400),\n",
       " 'concurrently': (883, 4084881553920),\n",
       " 'images': (884, 4092251888384),\n",
       " 'document_representation': (885, 4114341207900),\n",
       " 'partition': (886, 4133538002880),\n",
       " 'n-way': (887, 4136524106165),\n",
       " 'separates': (888, 4140536770026),\n",
       " 'conserved': (889, 4156459807500),\n",
       " 'sensors': (890, 4171907646788),\n",
       " 'encodes': (891, 4172860668480),\n",
       " 'version': (892, 4179095815656),\n",
       " 'extracted': (893, 4181076146754),\n",
       " 'psychol': (894, 4191189841440),\n",
       " 'finance-specific': (895, 4193518996800),\n",
       " 'n-gram': (896, 4197730497696),\n",
       " 'multi-domain': (897, 4203900985514),\n",
       " 'adjacent': (898, 4208528616888),\n",
       " 'hospital': (899, 4216595680128),\n",
       " 'orlando': (900, 4219619500800),\n",
       " 'rgb': (901, 4219786776072),\n",
       " 'score': (902, 4225923439920),\n",
       " 'aerospace': (903, 4227751799040),\n",
       " 'signals': (904, 4240761826080),\n",
       " '2007': (905, 4250200765668),\n",
       " 'axiological': (906, 4250437743200),\n",
       " 'pure': (907, 4255643420028),\n",
       " 'caregivers': (908, 4257647884350),\n",
       " 'demonstration': (909, 4264895259180),\n",
       " '//github.com/d2klab/zeste': (910, 4270239162514),\n",
       " 'scientific': (911, 4271319668736),\n",
       " 'pirnas': (912, 4273195773792),\n",
       " 'different': (913, 4281555632211),\n",
       " 'associated': (914, 4287894922080),\n",
       " 'honti': (915, 4301909271811),\n",
       " 'wikipedia': (916, 4309715912580),\n",
       " 'sophisticated': (917, 4321812196770),\n",
       " 'ideology': (918, 4335970818816),\n",
       " 'impart': (919, 4337273382960),\n",
       " 'discrete': (920, 4342087159566),\n",
       " 'pioneering': (921, 4343517347004),\n",
       " 'explicit': (922, 4343698319488),\n",
       " 'similar': (923, 4361364147910),\n",
       " 'data_science': (924, 4381546183560),\n",
       " 'level': (925, 4385940263040),\n",
       " 'generator': (926, 4409033250636),\n",
       " 'word-_embedding': (927, 4409188761600),\n",
       " 'clm': (928, 4409215622812),\n",
       " 'degradation': (929, 4411203066100),\n",
       " 'storing': (930, 4412742428160),\n",
       " 'call': (931, 4421891941740),\n",
       " '/italic': (932, 4424493983616),\n",
       " 'speech': (933, 4432307713380),\n",
       " 'causal': (934, 4434893148840),\n",
       " 'wille': (935, 4437202682880),\n",
       " 'weighted_average': (936, 4437810058500),\n",
       " 'fuzzy_rule': (937, 4441302217200),\n",
       " 'increases': (938, 4441347129024),\n",
       " 'representative': (939, 4455438283188),\n",
       " 'representing': (940, 4455620447040),\n",
       " 'b-tree': (941, 4465859969340),\n",
       " 'baselines': (942, 4467355622400),\n",
       " 'outputs': (943, 4490380897128),\n",
       " '2013': (944, 4501742826240),\n",
       " 'device': (945, 4501757451840),\n",
       " 'reproduced': (946, 4501843753680),\n",
       " 'location': (947, 4503389405697),\n",
       " 'superiorities': (948, 4513666569984),\n",
       " 'merges': (949, 4519457554824),\n",
       " 'vacancy': (950, 4536855013860),\n",
       " 'al': (951, 4549227412320),\n",
       " 'leave': (952, 4554878087376),\n",
       " 'typographic': (953, 4555027558125),\n",
       " 'prototype': (954, 4565538267008),\n",
       " 'criteria': (955, 4568237305926),\n",
       " 'sheds': (956, 4570644284112),\n",
       " 'ae': (957, 4579747321296),\n",
       " 'phoneme-based': (958, 4583548094125),\n",
       " 'scibert': (959, 4584742706124),\n",
       " 'dat': (960, 4585425504660),\n",
       " 'applications': (961, 4608020035584),\n",
       " 'grammatical': (962, 4608543714840),\n",
       " 'similarity': (963, 4616541362286),\n",
       " 'retroflex': (964, 4628367895668),\n",
       " 'complex_queries': (965, 4638867174936),\n",
       " 'translator': (966, 4650830954700),\n",
       " '4.0': (967, 4668213962304),\n",
       " 'triples': (968, 4672741316712),\n",
       " 'self-organizing_map': (969, 4675528988536),\n",
       " 'called': (970, 4693357592784),\n",
       " 'macedonian': (971, 4708956605535),\n",
       " 'success': (972, 4722325853760),\n",
       " 'kcnq2-': (973, 4736656270080),\n",
       " 'guendouzi': (974, 4740928858380),\n",
       " 'mimic': (975, 4743051460560),\n",
       " 'language-to-language': (976, 4747768066998),\n",
       " 'parameter': (977, 4751675976960),\n",
       " 'sentences': (978, 4757453497888),\n",
       " 'sheets': (979, 4761177670156),\n",
       " 'links': (980, 4765361724624),\n",
       " 'province': (981, 4786647396300),\n",
       " 'query/question': (982, 4786875364320),\n",
       " 'seqgan-based': (983, 4791985514430),\n",
       " 'employing': (984, 4803919420620),\n",
       " 'multi-class': (985, 4806561540420),\n",
       " '72.5': (986, 4807570950000),\n",
       " 'via': (987, 4808057513688),\n",
       " 'pedagogically': (988, 4809832350172),\n",
       " 'interpretation': (989, 4819733510592),\n",
       " 'context': (990, 4823349327680),\n",
       " 'understands': (991, 4823860124160),\n",
       " 'resource': (992, 4831122734880),\n",
       " 'traffic-related': (993, 4835562440940),\n",
       " 'probability': (994, 4852975195296),\n",
       " 'sentence_structures': (995, 4862027706844),\n",
       " 'generally': (996, 4880744428560),\n",
       " 'religion': (997, 4887600764904),\n",
       " 'classification_tasks': (998, 4891621868640),\n",
       " '69.0': (999, 4895725687120),\n",
       " ...}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "potential_siblings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_list = list(potential_siblings.keys())\n",
    "phrase_reprs = [taxo.static_emb[w] for w in vocab_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance = pairwise_distances(phrase_reprs, metric='cosine')\n",
    "clusterer = hdbscan.HDBSCAN(min_cluster_size=2, metric='precomputed')\n",
    "db = clusterer.fit(distance.astype('float64'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = {l:[] for l in set(db.labels_)}\n",
    "for idx, l in enumerate(db.labels_):\n",
    "    clusters[l].append(vocab_list[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: ['extractive_summarization',\n",
       "  'summarization_techniques',\n",
       "  'summarize',\n",
       "  'summarisation',\n",
       "  'summaries',\n",
       "  'summarization'],\n",
       " 1: ['86.93', '96.54', '97.2', '82.67', '93.3', '60.3'],\n",
       " 2: ['0.59',\n",
       "  '0.530',\n",
       "  '0.97',\n",
       "  '0.689',\n",
       "  '0.8638',\n",
       "  '0.9648',\n",
       "  '0.635',\n",
       "  '0.99',\n",
       "  '0.81',\n",
       "  '0.80',\n",
       "  '0.90',\n",
       "  '0.75'],\n",
       " 3: ['assimilation-individualization',\n",
       "  'objectivity-abstraction',\n",
       "  'determination-indetermination',\n",
       "  'nomination-categorization',\n",
       "  'nomination-identification'],\n",
       " 4: ['1988',\n",
       "  '1992',\n",
       "  '2011',\n",
       "  '©2004',\n",
       "  '2012',\n",
       "  '2003',\n",
       "  '2006',\n",
       "  '2009',\n",
       "  '1995',\n",
       "  '2014',\n",
       "  '1980',\n",
       "  '2007',\n",
       "  '2013',\n",
       "  '2010',\n",
       "  '©2010',\n",
       "  '©_springer-verlag',\n",
       "  '©_2011_springer-verlag',\n",
       "  '2005',\n",
       "  '2008'],\n",
       " 5: ['posing',\n",
       "  'mary',\n",
       "  'petersburg',\n",
       "  'highlighting',\n",
       "  'attracts',\n",
       "  'bringing',\n",
       "  'succeeding',\n",
       "  'yielding',\n",
       "  'whereas',\n",
       "  'listings',\n",
       "  'suggesting'],\n",
       " 6: ['manual_annotation',\n",
       "  'annotate',\n",
       "  'annotators',\n",
       "  'annotator',\n",
       "  'annotated_data',\n",
       "  'annotations',\n",
       "  'annotation',\n",
       "  'annotated'],\n",
       " 7: ['method_outperforms',\n",
       "  'outperforming',\n",
       "  'approach_outperforms',\n",
       "  'consistently_outperforms',\n",
       "  'significantly_outperforms',\n",
       "  'outperform',\n",
       "  'outperformed',\n",
       "  'outperforms'],\n",
       " 8: ['convolutional_neural_networks-gated_recurrent_unit',\n",
       "  'graph_convolutional_network',\n",
       "  'bidirectional_lstm',\n",
       "  'convolutional_neural_network',\n",
       "  'convolution',\n",
       "  'convolutional'],\n",
       " 9: ['semantic-embedding_vectors',\n",
       "  'word-_embedding',\n",
       "  'pre-trained_word_embeddings',\n",
       "  'sentence_embedding',\n",
       "  'word-embedding',\n",
       "  'word_embedding',\n",
       "  'embeddings',\n",
       "  'embedding'],\n",
       " 10: ['lexicon',\n",
       "  'lexical',\n",
       "  'lexicons',\n",
       "  'lexical_resources',\n",
       "  'lexical_database'],\n",
       " 11: ['conceptual_categorization',\n",
       "  'categorisation',\n",
       "  'text_categorization',\n",
       "  'document_categorization',\n",
       "  'categorizing',\n",
       "  'categorization',\n",
       "  'categorize'],\n",
       " 12: ['machine_learning',\n",
       "  'machine-learning',\n",
       "  'rule-based',\n",
       "  'corpus-based',\n",
       "  'text-based'],\n",
       " 13: ['learning',\n",
       "  'phrase',\n",
       "  'graph',\n",
       "  'models',\n",
       "  'fusion',\n",
       "  'fuzzy',\n",
       "  'model',\n",
       "  'machine',\n",
       "  'linear',\n",
       "  'optimization',\n",
       "  'hierarchical',\n",
       "  'neural',\n",
       "  'algorithms',\n",
       "  'sampling',\n",
       "  'network',\n",
       "  'algorithm',\n",
       "  'deep',\n",
       "  'technique',\n",
       "  'classification',\n",
       "  'architecture',\n",
       "  'methods',\n",
       "  'language',\n",
       "  'based',\n",
       "  'sequence',\n",
       "  'search',\n",
       "  'statistical',\n",
       "  'approaches',\n",
       "  'rule',\n",
       "  'techniques',\n",
       "  'representations',\n",
       "  'representation',\n",
       "  'semantic',\n",
       "  'ranking',\n",
       "  'component',\n",
       "  'modeling',\n",
       "  'retrieval',\n",
       "  'linguistic',\n",
       "  'framework',\n",
       "  'approach',\n",
       "  'shallow',\n",
       "  'concept',\n",
       "  'tree',\n",
       "  'feature',\n",
       "  'method',\n",
       "  'emotion',\n",
       "  'stemming',\n",
       "  'hybrid',\n",
       "  'map',\n",
       "  'supervised',\n",
       "  'label',\n",
       "  'classifications',\n",
       "  'mining',\n",
       "  'strategy',\n",
       "  'binary',\n",
       "  'technology',\n",
       "  'conditional',\n",
       "  'modelling',\n",
       "  'matching',\n",
       "  'features',\n",
       "  'setting',\n",
       "  'adaptive',\n",
       "  'strategies',\n",
       "  'mapping',\n",
       "  'acoustic',\n",
       "  'rules',\n",
       "  'trajectory',\n",
       "  'textual',\n",
       "  'pattern',\n",
       "  'structure',\n",
       "  'relation',\n",
       "  'labeling',\n",
       "  'knowledge',\n",
       "  'gradient',\n",
       "  'vector',\n",
       "  'embedded',\n",
       "  'transformations',\n",
       "  'greedy',\n",
       "  'temporal',\n",
       "  'local',\n",
       "  'biomedical',\n",
       "  'geometric',\n",
       "  'selection',\n",
       "  'generation',\n",
       "  'random',\n",
       "  'dialogue',\n",
       "  'dynamic',\n",
       "  'weighted',\n",
       "  'mechanism',\n",
       "  'along',\n",
       "  'scheme',\n",
       "  'global',\n",
       "  'filtering',\n",
       "  'module',\n",
       "  'using',\n",
       "  'inference',\n",
       "  'enriched',\n",
       "  'schemes',\n",
       "  'training',\n",
       "  'emotional',\n",
       "  'character',\n",
       "  'learned',\n",
       "  'teacher',\n",
       "  'integrated',\n",
       "  'residual',\n",
       "  'joint',\n",
       "  'computing',\n",
       "  'term',\n",
       "  'multimedia',\n",
       "  'scoring',\n",
       "  'attack',\n",
       "  ',',\n",
       "  'design',\n",
       "  'extraction',\n",
       "  'construction',\n",
       "  'attention',\n",
       "  'text',\n",
       "  'theory',\n",
       "  '(',\n",
       "  'formulation',\n",
       "  'analysis',\n",
       "  'could',\n",
       "  'dictionary',\n",
       "  'function',\n",
       "  'graphs',\n",
       "  'visual',\n",
       "  'morphological',\n",
       "  'tools',\n",
       "  'word',\n",
       "  'standard',\n",
       "  'xml',\n",
       "  'loss',\n",
       "  'classifiers',\n",
       "  'system',\n",
       "  'information',\n",
       "  'grammar',\n",
       "  'adaptation',\n",
       "  'distribution',\n",
       "  'paradigm',\n",
       "  'procedure',\n",
       "  'layer',\n",
       "  'community',\n",
       "  'processes',\n",
       "  'sample',\n",
       "  'weights',\n",
       "  'evaluation',\n",
       "  'data',\n",
       "  'solutions',\n",
       "  'error',\n",
       "  'distance',\n",
       "  'utilizing',\n",
       "  'methodology',\n",
       "  'performs',\n",
       "  'parameters',\n",
       "  'enhanced',\n",
       "  'artificial',\n",
       "  'without',\n",
       "  'bilingual',\n",
       "  'variant',\n",
       "  'filter',\n",
       "  'prediction',\n",
       "  'pipeline',\n",
       "  'complementary',\n",
       "  'automated',\n",
       "  'criterion',\n",
       "  'sentiment',\n",
       "  'measures',\n",
       "  'works',\n",
       "  'combined',\n",
       "  'node',\n",
       "  'active',\n",
       "  'medical',\n",
       "  'functions',\n",
       "  'encoding',\n",
       "  'compression',\n",
       "  'argument',\n",
       "  'light',\n",
       "  'produced',\n",
       "  'examples',\n",
       "  'principle',\n",
       "  '.',\n",
       "  ';',\n",
       "  'sequential',\n",
       "  'uncertainty',\n",
       "  'human',\n",
       "  'across',\n",
       "  'density',\n",
       "  'prior',\n",
       "  'category',\n",
       "  'labels',\n",
       "  'group',\n",
       "  'processing',\n",
       "  'interaction',\n",
       "  'measure',\n",
       "  'computational',\n",
       "  'prompt',\n",
       "  'distributions',\n",
       "  'soft',\n",
       "  '”',\n",
       "  'gives',\n",
       "  'block',\n",
       "  'usage',\n",
       "  'parallel',\n",
       "  'connections',\n",
       "  'transform',\n",
       "  'vectors',\n",
       "  'perspective',\n",
       "  'operation',\n",
       "  'simple',\n",
       "  'functional',\n",
       "  'requirements',\n",
       "  'adapted',\n",
       "  'transfer',\n",
       "  'simultaneously',\n",
       "  'open',\n",
       "  'independent',\n",
       "  'systems',\n",
       "  'controlled',\n",
       "  'multiple',\n",
       "  'correlation',\n",
       "  'may',\n",
       "  'discovery',\n",
       "  'together',\n",
       "  'improved',\n",
       "  'tool',\n",
       "  'expert',\n",
       "  'tasks',\n",
       "  'advanced',\n",
       "  'decision',\n",
       "  'concepts',\n",
       "  'intelligence',\n",
       "  'test',\n",
       "  'process',\n",
       "  'distributed',\n",
       "  'presentation',\n",
       "  'integration',\n",
       "  'synthetic',\n",
       "  'topic',\n",
       "  'combining',\n",
       "  'working',\n",
       "  'several',\n",
       "  'architectural',\n",
       "  'evolutionary',\n",
       "  'supports',\n",
       "  'improves',\n",
       "  'computer',\n",
       "  'maximum',\n",
       "  'completely',\n",
       "  'student',\n",
       "  'samples',\n",
       "  'spatial',\n",
       "  'tests',\n",
       "  'structures',\n",
       "  'continuous',\n",
       "  'translation',\n",
       "  'count',\n",
       "  'conversion',\n",
       "  'common',\n",
       "  'patterns',\n",
       "  'sarcasm',\n",
       "  'speaker',\n",
       "  'combination',\n",
       "  'previously',\n",
       "  'labeled',\n",
       "  'class_label',\n",
       "  'implementation',\n",
       "  'image',\n",
       "  'fused',\n",
       "  'instances',\n",
       "  'properties',\n",
       "  'rating',\n",
       "  'alone',\n",
       "  'modified',\n",
       "  'baseline',\n",
       "  '-',\n",
       "  'classic',\n",
       "  'related',\n",
       "  'intelligent',\n",
       "  'explanations',\n",
       "  'translations',\n",
       "  'static',\n",
       "  'matrix',\n",
       "  'referring',\n",
       "  'relational',\n",
       "  'patent',\n",
       "  'class',\n",
       "  'manually',\n",
       "  'task',\n",
       "  'database',\n",
       "  'recognition',\n",
       "  'various',\n",
       "  'aspect',\n",
       "  'space',\n",
       "  'relations',\n",
       "  '“',\n",
       "  'calculation',\n",
       "  'auxiliary',\n",
       "  'solution',\n",
       "  'type',\n",
       "  'modules',\n",
       "  'capability',\n",
       "  'automatic',\n",
       "  'bias',\n",
       "  'ambiguity',\n",
       "  'semantics',\n",
       "  'query',\n",
       "  'application',\n",
       "  'analytical',\n",
       "  'metric',\n",
       "  'universal',\n",
       "  'smart',\n",
       "  'among',\n",
       "  'attribute',\n",
       "  'predictions',\n",
       "  'facial',\n",
       "  'shared',\n",
       "  'generic',\n",
       "  'long',\n",
       "  'collection',\n",
       "  'formal',\n",
       "  'weight',\n",
       "  'efficient',\n",
       "  'gene',\n",
       "  'gender',\n",
       "  'directly',\n",
       "  'evidence',\n",
       "  'set',\n",
       "  'typing',\n",
       "  'automatically',\n",
       "  'separate',\n",
       "  'generated',\n",
       "  'relationships',\n",
       "  'trained',\n",
       "  'corpus',\n",
       "  'arabic',\n",
       "  'named',\n",
       "  'like',\n",
       "  'document',\n",
       "  'index',\n",
       "  'moral',\n",
       "  'studies',\n",
       "  'provides',\n",
       "  'social',\n",
       "  'numerous',\n",
       "  'message',\n",
       "  'structural',\n",
       "  'capabilities',\n",
       "  'yields',\n",
       "  'software',\n",
       "  'components',\n",
       "  'review',\n",
       "  'requires',\n",
       "  'segment',\n",
       "  'link',\n",
       "  'classification_task',\n",
       "  'images',\n",
       "  'document_representation',\n",
       "  'partition',\n",
       "  'extracted',\n",
       "  'adjacent',\n",
       "  'score',\n",
       "  'pure',\n",
       "  'scientific',\n",
       "  'different',\n",
       "  'associated',\n",
       "  'wikipedia',\n",
       "  'discrete',\n",
       "  'explicit',\n",
       "  'similar',\n",
       "  'level',\n",
       "  'generator',\n",
       "  'call',\n",
       "  'speech',\n",
       "  'increases',\n",
       "  'representative',\n",
       "  'representing',\n",
       "  'outputs',\n",
       "  'location',\n",
       "  'prototype',\n",
       "  'criteria',\n",
       "  'applications',\n",
       "  'grammatical',\n",
       "  'similarity',\n",
       "  'called',\n",
       "  'success',\n",
       "  'parameter',\n",
       "  'sentences',\n",
       "  'links',\n",
       "  'employing',\n",
       "  'via',\n",
       "  'interpretation',\n",
       "  'context',\n",
       "  'resource',\n",
       "  'probability',\n",
       "  'generally',\n",
       "  'classification_tasks',\n",
       "  'manual',\n",
       "  'news',\n",
       "  'cognitive',\n",
       "  'values',\n",
       "  'classical',\n",
       "  'handwriting',\n",
       "  'content',\n",
       "  'comment',\n",
       "  'general',\n",
       "  'single',\n",
       "  'performance',\n",
       "  'subjective',\n",
       "  'financial',\n",
       "  'sources',\n",
       "  'clinical',\n",
       "  'requirement',\n",
       "  'word_representation',\n",
       "  'entity',\n",
       "  'drug',\n",
       "  'typical',\n",
       "  'variables',\n",
       "  'efficiently',\n",
       "  'verification',\n",
       "  'value',\n",
       "  'encoded',\n",
       "  'analyses',\n",
       "  'one',\n",
       "  'communication',\n",
       "  'scenario',\n",
       "  'broad',\n",
       "  'two',\n",
       "  '[',\n",
       "  'points',\n",
       "  'confidence',\n",
       "  'new',\n",
       "  'power',\n",
       "  'traditional',\n",
       "  'pair',\n",
       "  'plays',\n",
       "  'resolution',\n",
       "  'problems',\n",
       "  'reading',\n",
       "  'narrative',\n",
       "  'severity',\n",
       "  'would',\n",
       "  'finding',\n",
       "  'object',\n",
       "  'statistics',\n",
       "  'mostly',\n",
       "  'cloud',\n",
       "  'form',\n",
       "  'pairs',\n",
       "  'within',\n",
       "  'settings',\n",
       "  'outcomes',\n",
       "  'due',\n",
       "  'fast',\n",
       "  'point',\n",
       "  'technical',\n",
       "  'recommendation',\n",
       "  'built',\n",
       "  'resources',\n",
       "  'integrating',\n",
       "  'objective',\n",
       "  'video',\n",
       "  'ensuing',\n",
       "  'short',\n",
       "  'rather',\n",
       "  'questions',\n",
       "  'source',\n",
       "  'textual_features',\n",
       "  'technologies',\n",
       "  'selected',\n",
       "  'obtained',\n",
       "  'conceptual',\n",
       "  'lower',\n",
       "  'chinese',\n",
       "  'problem',\n",
       "  'job',\n",
       "  'scale',\n",
       "  'utilizes',\n",
       "  'contrasting',\n",
       "  'question',\n",
       "  'existing',\n",
       "  'clusters',\n",
       "  'separately',\n",
       "  'jointly',\n",
       "  '?',\n",
       "  'balanced',\n",
       "  'cues',\n",
       "  'scripts',\n",
       "  'control',\n",
       "  'compact',\n",
       "  'user',\n",
       "  'conventional',\n",
       "  'feedback',\n",
       "  'list',\n",
       "  'developers',\n",
       "  'strong',\n",
       "  'units',\n",
       "  'verbs',\n",
       "  'highly',\n",
       "  'sentiment_classification',\n",
       "  'reach',\n",
       "  'natural',\n",
       "  'additional',\n",
       "  'program',\n",
       "  'depends',\n",
       "  'body',\n",
       "  'dimensions',\n",
       "  'followed',\n",
       "  'output',\n",
       "  'targeted',\n",
       "  'structured',\n",
       "  'reduced',\n",
       "  'according',\n",
       "  'missing',\n",
       "  'track',\n",
       "  'becomes',\n",
       "  'affects',\n",
       "  'project',\n",
       "  'empirical',\n",
       "  'historical',\n",
       "  'effectively',\n",
       "  'quantitative',\n",
       "  'nodes',\n",
       "  'full',\n",
       "  'robust',\n",
       "  'code',\n",
       "  'descriptive',\n",
       "  'reported',\n",
       "  'performances',\n",
       "  'predicted',\n",
       "  'sensitive',\n",
       "  'complete',\n",
       "  'healthcare',\n",
       "  'detection',\n",
       "  'complex',\n",
       "  'online',\n",
       "  'constructed',\n",
       "  'deploy',\n",
       "  'classes',\n",
       "  'unique',\n",
       "  'tend',\n",
       "  'autonomous',\n",
       "  'frequency',\n",
       "  'identified',\n",
       "  'provided',\n",
       "  'early',\n",
       "  'captures',\n",
       "  'seems',\n",
       "  'successfully',\n",
       "  'must',\n",
       "  'security',\n",
       "  'extracts',\n",
       "  'words',\n",
       "  'interactive',\n",
       "  'documents',\n",
       "  'mobile',\n",
       "  'diverse',\n",
       "  'information_extraction',\n",
       "  'judgment',\n",
       "  'generating',\n",
       "  'effective',\n",
       "  'categories',\n",
       "  'real',\n",
       "  'land',\n",
       "  'contribute',\n",
       "  'texts',\n",
       "  'learns',\n",
       "  'helps',\n",
       "  'description',\n",
       "  'practical',\n",
       "  'match',\n",
       "  'generates',\n",
       "  'state',\n",
       "  'validation',\n",
       "  'changes',\n",
       "  'needs',\n",
       "  'noise',\n",
       "  'accelerated',\n",
       "  'created',\n",
       "  'phonetic',\n",
       "  'hypothesis',\n",
       "  'special',\n",
       "  'attempts',\n",
       "  'significantly',\n",
       "  'domain',\n",
       "  'commonly',\n",
       "  'input',\n",
       "  'political',\n",
       "  'differences',\n",
       "  'way',\n",
       "  'thai',\n",
       "  'groups',\n",
       "  'expanding',\n",
       "  'direct',\n",
       "  'uses',\n",
       "  'event',\n",
       "  'capturing',\n",
       "  'preliminary',\n",
       "  'extreme',\n",
       "  'derived',\n",
       "  'instead',\n",
       "  'attributes',\n",
       "  'relative',\n",
       "  'performing',\n",
       "  'frequent',\n",
       "  'means',\n",
       "  'relevance',\n",
       "  'candidate',\n",
       "  'area',\n",
       "  'responses',\n",
       "  'stance',\n",
       "  'achieved',\n",
       "  'handling',\n",
       "  'understanding',\n",
       "  'relies',\n",
       "  'part',\n",
       "  'bug',\n",
       "  'hierarchy',\n",
       "  'conditions',\n",
       "  'blog',\n",
       "  'extended',\n",
       "  'rich',\n",
       "  'optimal',\n",
       "  'assessment',\n",
       "  'public',\n",
       "  'customer',\n",
       "  'automation',\n",
       "  'expression',\n",
       "  'document_representations',\n",
       "  'correctly',\n",
       "  'action',\n",
       "  'native',\n",
       "  'policy',\n",
       "  'numerical',\n",
       "  'mixed',\n",
       "  'required',\n",
       "  'leads',\n",
       "  'training_data',\n",
       "  'many',\n",
       "  'alternative',\n",
       "  'platform',\n",
       "  'speed',\n",
       "  'detected',\n",
       "  'disease',\n",
       "  'databases',\n",
       "  'leverage',\n",
       "  'perform',\n",
       "  'distinctive',\n",
       "  'claims',\n",
       "  'recommendations',\n",
       "  'definition',\n",
       "  'condition',\n",
       "  'reviews',\n",
       "  'rely',\n",
       "  'coded',\n",
       "  'even',\n",
       "  'play',\n",
       "  'estimated',\n",
       "  'previous',\n",
       "  'initial',\n",
       "  'industry',\n",
       "  'employs',\n",
       "  'normally',\n",
       "  'tags',\n",
       "  'recalls',\n",
       "  'deals',\n",
       "  'faster',\n",
       "  'use',\n",
       "  'behavior',\n",
       "  'psychological',\n",
       "  'rate',\n",
       "  'consumer',\n",
       "  'pose',\n",
       "  'applying',\n",
       "  'audio',\n",
       "  'consists',\n",
       "  'companies',\n",
       "  'emerging',\n",
       "  'case',\n",
       "  'usually',\n",
       "  'involves',\n",
       "  'three',\n",
       "  'arguments',\n",
       "  'root',\n",
       "  'consumers',\n",
       "  'patents',\n",
       "  'six',\n",
       "  'used',\n",
       "  'causes',\n",
       "  'recent',\n",
       "  'support',\n",
       "  'testing',\n",
       "  'script',\n",
       "  'often',\n",
       "  'result',\n",
       "  'require',\n",
       "  'collections',\n",
       "  'basic',\n",
       "  'explicitly',\n",
       "  'compared',\n",
       "  'change',\n",
       "  'commodity',\n",
       "  'corresponding',\n",
       "  'cultural',\n",
       "  'taxonomy',\n",
       "  'efforts',\n",
       "  'cases',\n",
       "  'variations',\n",
       "  'sentence',\n",
       "  'sequences',\n",
       "  'sufficiently',\n",
       "  'communities',\n",
       "  'known',\n",
       "  'position',\n",
       "  'useful',\n",
       "  'systematically',\n",
       "  'selecting',\n",
       "  'elements',\n",
       "  'experience',\n",
       "  'either',\n",
       "  'makes',\n",
       "  'ratings',\n",
       "  'five',\n",
       "  'physical',\n",
       "  'potential',\n",
       "  'descriptions',\n",
       "  'subject',\n",
       "  'textual_information',\n",
       "  'types',\n",
       "  'largely',\n",
       "  'food',\n",
       "  'scenes',\n",
       "  'applied',\n",
       "  'aligned',\n",
       "  'exploits',\n",
       "  'provide',\n",
       "  'f1',\n",
       "  'effects',\n",
       "  'research',\n",
       "  'characters',\n",
       "  'represents',\n",
       "  'objects',\n",
       "  'phrases',\n",
       "  'unified',\n",
       "  'facilitates',\n",
       "  'korean',\n",
       "  'duplicate',\n",
       "  'conversation',\n",
       "  'mainly',\n",
       "  'decisions',\n",
       "  'size',\n",
       "  'correct',\n",
       "  'flow',\n",
       "  'high',\n",
       "  'identifying',\n",
       "  'comparison',\n",
       "  'incorporating',\n",
       "  'parts',\n",
       "  'appears',\n",
       "  'characteristics',\n",
       "  'quickly',\n",
       "  'trend',\n",
       "  'combine',\n",
       "  'mentioned',\n",
       "  'fully',\n",
       "  'individual',\n",
       "  'monitoring',\n",
       "  'analyzing',\n",
       "  'powerful',\n",
       "  'less',\n",
       "  'users',\n",
       "  'much',\n",
       "  'successful',\n",
       "  'english',\n",
       "  'book',\n",
       "  'transforming',\n",
       "  'patient',\n",
       "  'emotional_states',\n",
       "  'fixed',\n",
       "  'suggested',\n",
       "  'accurate',\n",
       "  'printed',\n",
       "  'learn',\n",
       "  'risk',\n",
       "  'top',\n",
       "  'constructing',\n",
       "  'response',\n",
       "  'novel',\n",
       "  'towards',\n",
       "  'inside',\n",
       "  'relatively',\n",
       "  'modeled',\n",
       "  'implemented',\n",
       "  'target',\n",
       "  'narratives',\n",
       "  'intensity',\n",
       "  'property',\n",
       "  'topics',\n",
       "  'vocabulary',\n",
       "  'shows',\n",
       "  'update',\n",
       "  'relevant',\n",
       "  'classification_accuracy',\n",
       "  'focus',\n",
       "  'unit',\n",
       "  'progress',\n",
       "  'messages',\n",
       "  'internal',\n",
       "  'integrate',\n",
       "  'ability',\n",
       "  'carry',\n",
       "  'actions',\n",
       "  'relationship',\n",
       "  'seven',\n",
       "  'word_sequence',\n",
       "  'reference',\n",
       "  'offer',\n",
       "  'popular',\n",
       "  'business',\n",
       "  '11',\n",
       "  'considering',\n",
       "  'proper',\n",
       "  'educational',\n",
       "  'legal',\n",
       "  'indeed',\n",
       "  'roles',\n",
       "  'inspection',\n",
       "  'stock',\n",
       "  'utilize',\n",
       "  'twitter',\n",
       "  'might',\n",
       "  'importance',\n",
       "  'takes',\n",
       "  'greatly',\n",
       "  'acquired',\n",
       "  'flexible',\n",
       "  'established',\n",
       "  'text_regions',\n",
       "  'experiments',\n",
       "  'document_classification',\n",
       "  'almost',\n",
       "  'levels',\n",
       "  'frequently',\n",
       "  'association',\n",
       "  'introduced',\n",
       "  'items',\n",
       "  'current',\n",
       "  'depend',\n",
       "  'smaller',\n",
       "  'books',\n",
       "  'exploit',\n",
       "  'close',\n",
       "  'developed',\n",
       "  'segments',\n",
       "  'four',\n",
       "  'meaningful',\n",
       "  'document_retrieval',\n",
       "  'every',\n",
       "  'answer',\n",
       "  'genuine',\n",
       "  'marketing',\n",
       "  'ten',\n",
       "  'sentiments',\n",
       "  'unseen',\n",
       "  'enables',\n",
       "  'experimentation',\n",
       "  'emotions',\n",
       "  'resulting',\n",
       "  'predicting',\n",
       "  'classified',\n",
       "  'consistent',\n",
       "  'detecting',\n",
       "  'entities',\n",
       "  'comprehensive',\n",
       "  'subsequent',\n",
       "  'bugs',\n",
       "  'answers',\n",
       "  'status',\n",
       "  'distinct',\n",
       "  'regarding',\n",
       "  'highly_accurate',\n",
       "  'categorized',\n",
       "  'prominent',\n",
       "  'allows',\n",
       "  'apparently',\n",
       "  'building',\n",
       "  'produce',\n",
       "  'designed',\n",
       "  'improvements',\n",
       "  'quality',\n",
       "  'mined',\n",
       "  'literature',\n",
       "  'widely',\n",
       "  'naturally',\n",
       "  'regions',\n",
       "  'small',\n",
       "  'abstracts',\n",
       "  'course',\n",
       "  'sparse',\n",
       "  'enhancing',\n",
       "  'safety',\n",
       "  'combines',\n",
       "  'complexity',\n",
       "  'generate',\n",
       "  'document_image',\n",
       "  'varying',\n",
       "  'existing_approaches',\n",
       "  'web',\n",
       "  'precision',\n",
       "  'builds',\n",
       "  'retrieve',\n",
       "  'recognized',\n",
       "  'systematic',\n",
       "  'raw',\n",
       "  'textual_data',\n",
       "  'mapped',\n",
       "  'extends',\n",
       "  'large',\n",
       "  'reliable',\n",
       "  'suitable',\n",
       "  'comprised',\n",
       "  'another',\n",
       "  'hotels',\n",
       "  'applicable',\n",
       "  'taking',\n",
       "  'implementing',\n",
       "  'include',\n",
       "  'adding',\n",
       "  'confirm',\n",
       "  'tamil',\n",
       "  'possible',\n",
       "  'precise',\n",
       "  'extensive',\n",
       "  'currently',\n",
       "  'defined',\n",
       "  'sensitivity',\n",
       "  'creating',\n",
       "  'received',\n",
       "  'defeat',\n",
       "  'good',\n",
       "  'evaluating',\n",
       "  'capture',\n",
       "  'performed',\n",
       "  'already',\n",
       "  'newspaper',\n",
       "  'increase',\n",
       "  'existing_methods',\n",
       "  'events',\n",
       "  'greek',\n",
       "  \"'\",\n",
       "  'situations',\n",
       "  '5',\n",
       "  'accuracy',\n",
       "  'investigation',\n",
       "  'diversity',\n",
       "  'taken',\n",
       "  'comparisons',\n",
       "  'producing',\n",
       "  'researchers',\n",
       "  'sense',\n",
       "  'represented',\n",
       "  'potentially',\n",
       "  'expected',\n",
       "  'employed',\n",
       "  'written',\n",
       "  'lastly',\n",
       "  'unknown',\n",
       "  'restaurant',\n",
       "  'videos',\n",
       "  'collected',\n",
       "  'determines',\n",
       "  'seek',\n",
       "  'areas',\n",
       "  'comments',\n",
       "  'select',\n",
       "  'advantages',\n",
       "  'consisting',\n",
       "  'health',\n",
       "  'complicated',\n",
       "  'streams',\n",
       "  'nine',\n",
       "  'previous_studies',\n",
       "  'accurately',\n",
       "  'poses',\n",
       "  'given',\n",
       "  'also',\n",
       "  'recognise',\n",
       "  'transportation',\n",
       "  'students',\n",
       "  'activities',\n",
       "  'look',\n",
       "  'valuable',\n",
       "  'appropriate',\n",
       "  'later',\n",
       "  'meaning',\n",
       "  'treated',\n",
       "  'dataset',\n",
       "  'report',\n",
       "  'reduces',\n",
       "  'significant',\n",
       "  'feasible',\n",
       "  'thematic',\n",
       "  ...],\n",
       " 14: ['multi-label',\n",
       "  'multi-scale',\n",
       "  'multi-level',\n",
       "  'multi-label_classification',\n",
       "  'multi-domain',\n",
       "  'multi-class',\n",
       "  'multi-input',\n",
       "  'multi-layered',\n",
       "  'multi-modal',\n",
       "  'cross-domain'],\n",
       " -1: ['deep_learning',\n",
       "  'academy',\n",
       "  'supervised_learning',\n",
       "  'deep_belief_network',\n",
       "  'ctas',\n",
       "  'pivotal',\n",
       "  'ensemble_learning',\n",
       "  'supervised_machine_learning',\n",
       "  'supervised_topic_model',\n",
       "  'supervised_machine_learning_algorithms',\n",
       "  'dan',\n",
       "  'deep_neural_network',\n",
       "  'complexity-based',\n",
       "  'k-bert',\n",
       "  'fasttext',\n",
       "  'historically',\n",
       "  '84.4',\n",
       "  'decision_tree',\n",
       "  'path-lexicalization',\n",
       "  'strengthen',\n",
       "  'unsupervised_learning',\n",
       "  'regression',\n",
       "  'catalogue',\n",
       "  'artificial_neural_network',\n",
       "  'transitivity',\n",
       "  'divisions',\n",
       "  'artificial_intelligence',\n",
       "  'machine_learning-based',\n",
       "  'bayesian',\n",
       "  'curvature-based',\n",
       "  'unsupervised_clustering',\n",
       "  'repeatedly',\n",
       "  'interactional',\n",
       "  'unsupervised',\n",
       "  'attention-mechanism-based',\n",
       "  'gcc',\n",
       "  'spie',\n",
       "  'syndromes',\n",
       "  'networks',\n",
       "  'european',\n",
       "  'slavic_languages',\n",
       "  'semi-supervised',\n",
       "  'traditional_machine_learning',\n",
       "  'mlp-based',\n",
       "  'softmax',\n",
       "  'reinforcement_learning',\n",
       "  'harms',\n",
       "  'infers',\n",
       "  'featured',\n",
       "  'eastern',\n",
       "  'darkness',\n",
       "  'weakly_supervised',\n",
       "  '450',\n",
       "  'felicity',\n",
       "  'salle',\n",
       "  'inc.',\n",
       "  'pulling',\n",
       "  'x-vector',\n",
       "  'conversely',\n",
       "  'hie',\n",
       "  'recurrent_neural_network',\n",
       "  'fine',\n",
       "  'buy/sell',\n",
       "  'partially_supervised',\n",
       "  'non-grounded',\n",
       "  'transcriptional',\n",
       "  'topic_modelling',\n",
       "  'two-teacher',\n",
       "  'feature-based',\n",
       "  'incompatible',\n",
       "  '280',\n",
       "  'spikes',\n",
       "  'portfolio',\n",
       "  'resumption',\n",
       "  'r-cnn',\n",
       "  'contrastive_learning',\n",
       "  'phenotypes',\n",
       "  'big_data',\n",
       "  'som-based',\n",
       "  'distant_supervised',\n",
       "  'variational_bayes',\n",
       "  'communication_studies',\n",
       "  '1dsom',\n",
       "  'k-means',\n",
       "  'text-guided',\n",
       "  'wilson',\n",
       "  'attractive',\n",
       "  'advancing',\n",
       "  'quran',\n",
       "  'systematization',\n",
       "  'alternate',\n",
       "  'relation_facts',\n",
       "  'americans',\n",
       "  'compa-rable',\n",
       "  'neural_network-based',\n",
       "  'signs',\n",
       "  'leeuwen',\n",
       "  'multi-question_classification',\n",
       "  'averages',\n",
       "  'conservation',\n",
       "  '22',\n",
       "  'interrogation',\n",
       "  'god',\n",
       "  'servicing',\n",
       "  'accusative',\n",
       "  '*',\n",
       "  'softmax_classifier',\n",
       "  'international_classification_of_diseases',\n",
       "  'psycinfo',\n",
       "  'multi-agent',\n",
       "  'xenophobic',\n",
       "  'statistical_tests',\n",
       "  'gan-based',\n",
       "  'reimers',\n",
       "  'unableto',\n",
       "  'natural_language',\n",
       "  'presumably',\n",
       "  'classifier',\n",
       "  '1237',\n",
       "  'transformer-based',\n",
       "  '2.131',\n",
       "  'alexnet-l',\n",
       "  'sellers',\n",
       "  'healthy_subjects',\n",
       "  'decision_level',\n",
       "  'attesting',\n",
       "  'topic_models',\n",
       "  'sift',\n",
       "  'image_analysis',\n",
       "  'lda-based',\n",
       "  'diffusion',\n",
       "  'machine-learning-based',\n",
       "  'charge',\n",
       "  '1987',\n",
       "  'fuzzy_set',\n",
       "  'ss',\n",
       "  'classifier-free',\n",
       "  'rights_reserved',\n",
       "  'porto',\n",
       "  'rtsl',\n",
       "  '664',\n",
       "  '246',\n",
       "  'embed-dings',\n",
       "  'joint-entity-sentiment-topic',\n",
       "  'grounds',\n",
       "  'archival',\n",
       "  '579199',\n",
       "  'topology-based',\n",
       "  '-word',\n",
       "  'shark',\n",
       "  'cnn-based',\n",
       "  'shapes',\n",
       "  'instruction',\n",
       "  'misunderstanding',\n",
       "  'acoustic-textual',\n",
       "  'eleven',\n",
       "  'inquiry',\n",
       "  'interfering',\n",
       "  'moan',\n",
       "  '9945',\n",
       "  'literary_texts',\n",
       "  'south_wales',\n",
       "  'june',\n",
       "  'whatever',\n",
       "  'la-gan',\n",
       "  'janda',\n",
       "  'character_segmentation',\n",
       "  '—',\n",
       "  'ethnicity-related',\n",
       "  '378',\n",
       "  'cnn',\n",
       "  'operators',\n",
       "  'fictional',\n",
       "  'bottle',\n",
       "  '375',\n",
       "  '1266',\n",
       "  'soft_label',\n",
       "  '12,13',\n",
       "  'ref',\n",
       "  'reasoning',\n",
       "  '94.8',\n",
       "  'git',\n",
       "  'mapbox',\n",
       "  'functional_analysis',\n",
       "  'semantic-interactive',\n",
       "  'irrespective',\n",
       "  '0.25',\n",
       "  'scale_invariant_feature_transform',\n",
       "  'multi-hop',\n",
       "  'text-projection',\n",
       "  'volatility',\n",
       "  'decomposition',\n",
       "  'mathematical',\n",
       "  'external_knowledge-base',\n",
       "  'hmm',\n",
       "  'baudouin',\n",
       "  'cnnbatsk',\n",
       "  'subtlety',\n",
       "  'atec',\n",
       "  'post-purchase',\n",
       "  '62.74',\n",
       "  'invested',\n",
       "  'wall',\n",
       "  'scream',\n",
       "  'down-sampled',\n",
       "  'augmented_data',\n",
       "  'la_nación',\n",
       "  'sbnn',\n",
       "  'voicing',\n",
       "  'ā',\n",
       "  'delineates',\n",
       "  'resistance',\n",
       "  'naïve_bayes',\n",
       "  'š',\n",
       "  'gcn-based',\n",
       "  'dbn',\n",
       "  'north_africa',\n",
       "  'engineering',\n",
       "  'mono-objective',\n",
       "  'evoke',\n",
       "  'consistently_improves',\n",
       "  'deep‐learning‐based',\n",
       "  'late_fusion',\n",
       "  'e2e-asr',\n",
       "  'othering',\n",
       "  'unhappy',\n",
       "  'job_interview',\n",
       "  'conversations',\n",
       "  'gun',\n",
       "  'learningsetting',\n",
       "  'prepares',\n",
       "  'resumed',\n",
       "  'college',\n",
       "  'soundly',\n",
       "  'traces',\n",
       "  'back-propagation',\n",
       "  'manner',\n",
       "  'dual-view',\n",
       "  'rankings',\n",
       "  'bot',\n",
       "  'heritability',\n",
       "  'generative_model',\n",
       "  'knowledge-based',\n",
       "  'metric-learning-based',\n",
       "  'distant_supervision',\n",
       "  'cifar-10',\n",
       "  'submodular',\n",
       "  'theories',\n",
       "  'fuzzy_rules',\n",
       "  'disadvantage',\n",
       "  '102',\n",
       "  'signers',\n",
       "  'homogenous',\n",
       "  'reviewing',\n",
       "  'centuries',\n",
       "  'la',\n",
       "  'al.',\n",
       "  'flowing',\n",
       "  'beforethe',\n",
       "  'fatal',\n",
       "  'müller',\n",
       "  'lexicalization',\n",
       "  \"'flower\",\n",
       "  'regular_expression',\n",
       "  'job_seekers',\n",
       "  'uncover',\n",
       "  'machine_translation',\n",
       "  'ii',\n",
       "  'referendum',\n",
       "  'ccl',\n",
       "  'constrained',\n",
       "  'perceiver',\n",
       "  \"'big_data\",\n",
       "  'phonological',\n",
       "  '1d-som',\n",
       "  'visual-semantic',\n",
       "  '1990',\n",
       "  'coarse_grained',\n",
       "  'consequences',\n",
       "  'weakly-supervised',\n",
       "  'effortlessly',\n",
       "  'lakoff',\n",
       "  'justification',\n",
       "  'vehicle',\n",
       "  'urban_areas',\n",
       "  'competing',\n",
       "  'panel',\n",
       "  'restriction',\n",
       "  'crypto-currency',\n",
       "  'augmentation-agnostic',\n",
       "  'dcgan-based',\n",
       "  'menu',\n",
       "  'glove',\n",
       "  'interestingness',\n",
       "  'requirements_management',\n",
       "  'supervisory',\n",
       "  'weight_distribution',\n",
       "  'entropy',\n",
       "  'abusive',\n",
       "  'sensitive_words',\n",
       "  'underexplored',\n",
       "  'publics',\n",
       "  'devil',\n",
       "  'end-users',\n",
       "  'edge-reasoning',\n",
       "  '39',\n",
       "  'smote',\n",
       "  'extractions',\n",
       "  'classification_scheme',\n",
       "  'recent_spanbert',\n",
       "  'within-',\n",
       "  'dna',\n",
       "  'advancement',\n",
       "  'vowel',\n",
       "  'rendering',\n",
       "  'municipality',\n",
       "  'lsi-1dsom',\n",
       "  '81.51',\n",
       "  'policy_makers',\n",
       "  'indus',\n",
       "  'italic',\n",
       "  'hamza',\n",
       "  'rising',\n",
       "  'anchor-based',\n",
       "  'augmented',\n",
       "  '23.3',\n",
       "  'dravidian',\n",
       "  'f1m',\n",
       "  'equivalents',\n",
       "  'de-arteaga',\n",
       "  'hour',\n",
       "  'nightclub',\n",
       "  'sequence_alignment',\n",
       "  'thai-japanese',\n",
       "  '71.0',\n",
       "  'preventive',\n",
       "  'leaders',\n",
       "  'insurance-based',\n",
       "  'data-deficient',\n",
       "  'diagnostic',\n",
       "  'apa',\n",
       "  'failure_modes',\n",
       "  'assistant',\n",
       "  'analog',\n",
       "  'ganter',\n",
       "  'inquiries',\n",
       "  'pertaining',\n",
       "  'polynomial',\n",
       "  'insignificance',\n",
       "  'polite-rl',\n",
       "  'informing',\n",
       "  'transitions',\n",
       "  'acoustic_scene_classification',\n",
       "  'outline',\n",
       "  'tamil_language',\n",
       "  'advocates',\n",
       "  'user-interfaces',\n",
       "  'canada',\n",
       "  'doctor–patient',\n",
       "  'topic_model',\n",
       "  'connectionist',\n",
       "  'holding_companies',\n",
       "  'escaping',\n",
       "  'handshape',\n",
       "  'human_rights',\n",
       "  '26.4',\n",
       "  'spend',\n",
       "  'military',\n",
       "  'wishes',\n",
       "  '©_2010_springer-verlag_berlin_heidelberg',\n",
       "  'charles',\n",
       "  'retrieval-based',\n",
       "  'marginalize',\n",
       "  'paris',\n",
       "  'overcoming',\n",
       "  'morbidity',\n",
       "  'faults',\n",
       "  'mythology',\n",
       "  '65.97',\n",
       "  'information-theoretic',\n",
       "  'itemization',\n",
       "  'operator/',\n",
       "  'minds',\n",
       "  'presumptive',\n",
       "  'gaussians',\n",
       "  '27',\n",
       "  'use/cover',\n",
       "  'nineteen',\n",
       "  '52.5',\n",
       "  'back',\n",
       "  'cbms',\n",
       "  'compression-based',\n",
       "  'american',\n",
       "  'gmail',\n",
       "  'outdated',\n",
       "  'incompleteness',\n",
       "  'reclassifying',\n",
       "  'signifies',\n",
       "  'logic',\n",
       "  'conception',\n",
       "  'sacrificing',\n",
       "  'hlspc',\n",
       "  'aphasia',\n",
       "  'operator',\n",
       "  'content-based',\n",
       "  'declension',\n",
       "  'domain_adaptation',\n",
       "  'latch',\n",
       "  'fraud',\n",
       "  'hesitant_fuzzy',\n",
       "  'polygonal',\n",
       "  'qas',\n",
       "  'image_processing',\n",
       "  '93.6',\n",
       "  'associate',\n",
       "  'cgdialog',\n",
       "  'bias-corrected',\n",
       "  'algebra',\n",
       "  'calzolari',\n",
       "  'gigantic',\n",
       "  'tommola',\n",
       "  'nle-alone',\n",
       "  'downstream_classification_tasks',\n",
       "  'ascending',\n",
       "  'single-datset',\n",
       "  'sense_disambiguation',\n",
       "  'approached',\n",
       "  'till',\n",
       "  'me/cfs',\n",
       "  'generative',\n",
       "  'image_editing',\n",
       "  '6.9',\n",
       "  'ribonucleic',\n",
       "  'image-class-tags',\n",
       "  'synthesizing',\n",
       "  'april',\n",
       "  '232',\n",
       "  'trending_topics',\n",
       "  'variational_inference',\n",
       "  'nationality',\n",
       "  'pretrained_language_model',\n",
       "  'type-matching',\n",
       "  'discussions',\n",
       "  'deaf',\n",
       "  'mirnas',\n",
       "  '0.5',\n",
       "  'va',\n",
       "  '92.2',\n",
       "  'hours',\n",
       "  'gt',\n",
       "  'discourse_analysis',\n",
       "  'quality_assessment',\n",
       "  'culturology',\n",
       "  'conformance',\n",
       "  'a.k.a',\n",
       "  'supposing',\n",
       "  'dynamical_systems',\n",
       "  'symmetry',\n",
       "  'abstract',\n",
       "  'insurance_companies',\n",
       "  'backing',\n",
       "  'justifying',\n",
       "  'sirnas',\n",
       "  'semi-structured',\n",
       "  '3d-cnn',\n",
       "  'limiting',\n",
       "  'holy_quran',\n",
       "  'trees',\n",
       "  'brexit',\n",
       "  'non-function',\n",
       "  'racial',\n",
       "  'explicated',\n",
       "  'post-transcriptional',\n",
       "  'selections',\n",
       "  '592',\n",
       "  'aesthetic',\n",
       "  'classroom',\n",
       "  'gc',\n",
       "  'compilers',\n",
       "  'two-level',\n",
       "  'coordinates',\n",
       "  'artificially',\n",
       "  'privacy-centric',\n",
       "  'rent',\n",
       "  'intervention',\n",
       "  '59.4',\n",
       "  'text_classification-based',\n",
       "  'grammars',\n",
       "  'network_architecture',\n",
       "  'inventories',\n",
       "  'dms',\n",
       "  'neuroscience',\n",
       "  'kept',\n",
       "  'longest_common',\n",
       "  'debiasing',\n",
       "  'concurrently',\n",
       "  'n-way',\n",
       "  'separates',\n",
       "  'conserved',\n",
       "  'sensors',\n",
       "  'encodes',\n",
       "  'version',\n",
       "  'psychol',\n",
       "  'finance-specific',\n",
       "  'n-gram',\n",
       "  'hospital',\n",
       "  'orlando',\n",
       "  'rgb',\n",
       "  'aerospace',\n",
       "  'signals',\n",
       "  'axiological',\n",
       "  'caregivers',\n",
       "  'demonstration',\n",
       "  '//github.com/d2klab/zeste',\n",
       "  'pirnas',\n",
       "  'honti',\n",
       "  'sophisticated',\n",
       "  'ideology',\n",
       "  'impart',\n",
       "  'pioneering',\n",
       "  'data_science',\n",
       "  'clm',\n",
       "  'degradation',\n",
       "  'storing',\n",
       "  '/italic',\n",
       "  'causal',\n",
       "  'wille',\n",
       "  'weighted_average',\n",
       "  'fuzzy_rule',\n",
       "  'b-tree',\n",
       "  'baselines',\n",
       "  'device',\n",
       "  'reproduced',\n",
       "  'superiorities',\n",
       "  'merges',\n",
       "  'vacancy',\n",
       "  'al',\n",
       "  'leave',\n",
       "  'typographic',\n",
       "  'sheds',\n",
       "  'ae',\n",
       "  'phoneme-based',\n",
       "  'scibert',\n",
       "  'dat',\n",
       "  'retroflex',\n",
       "  'complex_queries',\n",
       "  'translator',\n",
       "  '4.0',\n",
       "  'triples',\n",
       "  'self-organizing_map',\n",
       "  'macedonian',\n",
       "  'kcnq2-',\n",
       "  'guendouzi',\n",
       "  'mimic',\n",
       "  'language-to-language',\n",
       "  'sheets',\n",
       "  'province',\n",
       "  'query/question',\n",
       "  'seqgan-based',\n",
       "  '72.5',\n",
       "  'pedagogically',\n",
       "  'understands',\n",
       "  'traffic-related',\n",
       "  'sentence_structures',\n",
       "  'religion',\n",
       "  '69.0',\n",
       "  'zoom',\n",
       "  'bid_price',\n",
       "  'concept-token_based',\n",
       "  'hyper-connectivity',\n",
       "  'excel',\n",
       "  'fourteen',\n",
       "  'american_psychological_association',\n",
       "  'motion',\n",
       "  'chat-bot',\n",
       "  'sbhnn',\n",
       "  '33',\n",
       "  'ethnicity',\n",
       "  'spatialize',\n",
       "  'recent_gcn',\n",
       "  'tsk',\n",
       "  'keyword',\n",
       "  'technicians',\n",
       "  '//github.com/epo/cf22-green-hands',\n",
       "  'twofold',\n",
       "  'umls-metathesaurus',\n",
       "  'minimum_description_length',\n",
       "  'sequencing',\n",
       "  'listeners',\n",
       "  'supervision',\n",
       "  'knowledge_engineering',\n",
       "  'mappable',\n",
       "  'graduate',\n",
       "  'lstm-rnn',\n",
       "  'general�',\n",
       "  'identities',\n",
       "  'er-hg',\n",
       "  'landmarks',\n",
       "  'empirical_research',\n",
       "  'bounding',\n",
       "  'term-matching',\n",
       "  'pre-trained',\n",
       "  'hinders',\n",
       "  'communicativeness',\n",
       "  'hyperbolic',\n",
       "  'finland',\n",
       "  'scgru',\n",
       "  'engineers',\n",
       "  'notifications',\n",
       "  'lisp-like',\n",
       "  'unavailability',\n",
       "  'neural_machine_translation',\n",
       "  'feature_extractor',\n",
       "  'infancy',\n",
       "  'decompose',\n",
       "  'covid‐19',\n",
       "  'refined',\n",
       "  'states',\n",
       "  'walls',\n",
       "  'academia_sinica',\n",
       "  'computer_mediated_communication',\n",
       "  'typologies',\n",
       "  'topic-model',\n",
       "  'primesrl-eval',\n",
       "  'countless',\n",
       "  'fda',\n",
       "  'frontiers',\n",
       "  'word-sense-based',\n",
       "  'funded',\n",
       "  'estimation',\n",
       "  'talk',\n",
       "  'terror',\n",
       "  'toextend',\n",
       "  'levant',\n",
       "  'feature_sets',\n",
       "  'exploiting',\n",
       "  'cis-regulatory',\n",
       "  '1,264',\n",
       "  'opposition',\n",
       "  'acids',\n",
       "  'google',\n",
       "  'channeling',\n",
       "  'claimed',\n",
       "  'ifsa',\n",
       "  'micrornas',\n",
       "  'debt',\n",
       "  'scanned_documents',\n",
       "  'exhausted',\n",
       "  'attach',\n",
       "  'visualizing',\n",
       "  'architectures',\n",
       "  'corrective',\n",
       "  'animation',\n",
       "  'labo',\n",
       "  'obligations',\n",
       "  'unique_challenges',\n",
       "  'isometric-invariant',\n",
       "  'eurojournals_publishing',\n",
       "  'stigmatization',\n",
       "  'support_vector_machine',\n",
       "  'enactment',\n",
       "  'sensor',\n",
       "  'chatting',\n",
       "  'months',\n",
       "  'multi-dataset',\n",
       "  'framed',\n",
       "  'captioning',\n",
       "  'inform',\n",
       "  'supplements',\n",
       "  'svm-r',\n",
       "  'kolmogorov',\n",
       "  'providesmore',\n",
       "  'foundations',\n",
       "  'account',\n",
       "  'meaningless',\n",
       "  'inevitable',\n",
       "  'anchor',\n",
       "  'conditional_independence',\n",
       "  'strong_baseline',\n",
       "  'naturalistic',\n",
       "  'labeled_data',\n",
       "  'practically',\n",
       "  'context-free',\n",
       "  'individualized',\n",
       "  'fourier',\n",
       "  'euclidean',\n",
       "  'head',\n",
       "  'mrna',\n",
       "  'seemingly',\n",
       "  'ventures',\n",
       "  'dividers',\n",
       "  'rotations',\n",
       "  'phoneme-level',\n",
       "  'prey',\n",
       "  'swedish-',\n",
       "  'robots',\n",
       "  'intelligent_agent',\n",
       "  'anomalies',\n",
       "  'cyrillic',\n",
       "  'registry',\n",
       "  'messenger_rna',\n",
       "  'revitalize',\n",
       "  'productions',\n",
       "  'certain/uncertain',\n",
       "  'k-mers',\n",
       "  'injuries',\n",
       "  'word-based',\n",
       "  'sincere',\n",
       "  '//zeste.tools.eurecom.fr/',\n",
       "  'grain',\n",
       "  's-expressions',\n",
       "  'aes',\n",
       "  'argues',\n",
       "  '1–41',\n",
       "  'redundancies',\n",
       "  'tree-like',\n",
       "  'exclusion',\n",
       "  'blame',\n",
       "  'hye-jeong',\n",
       "  'characterization',\n",
       "  'setup',\n",
       "  'listener',\n",
       "  '18th',\n",
       "  'syndrome',\n",
       "  'im/migrants',\n",
       "  'springer',\n",
       "  'theo',\n",
       "  'baseline_methods',\n",
       "  'doublets',\n",
       "  'cleared',\n",
       "  'ahrs',\n",
       "  'crypto',\n",
       "  'condensed',\n",
       "  'ice',\n",
       "  'tm_mmc',\n",
       "  'cifar-100',\n",
       "  'social_event',\n",
       "  'high-level',\n",
       "  'gan-augmented',\n",
       "  'non-dej-based',\n",
       "  'embedded_systems',\n",
       "  'dej-based',\n",
       "  'verb-framed',\n",
       "  'ensured',\n",
       "  'starting_point',\n",
       "  'caller',\n",
       "  'inertial',\n",
       "  'consensus',\n",
       "  'non-urban',\n",
       "  'isolating',\n",
       "  'policyholders',\n",
       "  'opposed',\n",
       "  'filling',\n",
       "  'reconcile',\n",
       "  'aams',\n",
       "  'gmbh',\n",
       "  'rfam',\n",
       "  'morphological/structural_analysis',\n",
       "  'gan',\n",
       "  'personalized',\n",
       "  'ones',\n",
       "  'florida',\n",
       "  'verbalized',\n",
       "  '0.9',\n",
       "  'collective',\n",
       "  '64,957',\n",
       "  'assembly',\n",
       "  'context-based',\n",
       "  '70.50',\n",
       "  'competitive_baselines',\n",
       "  'stimulating',\n",
       "  'updating',\n",
       "  'tobolsk',\n",
       "  'curtain',\n",
       "  'harmful',\n",
       "  'self-organizing',\n",
       "  'non-acted',\n",
       "  'reconstruction',\n",
       "  'bootstrapped',\n",
       "  'geometry',\n",
       "  'photos',\n",
       "  'loss_function',\n",
       "  'familiar',\n",
       "  'publicized',\n",
       "  'filed',\n",
       "  'gcc-git',\n",
       "  'questions.firstly',\n",
       "  'spurious_correlations',\n",
       "  'readings',\n",
       "  'movements',\n",
       "  'failing',\n",
       "  'social_studies',\n",
       "  'fulfills',\n",
       "  'non-manual',\n",
       "  'nets',\n",
       "  'racialization',\n",
       "  'roadblock',\n",
       "  'issue_tracking',\n",
       "  'publicly_accessible',\n",
       "  'structured_knowledge',\n",
       "  'updates',\n",
       "  'captured',\n",
       "  'language_families',\n",
       "  'relation_extraction',\n",
       "  'place',\n",
       "  'comprehendible',\n",
       "  'oversee',\n",
       "  'integrates',\n",
       "  'metric_space',\n",
       "  'probes',\n",
       "  'underwent',\n",
       "  'camera',\n",
       "  'manipulated',\n",
       "  'encounters',\n",
       "  'dilemma',\n",
       "  'spelled',\n",
       "  'infrastructure',\n",
       "  'sl',\n",
       "  'phoible',\n",
       "  'roth',\n",
       "  'pre-classification',\n",
       "  'k-shot',\n",
       "  'teaching-learning',\n",
       "  'slowed',\n",
       "  'representation_learning',\n",
       "  'knowledge_graph',\n",
       "  'bigartm',\n",
       "  'path',\n",
       "  'datastructure',\n",
       "  'cellular',\n",
       "  '82.8',\n",
       "  'downside',\n",
       "  'encephalomyelitis/',\n",
       "  'acm',\n",
       "  'reinforce',\n",
       "  'learninghas',\n",
       "  '2dsom',\n",
       "  'dianping',\n",
       "  'regulators',\n",
       "  'interruptions',\n",
       "  'courtenay',\n",
       "  'pressure',\n",
       "  'disclosing',\n",
       "  'blind',\n",
       "  'disciplinary',\n",
       "  'exerts',\n",
       "  'polite',\n",
       "  'synapases',\n",
       "  'philosophy',\n",
       "  'label-fine-tuning',\n",
       "  'visualise',\n",
       "  'argument_mining',\n",
       "  'spaces',\n",
       "  'icd',\n",
       "  'lifetime',\n",
       "  'executing',\n",
       "  'user_intent',\n",
       "  'llm-kd',\n",
       "  'pretrained_word_embeddings',\n",
       "  'ocrs',\n",
       "  'indo-aryan',\n",
       "  'mit',\n",
       "  'case-based_reasoning',\n",
       "  'unlike_traditional',\n",
       "  'triad',\n",
       "  'appearance',\n",
       "  'gastric_cancer',\n",
       "  'st.',\n",
       "  'continues',\n",
       "  'rank-sum',\n",
       "  'branch',\n",
       "  'listening',\n",
       "  'restrict',\n",
       "  'choi',\n",
       "  'code-mixedsentences',\n",
       "  'stylistic_features',\n",
       "  'timing',\n",
       "  'amendment',\n",
       "  'left/right',\n",
       "  '10.4',\n",
       "  'context-relevance',\n",
       "  '10.3389/fpsyg.2020.579199',\n",
       "  'data-intensive',\n",
       "  'swapped',\n",
       "  'pooling',\n",
       "  'epilepsies',\n",
       "  'collaborative',\n",
       "  'penalties',\n",
       "  'classics',\n",
       "  'disruption',\n",
       "  'sentiment_analysis',\n",
       "  'faulty',\n",
       "  'tumor',\n",
       "  'project-oriented',\n",
       "  'nonlinguistic',\n",
       "  'imminent',\n",
       "  'farra',\n",
       "  'purify',\n",
       "  'pixel',\n",
       "  'user-uploaded',\n",
       "  'few-shotlearning',\n",
       "  'employment',\n",
       "  'discourse',\n",
       "  'consonants',\n",
       "  'exceed',\n",
       "  '–',\n",
       "  'dissatisfied',\n",
       "  'register',\n",
       "  'conversing',\n",
       "  'hepatocellular_carcinoma',\n",
       "  'flawed',\n",
       "  'australia',\n",
       "  '227',\n",
       "  'natural_images',\n",
       "  'stemmer',\n",
       "  'lft',\n",
       "  'crossfunctional',\n",
       "  'street',\n",
       "  'isca',\n",
       "  'eiffel_tower',\n",
       "  'training_set',\n",
       "  'middle',\n",
       "  'linguistic-anthropology',\n",
       "  'films',\n",
       "  'dcgan',\n",
       "  'important_roles',\n",
       "  'citizen',\n",
       "  'clarify',\n",
       "  'few-shot',\n",
       "  'alice',\n",
       "  \"'non-dej-based\",\n",
       "  'accuracyfor',\n",
       "  'single-view',\n",
       "  'version_control',\n",
       "  'human_intelligence',\n",
       "  'twenty',\n",
       "  'surveying',\n",
       "  'migration-',\n",
       "  'bench-marked',\n",
       "  'archaeological',\n",
       "  '132',\n",
       "  'london',\n",
       "  'antiqua',\n",
       "  'colombia',\n",
       "  'correspondences',\n",
       "  'depressed',\n",
       "  'content_moderation',\n",
       "  'global_pandemic',\n",
       "  'primesrl',\n",
       "  'variational',\n",
       "  'isomorphism',\n",
       "  'melbourne',\n",
       "  'differentiation-indifferentiation',\n",
       "  'mansi',\n",
       "  'century',\n",
       "  'interviewees',\n",
       "  'handwritten_document',\n",
       "  'single-node',\n",
       "  'training_sets',\n",
       "  'gps',\n",
       "  'paralinguistically',\n",
       "  'afmpf',\n",
       "  'metaphors',\n",
       "  'non-iterative',\n",
       "  'term-',\n",
       "  'infectious_disease',\n",
       "  'visualization',\n",
       "  'caiq',\n",
       "  'migrants',\n",
       "  'osact2022',\n",
       "  'technical_debt',\n",
       "  'reward',\n",
       "  '7-class',\n",
       "  'algebraic_topology',\n",
       "  'counselors',\n",
       "  'nlp-based',\n",
       "  'successive',\n",
       "  'jest-ideology',\n",
       "  'partial',\n",
       "  'relaxing',\n",
       "  'policy_making',\n",
       "  'repeated',\n",
       "  'institute',\n",
       "  'two-stage',\n",
       "  'instrumentation',\n",
       "  'hash_tags',\n",
       "  'spawning',\n",
       "  'yunnan_province',\n",
       "  'assumptions',\n",
       "  'string',\n",
       "  'projects',\n",
       "  'hand',\n",
       "  'formalized',\n",
       "  'multi-perspective',\n",
       "  'heritage',\n",
       "  'columbia',\n",
       "  'epilepsy',\n",
       "  'opqa',\n",
       "  'zero-shot',\n",
       "  'prognosis',\n",
       "  ...]}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "cos_sim = cosine_similarity_embeddings(paper_reprs, class_reprs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.78230924, 0.7538578 , 0.77479338, 0.80200045, 0.75536154])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cos_sim[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8891159917311015,\n",
       " 0.9054942803449103,\n",
       " 0.8125112536457095,\n",
       " 0.8037140825601731,\n",
       " 0.7696589366397533]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[cos_sim[c.papers[-1].id, c_id] for c_id, c in enumerate(taxo.root.children)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_d = {1:3, 4:5}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 4]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[i for i in temp_d]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12,\n",
       " title : a comparison of classification methods for predicting deception in computer-mediated_communication ; abstract : the increased chance of deception in computer-mediated_communication and the potential risk of taking action based on deceptive information calls for automatic detection of deception . to achieve the ultimate_goal of automatic prediction of deception , we selected four common classification methods and empirically compared their performance in predicting deception . the deception and truth data were collected during two experimental studies . the results suggest that all of the four methods were promising for predicting deception with cues to deception . among them , neural_networks exhibited consistent performance and were robust across test settings . the comparisons also highlighted the importance of selecting important input variables and removing noise in an attempt to enhance the performance of classification methods . the selected cues offer both methodological and theoretical contributions to the body of deception and information systems research . © 2004 m.e . sharpe , inc .)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id = 3\n",
    "mapping[-1][id], taxo.collection[mapping[-1][id]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_mapped = []\n",
    "unmapped = []\n",
    "class_map = {i:[] for i in np.arange(len(taxo.root.children))}\n",
    "\n",
    "for p_id, l in enumerate(class_labels):\n",
    "    if len(l) <4:\n",
    "        all_mapped.append(p_id)\n",
    "        for c in l:\n",
    "            class_map[c].append(p_id)\n",
    "    else:\n",
    "        unmapped.append(p_id)\n",
    "\n",
    "class_map = {i:sorted(class_map[i], key=lambda x: -cos_sim[x, i]) for i in np.arange(len(taxo.root.children))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "supervised_learning 445\n",
      "unsupervised_learning 463\n",
      "semi_supervised_learning 98\n",
      "deep_learning 104\n",
      "ensemble_methods 262\n"
     ]
    }
   ],
   "source": [
    "for c_id, c in enumerate(taxo.root.children):\n",
    "    print(c.label, len(class_map[c_id]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bottom_classes = np.argmax(np.diff(np.sort(cos_sim, axis=1), axis=1), axis=1) + 1\n",
    "\n",
    "# classes = np.argsort(cos_sim, axis=1)\n",
    "# class_labels = [classes[p_id][b:] for p_id, b in enumerate(bottom_classes)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[supervised_learning,\n",
       " unsupervised_learning,\n",
       " semi_supervised_learning,\n",
       " deep_learning,\n",
       " ensemble_methods]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "taxo.root.children"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 [0 2]\n",
      "20 [0 2]\n",
      "30 [0 2]\n",
      "32 [1 0 2]\n",
      "41 [1 0 2]\n",
      "49 [2]\n",
      "61 [3 0 2]\n",
      "63 [2]\n",
      "69 [2 0]\n",
      "74 [2]\n",
      "149 [1 0 2]\n",
      "152 [2]\n",
      "153 [0 1 2]\n",
      "155 [3 0 2]\n",
      "159 [0]\n",
      "215 [0]\n",
      "232 [1 0 2]\n",
      "235 [0 2]\n",
      "261 [1 0 2]\n",
      "291 [1 0 2]\n",
      "292 [1 2 0]\n",
      "293 [0 2]\n",
      "326 [1 0 2]\n",
      "341 [2]\n",
      "367 [1 0 2]\n",
      "380 [0 2]\n",
      "391 [2]\n",
      "404 [1 0 2]\n",
      "412 [0 2]\n",
      "413 [0]\n",
      "416 [0 1 2]\n",
      "419 [1 0 2]\n",
      "428 [0 1 2]\n",
      "430 [1 2 0]\n",
      "449 [1 0 2]\n",
      "451 [0 2]\n",
      "471 [0]\n",
      "475 [1 0 2]\n",
      "482 [1 0 2]\n",
      "500 [2]\n",
      "508 [0]\n",
      "510 [0 2]\n",
      "528 [2 0]\n",
      "536 [0]\n",
      "586 [2]\n",
      "597 [2]\n",
      "600 [2 0]\n",
      "616 [0 2]\n",
      "663 [0 1 2]\n",
      "670 [0 2]\n",
      "702 [0 2 1]\n",
      "703 [2]\n",
      "736 [0 2]\n",
      "758 [1 0 2]\n",
      "759 [0 2]\n",
      "766 [1 0 2]\n",
      "777 [0 2]\n",
      "794 [3 0 2]\n",
      "798 [1 0 2]\n",
      "803 [0 2]\n",
      "811 [2 0]\n",
      "849 [2 0]\n",
      "870 [2]\n",
      "928 [2 0]\n",
      "948 [0 1 2]\n",
      "950 [0 2]\n",
      "954 [1 0 2]\n",
      "957 [0 2]\n",
      "960 [0 1 2]\n",
      "967 [2 0]\n",
      "974 [2 0]\n",
      "978 [0 2]\n",
      "979 [0 1 2]\n",
      "73\n"
     ]
    }
   ],
   "source": [
    "total = 0\n",
    "for idx, l in enumerate(class_labels):\n",
    "    if len(l) < 4:\n",
    "        print(idx, l)\n",
    "        total += 1\n",
    "print(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.41849622, 0.41452385, 0.4203428 , 0.39699356, 0.4142338 ],\n",
       "       [0.45134438, 0.44479938, 0.45326388, 0.44773577, 0.44168179],\n",
       "       [0.367142  , 0.36561152, 0.37268315, 0.34918534, 0.35883899],\n",
       "       ...,\n",
       "       [0.39107231, 0.38916193, 0.39409682, 0.37851251, 0.38478113],\n",
       "       [0.35289365, 0.35163603, 0.35420271, 0.32782443, 0.3481511 ],\n",
       "       [0.47117052, 0.46534621, 0.46529638, 0.44525649, 0.46789527]])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cos_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[28, 20, 11, 97, 16]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[len([w for w in c.all_node_terms if w in static_emb]) for c in taxo.root.children]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[29, 33, 24, 105, 23]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[len(c.all_node_terms) for c in taxo.root.children]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_reprs = [average_with_harmonic_series(np.concatenate([static_emb[w].reshape((1,-1)) for w in c.all_node_terms if w in static_emb], axis=0)) for c in taxo.root.children]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "iv_terms = [w for w in taxo.collection[0].vocabulary if w in word2emb]\n",
    "ranked_tok = rank_by_significance(np.concatenate([word2emb[w].reshape((-1, 768)) for w in iv_terms], axis=0), class_reprs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{92: 0,\n",
       " 9: 1,\n",
       " 70: 2,\n",
       " 87: 3,\n",
       " 65: 4,\n",
       " 17: 5,\n",
       " 50: 6,\n",
       " 60: 7,\n",
       " 32: 8,\n",
       " 44: 9,\n",
       " 84: 10,\n",
       " 105: 11,\n",
       " 2: 12,\n",
       " 39: 13,\n",
       " 13: 14,\n",
       " 7: 15,\n",
       " 41: 16,\n",
       " 28: 17,\n",
       " 59: 18,\n",
       " 57: 19,\n",
       " 66: 20,\n",
       " 71: 21,\n",
       " 11: 22,\n",
       " 85: 23,\n",
       " 67: 24,\n",
       " 94: 25,\n",
       " 93: 26,\n",
       " 102: 27,\n",
       " 78: 28,\n",
       " 99: 29,\n",
       " 89: 30,\n",
       " 8: 31,\n",
       " 61: 32,\n",
       " 74: 33,\n",
       " 101: 34,\n",
       " 23: 35,\n",
       " 52: 36,\n",
       " 77: 37,\n",
       " 72: 38,\n",
       " 18: 39,\n",
       " 33: 40,\n",
       " 62: 41,\n",
       " 42: 42,\n",
       " 98: 43,\n",
       " 3: 44,\n",
       " 37: 45,\n",
       " 43: 46,\n",
       " 6: 47,\n",
       " 88: 48,\n",
       " 45: 49,\n",
       " 53: 50,\n",
       " 0: 51,\n",
       " 104: 52,\n",
       " 25: 53,\n",
       " 81: 54,\n",
       " 76: 55,\n",
       " 1: 56,\n",
       " 91: 57,\n",
       " 79: 58,\n",
       " 54: 59,\n",
       " 86: 60,\n",
       " 51: 61,\n",
       " 15: 62,\n",
       " 22: 63,\n",
       " 97: 64,\n",
       " 100: 65,\n",
       " 14: 66,\n",
       " 10: 67,\n",
       " 35: 68,\n",
       " 69: 69,\n",
       " 21: 70,\n",
       " 36: 71,\n",
       " 55: 72,\n",
       " 64: 73,\n",
       " 106: 74,\n",
       " 95: 75,\n",
       " 48: 76,\n",
       " 12: 77,\n",
       " 80: 78,\n",
       " 96: 79,\n",
       " 19: 80,\n",
       " 24: 81,\n",
       " 73: 82,\n",
       " 30: 83,\n",
       " 107: 84,\n",
       " 4: 85,\n",
       " 46: 86,\n",
       " 108: 87,\n",
       " 83: 88,\n",
       " 38: 89,\n",
       " 26: 90,\n",
       " 47: 91,\n",
       " 16: 92,\n",
       " 58: 93,\n",
       " 5: 94,\n",
       " 82: 95,\n",
       " 56: 96,\n",
       " 31: 97,\n",
       " 68: 98,\n",
       " 34: 99,\n",
       " 63: 100,\n",
       " 75: 101,\n",
       " 49: 102,\n",
       " 40: 103,\n",
       " 103: 104,\n",
       " 20: 105,\n",
       " 27: 106,\n",
       " 90: 107,\n",
       " 29: 108}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ranked_tok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.95788369, 0.93276707, 0.95489257, 0.94776222, 0.93760071]])"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity_embeddings([static_emb[\"deep_learning\"].numpy()], class_reprs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rank: 0; token: semi-supervised_learning\n",
      "rank: 1; token: multi-task_learning\n",
      "rank: 2; token: transfer_learning\n",
      "rank: 3; token: multi-class\n",
      "rank: 4; token: binary_classification\n",
      "rank: 5; token: supervised_learning\n",
      "rank: 6; token: prediction_accuracy\n",
      "rank: 7; token: hierarchies\n",
      "rank: 8; token: generalization\n",
      "rank: 9; token: outperforms\n",
      "rank: 10; token: classification_task\n",
      "rank: 11; token: nearest_neighbor\n",
      "rank: 12; token: mtl\n",
      "rank: 13; token: classifying\n",
      "rank: 14; token: training_examples\n",
      "rank: 15; token: datasets\n",
      "rank: 16; token: jointly\n",
      "rank: 17; token: task\n",
      "rank: 18; token: concept\n",
      "rank: 19; token: approach\n",
      "rank: 20; token: classification\n",
      "rank: 21; token: tasks\n",
      "rank: 22; token: abstract\n",
      "rank: 23; token: also\n",
      "rank: 24; token: problem\n",
      "rank: 25; token: methods\n",
      "rank: 26; token: using\n",
      "rank: 27; token: developed\n",
      "rank: 28; token: approaches\n",
      "rank: 29; token: namely\n",
      "rank: 30; token: especially\n",
      "rank: 31; token: independently\n",
      "rank: 32; token: classes\n",
      "rank: 33; token: work\n",
      "rank: 34; token: improvement\n",
      "rank: 35; token: paradigm\n",
      "rank: 36; token: performance\n",
      "rank: 37; token: models\n",
      "rank: 38; token: our\n",
      "rank: 39; token: hierarchical\n",
      "rank: 40; token: ,\n",
      "rank: 41; token: only\n",
      "rank: 42; token: and\n",
      "rank: 43; token: instead\n",
      "rank: 44; token: considerably\n",
      "rank: 45; token: each\n",
      "rank: 46; token: strength\n",
      "rank: 47; token: documents\n",
      "rank: 48; token: compare\n",
      "rank: 49; token: relationships\n",
      "rank: 50; token: several\n",
      "rank: 51; token: :\n",
      "rank: 52; token: two\n",
      "rank: 53; token: number\n",
      "rank: 54; token: traditional\n",
      "rank: 55; token: title\n",
      "rank: 56; token: develop\n",
      "rank: 57; token: we\n",
      "rank: 58; token: standard\n",
      "rank: 59; token: this\n",
      "rank: 60; token: use\n",
      "rank: 61; token: demonstrate\n",
      "rank: 62; token: )\n",
      "rank: 63; token: evaluate\n",
      "rank: 64; token: terms\n",
      "rank: 65; token: defining\n",
      "rank: 66; token: ;\n",
      "rank: 67; token: the\n",
      "rank: 68; token: show\n",
      "rank: 69; token: prediction\n",
      "rank: 70; token: is\n",
      "rank: 71; token: an\n",
      "rank: 72; token: when\n",
      "rank: 73; token: empirical\n",
      "rank: 74; token: solve\n",
      "rank: 75; token: there\n",
      "rank: 76; token: for\n",
      "rank: 77; token: single\n",
      "rank: 78; token: (\n",
      "rank: 79; token: results\n",
      "rank: 80; token: in\n",
      "rank: 81; token: ieee\n",
      "rank: 82; token: within\n",
      "rank: 83; token: different\n",
      "rank: 84; token: 2013\n",
      "rank: 85; token: ©\n",
      "rank: 86; token: a\n",
      "rank: 87; token: achieve\n",
      "rank: 88; token: few\n",
      "rank: 89; token: with\n",
      "rank: 90; token: established\n",
      "rank: 91; token: multiple\n",
      "rank: 92; token: are\n",
      "rank: 93; token: that\n",
      "rank: 94; token: learning\n",
      "rank: 95; token: wikipedia\n",
      "rank: 96; token: by\n",
      "rank: 97; token: .\n",
      "rank: 98; token: based\n",
      "rank: 99; token: between\n",
      "rank: 100; token: better\n",
      "rank: 101; token: across\n",
      "rank: 102; token: fewer\n",
      "rank: 103; token: per\n",
      "rank: 104; token: which\n",
      "rank: 105; token: of\n",
      "rank: 106; token: learned\n",
      "rank: 107; token: to\n",
      "rank: 108; token: against\n"
     ]
    }
   ],
   "source": [
    "for idx, rank in ranked_tok.items():\n",
    "    print(f\"rank: {rank}; token: {iv_terms[idx]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rank: 0; token: semi-supervised_learning\n",
      "rank: 1; token: multi-task_learning\n",
      "rank: 2; token: binary_classification\n",
      "rank: 3; token: transfer_learning\n",
      "rank: 4; token: multi-class\n",
      "rank: 5; token: supervised_learning\n",
      "rank: 6; token: prediction_accuracy\n",
      "rank: 7; token: hierarchies\n",
      "rank: 8; token: generalization\n",
      "rank: 9; token: outperforms\n",
      "rank: 10; token: nearest_neighbor\n",
      "rank: 11; token: classification_task\n",
      "rank: 12; token: classifying\n",
      "rank: 13; token: training_examples\n",
      "rank: 14; token: mtl\n",
      "rank: 15; token: datasets\n",
      "rank: 16; token: task\n",
      "rank: 17; token: jointly\n",
      "rank: 18; token: concept\n",
      "rank: 19; token: approach\n",
      "rank: 20; token: classification\n",
      "rank: 21; token: tasks\n",
      "rank: 22; token: abstract\n",
      "rank: 23; token: also\n",
      "rank: 24; token: problem\n",
      "rank: 25; token: our\n",
      "rank: 26; token: approaches\n",
      "rank: 27; token: especially\n",
      "rank: 28; token: independently\n",
      "rank: 29; token: developed\n",
      "rank: 30; token: methods\n",
      "rank: 31; token: using\n",
      "rank: 32; token: namely\n",
      "rank: 33; token: classes\n",
      "rank: 34; token: improvement\n",
      "rank: 35; token: models\n",
      "rank: 36; token: work\n",
      "rank: 37; token: instead\n",
      "rank: 38; token: each\n",
      "rank: 39; token: paradigm\n",
      "rank: 40; token: performance\n",
      "rank: 41; token: and\n",
      "rank: 42; token: ,\n",
      "rank: 43; token: strength\n",
      "rank: 44; token: documents\n",
      "rank: 45; token: only\n",
      "rank: 46; token: considerably\n",
      "rank: 47; token: hierarchical\n",
      "rank: 48; token: compare\n",
      "rank: 49; token: traditional\n",
      "rank: 50; token: we\n",
      "rank: 51; token: title\n",
      "rank: 52; token: number\n",
      "rank: 53; token: several\n",
      "rank: 54; token: relationships\n",
      "rank: 55; token: two\n",
      "rank: 56; token: :\n",
      "rank: 57; token: standard\n",
      "rank: 58; token: use\n",
      "rank: 59; token: develop\n",
      "rank: 60; token: evaluate\n",
      "rank: 61; token: this\n",
      "rank: 62; token: is\n",
      "rank: 63; token: prediction\n",
      "rank: 64; token: demonstrate\n",
      "rank: 65; token: show\n",
      "rank: 66; token: )\n",
      "rank: 67; token: ;\n",
      "rank: 68; token: when\n",
      "rank: 69; token: defining\n",
      "rank: 70; token: the\n",
      "rank: 71; token: there\n",
      "rank: 72; token: an\n",
      "rank: 73; token: solve\n",
      "rank: 74; token: ©\n",
      "rank: 75; token: empirical\n",
      "rank: 76; token: terms\n",
      "rank: 77; token: (\n",
      "rank: 78; token: with\n",
      "rank: 79; token: results\n",
      "rank: 80; token: in\n",
      "rank: 81; token: for\n",
      "rank: 82; token: different\n",
      "rank: 83; token: achieve\n",
      "rank: 84; token: 2013\n",
      "rank: 85; token: within\n",
      "rank: 86; token: single\n",
      "rank: 87; token: ieee\n",
      "rank: 88; token: established\n",
      "rank: 89; token: few\n",
      "rank: 90; token: are\n",
      "rank: 91; token: learning\n",
      "rank: 92; token: a\n",
      "rank: 93; token: that\n",
      "rank: 94; token: multiple\n",
      "rank: 95; token: between\n",
      "rank: 96; token: based\n",
      "rank: 97; token: better\n",
      "rank: 98; token: by\n",
      "rank: 99; token: .\n",
      "rank: 100; token: wikipedia\n",
      "rank: 101; token: across\n",
      "rank: 102; token: of\n",
      "rank: 103; token: per\n",
      "rank: 104; token: fewer\n",
      "rank: 105; token: which\n",
      "rank: 106; token: learned\n",
      "rank: 107; token: against\n",
      "rank: 108; token: to\n"
     ]
    }
   ],
   "source": [
    "for idx, rank in ranked_tok.items():\n",
    "    print(f\"rank: {rank}; token: {iv_terms[idx]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[supervised_learning_methods,\n",
       " unsupervised_learning_methods,\n",
       " deep_learning_methods,\n",
       " ensemble_methods,\n",
       " transfer_learning_and_domain_adaptation]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# class representations\n",
    "class_reprs = [c.emb for c in taxo.root.children]\n",
    "taxo.root.children"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.78571259, 0.76266018, 0.8442609 , 0.87398888, 0.87627614]])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity_embeddings([sentence_model.encode(taxo.collection[7].title + \n",
    "                                                    \"[SEP]\" + \n",
    "                                                    taxo.collection[7].abstract)], \n",
    "                             class_reprs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array([[0.85956018, 0.90474514, 0.90334376, 0.88769259, 0.8412127 ]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = [[] for i in taxo.root.children]\n",
    "unmapped = []\n",
    "\n",
    "for p in range(len(collection)):\n",
    "    class_freq = [0] * len(taxo.root.children)\n",
    "\n",
    "    for c_id, c in enumerate(taxo.root.children):\n",
    "        # how many total mentions of the node terms\n",
    "        class_freq[c_id] = np.sum([collection[p].vocabulary[ele] for ele in c.all_node_terms if ele in collection[p].vocabulary.keys()])\n",
    "    \n",
    "    nonzero_idx = np.nonzero(class_freq)[0]\n",
    "    if len(nonzero_idx) == 0:\n",
    "        unmapped.append(p)\n",
    "        continue\n",
    "\n",
    "    for i in nonzero_idx:\n",
    "        # score: class_i_mentions / log(total_len)\n",
    "        score = class_freq[i] / np.log(collection[p].length)\n",
    "        classes[i].append((score, p))\n",
    "\n",
    "classes = [sorted(c, reverse=True) for c in classes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "303"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unmapped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bagging',\n",
       " 'boosting',\n",
       " 'stacking',\n",
       " 'voting',\n",
       " 'weighted_voting',\n",
       " 'random_forest',\n",
       " 'gradient_boosting',\n",
       " 'neural_network_ensemble',\n",
       " 'decision_tree_ensemble',\n",
       " 'support_vector_machine_ensemble',\n",
       " 'k_nearest_neighbors_ensemble',\n",
       " 'feature_bagging',\n",
       " 'feature_boosting',\n",
       " 'model_selection',\n",
       " 'hyperparameter_tuning',\n",
       " 'cross_validation',\n",
       " 'ensemble_methods',\n",
       " 'random_forests',\n",
       " 'base_learners',\n",
       " 'ensemble_learning',\n",
       " 'feature_combination',\n",
       " 'ensemble_techniques',\n",
       " 'cluster_based',\n",
       " 'rbf',\n",
       " 'mnb',\n",
       " 'dt',\n",
       " 'radial_basis_function',\n",
       " 'base_classifiers',\n",
       " 'gaussian_naive_bayes',\n",
       " 'multilayer_perceptron',\n",
       " 'c4.5',\n",
       " 'adaboost',\n",
       " 'attention_layer',\n",
       " 'feed-forward',\n",
       " 'thresholding',\n",
       " 'multinomial_logistic_regression',\n",
       " 'ensemble_classifier',\n",
       " 'memory-based',\n",
       " 'k-nearest_neighbor',\n",
       " 'nearest_neighbor',\n",
       " 'principal_component_analysis']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "taxo.root.children[-1].all_node_terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "supervised_learning\n",
      "15 arabic_text_categorization via binary particle_swarm_optimization and support_vector_machines ; abstract : document_categorization concerns automatically assigning a category label to a text document , and has increasingly many applications , particularly in the domains of organizing , browsing and search in large_document_collections . it is typically achieved via machine_learning , where a model is built on the basis of a ( typically ) large collection of document features . feature_selection is critical in this process , since there are typically several thousand potential features ( distinct words or terms ) . here we explore binary particle_swarm_optimization ( bpso ) hybridized with either k-nearest-neighbour ( knn ) or a support_vector_machine ( svm ) , for feature_selection in arabic document_categorization tasks . comparison between feature_selection methods is done on the basis of using the selected features , in conjunction with each of svm , c4.5 and naive_bayes , to classify a holdout test set . using publicly available datasets , we show that the bpsosvm approach seems promising in this domain . we also analyse the sets of selected features and consider the differences between the types of feature that bpsoknn and bpsosvm tend to choose\n",
      "16 a novel approach for ontology-based dimensionality_reduction for web text document_classification ; abstract : dimensionality_reduction of feature_vector size plays a vital role in enhancing the text processing capabilities ; it aims in reducing the size of the feature_vector used in the mining tasks ( classification , clustering ... etc. ) . this paper proposes an efficient approach to be used in reducing the size of the feature_vector for web text document_classification process . this approach is based on using wordnet ontology , utilizing the benefit of its hierarchal structure , to eliminate words from the generated feature_vector that has no relation with any of wordnet lexical categories\n",
      "449 25th pacific-asia conference on knowledge discovery and data_mining , pakdd 2021 ; abstract : the proceedings contain 157 papers . the special focus in this conference is on knowledge discovery and data_mining . the topics include : self-supervised graph_representation learning with variational_inference ; manifold approximation and projection by maximizing graph information ; learning attention-based translational knowledge_graph embedding via nonlinear dynamic mapping ; multi-grained dependency_graph neural_network for chinese open_information_extraction ; human-understandable decision_making for visual_recognition ; lightcake : a lightweight framework for context-aware knowledge_graph embedding ; transferring domain_knowledge with an adviser in continuous tasks ; inferring hierarchical mixture structures : a bayesian nonparametric approach ; quality_control for hierarchical classification with incomplete annotations ; learning discriminative_features using multi-label dual_space ; universal representation for code ; autocluster : meta-learning based ensemble_method for automated unsupervised_clustering ; banditrank : learning to rank using contextual bandits ; a compressed and accelerated segnet for plant leaf disease segmentation : a differential_evolution based approach ; meta-context transformers for domain-specific response_generation ; a multi-task kernel learning algorithm for survival_analysis ; meta-data augmentation based search strategy through generative_adversarial_network for automl model_selection ; tree-capsule : tree-structured capsule_network for improving relation_extraction ; rule injection-based generative_adversarial imitation learning for knowledge_graph reasoning ; hierarchical self attention_based autoencoder for open-set human activity_recognition ; reinforced natural_language inference for distantly_supervised_relation classification ; self-supervised adaptive aggregator learning on graph ; sagcn : structure-aware graph convolution network for document-level relation_extraction ; addressing the class_imbalance problem in medical image_segmentation via accelerated tversky loss_function ; incorporating relational knowledge in explainable fake_news_detection\n",
      "373 estimating the generalization performance of polynomial svm classifier for text_categorization\n",
      "354 a hybrid documents classification based on svm and rough_sets\n",
      "280 automatic polarity identification on twitter using machine_learning ; abstract : this work presents a study of emotions to analyze the polarity of a set of data that was extracted from twitter , detailing each of the resources in the different forms that a language has , and to be able to observe feelings such as irony , sarcasm , and happiness , among others . this research can help us classify the polarity of each one of them deeply in the corpus that deals with this research work . experimental results conducted using different machine_learning methods are presented : support_vector_machines , naïve_bayes , logistic_regression , knn and random_forest , with which a classification system based on cross-validation was implemented . all experiments were performed in python . the results obtained are shown with two different corpus ; where the first set is made up of 10,653 tweets in total divided equally each with 3551 tweets with a positive , negative and neutral label\n",
      "184 margin maximization with feed-forward neural_networks : a comparative study with svm and adaboost\n",
      "236 classification of forensic autopsy reports through conceptual_graph-based document_representation model\n",
      "335 forestexter : an efficient random_forest algorithm for imbalanced text_categorization\n",
      "946 an efficient approach for ensemble of svm and ann for sentiment_classification\n",
      "\n",
      "\n",
      "unsupervised_learning\n",
      "111 deep graph neural_networks for text_classification task ; abstract : text_classification is to organizing documents into predetermined_categories , usually by machinery learn algorithms . it is a significant ways to organize and utilize the large amount of information that exists in unstructured_text format . text_classification is an important module in text processing , and its applications are also very extensive , such as garbage filtering , news classification , part-of-speech_tagging , and so on . with the continuous development of deep_learning in recent_years ! its applications are also very extensive , such as : garbage filtering , news classification , part-of-speech_tagging , and so on . but the text also has its own characteristics . according to the characteristics of the text , the general process of text_classification is : 1 . preprocessing ; 2 . text_representation and feature_selection ; 3 . construction of a classifier\n",
      "237 hybrid supervised clustering based ensemble scheme for text_classification\n",
      "144 a text feature_selection method using the improved mutual_information and information entropy\n",
      "159 a tensor space model-based deep_neural_network for text_classification ; abstract : most text_classification systems use machine_learning algorithms ; among these , naïve_bayes and support_vector_machine algorithms adapted to handle text data afford reasonable_performance . recently , given developments in deep_learning technology , several scholars have used deep_neural_networks ( recurrent and convolutional_neural_networks ) to improve text_classification . however , deep_learning-based text_classification has not greatly_improved performance compared to that of conventional algorithms . this is because a textual document is essentially expressed as a vector ( only ) , albeit with word dimensions , which compromises the inherent semantic information , even if the vector is ( appropriately ) transformed to add conceptual information . to solve this ‘ loss of term senses ’ problem , we develop a concept-driven deep_neural_network based upon our semantic tensor space model . the semantic tensor used for text_representation features a dependency between the term and the concept\n",
      "273 research convey on text_classification method based on deep_learning\n",
      "206 a component clustering_algorithm based on semantic similarity and optimization\n",
      "967 research progress of text_classification technology based on deep_learning\n",
      "734 a method of text_classification based on statistical technology and set_theory\n",
      "346 a comparative research of different granularities in korean text_classification ; abstract : text_classification is a process , which can make the specified documents group into several categories , predefined at the beginning through learning a series of rules or under the guidance of the goal function . this paper compared the subword-level , spacing-level of korean and the word-level , then analyzed the influence of the preprocessing of different granularities on the text_classification task of korean . after that , analyzed the results of classification linguistically . thus we can choose the proper granularity as the input to improve the classification effect . firstly , cut the corpus according to different granularities\n",
      "910 knowledge-based clustering scheme for collection management and retrieval of library books ; abstract : we propose a knowledge-based clustering scheme for grouping books in a library . such a grouping is achieved with the help of domain_knowledge in the form of the acm cr ( computing reviews ) category hierarchy . a new knowledge-based similarity_measure is defined and used in clustering books . the proposed scheme is useful in overcoming several problems associated with the existing book collection management and document_retrieval systems . more specifically , it can be used in : ( 1 ) helping the user select an appropriate collection of books in a library which contains the topics of interest ; ( 2 ) assigning a classification number to a new book ; ( 3 ) designing a more appropriate and uniform classification_scheme for books\n",
      "\n",
      "\n",
      "semi_supervised_learning\n",
      "122 meta_learning for few-shot joint intent_detection_and_slot-filling\n",
      "516 batch active_learning for text_classification and sentiment_analysis\n",
      "227 multi-domain active_learning for text_classification\n",
      "246 revisiting uncertainty-based query_strategies for active_learning with transformers\n",
      "773 cutting the error by half : investigation of very deep cnn and advanced training strategies for document_image_classification ; abstract : we present an exhaustive investigation of recent deep_learning architectures , algorithms , and strategies for the task of document_image_classification to finally reduce the error by more than half . existing_approaches , such as the deepdoc-classifier , apply standard convolutional_network architectures with transfer_learning from the object_recognition domain . the contribution of the paper is threefold : first , it investigates recently introduced very deep_neural_network architectures ( googlenet , vgg , resnet ) using transfer_learning ( from real images ) . second , it proposes transfer_learning from a huge set of document_images , i.e . 400\n",
      "661 protaugment : unsupervised diverse short-texts paraphrasing for intent_detection meta-learning\n",
      "338 exploiting the matching information in the support set for few shot event classification\n",
      "525 active_learning in automated text_classification : a case_study exploring bias in predicted model performance_metrics\n",
      "389 classifying syntactic errors in learner language\n",
      "777 enriching pre-trained_language_model with entity information for relation_classification\n",
      "\n",
      "\n",
      "deep_learning\n",
      "293 a multi-scale convolutional attention_based gru network for text_classification\n",
      "1 a novel model combining transformer and bi-lstm for news categorization ; abstract : news categorization ( nc ) , the aim of which is to identify distinct categories of news through analyzing the contents , has acquired substantial progress since deep_learning was introduced into the natural_language_processing ( nlp ) field . as a state-of-art model , transformer & # x2019\n",
      "776 an automatic method using hybrid neural_networks and attention_mechanism for software_bug triaging\n",
      "199 phrase2vec : phrase embedding based on parsing\n",
      "379 an integrated fuzzy neural_network with topic-aware auto-encoding for sentiment_analysis\n",
      "773 cutting the error by half : investigation of very deep cnn and advanced training strategies for document_image_classification ; abstract : we present an exhaustive investigation of recent deep_learning architectures , algorithms , and strategies for the task of document_image_classification to finally reduce the error by more than half . existing_approaches , such as the deepdoc-classifier , apply standard convolutional_network architectures with transfer_learning from the object_recognition domain . the contribution of the paper is threefold : first , it investigates recently introduced very deep_neural_network architectures ( googlenet , vgg , resnet ) using transfer_learning ( from real images ) . second , it proposes transfer_learning from a huge set of document_images , i.e . 400\n",
      "398 pseudo-labeling with transformers for improving question_answering systems\n",
      "449 25th pacific-asia conference on knowledge discovery and data_mining , pakdd 2021 ; abstract : the proceedings contain 157 papers . the special focus in this conference is on knowledge discovery and data_mining . the topics include : self-supervised graph_representation learning with variational_inference ; manifold approximation and projection by maximizing graph information ; learning attention-based translational knowledge_graph embedding via nonlinear dynamic mapping ; multi-grained dependency_graph neural_network for chinese open_information_extraction ; human-understandable decision_making for visual_recognition ; lightcake : a lightweight framework for context-aware knowledge_graph embedding ; transferring domain_knowledge with an adviser in continuous tasks ; inferring hierarchical mixture structures : a bayesian nonparametric approach ; quality_control for hierarchical classification with incomplete annotations ; learning discriminative_features using multi-label dual_space ; universal representation for code ; autocluster : meta-learning based ensemble_method for automated unsupervised_clustering ; banditrank : learning to rank using contextual bandits ; a compressed and accelerated segnet for plant leaf disease segmentation : a differential_evolution based approach ; meta-context transformers for domain-specific response_generation ; a multi-task kernel learning algorithm for survival_analysis ; meta-data augmentation based search strategy through generative_adversarial_network for automl model_selection ; tree-capsule : tree-structured capsule_network for improving relation_extraction ; rule injection-based generative_adversarial imitation learning for knowledge_graph reasoning ; hierarchical self attention_based autoencoder for open-set human activity_recognition ; reinforced natural_language inference for distantly_supervised_relation classification ; self-supervised adaptive aggregator learning on graph ; sagcn : structure-aware graph convolution network for document-level relation_extraction ; addressing the class_imbalance problem in medical image_segmentation via accelerated tversky loss_function ; incorporating relational knowledge in explainable fake_news_detection\n",
      "890 discriminative learning of generative_models : large_margin multinomial mixture_models for document_classification\n",
      "837 improving transformer-based end-to-end speech_recognition with connectionist temporal classification and language model integration\n",
      "\n",
      "\n",
      "ensemble_methods\n",
      "941 document_classification using symbolic classifiers ; abstract : in this paper , we present symbolic classifiers to classify text documents . we propose to use cluster_based symbolic_representation followed by symbolic feature_selection methods to classify text documents . in particular , we propose symbolic clustering approaches ; symbolic cluster_based without feature_selection ; symbolic cluster_based with feature_selection ( using similarity_measure )\n",
      "827 application of bagging_ensemble classifier based on genetic_algorithm in the text_classification of railway fault hazards\n",
      "47 comparative_analysis of binary classifiers on an array of scientific_publications\n",
      "141 predicting software defect severity_level using sentence_embedding and ensemble_learning\n",
      "237 hybrid supervised clustering based ensemble scheme for text_classification\n",
      "280 automatic polarity identification on twitter using machine_learning ; abstract : this work presents a study of emotions to analyze the polarity of a set of data that was extracted from twitter , detailing each of the resources in the different forms that a language has , and to be able to observe feelings such as irony , sarcasm , and happiness , among others . this research can help us classify the polarity of each one of them deeply in the corpus that deals with this research work . experimental results conducted using different machine_learning methods are presented : support_vector_machines , naïve_bayes , logistic_regression , knn and random_forest , with which a classification system based on cross-validation was implemented . all experiments were performed in python . the results obtained are shown with two different corpus ; where the first set is made up of 10,653 tweets in total divided equally each with 3551 tweets with a positive , negative and neutral label\n",
      "512 enhanced malay sentiment_analysis with an ensemble classification machine_learning approach\n",
      "59 an ensemble model for stance_detection in social_media texts\n",
      "817 an intelligent hybrid sentiment_analyzer for personal protective medical equipments based on word_embedding technique : the covid-19 era\n",
      "732 a scalable meta-classifier combining search and classification techniques for multi-level text_categorization\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for idx, i in enumerate(classes):\n",
    "    print(taxo.root.children[idx])\n",
    "    for p in i[:10]:\n",
    "        print(p[-1], collection[p[-1]].title)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"datasets/updated_qa_phrases.json\", \"w\", encoding='utf-8') as f:\n",
    "    json_out = {}\n",
    "    json_out[taxo.root.label] = {\"description\": taxo.root.desc, \"seeds\": taxo.root.seeds, \"terms\": taxo.root.all_node_terms}\n",
    "    for c in taxo.root.children:\n",
    "        json_out[c.label] = {\"description\": c.desc, \"seeds\": c.seeds, \"terms\": c.all_node_terms}\n",
    "    json.dump(json_out, f, ensure_ascii=False, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "inverse",
   "language": "python",
   "name": "inverse"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
