Label: natural_language_processing
Dimension: datasets
Description: None
Level: 0
# of Papers: 675
Example Papers: [(1, 'Multi-News+: Cost-efficient Dataset Cleansing via LLM-based Data Annotation'), (4, 'Table Question Answering for Low-resourced Indic Languages'), (5, 'ImageInWords: Unlocking Hyper-Detailed Image Descriptions')]
----------------------------------------
Children:
     Label: text_classification_datasets
     Dimension: datasets
     Description: These datasets are designed for training models to categorize text into predefined classes, often used in sentiment analysis, topic detection, and spam detection.
     Level: 1
     # of Papers: 99
     Example Papers: [(1, 'Multi-News+: Cost-efficient Dataset Cleansing via LLM-based Data Annotation'), (13, 'A Usage-centric Take on Intent Understanding in E-Commerce'), (21, '"We Demand Justice!": Towards Social Context Grounding of Political Texts')]
     ----------------------------------------
     Children:
          Label: sentiment_analysis_datasets
          Dimension: datasets
          Description: Datasets specifically designed for training models to determine the sentiment expressed in text, often categorized as positive, negative, or neutral.
          Level: 2
          # of Papers: 13
          Example Papers: [(21, '"We Demand Justice!": Towards Social Context Grounding of Political Texts'), (1040, 'Semantics and Sentiment: Cross-lingual Variations in Emoji Use'), (1363, 'Refining App Reviews: Dataset, Methodology, and Evaluation')]
          ----------------------------------------
          Label: spam_detection_datasets
          Dimension: datasets
          Description: Collections of labeled emails or messages used to train algorithms to identify and filter out spam content from legitimate communications.
          Level: 2
          ----------------------------------------
          Label: topic_classification_datasets
          Dimension: datasets
          Description: Datasets that contain text samples labeled with specific topics, enabling models to classify documents based on their subject matter.
          Level: 2
          # of Papers: 63
          Example Papers: [(1, 'Multi-News+: Cost-efficient Dataset Cleansing via LLM-based Data Annotation'), (122, 'Optimizing Code Retrieval: High-Quality and Scalable Dataset Annotation through Large Language Models'), (150, 'Surveying the Dead Minds: Historical-Psychological Text Analysis with Contextualized Construct Representation (CCR) for Classical Chinese')]
          ----------------------------------------
          Children:
               Label: news_article_datasets
               Dimension: datasets
               Description: Datasets containing news articles categorized by topics such as politics, sports, technology, and entertainment, useful for training models in topic classification.
               Level: 3
               # of Papers: 7
               Example Papers: [(602, 'GlobeSumm: A Challenging Benchmark Towards Unifying Multi-lingual, Cross-lingual and Multi-document News Summarization'), (823, 'Building Resources for Emakhuwa: Machine Translation and News Classification Benchmarks'), (1972, 'Forecasting Future International Events: A Reliable Dataset for Text-Based Event Modeling')]
               ----------------------------------------
               Label: academic_paper_datasets
               Dimension: datasets
               Description: Collections of academic papers organized by research fields, enabling the classification of scholarly articles based on their topics.
               Level: 3
               # of Papers: 50
               Example Papers: [(1, 'Multi-News+: Cost-efficient Dataset Cleansing via LLM-based Data Annotation'), (150, 'Surveying the Dead Minds: Historical-Psychological Text Analysis with Contextualized Construct Representation (CCR) for Classical Chinese'), (216, 'C3PA: An Open Dataset of Expert-Annotated and Regulation-Aware Privacy Policies to Enable Scalable Regulatory Compliance Audits')]
               ----------------------------------------
               Label: social_media_post_datasets
               Dimension: datasets
               Description: Datasets comprising social media posts labeled with various topics, ideal for analyzing trends and sentiments in public discourse.
               Level: 3
               # of Papers: 4
               Example Papers: [(1112, 'The Empirical Variability of Narrative Perceptions of Social Media Texts'), (1122, 'Multilingual Topic Classification in X: Dataset and Analysis'), (2733, 'An NLP Case Study on Predicting the Before and After of the Ukraine-Russia and Hamas-Israel Conflicts')]
               ----------------------------------------
               Label: blog_post_datasets
               Dimension: datasets
               Description: Curated datasets of blog posts categorized by themes, providing a rich resource for understanding topic distribution in personal and professional blogging.
               Level: 3
               ----------------------------------------
               Label: product_review_datasets
               Dimension: datasets
               Description: Datasets of product reviews classified by topics such as electronics, clothing, and home goods, useful for sentiment analysis and topic classification in e-commerce.
               Level: 3
               # of Papers: 1
               Example Papers: [(1397, 'AmazonQAC: A Large-Scale, Naturalistic Query Autocomplete Dataset')]
               ----------------------------------------
          ----------------------------------------
          Label: intent_detection_datasets
          Dimension: datasets
          Description: Datasets focused on identifying user intentions in text, commonly used in building conversational agents and chatbots.
          Level: 2
          # of Papers: 6
          Example Papers: [(13, 'A Usage-centric Take on Intent Understanding in E-Commerce'), (838, 'Are Large Language Models Good Classifiers? A Study on Edit Intent Classification in Scientific Document Revisions'), (1522, 'CoXQL: A Dataset for Parsing Explanation Requests in Conversational XAI Systems')]
          ----------------------------------------
          Label: hate_speech_detection_datasets
          Dimension: datasets
          Description: Curated datasets that include examples of hate speech and non-hate speech, aimed at training models to recognize and mitigate harmful language.
          Level: 2
          # of Papers: 4
          Example Papers: [(258, 'Leveraging Conflicts in Social Media Posts: Unintended Offense Dataset'), (344, 'ToxiCloakCN: Evaluating Robustness of Offensive Language Detection in Chinese with Cloaking Perturbations'), (826, 'A Closer Look at Multidimensional Online Political Incivility')]
          ----------------------------------------
     ----------------------------------------
     Label: named_entity_recognition_datasets
     Dimension: datasets
     Description: These datasets provide annotated text for training models to identify and classify named entities such as people, organizations, and locations within the text.
     Level: 1
     # of Papers: 42
     Example Papers: [(149, 'Collaborative Performance Prediction for Large Language Models'), (150, 'Surveying the Dead Minds: Historical-Psychological Text Analysis with Contextualized Construct Representation (CCR) for Classical Chinese'), (354, 'Contrastive Entity Coreference and Disambiguation for Historical Texts')]
     ----------------------------------------
     Children:
          Label: conll-2003
          Dimension: datasets
          Description: The CoNLL-2003 dataset is a widely used benchmark for named entity recognition, featuring annotated news articles with entities classified into categories such as persons, organizations, locations, and miscellaneous.
          Level: 2
          ----------------------------------------
          Label: ontonotes
          Dimension: datasets
          Description: The OntoNotes dataset provides a rich resource for named entity recognition, containing a diverse set of texts annotated with entities across multiple genres, including news, conversational, and web text.
          Level: 2
          ----------------------------------------
          Label: ace_2005
          Dimension: datasets
          Description: The ACE 2005 dataset is designed for evaluating named entity recognition systems, featuring a variety of texts annotated with entities, relations, and coreference information across different domains.
          Level: 2
          # of Papers: 1
          Example Papers: [(1481, 'DocEE-zh: A Fine-grained Benchmark for Chinese Document-level Event Extraction')]
          ----------------------------------------
          Label: wikigold
          Dimension: datasets
          Description: WikiGold is a dataset derived from Wikipedia articles, annotated for named entities, making it a valuable resource for training and evaluating NER systems in a rich and diverse context.
          Level: 2
          # of Papers: 2
          Example Papers: [(1267, 'Entity Insertion in Multilingual Linked Corpora: The Case of Wikipedia'), (2807, 'Embedded Topic Models Enhanced by Wikification')]
          ----------------------------------------
          Label: ner_in_the_wild
          Dimension: datasets
          Description: The NER in the Wild dataset consists of real-world text data collected from various sources, annotated for named entities, providing a challenging and practical resource for testing NER models in uncontrolled environments.
          Level: 2
          # of Papers: 12
          Example Papers: [(149, 'Collaborative Performance Prediction for Large Language Models'), (835, 'RaTEScore: A Metric for Radiology Report Generation'), (1010, 'NoiseBench: Benchmarking the Impact of Real Label Noise on Named Entity Recognition')]
          ----------------------------------------
     ----------------------------------------
     Label: machine_translation_datasets
     Dimension: datasets
     Description: These datasets consist of parallel corpora in multiple languages, enabling the training and evaluation of models for translating text from one language to another.
     Level: 1
     # of Papers: 76
     Example Papers: [(149, 'Collaborative Performance Prediction for Large Language Models'), (150, 'Surveying the Dead Minds: Historical-Psychological Text Analysis with Contextualized Construct Representation (CCR) for Classical Chinese'), (237, 'MiTTenS: A Dataset for Evaluating Gender Mistranslation')]
     ----------------------------------------
     Children:
          Label: parallel_corpora
          Dimension: datasets
          Description: Parallel corpora consist of texts that are translated into multiple languages, providing a direct comparison of source and target language pairs for training machine translation models.
          Level: 2
          # of Papers: 15
          Example Papers: [(250, 'Voices Unheard: NLP Resources and Models for Yoruba Regional Dialects'), (595, 'Data, Data Everywhere: A Guide for Pretraining Dataset Construction'), (633, 'MMTE: Corpus and Metrics for Evaluating Machine Translation Quality of Metaphorical Language')]
          ----------------------------------------
          Label: multilingual_datasets
          Dimension: datasets
          Description: Multilingual datasets contain text data in multiple languages, allowing for the development of translation systems that can handle various language pairs simultaneously.
          Level: 2
          # of Papers: 10
          Example Papers: [(316, 'NLEBench+NorGLM: A Comprehensive Empirical Analysis and Benchmark Dataset for Generative Language Models in Norwegian'), (602, 'GlobeSumm: A Challenging Benchmark Towards Unifying Multi-lingual, Cross-lingual and Multi-document News Summarization'), (682, 'GlossLM: A Massively Multilingual Corpus and Pretrained Model for Interlinear Glossed Text')]
          ----------------------------------------
          Label: domain_specific_datasets
          Dimension: datasets
          Description: Domain-specific datasets are tailored for particular fields such as legal, medical, or technical translations, ensuring that machine translation models are trained on relevant terminology and context.
          Level: 2
          # of Papers: 57
          Example Papers: [(150, 'Surveying the Dead Minds: Historical-Psychological Text Analysis with Contextualized Construct Representation (CCR) for Classical Chinese'), (162, 'PhiloGPT: A Philology-Oriented Large Language Model for Ancient Chinese Manuscripts with Dunhuang as Case Study'), (273, 'MuMath-Code: Combining Tool-Use Large Language Models with Multi-perspective Data Augmentation for Mathematical Reasoning')]
          ----------------------------------------
          Children:
               Label: medical_datasets
               Dimension: datasets
               Description: Datasets specifically curated for research and applications in the medical field, including clinical notes, patient records, and medical imaging data.
               Level: 3
               # of Papers: 3
               Example Papers: [(1707, 'RoQLlama: A Lightweight Romanian Adapted Language Model'), (1928, 'MedINST: Meta Dataset of Biomedical Instructions'), (2120, 'Ask the experts: sourcing a high-quality nutrition counseling dataset through Human-AI collaboration')]
               ----------------------------------------
               Label: financial_datasets
               Dimension: datasets
               Description: Datasets that encompass financial transactions, stock market data, and economic indicators, tailored for analysis in finance and economics.
               Level: 3
               # of Papers: 3
               Example Papers: [(600, 'DataTales: A Benchmark for Real-World Intelligent Data Narration'), (1345, 'Greenback Bears and Fiscal Hawks: Finance is a Jungle and Text Embeddings Must Adapt'), (1407, 'Systematic Evaluation of Long-Context LLMs on Financial Concepts')]
               ----------------------------------------
               Label: legal_datasets
               Dimension: datasets
               Description: Datasets containing legal documents, case law, and statutes, designed for applications in legal research and analysis.
               Level: 3
               # of Papers: 5
               Example Papers: [(900, 'TKGT: Redefinition and A New Way of Text-to-Table Tasks Based on Real World Demands and Knowledge Graphs Augmented LLMs'), (1420, 'Patentformer: A Novel Method to Automate the Generation of Patent Applications'), (1995, 'AgentsCourt: Building Judicial Decision-Making Agents with Court Debate Simulation and Legal Knowledge Augmentation')]
               ----------------------------------------
               Label: scientific_research_datasets
               Dimension: datasets
               Description: Datasets focused on scientific publications, experimental results, and research findings, aimed at facilitating advancements in various scientific fields.
               Level: 3
               # of Papers: 23
               Example Papers: [(150, 'Surveying the Dead Minds: Historical-Psychological Text Analysis with Contextualized Construct Representation (CCR) for Classical Chinese'), (273, 'MuMath-Code: Combining Tool-Use Large Language Models with Multi-perspective Data Augmentation for Mathematical Reasoning'), (276, 'KidLM: Advancing Language Models for Children - Early Insights and Future Directions')]
               ----------------------------------------
               Label: e-commerce_datasets
               Dimension: datasets
               Description: Datasets that include product descriptions, customer reviews, and transaction records, specifically for applications in online retail and market analysis.
               Level: 3
               ----------------------------------------
          ----------------------------------------
          Label: sentence_aligned_datasets
          Dimension: datasets
          Description: Sentence-aligned datasets consist of texts where sentences from the source language are matched with their corresponding translations in the target language, facilitating precise training for translation tasks.
          Level: 2
          # of Papers: 25
          Example Papers: [(250, 'Voices Unheard: NLP Resources and Models for Yoruba Regional Dialects'), (277, 'Using Language Models to Disambiguate Lexical Choices in Translation'), (802, 'Modeling User Preferences with Automatic Metrics: Creating a High-Quality Preference Dataset for Machine Translation')]
          ----------------------------------------
          Label: open_domain_datasets
          Dimension: datasets
          Description: Open domain datasets include a wide range of topics and styles, making them suitable for training machine translation systems that need to perform well across diverse content.
          Level: 2
          # of Papers: 16
          Example Papers: [(277, 'Using Language Models to Disambiguate Lexical Choices in Translation'), (724, 'AnaloBench: Benchmarking the Identification of Abstract and Long-context Analogies'), (823, 'Building Resources for Emakhuwa: Machine Translation and News Classification Benchmarks')]
          ----------------------------------------
     ----------------------------------------
     Label: question_answering_datasets
     Dimension: datasets
     Description: These datasets contain questions paired with corresponding answers, often sourced from various domains, to facilitate the development of models that can understand and respond to inquiries.
     Level: 1
     # of Papers: 81
     Example Papers: [(4, 'Table Question Answering for Low-resourced Indic Languages'), (149, 'Collaborative Performance Prediction for Large Language Models'), (150, 'Surveying the Dead Minds: Historical-Psychological Text Analysis with Contextualized Construct Representation (CCR) for Classical Chinese')]
     ----------------------------------------
     Children:
          Label: squad
          Dimension: datasets
          Description: The Stanford Question Answering Dataset (SQuAD) is a popular dataset for training and evaluating question answering systems, consisting of questions posed on a set of Wikipedia articles and their corresponding answers.
          Level: 2
          # of Papers: 2
          Example Papers: [(1662, 'MoleculeQA: A Dataset to Evaluate Factual Accuracy in Molecular Comprehension'), (1811, 'M2QA: Multi-domain Multilingual Question Answering')]
          ----------------------------------------
          Label: natural_questions
          Dimension: datasets
          Description: Natural Questions is a dataset that includes real user queries from Google Search, along with long-form answers extracted from Wikipedia, designed to evaluate open-domain question answering systems.
          Level: 2
          # of Papers: 3
          Example Papers: [(1662, 'MoleculeQA: A Dataset to Evaluate Factual Accuracy in Molecular Comprehension'), (1811, 'M2QA: Multi-domain Multilingual Question Answering'), (1859, 'TurkishMMLU: Measuring Massive Multitask Language Understanding in Turkish')]
          ----------------------------------------
          Label: triviaqa
          Dimension: datasets
          Description: TriviaQA is a dataset that contains trivia questions along with evidence documents from which the answers can be derived, aimed at testing the ability of models to extract information from various sources.
          Level: 2
          # of Papers: 3
          Example Papers: [(1662, 'MoleculeQA: A Dataset to Evaluate Factual Accuracy in Molecular Comprehension'), (1811, 'M2QA: Multi-domain Multilingual Question Answering'), (1994, 'PEDANTS: Cheap but Effective and Interpretable Answer Equivalence')]
          ----------------------------------------
          Label: hotpotqa
          Dimension: datasets
          Description: HotpotQA is a dataset designed for multi-hop question answering, where questions require reasoning over multiple documents to find the correct answer, promoting deeper understanding and inference capabilities.
          Level: 2
          # of Papers: 6
          Example Papers: [(287, 'Hierarchical Deconstruction of LLM Reasoning: A Graph-Based Framework for Analyzing Knowledge Utilization'), (1162, 'SciDQA: A Deep Reading Comprehension Dataset over Scientific Papers'), (1427, 'RAC: Retrieval-augmented Conversation Dataset for Open-domain Question Answering in Conversational Settings')]
          ----------------------------------------
          Label: quac
          Dimension: datasets
          Description: The Question Answering in Context (QuAC) dataset features a dialogue-based format where questions are asked in the context of a conversation, allowing for the evaluation of models in interactive question answering scenarios.
          Level: 2
          # of Papers: 10
          Example Papers: [(241, "I Could've Asked That: Reformulating Unanswerable Questions"), (960, "StorySparkQA: Expert-Annotated QA Pairs with Real-World Knowledge for Children's Story-Based Learning"), (1408, 'ConvKGYarn: Spinning Configurable and Scalable Conversational Knowledge Graph QA Datasets with Large Language Models')]
          ----------------------------------------
          Label: cultural_comprehension
          Dimension: datasets
          Description: Cultural comprehension datasets focus on understanding and interpreting cultural contexts and nuances in question answering scenarios.
          Level: 2
          # of Papers: 5
          Example Papers: [(328, 'Benchmarking Vision Language Models for Cultural Understanding'), (1144, 'Can LLM Generate Culturally Relevant Commonsense QA Data? Case Study in Indonesian and Sundanese'), (1662, 'MoleculeQA: A Dataset to Evaluate Factual Accuracy in Molecular Comprehension')]
          ----------------------------------------
          Label: finance
          Dimension: datasets
          Description: Finance-related question answering datasets are designed to evaluate models on financial queries and information retrieval.
          Level: 2
          # of Papers: 6
          Example Papers: [(968, 'ClimRetrieve: A Benchmarking Dataset for Information Retrieval from Corporate Climate Disclosures'), (1203, 'Evaluating Large Language Models on Time Series Feature Understanding: A Comprehensive Taxonomy and Benchmark'), (1345, 'Greenback Bears and Fiscal Hawks: Finance is a Jungle and Text Embeddings Must Adapt')]
          ----------------------------------------
          Label: legal_question_answering
          Dimension: datasets
          Description: Legal question answering datasets provide scenarios and queries specific to the legal domain, assessing models' abilities to interpret legal texts and contexts.
          Level: 2
          # of Papers: 10
          Example Papers: [(1025, 'CasiMedicos-Arg: A Medical Question Answering Dataset Annotated with Explanatory Argumentative Structures'), (1203, 'Evaluating Large Language Models on Time Series Feature Understanding: A Comprehensive Taxonomy and Benchmark'), (1477, 'Few shot chain-of-thought driven reasoning to prompt LLMs for open-ended medical question answering')]
          ----------------------------------------
          Label: long_document_question_answering
          Dimension: datasets
          Description: Long document question answering datasets challenge models to extract information and answer questions based on extensive textual sources.
          Level: 2
          # of Papers: 29
          Example Papers: [(248, 'RAG-QA Arena: Evaluating Domain Robustness for Long-form Retrieval Augmented Question Answering'), (814, 'Revisiting Automated Evaluation for Long-form Table Question Answering'), (960, "StorySparkQA: Expert-Annotated QA Pairs with Real-World Knowledge for Children's Story-Based Learning")]
          ----------------------------------------
          Label: videoqa
          Dimension: datasets
          Description: VideoQA datasets involve question answering based on video content, requiring models to interpret visual and auditory information to provide accurate answers.
          Level: 2
          # of Papers: 11
          Example Papers: [(399, 'Encoding and Controlling Global Semantics for Long-form Video Question Answering'), (740, 'CommVQA: Situating Visual Question Answering in Communicative Contexts'), (797, 'ECIS-VQG: Generation of Entity-centric Information-seeking Questions from Videos')]
          ----------------------------------------
     ----------------------------------------
     Label: text_generation_datasets
     Dimension: datasets
     Description: These datasets are used to train models for generating coherent and contextually relevant text, often sourced from creative writing, dialogues, or other narrative forms.
     Level: 1
     # of Papers: 174
     Example Papers: [(51, "What's Mine becomes Yours: Defining, Annotating and Detecting Context-Dependent Paraphrases in News Interview Dialogs"), (58, 'HEART-felt Narratives: Tracing Empathy and Narrative Style in Personal Stories with LLMs'), (81, 'Towards Tool Use Alignment of Large Language Models')]
     ----------------------------------------
     Children:
          Label: language_model_datasets
          Dimension: datasets
          Description: Datasets specifically designed for training and evaluating language models, often containing large corpora of text from diverse sources.
          Level: 2
          # of Papers: 98
          Example Papers: [(81, 'Towards Tool Use Alignment of Large Language Models'), (97, 'SHIELD: Evaluation and Defense Strategies for Copyright Compliance in LLM Text Generation'), (149, 'Collaborative Performance Prediction for Large Language Models')]
          ----------------------------------------
          Children:
               Label: general_language_corpora
               Dimension: datasets
               Description: General language corpora consist of large collections of text data from diverse sources, providing a broad representation of language usage for training language models.
               Level: 3
               # of Papers: 15
               Example Papers: [(81, 'Towards Tool Use Alignment of Large Language Models'), (209, 'A User-Centric Multi-Intent Benchmark for Evaluating Large Language Models'), (496, 'Jellyfish: Instruction-Tuning Local Large Language Models for Data Preprocessing')]
               ----------------------------------------
               Label: conversational_datasets
               Dimension: datasets
               Description: Conversational datasets are specifically designed to capture dialogue and interaction patterns, making them ideal for training models on conversational AI tasks.
               Level: 3
               # of Papers: 5
               Example Papers: [(553, 'Into the Unknown Unknowns: Engaged Human Learning through Participation in Language Model Agent Conversations'), (1017, 'ToolPlanner: A Tool Augmented LLM for Multi Granularity Instructions with Path Planning and Feedback'), (1230, 'Is Child-Directed Speech Effective Training Data for Language Models?')]
               ----------------------------------------
               Label: domain_specific_datasets
               Label: multilingual_datasets
               Label: text_completion_datasets
               Dimension: datasets
               Description: Text completion datasets are curated collections of text that challenge models to predict and generate the continuation of a given text prompt, enhancing their generative capabilities.
               Level: 3
               # of Papers: 22
               Example Papers: [(97, 'SHIELD: Evaluation and Defense Strategies for Copyright Compliance in LLM Text Generation'), (316, 'NLEBench+NorGLM: A Comprehensive Empirical Analysis and Benchmark Dataset for Generative Language Models in Norwegian'), (431, 'XplainLLM: A Knowledge-Augmented Dataset for Reliable Grounded Explanations in LLMs')]
               ----------------------------------------
          ----------------------------------------
          Label: story_generation_datasets
          Dimension: datasets
          Description: Collections of narratives and story-like texts used to train models in generating coherent and engaging fictional stories.
          Level: 2
          # of Papers: 9
          Example Papers: [(58, 'HEART-felt Narratives: Tracing Empathy and Narrative Style in Personal Stories with LLMs'), (240, 'StyleRemix: Interpretable Authorship Obfuscation via Distillation and Perturbation of Style Elements'), (381, 'MirrorStories: Reflecting Diversity through Personalized Narrative Generation with Large Language Models')]
          ----------------------------------------
          Label: dialogue_generation_datasets
          Dimension: datasets
          Description: Datasets that consist of conversational exchanges, aimed at improving the ability of models to generate human-like dialogue.
          Level: 2
          # of Papers: 28
          Example Papers: [(51, "What's Mine becomes Yours: Defining, Annotating and Detecting Context-Dependent Paraphrases in News Interview Dialogs"), (309, 'Dialog2Flow: Pre-training Soft-Contrastive Action-Driven Sentence Embeddings for Automatic Dialog Flow Extraction'), (519, 'Ontologically Faithful Generation of Non-Player Character Dialogues')]
          ----------------------------------------
          Label: code_generation_datasets
          Dimension: datasets
          Description: Datasets that include programming code snippets and documentation, used to train models for generating code from natural language descriptions.
          Level: 2
          # of Papers: 9
          Example Papers: [(748, 'Leveraging Context-Aware Prompting for Commit Message Generation'), (776, 'How Do Your Code LLMs perform? Empowering Code Instruction Tuning with Really Good Data'), (901, 'Free your mouse! Command Large Language Models to Generate Code to Format Word Documents')]
          ----------------------------------------
          Label: poetry_generation_datasets
          Dimension: datasets
          Description: Curated collections of poems and poetic forms that serve as training material for models focused on generating creative and stylistic text.
          Level: 2
          # of Papers: 1
          Example Papers: [(2360, 'Sonnet or Not, Bot? Poetry Evaluation for Large Models and Datasets')]
          ----------------------------------------
     ----------------------------------------
     Label: cognitive_distortion_detection_datasets
     Dimension: datasets
     Description: These datasets are designed to identify and analyze cognitive distortions in text, aiding in mental health applications and therapeutic interventions.
     Level: 1
     # of Papers: 38
     Example Papers: [(38, 'CoCoLoFa: A Dataset of News Comments with Common Logical Fallacies Written by LLM-Assisted Crowds'), (58, 'HEART-felt Narratives: Tracing Empathy and Narrative Style in Personal Stories with LLMs'), (150, 'Surveying the Dead Minds: Historical-Psychological Text Analysis with Contextualized Construct Representation (CCR) for Classical Chinese')]
     ----------------------------------------
     Label: fairness_benchmarking_datasets
     Dimension: datasets
     Description: These datasets are utilized to evaluate and benchmark the fairness of natural language processing models across various demographic groups.
     Level: 1
     # of Papers: 70
     Example Papers: [(131, 'Oddballs and Misfits: Detecting Implicit Abuse in Which Identity Groups are Depicted as Deviating from the Norm'), (149, 'Collaborative Performance Prediction for Large Language Models'), (150, 'Surveying the Dead Minds: Historical-Psychological Text Analysis with Contextualized Construct Representation (CCR) for Classical Chinese')]
     ----------------------------------------
     Children:
          Label: gender_bias_datasets
          Dimension: datasets
          Description: Datasets specifically designed to evaluate and benchmark gender bias in natural language processing models, often containing examples that highlight disparities in treatment or representation.
          Level: 2
          # of Papers: 13
          Example Papers: [(473, 'Humans or LLMs as the Judge? A Study on Judgement Bias'), (493, '"Flex Tape Can\'t Fix That": Bias and Misinformation in Edited Language Models'), (811, 'Social Bias Probing: Fairness Benchmarking for Language Models')]
          ----------------------------------------
          Label: racial_bias_datasets
          Dimension: datasets
          Description: Datasets focused on assessing racial bias in AI systems, providing instances that reveal potential prejudices or unequal treatment based on race in language processing tasks.
          Level: 2
          # of Papers: 7
          Example Papers: [(493, '"Flex Tape Can\'t Fix That": Bias and Misinformation in Edited Language Models'), (811, 'Social Bias Probing: Fairness Benchmarking for Language Models'), (1034, 'Who is better at math, Jenny or Jingzhen? Uncovering Stereotypes in Large Language Models')]
          ----------------------------------------
          Label: age_bias_datasets
          Dimension: datasets
          Description: Datasets aimed at measuring age-related biases in NLP applications, featuring text samples that reflect stereotypes or biases against different age groups.
          Level: 2
          # of Papers: 4
          Example Papers: [(276, 'KidLM: Advancing Language Models for Children - Early Insights and Future Directions'), (1512, 'A Unified Framework and Dataset for Assessing Societal Bias in Vision-Language Models'), (2019, 'Can LLMs Reason in the Wild with Programs?')]
          ----------------------------------------
          Label: disability_bias_datasets
          Dimension: datasets
          Description: Datasets created to analyze biases against individuals with disabilities, offering insights into how language models may misrepresent or overlook this demographic.
          Level: 2
          # of Papers: 3
          Example Papers: [(811, 'Social Bias Probing: Fairness Benchmarking for Language Models'), (2019, 'Can LLMs Reason in the Wild with Programs?'), (2057, 'BiasDora: Exploring Hidden Biased Associations in Vision-Language Models')]
          ----------------------------------------
          Label: intersectional_bias_datasets
          Dimension: datasets
          Description: Datasets that explore the intersection of multiple identities, such as race and gender, to evaluate how combined biases affect the performance of NLP models.
          Level: 2
          # of Papers: 7
          Example Papers: [(131, 'Oddballs and Misfits: Detecting Implicit Abuse in Which Identity Groups are Depicted as Deviating from the Norm'), (473, 'Humans or LLMs as the Judge? A Study on Judgement Bias'), (695, 'Voices in a Crowd: Searching for clusters of unique perspectives')]
          ----------------------------------------
          Label: safety_bias_datasets
          Dimension: datasets
          Description: Datasets designed to evaluate biases related to safety risks in language processing, focusing on how models handle sensitive topics and potential harm.
          Level: 2
          # of Papers: 10
          Example Papers: [(242, 'STOP! Benchmarking Large Language Models with Sensitivity Testing on Offensive Progressions'), (510, 'Annotation alignment: Comparing LLM and human annotations of conversational safety'), (1335, 'Debiasing Text Safety Classifiers through a Fairness-Aware Ensemble')]
          ----------------------------------------
          Label: moral_bias_datasets
          Dimension: datasets
          Description: Datasets that assess biases in moral beliefs and ethical considerations within NLP applications, highlighting how different moral frameworks influence language understanding.
          Level: 2
          # of Papers: 4
          Example Papers: [(1028, 'D3CODE: Disentangling Disagreements in Data across Cultures on Offensiveness Detection and Evaluation'), (1718, 'Evaluating Moral Beliefs across LLMs through a Pluralistic Framework'), (2019, 'Can LLMs Reason in the Wild with Programs?')]
          ----------------------------------------
          Label: historical_bias_datasets
          Dimension: datasets
          Description: Datasets that explore biases rooted in historical contexts, providing insights into how past events and narratives shape current language models.
          Level: 2
          # of Papers: 8
          Example Papers: [(693, 'Enhancing Data Quality through Simple De-duplication: Navigating Responsible Computational Social Science Research'), (1154, "Let's discuss! Quality Dimensions and Annotated Datasets for Computational Argument Quality Assessment"), (2019, 'Can LLMs Reason in the Wild with Programs?')]
          ----------------------------------------
          Label: toxic_language_datasets
          Dimension: datasets
          Description: Datasets specifically aimed at identifying and evaluating toxic language usage in NLP systems, focusing on harmful or offensive expressions.
          Level: 2
          # of Papers: 9
          Example Papers: [(242, 'STOP! Benchmarking Large Language Models with Sensitivity Testing on Offensive Progressions'), (344, 'ToxiCloakCN: Evaluating Robustness of Offensive Language Detection in Chinese with Cloaking Perturbations'), (811, 'Social Bias Probing: Fairness Benchmarking for Language Models')]
          ----------------------------------------
          Label: cultural_bias_datasets
          Dimension: datasets
          Description: Datasets that investigate biases arising from cultural differences, examining how language models may misinterpret or misrepresent diverse cultural contexts.
          Level: 2
          # of Papers: 6
          Example Papers: [(493, '"Flex Tape Can\'t Fix That": Bias and Misinformation in Edited Language Models'), (811, 'Social Bias Probing: Fairness Benchmarking for Language Models'), (1028, 'D3CODE: Disentangling Disagreements in Data across Cultures on Offensiveness Detection and Evaluation')]
          ----------------------------------------
     ----------------------------------------
     Label: fact_verification_datasets
     Dimension: datasets
     Description: These datasets consist of claims paired with evidence to train models for verifying the accuracy of information in text.
     Level: 1
     # of Papers: 117
     Example Papers: [(112, 'Do We Need Language-Specific Fact-Checking Models? The Case of Chinese'), (139, 'In Search of the Long-Tail: Systematic Generation of Long-Tail Inferential Knowledge via Logical Rule Guided Search'), (149, 'Collaborative Performance Prediction for Large Language Models')]
     ----------------------------------------
     Children:
          Label: claim_review_datasets
          Dimension: datasets
          Description: Datasets that contain claims made in various contexts along with their corresponding verifications, often sourced from fact-checking organizations.
          Level: 2
          ----------------------------------------
          Label: fact_checking_challenge_datasets
          Dimension: datasets
          Description: Datasets specifically designed for fact-checking challenges, providing a variety of claims and their veracity for evaluation purposes.
          Level: 2
          # of Papers: 49
          Example Papers: [(112, 'Do We Need Language-Specific Fact-Checking Models? The Case of Chinese'), (246, 'An Analysis of Multilingual FActScore'), (281, 'EVEDIT: Event-based Knowledge Editing for Deterministic Knowledge Propagation')]
          ----------------------------------------
          Children:
               Label: claim_verification_datasets
               Dimension: datasets
               Description: Datasets specifically designed for verifying the truthfulness of claims made in various contexts, often containing labeled examples of true and false claims.
               Level: 3
               # of Papers: 1
               Example Papers: [(1367, 'Time Matters: An End-to-End Solution for Temporal Claim Verification')]
               ----------------------------------------
               Label: fact_checking_evaluation_datasets
               Dimension: datasets
               Description: Datasets used to evaluate the performance of fact-checking systems, typically including a mix of verified claims and their sources.
               Level: 3
               # of Papers: 20
               Example Papers: [(112, 'Do We Need Language-Specific Fact-Checking Models? The Case of Chinese'), (246, 'An Analysis of Multilingual FActScore'), (447, '"Image, Tell me your story!" Predicting the original meta-context of visual misinformation')]
               ----------------------------------------
               Label: misinformation_detection_datasets
               Dimension: datasets
               Description: Datasets focused on identifying and categorizing misinformation across different platforms, providing examples of false information and its spread.
               Level: 3
               # of Papers: 1
               Example Papers: [(447, '"Image, Tell me your story!" Predicting the original meta-context of visual misinformation')]
               ----------------------------------------
               Label: source_reliability_datasets
               Dimension: datasets
               Description: Datasets that assess the reliability of various sources of information, often containing ratings or classifications of sources based on their credibility.
               Level: 3
               ----------------------------------------
               Label: fact_checking_benchmark_datasets
               Dimension: datasets
               Description: Standardized datasets used as benchmarks for testing and comparing the effectiveness of different fact-checking algorithms and methodologies.
               Level: 3
               # of Papers: 38
               Example Papers: [(112, 'Do We Need Language-Specific Fact-Checking Models? The Case of Chinese'), (246, 'An Analysis of Multilingual FActScore'), (281, 'EVEDIT: Event-based Knowledge Editing for Deterministic Knowledge Propagation')]
               ----------------------------------------
          ----------------------------------------
          Label: news_article_fact_verification_datasets
          Dimension: datasets
          Description: Datasets that pair news articles with verified facts, allowing researchers to assess the accuracy of information presented in media.
          Level: 2
          # of Papers: 10
          Example Papers: [(602, 'GlobeSumm: A Challenging Benchmark Towards Unifying Multi-lingual, Cross-lingual and Multi-document News Summarization'), (1721, 'Reap the Wild Wind: Detecting Media Storms in Large-Scale News Corpora'), (1729, 'Generating Media Background Checks for Automated Source Critical Reasoning')]
          ----------------------------------------
          Label: social_media_fact_verification_datasets
          Dimension: datasets
          Description: Datasets that compile claims made on social media platforms along with their fact-checked statuses, highlighting the rapid spread of misinformation.
          Level: 2
          # of Papers: 10
          Example Papers: [(258, 'Leveraging Conflicts in Social Media Posts: Unintended Offense Dataset'), (602, 'GlobeSumm: A Challenging Benchmark Towards Unifying Multi-lingual, Cross-lingual and Multi-document News Summarization'), (719, 'SPEED++: A Multilingual Event Extraction Framework for Epidemic Prediction and Preparedness')]
          ----------------------------------------
          Label: scientific_claim_verification_datasets
          Dimension: datasets
          Description: Datasets focused on claims made in scientific literature, providing a resource for verifying the accuracy of scientific assertions.
          Level: 2
          # of Papers: 40
          Example Papers: [(112, 'Do We Need Language-Specific Fact-Checking Models? The Case of Chinese'), (246, 'An Analysis of Multilingual FActScore'), (477, 'Stepwise Verification and Remediation of Student Reasoning Errors with Large Language Model Tutors')]
          ----------------------------------------
          Label: chronological_text_corpus_fact_verification_datasets
          Dimension: datasets
          Description: Datasets that consist of chronological text corpora used for verifying facts over time, enabling the analysis of temporal accuracy.
          Level: 2
          # of Papers: 6
          Example Papers: [(602, 'GlobeSumm: A Challenging Benchmark Towards Unifying Multi-lingual, Cross-lingual and Multi-document News Summarization'), (2147, 'Cross-Lingual Multi-Hop Knowledge Editing'), (2549, 'Constructing Domain-Specific Evaluation Sets for LLM-as-a-judge')]
          ----------------------------------------
          Label: knowledge_conflict_datasets
          Dimension: datasets
          Description: Datasets that explore conflicts in knowledge claims across various domains, providing insights into discrepancies and verification challenges.
          Level: 2
          # of Papers: 11
          Example Papers: [(602, 'GlobeSumm: A Challenging Benchmark Towards Unifying Multi-lingual, Cross-lingual and Multi-document News Summarization'), (842, 'AKEW: Assessing Knowledge Editing in the Wild'), (1408, 'ConvKGYarn: Spinning Configurable and Scalable Conversational Knowledge Graph QA Datasets with Large Language Models')]
          ----------------------------------------
          Label: web_agent_fact_verification_datasets
          Dimension: datasets
          Description: Datasets designed for evaluating the performance of web agents in fact-checking claims sourced from online content.
          Level: 2
          # of Papers: 11
          Example Papers: [(504, 'AssistantBench: Can Web Agents Solve Realistic and Time-Consuming Tasks?'), (602, 'GlobeSumm: A Challenging Benchmark Towards Unifying Multi-lingual, Cross-lingual and Multi-document News Summarization'), (842, 'AKEW: Assessing Knowledge Editing in the Wild')]
          ----------------------------------------
          Label: cultural_commonsense_fact_verification_datasets
          Dimension: datasets
          Description: Datasets that focus on verifying claims related to cultural commonsense knowledge, aiding in the understanding of cultural context in fact-checking.
          Level: 2
          # of Papers: 4
          Example Papers: [(531, 'Susu Box or Piggy Bank: Assessing Cultural Commonsense Knowledge between Ghana and the US'), (602, 'GlobeSumm: A Challenging Benchmark Towards Unifying Multi-lingual, Cross-lingual and Multi-document News Summarization'), (2549, 'Constructing Domain-Specific Evaluation Sets for LLM-as-a-judge')]
          ----------------------------------------
          Label: financial_document_fact_verification_datasets
          Dimension: datasets
          Description: Datasets that compile financial documents with corresponding fact verifications, facilitating the assessment of accuracy in financial reporting.
          Level: 2
          # of Papers: 6
          Example Papers: [(602, 'GlobeSumm: A Challenging Benchmark Towards Unifying Multi-lingual, Cross-lingual and Multi-document News Summarization'), (817, 'FinDVer: Explainable Claim Verification over Long and Hybrid-content Financial Documents'), (1345, 'Greenback Bears and Fiscal Hawks: Finance is a Jungle and Text Embeddings Must Adapt')]
          ----------------------------------------
     ----------------------------------------
     Label: speech_recognition_datasets
     Dimension: datasets
     Description: These datasets are used to train models for converting spoken language into text, facilitating advancements in voice-activated technologies.
     Level: 1
     # of Papers: 46
     Example Papers: [(51, "What's Mine becomes Yours: Defining, Annotating and Detecting Context-Dependent Paraphrases in News Interview Dialogs"), (149, 'Collaborative Performance Prediction for Large Language Models'), (150, 'Surveying the Dead Minds: Historical-Psychological Text Analysis with Contextualized Construct Representation (CCR) for Classical Chinese')]
     ----------------------------------------
     Children:
          Label: librispeech
          Dimension: datasets
          Description: LibriSpeech is a large-scale corpus of read English speech derived from audiobooks, designed for training and evaluating automatic speech recognition systems.
          Level: 2
          ----------------------------------------
          Label: common_voice
          Dimension: datasets
          Description: Common Voice is an open-source dataset created by Mozilla, featuring diverse voice recordings from volunteers around the world to improve speech recognition technology.
          Level: 2
          ----------------------------------------
          Label: timit
          Dimension: datasets
          Description: TIMIT is a phonemically and lexically transcribed corpus of American English speech, widely used for acoustic-phonetic studies and speech recognition research.
          Level: 2
          ----------------------------------------
          Label: wsj
          Dimension: datasets
          Description: The Wall Street Journal (WSJ) corpus consists of read speech from news articles, providing a benchmark for evaluating speech recognition systems in a controlled environment.
          Level: 2
          ----------------------------------------
          Label: voxforge
          Dimension: datasets
          Description: VoxForge is a collection of transcribed speech data from various speakers, aimed at creating open-source speech recognition engines and promoting multilingual support.
          Level: 2
          ----------------------------------------
          Label: multilingual_speech_recognition_datasets
          Dimension: datasets
          Description: This cluster encompasses datasets specifically designed for training and evaluating speech recognition systems across multiple languages and dialects.
          Level: 2
          # of Papers: 24
          Example Papers: [(149, 'Collaborative Performance Prediction for Large Language Models'), (285, 'Cross-Domain Audio Deepfake Detection: Dataset and Analysis'), (425, 'Multi-Dialect Vietnamese: Task, Dataset, Baseline Models and Challenges')]
          ----------------------------------------
          Label: intelligent_assistant_datasets
          Dimension: datasets
          Description: This cluster includes datasets tailored for developing and improving intelligent assistant technologies, focusing on conversational and task-oriented interactions.
          Level: 2
          # of Papers: 6
          Example Papers: [(613, 'Towards Probing Speech-Specific Risks in Large Multimodal Models: A Taxonomy, Benchmark, and Insights'), (1104, 'Perceptions to Beliefs: Exploring Precursory Inferences for Theory of Mind in Large Language Models'), (1347, 'Detecting Ambiguous Utterances in an Intelligent Assistant')]
          ----------------------------------------
          Label: code-switched_datasets
          Dimension: datasets
          Description: This cluster features datasets that contain instances of code-switching, where speakers alternate between languages or dialects within a conversation, useful for training multilingual speech recognition systems.
          Level: 2
          # of Papers: 2
          Example Papers: [(613, 'Towards Probing Speech-Specific Risks in Large Multimodal Models: A Taxonomy, Benchmark, and Insights'), (1802, 'PolyWER: A Holistic Evaluation Framework for Code-Switched Speech Recognition')]
          ----------------------------------------
          Label: multidialectal_arabic
          Dimension: datasets
          Description: This cluster focuses on datasets that capture various dialects of Arabic, aimed at enhancing speech recognition capabilities in diverse Arabic-speaking regions.
          Level: 2
          # of Papers: 1
          Example Papers: [(1210, 'Casablanca: Data and Models for Multidialectal Arabic Speech Recognition')]
          ----------------------------------------
          Label: news_interview_dialogs
          Dimension: datasets
          Description: This cluster consists of datasets derived from news interviews, providing real-world conversational data for training speech recognition systems in journalistic contexts.
          Level: 2
          # of Papers: 2
          Example Papers: [(51, "What's Mine becomes Yours: Defining, Annotating and Detecting Context-Dependent Paraphrases in News Interview Dialogs"), (2355, 'Large Language Models Know What To Say But Not When To Speak')]
          ----------------------------------------
     ----------------------------------------
     Label: multimodal_datasets
     Dimension: datasets
     Description: These datasets integrate multiple forms of data, such as text, images, and audio, to enhance the training of models that understand and generate content across modalities.
     Level: 1
     # of Papers: 148
     Example Papers: [(10, "Eyes Don't Lie: Subjective Hate Annotation and Detection with Gaze"), (43, 'GeoGPT4V: Towards Geometric Multi-modal Large Language Models with Geometric Image Generation'), (60, 'Bridging Cultures in the Kitchen: A Framework and Benchmark for Cross-Cultural Recipe Retrieval')]
     ----------------------------------------
     Children:
          Label: image_captioning_datasets
          Dimension: datasets
          Description: These datasets contain images paired with descriptive captions, enabling models to learn the relationship between visual content and textual descriptions.
          Level: 2
          # of Papers: 1
          Example Papers: [(2803, 'Retrieval Evaluation for Long-Form and Knowledge-Intensive Image-Text Article Composition')]
          ----------------------------------------
          Label: video_text_datasets
          Dimension: datasets
          Description: This category includes datasets that consist of videos along with corresponding textual annotations or transcripts, facilitating the study of temporal and spatial relationships in multimodal contexts.
          Level: 2
          # of Papers: 8
          Example Papers: [(897, 'VideoCLIP-XL: Advancing Long Description Understanding for Video CLIP Models'), (1127, 'VIEWS: Entity-Aware News Video Captioning'), (1273, 'Lighthouse: A User-Friendly Library for Reproducible Video Moment Retrieval and Highlight Detection')]
          ----------------------------------------
          Label: audio_visual_datasets
          Dimension: datasets
          Description: These datasets feature synchronized audio and visual data, often used for tasks such as speech recognition in video or emotion detection from both audio and visual cues.
          Level: 2
          # of Papers: 4
          Example Papers: [(613, 'Towards Probing Speech-Specific Risks in Large Multimodal Models: A Taxonomy, Benchmark, and Insights'), (820, 'VHASR: A Multimodal Speech Recognition System With Vision Hotwords'), (1687, 'Emosical: An Emotion-Annotated Musical Theatre Dataset')]
          ----------------------------------------
          Label: multimodal_sentiment_analysis_datasets
          Dimension: datasets
          Description: This type of dataset combines text, audio, and visual data to analyze and predict sentiment, providing a richer context for understanding emotional expression.
          Level: 2
          # of Papers: 20
          Example Papers: [(126, 'VideoScore: Building Automatic Metrics to Simulate Fine-grained Human Feedback for Video Generation'), (295, 'SEACrowd: A Multilingual Multimodal Data Hub and Benchmark Suite for Southeast Asian Languages'), (357, 'VLFeedback: A Large-Scale AI Feedback Dataset for Large Vision-Language Models Alignment')]
          ----------------------------------------
          Label: multimodal_dialogue_datasets
          Dimension: datasets
          Description: These datasets consist of dialogues that include both text and visual elements, such as images or videos, to enhance the understanding of conversational context and intent.
          Level: 2
          # of Papers: 20
          Example Papers: [(43, 'GeoGPT4V: Towards Geometric Multi-modal Large Language Models with Geometric Image Generation'), (150, 'Surveying the Dead Minds: Historical-Psychological Text Analysis with Contextualized Construct Representation (CCR) for Classical Chinese'), (357, 'VLFeedback: A Large-Scale AI Feedback Dataset for Large Vision-Language Models Alignment')]
          ----------------------------------------
          Label: multimodal_benchmarking_datasets
          Dimension: datasets
          Description: These datasets are designed for evaluating and comparing the performance of multimodal models across various tasks and benchmarks.
          Level: 2
          # of Papers: 67
          Example Papers: [(60, 'Bridging Cultures in the Kitchen: A Framework and Benchmark for Cross-Cultural Recipe Retrieval'), (105, 'TopViewRS: Vision-Language Models as Top-View Spatial Reasoners'), (126, 'VideoScore: Building Automatic Metrics to Simulate Fine-grained Human Feedback for Video Generation')]
          ----------------------------------------
          Children:
               Label: image_text_matching
               Dimension: datasets
               Description: This dataset evaluates the ability of models to match images with their corresponding textual descriptions, facilitating advancements in understanding the relationship between visual and textual information.
               Level: 3
               # of Papers: 9
               Example Papers: [(60, 'Bridging Cultures in the Kitchen: A Framework and Benchmark for Cross-Cultural Recipe Retrieval'), (295, 'SEACrowd: A Multilingual Multimodal Data Hub and Benchmark Suite for Southeast Asian Languages'), (800, 'ASL STEM Wiki: Dataset and Benchmark for Interpreting STEM Articles')]
               ----------------------------------------
               Label: visual_question_answering
               Dimension: datasets
               Description: This dataset challenges models to answer questions about images, requiring a deep understanding of both visual content and natural language processing to provide accurate responses.
               Level: 3
               # of Papers: 9
               Example Papers: [(105, 'TopViewRS: Vision-Language Models as Top-View Spatial Reasoners'), (283, 'From the Least to the Most: Building a Plug-and-Play Visual Reasoner via Data Synthesis'), (295, 'SEACrowd: A Multilingual Multimodal Data Hub and Benchmark Suite for Southeast Asian Languages')]
               ----------------------------------------
               Label: multimodal_sentiment_analysis
               Dimension: datasets
               Description: This dataset focuses on analyzing sentiments expressed in both text and images, allowing for a comprehensive understanding of emotional context across different modalities.
               Level: 3
               # of Papers: 23
               Example Papers: [(60, 'Bridging Cultures in the Kitchen: A Framework and Benchmark for Cross-Cultural Recipe Retrieval'), (295, 'SEACrowd: A Multilingual Multimodal Data Hub and Benchmark Suite for Southeast Asian Languages'), (445, 'MIND: Multimodal Shopping Intention Distillation from Large Vision-language Models for E-commerce Purchase Understanding')]
               ----------------------------------------
               Label: video_captioning
               Dimension: datasets
               Description: This dataset involves generating descriptive captions for video content, testing the ability of models to comprehend and summarize dynamic visual information in conjunction with language.
               Level: 3
               # of Papers: 9
               Example Papers: [(295, 'SEACrowd: A Multilingual Multimodal Data Hub and Benchmark Suite for Southeast Asian Languages'), (1127, 'VIEWS: Entity-Aware News Video Captioning'), (1132, 'Unveiling Multi-level and Multi-modal Semantic Representations in the Human Brain using Large Language Models')]
               ----------------------------------------
               Label: audio_visual_scene_analysis
               Dimension: datasets
               Description: This dataset combines audio and visual inputs to analyze scenes, enabling models to interpret and understand complex environments through multiple sensory modalities.
               Level: 3
               # of Papers: 10
               Example Papers: [(295, 'SEACrowd: A Multilingual Multimodal Data Hub and Benchmark Suite for Southeast Asian Languages'), (613, 'Towards Probing Speech-Specific Risks in Large Multimodal Models: A Taxonomy, Benchmark, and Insights'), (820, 'VHASR: A Multimodal Speech Recognition System With Vision Hotwords')]
               ----------------------------------------
          ----------------------------------------
          Label: multimodal_causal_reasoning_datasets
          Dimension: datasets
          Description: This category includes datasets that facilitate the study of causal relationships using multimodal data, integrating text, images, and other modalities.
          Level: 2
          # of Papers: 28
          Example Papers: [(126, 'VideoScore: Building Automatic Metrics to Simulate Fine-grained Human Feedback for Video Generation'), (136, 'VIVA: A Benchmark for Vision-Grounded Decision-Making with Human Values'), (142, 'Selective Vision is the Challenge for Visual Reasoning: A Benchmark for Visual Argument Understanding')]
          ----------------------------------------
          Label: multimodal_fake_news_detection_datasets
          Dimension: datasets
          Description: These datasets are specifically curated to help in the detection and analysis of fake news through the integration of text and visual content.
          Level: 2
          # of Papers: 19
          Example Papers: [(10, "Eyes Don't Lie: Subjective Hate Annotation and Detection with Gaze"), (126, 'VideoScore: Building Automatic Metrics to Simulate Fine-grained Human Feedback for Video Generation'), (295, 'SEACrowd: A Multilingual Multimodal Data Hub and Benchmark Suite for Southeast Asian Languages')]
          ----------------------------------------
          Label: multimodal_question_answering_datasets
          Dimension: datasets
          Description: This type of dataset combines various modalities to enable models to answer questions based on both textual and visual information.
          Level: 2
          # of Papers: 38
          Example Papers: [(126, 'VideoScore: Building Automatic Metrics to Simulate Fine-grained Human Feedback for Video Generation'), (283, 'From the Least to the Most: Building a Plug-and-Play Visual Reasoner via Data Synthesis'), (295, 'SEACrowd: A Multilingual Multimodal Data Hub and Benchmark Suite for Southeast Asian Languages')]
          ----------------------------------------
          Label: multimodal_language_learning_datasets
          Dimension: datasets
          Description: These datasets are designed to support language learning by integrating text, audio, and visual elements to enhance comprehension and engagement.
          Level: 2
          # of Papers: 49
          Example Papers: [(43, 'GeoGPT4V: Towards Geometric Multi-modal Large Language Models with Geometric Image Generation'), (60, 'Bridging Cultures in the Kitchen: A Framework and Benchmark for Cross-Cultural Recipe Retrieval'), (126, 'VideoScore: Building Automatic Metrics to Simulate Fine-grained Human Feedback for Video Generation')]
          ----------------------------------------
          Children:
               Label: image_captioning_datasets
               Label: video_language_datasets
               Dimension: datasets
               Description: This category includes datasets that combine video content with corresponding textual descriptions or transcripts, facilitating the study of language in dynamic visual contexts.
               Level: 3
               # of Papers: 4
               Example Papers: [(126, 'VideoScore: Building Automatic Metrics to Simulate Fine-grained Human Feedback for Video Generation'), (517, 'SignCLIP: Connecting Text and Sign Language by Contrastive Learning'), (1534, 'MMAR: Multilingual and Multimodal Anaphora Resolution in Instructional Videos')]
               ----------------------------------------
               Label: audio_transcription_datasets
               Dimension: datasets
               Description: These datasets feature audio recordings along with their transcriptions, allowing for the exploration of language learning through auditory stimuli.
               Level: 3
               ----------------------------------------
               Label: multimodal_dialogue_datasets
               Label: gesture_language_datasets
               Dimension: datasets
               Description: These datasets focus on the integration of sign language gestures with corresponding spoken or written language, promoting the study of multimodal communication.
               Level: 3
               # of Papers: 1
               Example Papers: [(517, 'SignCLIP: Connecting Text and Sign Language by Contrastive Learning')]
               ----------------------------------------
          ----------------------------------------
     ----------------------------------------
----------------------------------------
