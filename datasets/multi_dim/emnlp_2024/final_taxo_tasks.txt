Label: natural_language_processing
Dimension: tasks
Description: None
Level: 0
# of Papers: 2954
Example Papers: [(0, 'UniGen: Universal Domain Generalization for Sentiment Classification via Zero-shot Dataset Generation'), (1, 'Multi-News+: Cost-efficient Dataset Cleansing via LLM-based Data Annotation'), (2, 'FIZZ: Factual Inconsistency Detection by Zoom-in Summary and Zoom-out Document')]
----------------------------------------
Children:
     Label: text_classification
     Dimension: tasks
     Description: The task of assigning predefined categories to text documents based on their content, often used in applications like spam detection and sentiment analysis.
     Level: 1
     # of Papers: 455
     Example Papers: [(5, 'ImageInWords: Unlocking Hyper-Detailed Image Descriptions'), (11, "NumeroLogic: Number Encoding for Enhanced LLMs' Numerical Reasoning"), (13, 'A Usage-centric Take on Intent Understanding in E-Commerce')]
     ----------------------------------------
     Children:
          Label: sentiment_analysis
          Dimension: tasks
          Description: The task of determining the emotional tone behind a body of text, often used to gauge public opinion or customer feedback.
          Level: 1
          # of Papers: 9
          Example Papers: [(48, 'Overcome Noise and Bias: Segmentation-Aided Multi-Granularity Denoising and Debiasing for Enhanced Quarduples Extraction in Dialogue'), (108, 'An Effective Deployment of Diffusion LM for Data Augmentation in Low-Resource Sentiment Classification'), (687, 'Leveraging Estimated Transferability Over Human Intuition for Model Selection in Text Ranking')]
          ----------------------------------------
          Children:
               Label: aspect_based_sentiment_analysis
               Dimension: tasks
               Description: This subtopic focuses on analyzing sentiments related to specific aspects or features of products or services, allowing for a more granular understanding of customer opinions.
               Level: 2
               # of Papers: 3
               Example Papers: [(48, 'Overcome Noise and Bias: Segmentation-Aided Multi-Granularity Denoising and Debiasing for Enhanced Quarduples Extraction in Dialogue'), (1170, 'I love pineapple on pizza != I hate pineapple on pizza: Stance-Aware Sentence Transformers for Opinion Mining'), (1732, 'Stanceformer: Target-Aware Transformer for Stance Detection')]
               ----------------------------------------
               Label: emotion_classification
               Dimension: tasks
               Description: This subtopic involves categorizing text based on the emotional states expressed within, such as happiness, sadness, anger, or fear, to better understand the emotional tone of the content.
               Level: 2
               ----------------------------------------
               Label: sarcasm_detection
               Dimension: tasks
               Description: This subtopic aims to identify and interpret sarcastic remarks in text, which can often convey sentiments that differ from their literal meanings.
               Level: 2
               # of Papers: 1
               Example Papers: [(1170, 'I love pineapple on pizza != I hate pineapple on pizza: Stance-Aware Sentence Transformers for Opinion Mining')]
               ----------------------------------------
               Label: multimodal_sentiment_analysis
               Dimension: tasks
               Description: This subtopic integrates multiple data modalities, such as text, audio, and visual elements, to enhance the accuracy of sentiment detection and analysis.
               Level: 2
               # of Papers: 2
               Example Papers: [(687, 'Leveraging Estimated Transferability Over Human Intuition for Model Selection in Text Ranking'), (1170, 'I love pineapple on pizza != I hate pineapple on pizza: Stance-Aware Sentence Transformers for Opinion Mining')]
               ----------------------------------------
               Label: depression_detection
               Dimension: tasks
               Description: This subtopic focuses on identifying signs of depression in text, which can be crucial for mental health assessments and interventions.
               Level: 2
               # of Papers: 1
               Example Papers: [(1170, 'I love pineapple on pizza != I hate pineapple on pizza: Stance-Aware Sentence Transformers for Opinion Mining')]
               ----------------------------------------
          ----------------------------------------
          Label: spam_detection
          Dimension: tasks
          Description: The process of identifying and filtering out unwanted or harmful messages, typically in email or messaging systems, based on their content.
          Level: 2
          # of Papers: 3
          Example Papers: [(687, 'Leveraging Estimated Transferability Over Human Intuition for Model Selection in Text Ranking'), (938, 'RAFT: Realistic Attacks to Fool Text Detectors'), (1366, 'KorSmishing Explainer: A Korean-centric LLM-based Framework for Smishing Detection and Explanation Generation')]
          ----------------------------------------
          Label: multi_label_classification
          Dimension: tasks
          Description: A classification task where each instance can be assigned multiple labels, allowing for more complex categorization of text documents.
          Level: 2
          # of Papers: 146
          Example Papers: [(42, 'Parameter-Efficient Sparsity Crafting from Dense to Mixture-of-Experts for Instruction Tuning on General Tasks'), (101, 'MetaGPT: Merging Large Language Models Using Model Exclusive Task Arithmetic'), (108, 'An Effective Deployment of Diffusion LM for Data Augmentation in Low-Resource Sentiment Classification')]
          ----------------------------------------
          Children:
               Label: adversarial_methods
               Dimension: tasks
               Description: This cluster encompasses techniques focused on adversarial attacks and training methods aimed at enhancing the robustness of multi-label classification models.
               Level: 3
               # of Papers: 10
               Example Papers: [(163, 'Alignment-Enhanced Decoding: Defending Jailbreaks via Token-Level Adaptive Refining of Probability Distributions'), (480, 'The Best Defense is Attack: Repairing Semantics in Textual Adversarial Examples'), (833, 'Shortcuts Arising from Contrast: Towards Effective and Lightweight Clean-Label Attacks in Prompt-Based Learning')]
               ----------------------------------------
               Label: prompt_based_techniques
               Dimension: tasks
               Description: This cluster includes various prompt optimization, engineering, and tuning methods that leverage prompts to improve multi-label classification performance.
               Level: 3
               # of Papers: 19
               Example Papers: [(219, 'Incubating Text Classifiers Following User Instruction with Nothing but LLM'), (225, 'PRompt Optimization in Multi-Step Tasks (PROMST): Integrating Human Feedback and Heuristic-based Sampling'), (305, 'How Far Can We Extract Diverse Perspectives from Large Language Models?')]
               ----------------------------------------
               Label: learning_strategies
               Dimension: tasks
               Description: This cluster covers diverse learning strategies such as zero-shot learning, few-shot learning, and active learning that facilitate effective multi-label classification in various contexts.
               Level: 3
               # of Papers: 53
               Example Papers: [(42, 'Parameter-Efficient Sparsity Crafting from Dense to Mixture-of-Experts for Instruction Tuning on General Tasks'), (101, 'MetaGPT: Merging Large Language Models Using Model Exclusive Task Arithmetic'), (214, 'Performance-Guided LLM Knowledge Distillation for Efficient Text Classification at Scale')]
               ----------------------------------------
               Label: data_handling_and_augmentation
               Dimension: tasks
               Description: This cluster focuses on methods related to data augmentation, selection, and preprocessing techniques that enhance the quality and quantity of training data for multi-label classification.
               Level: 3
               # of Papers: 38
               Example Papers: [(108, 'An Effective Deployment of Diffusion LM for Data Augmentation in Low-Resource Sentiment Classification'), (218, 'Text Grafting: Near-Distribution Weak Supervision for Minority Classes in Text Classification'), (219, 'Incubating Text Classifiers Following User Instruction with Nothing but LLM')]
               ----------------------------------------
               Label: evaluation_and_analysis
               Dimension: tasks
               Description: This cluster includes techniques for model evaluation, performance prediction, and analysis methods that assess the effectiveness and fairness of multi-label classification systems.
               Level: 3
               # of Papers: 64
               Example Papers: [(149, 'Collaborative Performance Prediction for Large Language Models'), (214, 'Performance-Guided LLM Knowledge Distillation for Efficient Text Classification at Scale'), (219, 'Incubating Text Classifiers Following User Instruction with Nothing but LLM')]
               ----------------------------------------
          ----------------------------------------
          Label: document_classification
          Dimension: tasks
          Description: The task of categorizing entire documents into predefined categories based on their content, often used in organizing large datasets.
          Level: 2
          # of Papers: 176
          Example Papers: [(39, 'Tokenization Is More Than Compression'), (42, 'Parameter-Efficient Sparsity Crafting from Dense to Mixture-of-Experts for Instruction Tuning on General Tasks'), (149, 'Collaborative Performance Prediction for Large Language Models')]
          ----------------------------------------
          Children:
               Label: text_quality_evaluation
               Dimension: tasks
               Description: The task of assessing the quality of text documents based on various criteria, ensuring that they meet specific standards for classification purposes.
               Level: 3
               # of Papers: 27
               Example Papers: [(186, 'ScalingFilter: Assessing Data Quality through Inverse Utilization of Scaling Laws'), (272, 'Bayesian Calibration of Win Rate Estimation with LLM Evaluators'), (480, 'The Best Defense is Attack: Repairing Semantics in Textual Adversarial Examples')]
               ----------------------------------------
               Label: genre_classification
               Dimension: tasks
               Description: The process of categorizing documents into distinct genres, such as fiction, non-fiction, academic, or technical, based on their content and style.
               Level: 3
               # of Papers: 6
               Example Papers: [(1096, 'Evaluating Diversity in Automatic Poetry Generation'), (1112, 'The Empirical Variability of Narrative Perceptions of Social Media Texts'), (1879, 'HiCuLR: Hierarchical Curriculum Learning for Rhetorical Role Labeling of Legal Documents')]
               ----------------------------------------
               Label: news_classification
               Dimension: tasks
               Description: The task of categorizing news articles into predefined categories, such as politics, sports, entertainment, and technology, to facilitate better organization and retrieval.
               Level: 3
               # of Papers: 6
               Example Papers: [(823, 'Building Resources for Emakhuwa: Machine Translation and News Classification Benchmarks'), (1215, 'Do LLMs Plan Like Human Writers? Comparing Journalist Coverage of Press Releases with LLMs'), (1907, 'Multilingual Fine-Grained News Headline Hallucination Detection')]
               ----------------------------------------
               Label: long_document_classification
               Dimension: tasks
               Description: The specialized task of classifying lengthy documents, which may require different techniques and considerations compared to shorter texts.
               Level: 3
               # of Papers: 16
               Example Papers: [(496, 'Jellyfish: Instruction-Tuning Local Large Language Models for Data Preprocessing'), (1036, 'Recurrent Alignment with Hard Attention for Hierarchical Text Rating'), (1155, 'Automatic sentence segmentation of clinical record narratives in real-world data')]
               ----------------------------------------
               Label: multi_label_text_classification
               Dimension: tasks
               Description: The task of assigning multiple labels to a single document, allowing for a more nuanced categorization that reflects the complexity of its content.
               Level: 3
               # of Papers: 125
               Example Papers: [(39, 'Tokenization Is More Than Compression'), (42, 'Parameter-Efficient Sparsity Crafting from Dense to Mixture-of-Experts for Instruction Tuning on General Tasks'), (207, 'A Generic Method for Fine-grained Category Discovery in Natural Language Texts')]
               ----------------------------------------
          ----------------------------------------
          Label: intent_classification
          Dimension: tasks
          Description: The process of identifying the intention behind a user's input, commonly used in conversational agents and chatbots to determine appropriate responses.
          Level: 2
          # of Papers: 37
          Example Papers: [(13, 'A Usage-centric Take on Intent Understanding in E-Commerce'), (169, 'DGLF: A Dual Graph-based Learning Framework for Multi-modal Sarcasm Detection'), (214, 'Performance-Guided LLM Knowledge Distillation for Efficient Text Classification at Scale')]
          ----------------------------------------
          Label: event_classification
          Dimension: tasks
          Description: The task of categorizing events based on their characteristics and context, often used in information retrieval and content organization.
          Level: 2
          # of Papers: 26
          Example Papers: [(169, 'DGLF: A Dual Graph-based Learning Framework for Multi-modal Sarcasm Detection'), (214, 'Performance-Guided LLM Knowledge Distillation for Efficient Text Classification at Scale'), (219, 'Incubating Text Classifiers Following User Instruction with Nothing but LLM')]
          ----------------------------------------
          Label: knowledge_extraction
          Dimension: tasks
          Description: The process of identifying and extracting relevant knowledge from text, enabling better understanding and utilization of information.
          Level: 2
          # of Papers: 181
          Example Papers: [(48, 'Overcome Noise and Bias: Segmentation-Aided Multi-Granularity Denoising and Debiasing for Enhanced Quarduples Extraction in Dialogue'), (53, 'Large Language Models for Data Annotation and Synthesis: A Survey'), (56, 'RoseLoRA: Row and Column-wise Sparse Low-rank Adaptation of Pre-trained Language Model for Knowledge Editing and Fine-tuning')]
          ----------------------------------------
          Children:
               Label: text_analysis
               Dimension: tasks
               Description: The process of examining and interpreting text data to extract meaningful insights and knowledge.
               Level: 3
               # of Papers: 143
               Example Papers: [(48, 'Overcome Noise and Bias: Segmentation-Aided Multi-Granularity Denoising and Debiasing for Enhanced Quarduples Extraction in Dialogue'), (56, 'RoseLoRA: Row and Column-wise Sparse Low-rank Adaptation of Pre-trained Language Model for Knowledge Editing and Fine-tuning'), (58, 'HEART-felt Narratives: Tracing Empathy and Narrative Style in Personal Stories with LLMs')]
               ----------------------------------------
               Label: relation_extraction
               Dimension: tasks
               Description: The task of identifying and extracting relationships between entities mentioned in the text.
               Level: 3
               # of Papers: 14
               Example Papers: [(305, 'How Far Can We Extract Diverse Perspectives from Large Language Models?'), (746, 'Grasping the Essentials: Tailoring Large Language Models for Zero-Shot Relation Extraction'), (765, 'Topic-Oriented Open Relation Extraction with A Priori Seed Generation')]
               ----------------------------------------
               Label: text_preprocessing
               Dimension: tasks
               Description: The techniques used to prepare and clean text data for further analysis and knowledge extraction.
               Level: 3
               # of Papers: 95
               Example Papers: [(48, 'Overcome Noise and Bias: Segmentation-Aided Multi-Granularity Denoising and Debiasing for Enhanced Quarduples Extraction in Dialogue'), (56, 'RoseLoRA: Row and Column-wise Sparse Low-rank Adaptation of Pre-trained Language Model for Knowledge Editing and Fine-tuning'), (65, 'AMR-Evol: Adaptive Modular Response Evolution Elicits Better Knowledge Distillation for Large Language Models in Code Generation')]
               ----------------------------------------
               Label: text_annotation
               Dimension: tasks
               Description: The process of labeling text data with relevant tags or categories to facilitate knowledge extraction.
               Level: 3
               # of Papers: 40
               Example Papers: [(53, 'Large Language Models for Data Annotation and Synthesis: A Survey'), (155, 'To Word Senses and Beyond: Inducing Concepts with Contextualized Language Models'), (193, 'Pixology: Probing the Linguistic and Visual Capabilities of Pixel-based Language Models')]
               ----------------------------------------
               Label: event_extraction
               Dimension: tasks
               Description: The identification and extraction of events described in text, including their participants and attributes.
               Level: 3
               # of Papers: 33
               Example Papers: [(48, 'Overcome Noise and Bias: Segmentation-Aided Multi-Granularity Denoising and Debiasing for Enhanced Quarduples Extraction in Dialogue'), (58, 'HEART-felt Narratives: Tracing Empathy and Narrative Style in Personal Stories with LLMs'), (219, 'Incubating Text Classifiers Following User Instruction with Nothing but LLM')]
               ----------------------------------------
          ----------------------------------------
          Label: response_evaluation
          Dimension: tasks
          Description: The task of assessing the clarity and relevance of responses in various contexts, such as customer service or educational settings.
          Level: 2
          # of Papers: 15
          Example Papers: [(65, 'AMR-Evol: Adaptive Modular Response Evolution Elicits Better Knowledge Distillation for Large Language Models in Code Generation'), (397, 'RepEval: Effective Text Evaluation with LLM Representation'), (570, 'I Learn Better If You Speak My Language: Understanding the Superior Performance of Fine-Tuning Large Language Models with LLM-Generated Responses')]
          ----------------------------------------
          Label: problem_solving
          Dimension: tasks
          Description: The process of identifying and solving mathematical problems through various techniques and methodologies.
          Level: 2
          # of Papers: 25
          Example Papers: [(273, 'MuMath-Code: Combining Tool-Use Large Language Models with Multi-perspective Data Augmentation for Mathematical Reasoning'), (628, 'Code Prompting Elicits Conditional Reasoning Abilities in Text+Code LLMs'), (679, 'ControlMath: Controllable Data Generation Promotes Math Generalist Models')]
          ----------------------------------------
          Label: language_understanding
          Dimension: tasks
          Description: The task of comprehending and interpreting human language in a way that enables effective communication and interaction.
          Level: 2
          # of Papers: 324
          Example Papers: [(11, "NumeroLogic: Number Encoding for Enhanced LLMs' Numerical Reasoning"), (17, 'Uncertainty in Language Models: Assessment through Rank-Calibration'), (39, 'Tokenization Is More Than Compression')]
          ----------------------------------------
          Children:
               Label: text_generation
               Dimension: tasks
               Description: The task of creating coherent and contextually relevant text based on given prompts or input, often used in applications like chatbots and content creation.
               Level: 3
               # of Papers: 85
               Example Papers: [(17, 'Uncertainty in Language Models: Assessment through Rank-Calibration'), (53, 'Large Language Models for Data Annotation and Synthesis: A Survey'), (101, 'MetaGPT: Merging Large Language Models Using Model Exclusive Task Arithmetic')]
               ----------------------------------------
               Label: spoken_language_understanding
               Dimension: tasks
               Description: The process of interpreting and comprehending spoken language, enabling systems to understand and respond to verbal communication effectively.
               Level: 3
               # of Papers: 63
               Example Papers: [(52, 'Language Models Learn Rare Phenomena from Less Rare Phenomena: The Case of the Missing AANNs'), (141, 'Backward Lens: Projecting Language Model Gradients into the Vocabulary Space'), (166, 'With Ears to See and Eyes to Hear: Sound Symbolism Experiments with Multimodal Large Language Models')]
               ----------------------------------------
               Label: textual_inference
               Dimension: tasks
               Description: The task of deriving logical conclusions from text, which involves understanding relationships and implications within the written content.
               Level: 3
               # of Papers: 177
               Example Papers: [(11, "NumeroLogic: Number Encoding for Enhanced LLMs' Numerical Reasoning"), (39, 'Tokenization Is More Than Compression'), (42, 'Parameter-Efficient Sparsity Crafting from Dense to Mixture-of-Experts for Instruction Tuning on General Tasks')]
               ----------------------------------------
               Label: conversational_ai
               Dimension: tasks
               Description: The development of systems that can engage in human-like dialogue, understanding context and intent to facilitate meaningful interactions.
               Level: 3
               # of Papers: 179
               Example Papers: [(11, "NumeroLogic: Number Encoding for Enhanced LLMs' Numerical Reasoning"), (39, 'Tokenization Is More Than Compression'), (42, 'Parameter-Efficient Sparsity Crafting from Dense to Mixture-of-Experts for Instruction Tuning on General Tasks')]
               ----------------------------------------
               Label: text_style_transfer
               Dimension: tasks
               Description: The task of transforming text from one stylistic form to another while preserving its original meaning, often used in creative writing and content adaptation.
               Level: 3
               # of Papers: 5
               Example Papers: [(1278, 'Commentator: A Code-mixed Multilingual Text Annotation Framework'), (1941, 'PSST: A Benchmark for Evaluation-driven Text Public-Speaking Style Transfer'), (1981, "Are ELECTRA's Sentence Embeddings Beyond Repair? The Case of Semantic Textual Similarity")]
               ----------------------------------------
          ----------------------------------------
     ----------------------------------------
     Label: named_entity_recognition
     Dimension: tasks
     Description: The process of identifying and classifying key entities in text, such as names of people, organizations, locations, and dates, to extract meaningful information.
     Level: 1
     # of Papers: 350
     Example Papers: [(5, 'ImageInWords: Unlocking Hyper-Detailed Image Descriptions'), (13, 'A Usage-centric Take on Intent Understanding in E-Commerce'), (17, 'Uncertainty in Language Models: Assessment through Rank-Calibration')]
     ----------------------------------------
     Children:
          Label: entity_extraction
          Dimension: tasks
          Description: This cluster focuses on the techniques and methodologies for extracting entities from text, including named entities such as people, organizations, and locations.
          Level: 2
          # of Papers: 176
          Example Papers: [(48, 'Overcome Noise and Bias: Segmentation-Aided Multi-Granularity Denoising and Debiasing for Enhanced Quarduples Extraction in Dialogue'), (52, 'Language Models Learn Rare Phenomena from Less Rare Phenomena: The Case of the Missing AANNs'), (53, 'Large Language Models for Data Annotation and Synthesis: A Survey')]
          ----------------------------------------
          Children:
               Label: entity_matching
               Dimension: tasks
               Description: This subtopic focuses on techniques for identifying and matching entities across different datasets or contexts, ensuring consistency and accuracy in entity representation.
               Level: 3
               # of Papers: 14
               Example Papers: [(52, 'Language Models Learn Rare Phenomena from Less Rare Phenomena: The Case of the Missing AANNs'), (155, 'To Word Senses and Beyond: Inducing Concepts with Contextualized Language Models'), (193, 'Pixology: Probing the Linguistic and Visual Capabilities of Pixel-based Language Models')]
               ----------------------------------------
               Label: structured_entity_extraction
               Dimension: tasks
               Description: This subtopic involves extracting entities from structured data formats, such as tables or databases, to facilitate better information retrieval and analysis.
               Level: 3
               # of Papers: 2
               Example Papers: [(387, 'Learning to Extract Structured Entities Using Language Models'), (2645, 'Information Extraction for Planning Court Cases')]
               ----------------------------------------
               Label: entity_relation_extraction
               Dimension: tasks
               Description: This subtopic deals with identifying and extracting relationships between entities within text, enhancing the understanding of how entities interact with one another.
               Level: 3
               # of Papers: 49
               Example Papers: [(52, 'Language Models Learn Rare Phenomena from Less Rare Phenomena: The Case of the Missing AANNs'), (163, 'Alignment-Enhanced Decoding: Defending Jailbreaks via Token-Level Adaptive Refining of Probability Distributions'), (193, 'Pixology: Probing the Linguistic and Visual Capabilities of Pixel-based Language Models')]
               ----------------------------------------
               Label: entity_resolution
               Dimension: tasks
               Description: This subtopic focuses on the process of determining when different representations refer to the same entity, thereby consolidating information and reducing redundancy.
               Level: 3
               # of Papers: 63
               Example Papers: [(67, 'Rethinking Pruning Large Language Models: Benefits and Pitfalls of Reconstruction Error Minimization'), (163, 'Alignment-Enhanced Decoding: Defending Jailbreaks via Token-Level Adaptive Refining of Probability Distributions'), (193, 'Pixology: Probing the Linguistic and Visual Capabilities of Pixel-based Language Models')]
               ----------------------------------------
               Label: nested_named_entity_recognition
               Dimension: tasks
               Description: This subtopic addresses the challenge of recognizing entities that are nested within other entities, allowing for a more nuanced extraction of complex information.
               Level: 3
               # of Papers: 7
               Example Papers: [(491, 'Exploring Nested Named Entity Recognition with Large Language Models: Methods, Challenges, and Insights'), (628, 'Code Prompting Elicits Conditional Reasoning Abilities in Text+Code LLMs'), (1166, 'TokenVerse: Towards Unifying Speech and NLP Tasks via Transducer-based ASR')]
               ----------------------------------------
          ----------------------------------------
          Label: entity_linking
          Dimension: tasks
          Description: This cluster encompasses methods for linking extracted entities to their corresponding entries in knowledge bases or databases, ensuring accurate identification and context.
          Level: 2
          # of Papers: 102
          Example Papers: [(67, 'Rethinking Pruning Large Language Models: Benefits and Pitfalls of Reconstruction Error Minimization'), (163, 'Alignment-Enhanced Decoding: Defending Jailbreaks via Token-Level Adaptive Refining of Probability Distributions'), (193, 'Pixology: Probing the Linguistic and Visual Capabilities of Pixel-based Language Models')]
          ----------------------------------------
          Children:
               Label: knowledge_graph_enhancement
               Dimension: tasks
               Description: This subtopic focuses on methods and techniques for improving the quality and utility of knowledge graphs, which are essential for effective entity linking.
               Level: 3
               # of Papers: 3
               Example Papers: [(831, 'MoCoKGC: Momentum Contrast Entity Encoding for Knowledge Graph Completion'), (1260, 'Knowledge Graph Enhanced Large Language Model Editing'), (1320, 'Optimizing Entity Resolution in Voice Interfaces: An ASR-Aware Entity Reference Expansion Approach')]
               ----------------------------------------
               Label: entity_resolution
               Label: data_quality_improvement
               Dimension: tasks
               Description: This subtopic involves strategies and methodologies for enhancing the quality of data used in entity linking tasks, ensuring better accuracy and reliability.
               Level: 3
               # of Papers: 22
               Example Papers: [(276, 'KidLM: Advancing Language Models for Children - Early Insights and Future Directions'), (279, 'An Unsupervised Approach to Achieve Supervised-Level Explainability in Healthcare Records'), (299, 'Pretraining Data Detection for Large Language Models: A Divergence-based Calibration Method')]
               ----------------------------------------
               Label: few_shot_entity_linking
               Dimension: tasks
               Description: This cluster focuses on techniques that enable effective entity linking with minimal labeled data, leveraging few-shot learning paradigms.
               Level: 3
               # of Papers: 18
               Example Papers: [(351, 'Learning from Natural Language Explanations for Generalizable Entity Matching'), (628, 'Code Prompting Elicits Conditional Reasoning Abilities in Text+Code LLMs'), (651, 'Major Entity Identification: A Generalizable Alternative to Coreference Resolution')]
               ----------------------------------------
               Label: wikification
               Dimension: tasks
               Description: This subtopic pertains to the process of linking textual mentions to their corresponding entries in Wikipedia, facilitating enhanced contextual understanding of entities.
               Level: 3
               # of Papers: 13
               Example Papers: [(800, 'ASL STEM Wiki: Dataset and Benchmark for Interpreting STEM Articles'), (1127, 'VIEWS: Entity-Aware News Video Captioning'), (1166, 'TokenVerse: Towards Unifying Speech and NLP Tasks via Transducer-based ASR')]
               ----------------------------------------
          ----------------------------------------
          Label: entity_disambiguation
          Dimension: tasks
          Description: This cluster deals with resolving ambiguities in entity recognition, determining the correct entity when multiple candidates exist for the same mention in text.
          Level: 2
          # of Papers: 111
          Example Papers: [(67, 'Rethinking Pruning Large Language Models: Benefits and Pitfalls of Reconstruction Error Minimization'), (143, 'Can visual language models resolve textual ambiguity with visual cues? Let visual puns tell you!'), (155, 'To Word Senses and Beyond: Inducing Concepts with Contextualized Language Models')]
          ----------------------------------------
          Children:
               Label: word_sense_disambiguation
               Dimension: tasks
               Description: This subtopic focuses on resolving ambiguities in word meanings, determining the correct sense of a word based on its context in the text.
               Level: 3
               # of Papers: 5
               Example Papers: [(143, 'Can visual language models resolve textual ambiguity with visual cues? Let visual puns tell you!'), (155, 'To Word Senses and Beyond: Inducing Concepts with Contextualized Language Models'), (691, 'Latent Concept-based Explanation of NLP Models')]
               ----------------------------------------
               Label: named_entity_disambiguation
               Dimension: tasks
               Description: This subtopic deals with identifying and resolving ambiguities in named entities, ensuring the correct entity is recognized when multiple candidates exist.
               Level: 3
               # of Papers: 85
               Example Papers: [(67, 'Rethinking Pruning Large Language Models: Benefits and Pitfalls of Reconstruction Error Minimization'), (163, 'Alignment-Enhanced Decoding: Defending Jailbreaks via Token-Level Adaptive Refining of Probability Distributions'), (193, 'Pixology: Probing the Linguistic and Visual Capabilities of Pixel-based Language Models')]
               ----------------------------------------
               Label: extractive_disambiguation
               Dimension: tasks
               Description: This subtopic involves the extraction of relevant information to clarify ambiguities in entity recognition, enhancing the accuracy of identified entities.
               Level: 3
               # of Papers: 36
               Example Papers: [(67, 'Rethinking Pruning Large Language Models: Benefits and Pitfalls of Reconstruction Error Minimization'), (163, 'Alignment-Enhanced Decoding: Defending Jailbreaks via Token-Level Adaptive Refining of Probability Distributions'), (279, 'An Unsupervised Approach to Achieve Supervised-Level Explainability in Healthcare Records')]
               ----------------------------------------
               Label: pronoun_resolution
               Dimension: tasks
               Description: This subtopic addresses the challenge of determining the correct entities that pronouns refer to in a given text, resolving potential ambiguities.
               Level: 3
               # of Papers: 22
               Example Papers: [(193, 'Pixology: Probing the Linguistic and Visual Capabilities of Pixel-based Language Models'), (276, 'KidLM: Advancing Language Models for Children - Early Insights and Future Directions'), (390, 'Beyond Embeddings: The Promise of Visual Table in Visual Reasoning')]
               ----------------------------------------
               Label: cross_document_coreference
               Dimension: tasks
               Description: This subtopic focuses on resolving ambiguities in entity references across multiple documents, ensuring consistent identification of entities throughout a corpus.
               Level: 3
               # of Papers: 11
               Example Papers: [(215, 'External Knowledge-Driven Argument Mining: Leveraging Attention-Enhanced Multi-Network Models'), (354, 'Contrastive Entity Coreference and Disambiguation for Historical Texts'), (732, 'A Bayesian Approach to Harnessing the Power of LLMs in Authorship Attribution')]
               ----------------------------------------
          ----------------------------------------
          Label: evaluation_metrics
          Dimension: tasks
          Description: This cluster is dedicated to the assessment and evaluation of named entity recognition systems, focusing on metrics and methodologies to measure their performance.
          Level: 2
          # of Papers: 104
          Example Papers: [(17, 'Uncertainty in Language Models: Assessment through Rank-Calibration'), (67, 'Rethinking Pruning Large Language Models: Benefits and Pitfalls of Reconstruction Error Minimization'), (165, 'Evaluating Large Language Models via Linguistic Profiling')]
          ----------------------------------------
          Children:
               Label: evaluation_metrics_methods
               Dimension: tasks
               Description: This cluster focuses on the various methodologies and techniques used to evaluate the performance of named entity recognition systems.
               Level: 3
               # of Papers: 28
               Example Papers: [(165, 'Evaluating Large Language Models via Linguistic Profiling'), (186, 'ScalingFilter: Assessing Data Quality through Inverse Utilization of Scaling Laws'), (332, 'Teaching Small Language Models Reasoning through Counterfactual Distillation')]
               ----------------------------------------
               Label: evaluation_of_performance
               Dimension: tasks
               Description: This cluster is dedicated to assessing the overall performance of named entity recognition systems through various evaluation metrics.
               Level: 3
               # of Papers: 64
               Example Papers: [(17, 'Uncertainty in Language Models: Assessment through Rank-Calibration'), (67, 'Rethinking Pruning Large Language Models: Benefits and Pitfalls of Reconstruction Error Minimization'), (186, 'ScalingFilter: Assessing Data Quality through Inverse Utilization of Scaling Laws')]
               ----------------------------------------
               Label: data_quality
               Dimension: tasks
               Description: This cluster examines the impact of data quality on the performance of named entity recognition systems and the metrics used to evaluate it.
               Level: 3
               # of Papers: 4
               Example Papers: [(186, 'ScalingFilter: Assessing Data Quality through Inverse Utilization of Scaling Laws'), (776, 'How Do Your Code LLMs perform? Empowering Code Instruction Tuning with Really Good Data'), (2340, 'Evaluating Differentially Private Synthetic Data Generation in High-Stakes Domains')]
               ----------------------------------------
               Label: interpretability
               Dimension: tasks
               Description: This cluster explores the interpretability of evaluation metrics in named entity recognition, focusing on how well these metrics can be understood and applied.
               Level: 3
               # of Papers: 9
               Example Papers: [(279, 'An Unsupervised Approach to Achieve Supervised-Level Explainability in Healthcare Records'), (1472, 'Can Large Language Models Identify Authorship?'), (1576, 'Faithful and Plausible Natural Language Explanations for Image Classification: A Pipeline Approach')]
               ----------------------------------------
               Label: evaluation_of_noise_impact
               Dimension: tasks
               Description: This cluster investigates how noise in data affects the performance of named entity recognition systems and the corresponding evaluation metrics.
               Level: 3
               # of Papers: 11
               Example Papers: [(67, 'Rethinking Pruning Large Language Models: Benefits and Pitfalls of Reconstruction Error Minimization'), (193, 'Pixology: Probing the Linguistic and Visual Capabilities of Pixel-based Language Models'), (425, 'Multi-Dialect Vietnamese: Task, Dataset, Baseline Models and Challenges')]
               ----------------------------------------
          ----------------------------------------
          Label: cross-lingual_ner
          Dimension: tasks
          Description: This cluster explores named entity recognition across different languages, addressing the challenges and techniques for recognizing entities in multilingual contexts.
          Level: 2
          # of Papers: 57
          Example Papers: [(67, 'Rethinking Pruning Large Language Models: Benefits and Pitfalls of Reconstruction Error Minimization'), (94, 'Cross-domain NER with Generated Task-Oriented Knowledge: An Empirical Study from Information Density Perspective'), (193, 'Pixology: Probing the Linguistic and Visual Capabilities of Pixel-based Language Models')]
          ----------------------------------------
          Children:
               Label: transfer_learning
               Dimension: tasks
               Description: This subtopic focuses on leveraging knowledge from one or more source languages to improve named entity recognition performance in target languages, particularly in cross-lingual contexts.
               Level: 3
               # of Papers: 16
               Example Papers: [(332, 'Teaching Small Language Models Reasoning through Counterfactual Distillation'), (570, 'I Learn Better If You Speak My Language: Understanding the Superior Performance of Fine-Tuning Large Language Models with LLM-Generated Responses'), (637, 'TEMA: Token Embeddings Mapping for Enriching Low-Resource Language Models')]
               ----------------------------------------
               Label: low_resource_languages
               Dimension: tasks
               Description: This subtopic addresses the challenges and methodologies for performing named entity recognition in languages that have limited annotated data available.
               Level: 3
               # of Papers: 9
               Example Papers: [(637, 'TEMA: Token Embeddings Mapping for Enriching Low-Resource Language Models'), (752, 'Zero-Shot Cross-Lingual NER Using Phonemic Representations for Low-Resource Languages'), (1230, 'Is Child-Directed Speech Effective Training Data for Language Models?')]
               ----------------------------------------
               Label: multimodal_ner
               Dimension: tasks
               Description: This subtopic explores the integration of multiple data modalities, such as text and images, to enhance named entity recognition across different languages.
               Level: 3
               # of Papers: 3
               Example Papers: [(1166, 'TokenVerse: Towards Unifying Speech and NLP Tasks via Transducer-based ASR'), (1513, 'Breaking the Boundaries: A Unified Framework for Chinese Named Entity Recognition Across Text and Speech'), (1952, 'Exploring the Capability of Multimodal LLMs with Yonkoma Manga: The YManga Dataset and Its Challenging Tasks')]
               ----------------------------------------
               Label: domain_adaptation
               Dimension: tasks
               Description: This subtopic investigates techniques for adapting named entity recognition models to perform effectively in specific domains or contexts across various languages.
               Level: 3
               # of Papers: 13
               Example Papers: [(67, 'Rethinking Pruning Large Language Models: Benefits and Pitfalls of Reconstruction Error Minimization'), (94, 'Cross-domain NER with Generated Task-Oriented Knowledge: An Empirical Study from Information Density Perspective'), (279, 'An Unsupervised Approach to Achieve Supervised-Level Explainability in Healthcare Records')]
               ----------------------------------------
               Label: cross-lingual_entity_alignment
               Dimension: tasks
               Description: This subtopic focuses on aligning named entities across different languages, ensuring that entities are recognized and linked correctly in multilingual datasets.
               Level: 3
               # of Papers: 25
               Example Papers: [(94, 'Cross-domain NER with Generated Task-Oriented Knowledge: An Empirical Study from Information Density Perspective'), (193, 'Pixology: Probing the Linguistic and Visual Capabilities of Pixel-based Language Models'), (407, 'Python is Not Always the Best Choice: Embracing Multilingual Program of Thoughts')]
               ----------------------------------------
          ----------------------------------------
     ----------------------------------------
     Label: machine_translation
     Dimension: tasks
     Description: The task of automatically translating text from one language to another while preserving its meaning and context, facilitating cross-lingual communication.
     Level: 1
     # of Papers: 520
     Example Papers: [(5, 'ImageInWords: Unlocking Hyper-Detailed Image Descriptions'), (17, 'Uncertainty in Language Models: Assessment through Rank-Calibration'), (23, 'Fine-Tuning Large Language Models to Translate: Will a Touch of Noisy Data in Misaligned Languages Suffice?')]
     ----------------------------------------
     Children:
          Label: evaluation
          Dimension: tasks
          Description: This cluster encompasses various methods and metrics for assessing the quality and effectiveness of machine translation systems, including evaluation benchmarks and translation quality estimation.
          Level: 2
          # of Papers: 127
          Example Papers: [(17, 'Uncertainty in Language Models: Assessment through Rank-Calibration'), (29, 'EmphAssess : a Prosodic Benchmark on Assessing Emphasis Transfer in Speech-to-Speech Models'), (149, 'Collaborative Performance Prediction for Large Language Models')]
          ----------------------------------------
          Children:
               Label: translation_quality_estimation
               Dimension: tasks
               Description: This subtopic focuses on methods and metrics used to estimate the quality of translations produced by machine translation systems, providing a quantitative assessment of translation outputs.
               Level: 3
               # of Papers: 4
               Example Papers: [(2814, 'Findings of the Quality Estimation Shared Task at WMT 2024: Are LLMs Closing the Gap in QE?'), (2850, 'HW-TSC 2024 Submission for the Quality Estimation Shared Task'), (2860, 'FLORES+ Translation and Machine Translation Evaluation for the Erzya Language')]
               ----------------------------------------
               Label: machine_translation_evaluation
               Dimension: tasks
               Description: This subtopic encompasses various evaluation techniques specifically designed to assess the performance and effectiveness of machine translation systems.
               Level: 3
               # of Papers: 111
               Example Papers: [(17, 'Uncertainty in Language Models: Assessment through Rank-Calibration'), (149, 'Collaborative Performance Prediction for Large Language Models'), (165, 'Evaluating Large Language Models via Linguistic Profiling')]
               ----------------------------------------
               Label: evaluation_benchmarks
               Dimension: tasks
               Description: This subtopic includes standardized datasets and benchmarks used to evaluate and compare the performance of different machine translation systems.
               Level: 3
               # of Papers: 40
               Example Papers: [(17, 'Uncertainty in Language Models: Assessment through Rank-Calibration'), (29, 'EmphAssess : a Prosodic Benchmark on Assessing Emphasis Transfer in Speech-to-Speech Models'), (165, 'Evaluating Large Language Models via Linguistic Profiling')]
               ----------------------------------------
               Label: machine_translation_quality_evaluation
               Dimension: tasks
               Description: This subtopic deals with the assessment of the overall quality of translations generated by machine translation systems, focusing on various quality dimensions.
               Level: 3
               # of Papers: 20
               Example Papers: [(633, 'MMTE: Corpus and Metrics for Evaluating Machine Translation Quality of Metaphorical Language'), (802, 'Modeling User Preferences with Automatic Metrics: Creating a High-Quality Preference Dataset for Machine Translation'), (1101, 'Error Analysis of Multilingual Language Models in Machine Translation: A Case Study of English-Amharic Translation')]
               ----------------------------------------
               Label: machine_translation_quality_estimation
               Dimension: tasks
               Description: This subtopic involves techniques for estimating the quality of machine translations without relying on human judgment, often using automated metrics.
               Level: 3
               # of Papers: 30
               Example Papers: [(186, 'ScalingFilter: Assessing Data Quality through Inverse Utilization of Scaling Laws'), (213, 'What do Large Language Models Need for Machine Translation Evaluation?'), (277, 'Using Language Models to Disambiguate Lexical Choices in Translation')]
               ----------------------------------------
          ----------------------------------------
          Label: model_improvement
          Dimension: tasks
          Description: This cluster focuses on techniques and strategies aimed at enhancing the performance and accuracy of machine translation models, including model adaptation and optimization methods.
          Level: 2
          # of Papers: 321
          Example Papers: [(5, 'ImageInWords: Unlocking Hyper-Detailed Image Descriptions'), (23, 'Fine-Tuning Large Language Models to Translate: Will a Touch of Noisy Data in Misaligned Languages Suffice?'), (29, 'EmphAssess : a Prosodic Benchmark on Assessing Emphasis Transfer in Speech-to-Speech Models')]
          ----------------------------------------
          Children:
               Label: model_adaptation
               Dimension: tasks
               Description: This subtopic focuses on techniques that adjust machine translation models to better fit specific domains or datasets, enhancing their performance in targeted applications.
               Level: 3
               # of Papers: 68
               Example Papers: [(54, 'Chain-of-Dictionary Prompting Elicits Translation in Large Language Models'), (78, 'Reuse Your Rewards: Reward Model Transfer for Zero-Shot Cross-Lingual Alignment'), (101, 'MetaGPT: Merging Large Language Models Using Model Exclusive Task Arithmetic')]
               ----------------------------------------
               Label: prompt_optimization
               Dimension: tasks
               Description: This subtopic involves refining the input prompts given to machine translation models to improve their output quality and relevance.
               Level: 3
               # of Papers: 10
               Example Papers: [(594, 'Speechworthy Instruction-tuned Language Models'), (1129, 'AMPO: Automatic Multi-Branched Prompt Optimization'), (2022, 'Monotonic Paraphrasing Improves Generalization of Language Model Prompting')]
               ----------------------------------------
               Label: model_optimization
               Dimension: tasks
               Description: This subtopic encompasses various strategies aimed at improving the efficiency and effectiveness of machine translation models, including algorithmic enhancements and resource management.
               Level: 3
               # of Papers: 136
               Example Papers: [(5, 'ImageInWords: Unlocking Hyper-Detailed Image Descriptions'), (42, 'Parameter-Efficient Sparsity Crafting from Dense to Mixture-of-Experts for Instruction Tuning on General Tasks'), (54, 'Chain-of-Dictionary Prompting Elicits Translation in Large Language Models')]
               ----------------------------------------
               Label: adversarial_attack
               Dimension: tasks
               Description: This subtopic examines methods to test and improve the robustness of machine translation models against adversarial inputs that may degrade their performance.
               Level: 3
               # of Papers: 5
               Example Papers: [(163, 'Alignment-Enhanced Decoding: Defending Jailbreaks via Token-Level Adaptive Refining of Probability Distributions'), (480, 'The Best Defense is Attack: Repairing Semantics in Textual Adversarial Examples'), (894, "MLLM-Protector: Ensuring MLLM's Safety without Hurting Performance")]
               ----------------------------------------
               Label: instruction_tuning
               Dimension: tasks
               Description: This subtopic focuses on fine-tuning machine translation models based on specific instructions or guidelines to enhance their accuracy and contextual understanding.
               Level: 3
               # of Papers: 20
               Example Papers: [(42, 'Parameter-Efficient Sparsity Crafting from Dense to Mixture-of-Experts for Instruction Tuning on General Tasks'), (270, 'CoEvol: Constructing Better Responses for Instruction Finetuning through Multi-Agent Cooperation'), (491, 'Exploring Nested Named Entity Recognition with Large Language Models: Methods, Challenges, and Insights')]
               ----------------------------------------
               Label: parameter_efficient_fine_tuning
               Dimension: tasks
               Description: This subtopic explores techniques that allow for effective fine-tuning of machine translation models with minimal adjustments to their parameters, optimizing resource usage.
               Level: 3
               # of Papers: 23
               Example Papers: [(42, 'Parameter-Efficient Sparsity Crafting from Dense to Mixture-of-Experts for Instruction Tuning on General Tasks'), (56, 'RoseLoRA: Row and Column-wise Sparse Low-rank Adaptation of Pre-trained Language Model for Knowledge Editing and Fine-tuning'), (203, 'From Bottom to Top: Extending the Potential of Parameter Efficient Fine-Tuning')]
               ----------------------------------------
               Label: prompt_engineering
               Dimension: tasks
               Description: This subtopic focuses on the design and development of effective prompts to guide machine translation models in generating high-quality outputs tailored to specific tasks.
               Level: 3
               # of Papers: 18
               Example Papers: [(54, 'Chain-of-Dictionary Prompting Elicits Translation in Large Language Models'), (379, 'Understanding and Mitigating Language Confusion in LLMs'), (416, 'Position Engineering: Boosting Large Language Models through Positional Information Manipulation')]
               ----------------------------------------
          ----------------------------------------
          Label: low_resource_machine_translation
          Dimension: tasks
          Description: This cluster addresses the challenges and solutions related to translating languages with limited resources, including low-resource languages and low-resource translation techniques.
          Level: 2
          # of Papers: 97
          Example Papers: [(235, 'When Is Multilinguality a Curse? Language Modeling for 250 High- and Low-Resource Languages'), (250, 'Voices Unheard: NLP Resources and Models for Yoruba Regional Dialects'), (316, 'NLEBench+NorGLM: A Comprehensive Empirical Analysis and Benchmark Dataset for Generative Language Models in Norwegian')]
          ----------------------------------------
          Children:
               Label: low_resource_translation_techniques
               Dimension: tasks
               Description: This subtopic focuses on various techniques specifically designed for translating low-resource languages, addressing the unique challenges posed by limited linguistic data.
               Level: 3
               # of Papers: 60
               Example Papers: [(461, 'Language-to-Code Translation with a Single Labeled Example'), (707, 'Optimizing Rare Word Accuracy in Direct Speech Translation with a Retrieval-and-Demonstration Approach'), (1101, 'Error Analysis of Multilingual Language Models in Machine Translation: A Case Study of English-Amharic Translation')]
               ----------------------------------------
               Label: low_resource_language_evaluation
               Dimension: tasks
               Description: This subtopic encompasses methods and metrics for evaluating the quality and effectiveness of translations in low-resource languages.
               Level: 3
               # of Papers: 11
               Example Papers: [(316, 'NLEBench+NorGLM: A Comprehensive Empirical Analysis and Benchmark Dataset for Generative Language Models in Norwegian'), (800, 'ASL STEM Wiki: Dataset and Benchmark for Interpreting STEM Articles'), (1101, 'Error Analysis of Multilingual Language Models in Machine Translation: A Case Study of English-Amharic Translation')]
               ----------------------------------------
               Label: low_resource_language_modeling
               Dimension: tasks
               Description: This subtopic deals with the development and application of language models tailored for low-resource languages, enhancing translation accuracy and fluency.
               Level: 3
               # of Papers: 36
               Example Papers: [(235, 'When Is Multilinguality a Curse? Language Modeling for 250 High- and Low-Resource Languages'), (250, 'Voices Unheard: NLP Resources and Models for Yoruba Regional Dialects'), (316, 'NLEBench+NorGLM: A Comprehensive Empirical Analysis and Benchmark Dataset for Generative Language Models in Norwegian')]
               ----------------------------------------
               Label: language_adaptation
               Dimension: tasks
               Description: This subtopic explores strategies for adapting existing machine translation systems to better handle low-resource languages and their specific linguistic features.
               Level: 3
               # of Papers: 29
               Example Papers: [(250, 'Voices Unheard: NLP Resources and Models for Yoruba Regional Dialects'), (707, 'Optimizing Rare Word Accuracy in Direct Speech Translation with a Retrieval-and-Demonstration Approach'), (823, 'Building Resources for Emakhuwa: Machine Translation and News Classification Benchmarks')]
               ----------------------------------------
               Label: training_low_resource_languages
               Dimension: tasks
               Description: This subtopic focuses on the methodologies and practices for training machine translation models specifically for low-resource languages.
               Level: 3
               # of Papers: 59
               Example Papers: [(235, 'When Is Multilinguality a Curse? Language Modeling for 250 High- and Low-Resource Languages'), (250, 'Voices Unheard: NLP Resources and Models for Yoruba Regional Dialects'), (316, 'NLEBench+NorGLM: A Comprehensive Empirical Analysis and Benchmark Dataset for Generative Language Models in Norwegian')]
               ----------------------------------------
          ----------------------------------------
          Label: multilingual_machine_translation
          Dimension: tasks
          Description: This cluster explores approaches for translating multiple languages simultaneously, including multilingual learning and multilingual translation strategies.
          Level: 2
          # of Papers: 108
          Example Papers: [(23, 'Fine-Tuning Large Language Models to Translate: Will a Touch of Noisy Data in Misaligned Languages Suffice?'), (54, 'Chain-of-Dictionary Prompting Elicits Translation in Large Language Models'), (68, 'LLMs Are Zero-Shot Context-Aware Simultaneous Translators')]
          ----------------------------------------
          Children:
               Label: multilingual_translation_strategies
               Dimension: tasks
               Description: This subtopic focuses on various strategies and methodologies for effectively translating multiple languages simultaneously, emphasizing the development of robust multilingual translation systems.
               Level: 3
               # of Papers: 77
               Example Papers: [(23, 'Fine-Tuning Large Language Models to Translate: Will a Touch of Noisy Data in Misaligned Languages Suffice?'), (54, 'Chain-of-Dictionary Prompting Elicits Translation in Large Language Models'), (68, 'LLMs Are Zero-Shot Context-Aware Simultaneous Translators')]
               ----------------------------------------
               Label: multilingual_learning
               Dimension: tasks
               Description: This subtopic explores techniques and approaches for learning representations and models that can handle multiple languages, enhancing the efficiency of multilingual machine translation.
               Level: 3
               # of Papers: 46
               Example Papers: [(68, 'LLMs Are Zero-Shot Context-Aware Simultaneous Translators'), (205, 'MTLS: Making Texts into Linguistic Symbols'), (235, 'When Is Multilinguality a Curse? Language Modeling for 250 High- and Low-Resource Languages')]
               ----------------------------------------
               Label: cross-lingual_transfer
               Dimension: tasks
               Description: This subtopic investigates methods for transferring knowledge across languages, enabling the application of models trained on high-resource languages to low-resource languages in multilingual translation tasks.
               Level: 3
               # of Papers: 62
               Example Papers: [(54, 'Chain-of-Dictionary Prompting Elicits Translation in Large Language Models'), (68, 'LLMs Are Zero-Shot Context-Aware Simultaneous Translators'), (78, 'Reuse Your Rewards: Reward Model Transfer for Zero-Shot Cross-Lingual Alignment')]
               ----------------------------------------
               Label: low_resource_translation
               Dimension: tasks
               Description: This subtopic addresses the challenges and solutions related to translating languages with limited available data, focusing on techniques that improve translation quality in low-resource scenarios.
               Level: 3
               # of Papers: 47
               Example Papers: [(23, 'Fine-Tuning Large Language Models to Translate: Will a Touch of Noisy Data in Misaligned Languages Suffice?'), (54, 'Chain-of-Dictionary Prompting Elicits Translation in Large Language Models'), (68, 'LLMs Are Zero-Shot Context-Aware Simultaneous Translators')]
               ----------------------------------------
               Label: evaluation_of_multilingual_llms
               Dimension: tasks
               Description: This subtopic examines the evaluation metrics and methodologies specifically designed for assessing the performance of multilingual large language models in translation tasks.
               Level: 3
               # of Papers: 46
               Example Papers: [(68, 'LLMs Are Zero-Shot Context-Aware Simultaneous Translators'), (213, 'What do Large Language Models Need for Machine Translation Evaluation?'), (334, 'Quantifying the Gaps Between Translation and Native Perception in Training for Multimodal, Multilingual Retrieval')]
               ----------------------------------------
          ----------------------------------------
          Label: neural_machine_translation
          Dimension: tasks
          Description: This cluster is dedicated to the use of neural network architectures in machine translation, focusing on advancements in neural machine translation techniques and their applications.
          Level: 2
          # of Papers: 283
          Example Papers: [(23, 'Fine-Tuning Large Language Models to Translate: Will a Touch of Noisy Data in Misaligned Languages Suffice?'), (39, 'Tokenization Is More Than Compression'), (52, 'Language Models Learn Rare Phenomena from Less Rare Phenomena: The Case of the Missing AANNs')]
          ----------------------------------------
          Children:
               Label: neural_machine_translation_techniques
               Dimension: tasks
               Description: This cluster focuses on various techniques specifically developed for neural machine translation, including advancements in architectures and methodologies.
               Level: 3
               # of Papers: 219
               Example Papers: [(23, 'Fine-Tuning Large Language Models to Translate: Will a Touch of Noisy Data in Misaligned Languages Suffice?'), (39, 'Tokenization Is More Than Compression'), (52, 'Language Models Learn Rare Phenomena from Less Rare Phenomena: The Case of the Missing AANNs')]
               ----------------------------------------
               Label: low_resource_neural_machine_translation
               Dimension: tasks
               Description: This cluster addresses the challenges and solutions related to neural machine translation in low-resource language settings, emphasizing techniques that enhance translation quality despite limited data.
               Level: 3
               # of Papers: 54
               Example Papers: [(23, 'Fine-Tuning Large Language Models to Translate: Will a Touch of Noisy Data in Misaligned Languages Suffice?'), (54, 'Chain-of-Dictionary Prompting Elicits Translation in Large Language Models'), (68, 'LLMs Are Zero-Shot Context-Aware Simultaneous Translators')]
               ----------------------------------------
               Label: multimodal_neural_machine_translation
               Dimension: tasks
               Description: This cluster explores the integration of multiple modalities, such as text and images, in neural machine translation to improve contextual understanding and translation accuracy.
               Level: 3
               # of Papers: 23
               Example Papers: [(181, 'Autoregressive Pre-Training on Pixels and Texts'), (286, 'MaPPER: Multimodal Prior-guided Parameter Efficient Tuning for Referring Expression Comprehension'), (341, 'Video-LLaVA: Learning United Visual Representation by Alignment Before Projection')]
               ----------------------------------------
               Label: translation_quality_evaluation
               Dimension: tasks
               Description: This cluster is dedicated to methods and metrics for evaluating the quality of translations produced by neural machine translation systems, ensuring reliability and effectiveness.
               Level: 3
               # of Papers: 18
               Example Papers: [(186, 'ScalingFilter: Assessing Data Quality through Inverse Utilization of Scaling Laws'), (213, 'What do Large Language Models Need for Machine Translation Evaluation?'), (237, 'MiTTenS: A Dataset for Evaluating Gender Mistranslation')]
               ----------------------------------------
               Label: cross-lingual_learning
               Dimension: tasks
               Description: This cluster investigates techniques that leverage knowledge from multiple languages to improve neural machine translation performance across different language pairs.
               Level: 3
               # of Papers: 26
               Example Papers: [(54, 'Chain-of-Dictionary Prompting Elicits Translation in Large Language Models'), (78, 'Reuse Your Rewards: Reward Model Transfer for Zero-Shot Cross-Lingual Alignment'), (395, 'Revealing the Parallel Multilingual Learning within Large Language Models')]
               ----------------------------------------
          ----------------------------------------
     ----------------------------------------
     Label: sentiment_analysis
     Label: text_summarization
     Dimension: tasks
     Description: The process of generating a concise and coherent summary of a longer text document, capturing the main ideas and essential information.
     Level: 1
     # of Papers: 393
     Example Papers: [(1, 'Multi-News+: Cost-efficient Dataset Cleansing via LLM-based Data Annotation'), (5, 'ImageInWords: Unlocking Hyper-Detailed Image Descriptions'), (13, 'A Usage-centric Take on Intent Understanding in E-Commerce')]
     ----------------------------------------
     Children:
          Label: extractive_summarization
          Dimension: tasks
          Description: The process of selecting and extracting key sentences or phrases from a text document to create a summary that retains the original wording and structure.
          Level: 2
          # of Papers: 13
          Example Papers: [(177, 'SEER: Self-Aligned Evidence Extraction for Retrieval-Augmented Generation'), (432, 'Divide and Conquer Radiology Report Generation via Observation Level Fine-grained Pretraining and Prompt Tuning'), (518, 'APPLS: Evaluating Evaluation Metrics for Plain Language Summarization')]
          ----------------------------------------
          Label: abstractive_summarization
          Dimension: tasks
          Description: The generation of new sentences that convey the main ideas of a text document, often paraphrasing and rephrasing the original content to create a coherent summary.
          Level: 2
          # of Papers: 46
          Example Papers: [(342, 'SaySelf: Teaching LLMs to Express Confidence with Self-Reflective Rationales'), (364, 'Satyrn: A Platform for Analytics Augmented Generation'), (514, 'Enhancing Reinforcement Learning with Dense Rewards from Language Model Critic')]
          ----------------------------------------
          Children:
               Label: evaluation_metrics
               Label: learning_techniques
               Dimension: tasks
               Description: This cluster encompasses various learning methodologies applied to abstractive summarization, such as reinforcement learning, multi-objective finetuning, and active learning.
               Level: 3
               # of Papers: 11
               Example Papers: [(514, 'Enhancing Reinforcement Learning with Dense Rewards from Language Model Critic'), (950, 'GDPO: Learning to Directly Align Language Models with Diversity Using GFlowNets'), (975, "Don't Forget Your Reward Values: Language Model Alignment via Value-based Calibration")]
               ----------------------------------------
               Label: alignment_and_consistency
               Dimension: tasks
               Description: This cluster addresses the alignment of generated summaries with factual content and user preferences, including factual consistency detection, language model alignment, and reward alignment.
               Level: 3
               # of Papers: 14
               Example Papers: [(556, 'STORYSUMM: Evaluating Faithfulness in Story Summarization'), (950, 'GDPO: Learning to Directly Align Language Models with Diversity Using GFlowNets'), (975, "Don't Forget Your Reward Values: Language Model Alignment via Value-based Calibration")]
               ----------------------------------------
               Label: multimodal_and_multilingual_summarization
               Dimension: tasks
               Description: This cluster includes techniques for generating summaries from multiple sources or modalities, such as multilingual aspect-centric review summarization, multimodal summarization, and multi-source summarization.
               Level: 3
               # of Papers: 4
               Example Papers: [(1386, 'MARS: Multilingual Aspect-centric Review Summarisation'), (1388, 'Tell me what I need to know: Exploring LLM-based (Personalized) Abstractive Multi-Source Meeting Summarization'), (1417, 'AnyMAL: An Efficient and Scalable Any-Modality Augmented Language Model')]
               ----------------------------------------
               Label: advanced_generation_techniques
               Dimension: tasks
               Description: This cluster explores innovative generation strategies in abstractive summarization, including prompting techniques, structured reasoning, and zero-shot summarization.
               Level: 3
               # of Papers: 21
               Example Papers: [(364, 'Satyrn: A Platform for Analytics Augmented Generation'), (983, 'Knowledge Planning in Large Language Models for Domain-Aligned Counseling Summarization'), (1038, 'Semformer: Transformer Language Models with Semantic Planning')]
               ----------------------------------------
          ----------------------------------------
          Label: multi_document_summarization
          Dimension: tasks
          Description: The task of summarizing information from multiple documents into a single concise summary, capturing the essential points from each source.
          Level: 2
          # of Papers: 20
          Example Papers: [(1, 'Multi-News+: Cost-efficient Dataset Cleansing via LLM-based Data Annotation'), (551, 'Summary of a Haystack: A Challenge to Long-Context LLMs and RAG Systems'), (602, 'GlobeSumm: A Challenging Benchmark Towards Unifying Multi-lingual, Cross-lingual and Multi-document News Summarization')]
          ----------------------------------------
          Label: query-focused_summarization
          Dimension: tasks
          Description: A specialized form of summarization that generates summaries based on specific queries or information needs, ensuring relevance to the user's request.
          Level: 2
          # of Papers: 7
          Example Papers: [(837, 'Learning to Rank Salient Content for Query-focused Summarization'), (1405, 'Query-OPT: Optimizing Inference of Large Language Models via Multi-Query Instructions in Meeting Summarization'), (1470, 'Disordered-DABS: A Benchmark for Dynamic Aspect-Based Summarization in Disordered Texts')]
          ----------------------------------------
          Label: incremental_summarization
          Dimension: tasks
          Description: The process of continuously updating a summary as new information becomes available, allowing for real-time summarization of ongoing content.
          Level: 2
          # of Papers: 11
          Example Papers: [(409, 'Incomplete Utterance Rewriting with Editing Operation Guidance and Utterance Augmentation'), (675, 'TL-CL: Task And Language Incremental Continual Learning'), (983, 'Knowledge Planning in Large Language Models for Domain-Aligned Counseling Summarization')]
          ----------------------------------------
          Label: text_simplification
          Dimension: tasks
          Description: The process of modifying text to make it easier to read and understand while retaining the original meaning.
          Level: 2
          # of Papers: 150
          Example Papers: [(35, 'Evaluating Readability and Faithfulness of Concept-based Explanations'), (37, 'MSI-Agent: Incorporating Multi-Scale Insight into Embodied Agents for Superior Planning and Decision-Making'), (42, 'Parameter-Efficient Sparsity Crafting from Dense to Mixture-of-Experts for Instruction Tuning on General Tasks')]
          ----------------------------------------
          Children:
               Label: text_simplification_techniques
               Dimension: tasks
               Description: This cluster encompasses various methods and approaches used to simplify text, ensuring that the original meaning is preserved while enhancing readability.
               Level: 3
               # of Papers: 81
               Example Papers: [(37, 'MSI-Agent: Incorporating Multi-Scale Insight into Embodied Agents for Superior Planning and Decision-Making'), (52, 'Language Models Learn Rare Phenomena from Less Rare Phenomena: The Case of the Missing AANNs'), (93, 'Standardize: Aligning Language Models with Expert-Defined Standards for Content Generation')]
               ----------------------------------------
               Label: sentence_simplification
               Dimension: tasks
               Description: This cluster focuses on techniques specifically aimed at simplifying individual sentences to improve comprehension without losing essential information.
               Level: 3
               # of Papers: 6
               Example Papers: [(52, 'Language Models Learn Rare Phenomena from Less Rare Phenomena: The Case of the Missing AANNs'), (998, 'Label Confidence Weighted Learning for Target-level Sentence Simplification'), (1485, 'LLM-supertagger: Categorial Grammar Supertagging via Large Language Models')]
               ----------------------------------------
               Label: text_simplification_evaluation
               Dimension: tasks
               Description: This cluster includes methods and metrics for assessing the effectiveness of text simplification processes, ensuring that the simplified text meets desired readability standards.
               Level: 3
               # of Papers: 47
               Example Papers: [(35, 'Evaluating Readability and Faithfulness of Concept-based Explanations'), (52, 'Language Models Learn Rare Phenomena from Less Rare Phenomena: The Case of the Missing AANNs'), (149, 'Collaborative Performance Prediction for Large Language Models')]
               ----------------------------------------
               Label: length_control
               Dimension: tasks
               Description: This cluster involves strategies for managing the length of simplified text, balancing brevity with clarity to enhance reader understanding.
               Level: 3
               # of Papers: 9
               Example Papers: [(52, 'Language Models Learn Rare Phenomena from Less Rare Phenomena: The Case of the Missing AANNs'), (1131, 'DEFT-UCS: Data Efficient Fine-Tuning for Pre-Trained Language Models via Unsupervised Core-Set Selection for Text-Editing'), (1385, 'Retrieval Augmented Generation or Long-Context LLMs? A Comprehensive Study and Hybrid Approach')]
               ----------------------------------------
               Label: lexical_simplification
               Dimension: tasks
               Description: This cluster is dedicated to the simplification of vocabulary and phrasing within texts, making complex words and expressions more accessible to a broader audience.
               Level: 3
               # of Papers: 7
               Example Papers: [(52, 'Language Models Learn Rare Phenomena from Less Rare Phenomena: The Case of the Missing AANNs'), (848, 'Optimizing Chinese Lexical Simplification Across Word Types: A Hybrid Approach'), (849, 'Control Large Language Models via Divide and Conquer')]
               ----------------------------------------
          ----------------------------------------
          Label: knowledge_editing
          Dimension: tasks
          Description: The task of refining and updating knowledge representations to improve accuracy and relevance in information retrieval.
          Level: 2
          # of Papers: 15
          Example Papers: [(53, 'Large Language Models for Data Annotation and Synthesis: A Survey'), (56, 'RoseLoRA: Row and Column-wise Sparse Low-rank Adaptation of Pre-trained Language Model for Knowledge Editing and Fine-tuning'), (547, 'Extract, Define, Canonicalize: An LLM-based Framework for Knowledge Graph Construction')]
          ----------------------------------------
          Label: keyphrase_generation
          Dimension: tasks
          Description: The automated identification of key phrases within a text that capture the main topics and themes.
          Level: 2
          # of Papers: 20
          Example Papers: [(623, 'One2Set + Large Language Model: Best Partners for Keyphrase Generation'), (977, 'Are Large Language Models Capable of Generating Human-Level Narratives?'), (1052, 'Generation with Dynamic Vocabulary')]
          ----------------------------------------
          Label: text_segmentation
          Dimension: tasks
          Description: The division of text into meaningful segments or units to facilitate better understanding and processing.
          Level: 2
          # of Papers: 51
          Example Papers: [(39, 'Tokenization Is More Than Compression'), (166, 'With Ears to See and Eyes to Hear: Sound Symbolism Experiments with Multimodal Large Language Models'), (390, 'Beyond Embeddings: The Promise of Visual Table in Visual Reasoning')]
          ----------------------------------------
          Children:
               Label: text_representation
               Dimension: tasks
               Description: This cluster focuses on various methods and techniques for representing text in a structured format to enhance segmentation and understanding.
               Level: 3
               # of Papers: 1
               Example Papers: [(39, 'Tokenization Is More Than Compression')]
               ----------------------------------------
               Label: text_segmentation_techniques
               Dimension: tasks
               Description: This cluster encompasses different methodologies and approaches specifically designed for effective text segmentation.
               Level: 3
               # of Papers: 42
               Example Papers: [(39, 'Tokenization Is More Than Compression'), (390, 'Beyond Embeddings: The Promise of Visual Table in Visual Reasoning'), (402, 'Does Large Language Model Contain Task-Specific Neurons?')]
               ----------------------------------------
               Label: sentence_segmentation
               Dimension: tasks
               Description: This cluster is dedicated to the task of dividing text into individual sentences, which is a fundamental aspect of text segmentation.
               Level: 3
               # of Papers: 1
               Example Papers: [(664, 'Segment Any Text: A Universal Approach for Robust, Efficient and Adaptable Sentence Segmentation')]
               ----------------------------------------
               Label: document_segmentation
               Dimension: tasks
               Description: This cluster involves the segmentation of entire documents into coherent sections or units, facilitating better processing and comprehension.
               Level: 3
               # of Papers: 6
               Example Papers: [(1620, 'Recent Trends in Linear Text Segmentation: A Survey'), (1823, 'LumberChunker: Long-Form Narrative Document Segmentation'), (2186, 'Problem-Oriented Segmentation and Retrieval: Case Study on Tutoring Conversations')]
               ----------------------------------------
               Label: word_segmentation
               Dimension: tasks
               Description: This cluster focuses on the task of identifying and separating individual words within a continuous stream of text, crucial for languages without clear word boundaries.
               Level: 3
               # of Papers: 1
               Example Papers: [(2251, 'One Model is All You Need: ByT5-Sanskrit, a Unified Model for Sanskrit NLP Tasks')]
               ----------------------------------------
          ----------------------------------------
          Label: information_extraction
          Dimension: tasks
          Description: The process of automatically extracting structured information from unstructured text, such as identifying entities and relationships.
          Level: 2
          # of Papers: 75
          Example Papers: [(48, 'Overcome Noise and Bias: Segmentation-Aided Multi-Granularity Denoising and Debiasing for Enhanced Quarduples Extraction in Dialogue'), (53, 'Large Language Models for Data Annotation and Synthesis: A Survey'), (155, 'To Word Senses and Beyond: Inducing Concepts with Contextualized Language Models')]
          ----------------------------------------
          Children:
               Label: entity_recognition
               Dimension: tasks
               Description: The task of identifying and classifying key entities in text, such as names of people, organizations, locations, and other relevant items.
               Level: 3
               # of Papers: 1
               Example Papers: [(1127, 'VIEWS: Entity-Aware News Video Captioning')]
               ----------------------------------------
               Label: knowledge_graph_construction
               Dimension: tasks
               Description: The process of creating a structured representation of knowledge by extracting entities and their relationships from unstructured text.
               Level: 3
               # of Papers: 2
               Example Papers: [(547, 'Extract, Define, Canonicalize: An LLM-based Framework for Knowledge Graph Construction'), (2653, 'Cross Examine: An Ensemble-based approach to leverage Large Language Models for Legal Text Analytics')]
               ----------------------------------------
               Label: role_extraction
               Dimension: tasks
               Description: The task of identifying and categorizing the roles that entities play within a given context or relationship in the text.
               Level: 3
               # of Papers: 3
               Example Papers: [(436, 'MORPHEUS: Modeling Role from Personalized Dialogue History by Exploring and Utilizing Latent Space'), (1879, 'HiCuLR: Hierarchical Curriculum Learning for Rhetorical Role Labeling of Legal Documents'), (2215, 'Unleashing the Power of Large Language Models in Zero-shot Relation Extraction via Self-Prompting')]
               ----------------------------------------
               Label: text_to_table_generation
               Dimension: tasks
               Description: The process of converting unstructured text data into structured tabular formats, facilitating easier data analysis and retrieval.
               Level: 3
               # of Papers: 4
               Example Papers: [(522, 'Text-Tuple-Table: Towards Information Integration in Text-to-Table Generation via Global Tuple Extraction'), (537, 'ArxivDIGESTables: Synthesizing Scientific Literature into Tables using Language Models'), (900, 'TKGT: Redefinition and A New Way of Text-to-Table Tasks Based on Real World Demands and Knowledge Graphs Augmented LLMs')]
               ----------------------------------------
               Label: document_level_information_extraction
               Dimension: tasks
               Description: The extraction of structured information from entire documents, focusing on capturing comprehensive insights rather than isolated data points.
               Level: 3
               # of Papers: 68
               Example Papers: [(48, 'Overcome Noise and Bias: Segmentation-Aided Multi-Granularity Denoising and Debiasing for Enhanced Quarduples Extraction in Dialogue'), (53, 'Large Language Models for Data Annotation and Synthesis: A Survey'), (155, 'To Word Senses and Beyond: Inducing Concepts with Contextualized Language Models')]
               ----------------------------------------
          ----------------------------------------
     ----------------------------------------
     Label: information_retrieval
     Dimension: tasks
     Description: The task of obtaining information system resources that are relevant to an information need from a collection of those resources.
     Level: 1
     # of Papers: 1176
     Example Papers: [(5, 'ImageInWords: Unlocking Hyper-Detailed Image Descriptions'), (8, 'Speaking in Wavelet Domain: A Simple and Efficient Approach to Speed up Speech Diffusion Model'), (13, 'A Usage-centric Take on Intent Understanding in E-Commerce')]
     ----------------------------------------
     Children:
          Label: document_retrieval
          Dimension: tasks
          Description: This cluster focuses on tasks related to retrieving documents from a collection based on user queries, including techniques for document ranking and relevance assessment.
          Level: 2
          # of Papers: 297
          Example Papers: [(14, 'Fine-Tuning or Retrieval? Comparing Knowledge Injection in LLMs'), (24, 'Consolidating Ranking and Relevance Predictions of Large Language Models through Post-Processing'), (27, 'Clustering and Ranking: Diversity-preserved Instruction Selection through Expert-aligned Quality Estimation')]
          ----------------------------------------
          Children:
               Label: document_ranking
               Dimension: tasks
               Description: This subtopic focuses on techniques and algorithms for ranking documents based on their relevance to user queries, ensuring that the most pertinent documents are presented first.
               Level: 3
               # of Papers: 35
               Example Papers: [(24, 'Consolidating Ranking and Relevance Predictions of Large Language Models through Post-Processing'), (44, 'DyVo: Dynamic Vocabularies for Learned Sparse Retrieval with Entities'), (46, 'LongEmbed: Extending Embedding Models for Long Context Retrieval')]
               ----------------------------------------
               Label: relevance_assessment
               Dimension: tasks
               Description: This subtopic involves evaluating the relevance of retrieved documents to user queries, utilizing various metrics and methodologies to assess how well documents meet user needs.
               Level: 3
               # of Papers: 46
               Example Papers: [(24, 'Consolidating Ranking and Relevance Predictions of Large Language Models through Post-Processing'), (120, 'GLaPE: Gold Label-agnostic Prompt Evaluation for Large Language Models'), (320, 'REAR: A Relevance-Aware Retrieval-Augmented Framework for Open-Domain Question Answering')]
               ----------------------------------------
               Label: dense_retrieval
               Dimension: tasks
               Description: This subtopic explores methods for retrieving documents using dense representations, leveraging advanced embedding techniques to improve retrieval effectiveness.
               Level: 3
               # of Papers: 119
               Example Papers: [(44, 'DyVo: Dynamic Vocabularies for Learned Sparse Retrieval with Entities'), (46, 'LongEmbed: Extending Embedding Models for Long Context Retrieval'), (48, 'Overcome Noise and Bias: Segmentation-Aided Multi-Granularity Denoising and Debiasing for Enhanced Quarduples Extraction in Dialogue')]
               ----------------------------------------
               Label: query_rewriting
               Dimension: tasks
               Description: This subtopic deals with transforming user queries into more effective forms to enhance the retrieval of relevant documents, often involving synonym expansion and query optimization.
               Level: 3
               # of Papers: 5
               Example Papers: [(134, 'CHIQ: Contextual History Enhancement for Improving Query Rewriting in Conversational Search'), (745, 'Adaptive Query Rewriting: Aligning Rewriters through Marginal Probability of Conversational Answers'), (1427, 'RAC: Retrieval-augmented Conversation Dataset for Open-domain Question Answering in Conversational Settings')]
               ----------------------------------------
               Label: retrieval_augmentation
               Dimension: tasks
               Description: This subtopic focuses on enhancing document retrieval processes by integrating additional information or techniques, such as using external knowledge sources to improve retrieval outcomes.
               Level: 3
               # of Papers: 109
               Example Papers: [(14, 'Fine-Tuning or Retrieval? Comparing Knowledge Injection in LLMs'), (44, 'DyVo: Dynamic Vocabularies for Learned Sparse Retrieval with Entities'), (57, 'BlendFilter: Advancing Retrieval-Augmented Large Language Models via Query Generation Blending and Knowledge Filtering')]
               ----------------------------------------
               Label: cross_cultural_document_retrieval
               Dimension: tasks
               Description: This subtopic examines the methodologies and challenges involved in retrieving documents that are relevant across different cultural contexts, focusing on the nuances of language and cultural references.
               Level: 3
               # of Papers: 6
               Example Papers: [(60, 'Bridging Cultures in the Kitchen: A Framework and Benchmark for Cross-Cultural Recipe Retrieval'), (1603, 'McCrolin: Multi-consistency Cross-lingual Training for Retrieval Question Answering'), (1829, 'Cross-lingual Contextualized Phrase Retrieval')]
               ----------------------------------------
          ----------------------------------------
          Label: query_expansion
          Dimension: tasks
          Description: This cluster encompasses methods aimed at enhancing user queries to improve retrieval performance, including techniques for query reformulation and synonym generation.
          Level: 2
          # of Papers: 26
          Example Papers: [(57, 'BlendFilter: Advancing Retrieval-Augmented Large Language Models via Query Generation Blending and Knowledge Filtering'), (120, 'GLaPE: Gold Label-agnostic Prompt Evaluation for Large Language Models'), (134, 'CHIQ: Contextual History Enhancement for Improving Query Rewriting in Conversational Search')]
          ----------------------------------------
          Label: multimodal_information_retrieval
          Dimension: tasks
          Description: This cluster involves retrieving information from multiple modalities, such as text, images, and audio, to provide comprehensive responses to user queries.
          Level: 2
          # of Papers: 226
          Example Papers: [(5, 'ImageInWords: Unlocking Hyper-Detailed Image Descriptions'), (43, 'GeoGPT4V: Towards Geometric Multi-modal Large Language Models with Geometric Image Generation'), (60, 'Bridging Cultures in the Kitchen: A Framework and Benchmark for Cross-Cultural Recipe Retrieval')]
          ----------------------------------------
          Children:
               Label: multimodal_retrieval
               Dimension: tasks
               Description: This cluster focuses on techniques and methodologies for retrieving information from multiple modalities, including text, images, and audio, to enhance the quality and relevance of search results.
               Level: 3
               # of Papers: 196
               Example Papers: [(5, 'ImageInWords: Unlocking Hyper-Detailed Image Descriptions'), (43, 'GeoGPT4V: Towards Geometric Multi-modal Large Language Models with Geometric Image Generation'), (60, 'Bridging Cultures in the Kitchen: A Framework and Benchmark for Cross-Cultural Recipe Retrieval')]
               ----------------------------------------
               Label: visual_language_models
               Dimension: tasks
               Description: This cluster encompasses models that integrate visual and linguistic information to improve understanding and generation tasks across multimodal datasets.
               Level: 3
               # of Papers: 65
               Example Papers: [(5, 'ImageInWords: Unlocking Hyper-Detailed Image Descriptions'), (43, 'GeoGPT4V: Towards Geometric Multi-modal Large Language Models with Geometric Image Generation'), (66, 'EFUF: Efficient Fine-Grained Unlearning Framework for Mitigating Hallucinations in Multimodal Large Language Models')]
               ----------------------------------------
               Label: video_retrieval
               Dimension: tasks
               Description: This cluster specializes in retrieving relevant video content based on user queries, leveraging both visual and audio features to enhance search accuracy.
               Level: 3
               # of Papers: 10
               Example Papers: [(126, 'VideoScore: Building Automatic Metrics to Simulate Fine-grained Human Feedback for Video Generation'), (253, 'VIMI: Grounding Video Generation through Multi-modal Instruction'), (453, 'Efficient Vision-Language pre-training via domain-specific learning for human activities')]
               ----------------------------------------
               Label: image_captioning
               Dimension: tasks
               Description: This cluster involves generating descriptive captions for images by combining visual analysis with natural language processing techniques.
               Level: 3
               # of Papers: 5
               Example Papers: [(5, 'ImageInWords: Unlocking Hyper-Detailed Image Descriptions'), (1152, 'IFCap: Image-like Retrieval and Frequency-based Entity Filtering for Zero-shot Captioning'), (1490, 'Preserving Pre-trained Representation Space: On Effectiveness of Prefix-tuning for Large Multi-modal Models')]
               ----------------------------------------
               Label: cross_modal_alignment
               Dimension: tasks
               Description: This cluster focuses on aligning information across different modalities, ensuring that data from text, images, and audio can be effectively correlated and utilized.
               Level: 3
               # of Papers: 29
               Example Papers: [(66, 'EFUF: Efficient Fine-Grained Unlearning Framework for Mitigating Hallucinations in Multimodal Large Language Models'), (286, 'MaPPER: Multimodal Prior-guided Parameter Efficient Tuning for Referring Expression Comprehension'), (459, 'mDPO: Conditional Preference Optimization for Multimodal Large Language Models')]
               ----------------------------------------
          ----------------------------------------
          Label: semantic_search
          Dimension: tasks
          Description: This cluster focuses on enhancing search capabilities by understanding the meaning behind queries and documents, utilizing techniques like semantic indexing and knowledge graphs.
          Level: 2
          # of Papers: 208
          Example Papers: [(35, 'Evaluating Readability and Faithfulness of Concept-based Explanations'), (44, 'DyVo: Dynamic Vocabularies for Learned Sparse Retrieval with Entities'), (48, 'Overcome Noise and Bias: Segmentation-Aided Multi-Granularity Denoising and Debiasing for Enhanced Quarduples Extraction in Dialogue')]
          ----------------------------------------
          Children:
               Label: semantic_indexing
               Dimension: tasks
               Description: This cluster focuses on techniques and methodologies for indexing documents based on their semantic content, enhancing retrieval effectiveness by understanding the meaning behind the text.
               Level: 3
               # of Papers: 84
               Example Papers: [(44, 'DyVo: Dynamic Vocabularies for Learned Sparse Retrieval with Entities'), (48, 'Overcome Noise and Bias: Segmentation-Aided Multi-Granularity Denoising and Debiasing for Enhanced Quarduples Extraction in Dialogue'), (57, 'BlendFilter: Advancing Retrieval-Augmented Large Language Models via Query Generation Blending and Knowledge Filtering')]
               ----------------------------------------
               Label: knowledge_graphs
               Dimension: tasks
               Description: This cluster explores the use of knowledge graphs to improve search capabilities, enabling systems to understand relationships and context within data for more accurate retrieval.
               Level: 3
               # of Papers: 40
               Example Papers: [(80, 'A New Pipeline for Knowledge Graph Reasoning Enhanced by Large Language Models Without Fine-Tuning'), (308, 'Relevance Is a Guiding Light: Relevance-aware Adaptive Learning for End-to-end Task-oriented Dialogue System'), (335, 'MTA4DPR: Multi-Teaching-Assistants Based Iterative Knowledge Distillation for Dense Passage Retrieval')]
               ----------------------------------------
               Label: query_understanding
               Dimension: tasks
               Description: This cluster emphasizes the interpretation and analysis of user queries to enhance search results, ensuring that the intent behind the queries is accurately captured.
               Level: 3
               # of Papers: 47
               Example Papers: [(48, 'Overcome Noise and Bias: Segmentation-Aided Multi-Granularity Denoising and Debiasing for Enhanced Quarduples Extraction in Dialogue'), (57, 'BlendFilter: Advancing Retrieval-Augmented Large Language Models via Query Generation Blending and Knowledge Filtering'), (134, 'CHIQ: Contextual History Enhancement for Improving Query Rewriting in Conversational Search')]
               ----------------------------------------
               Label: cross-lingual_retrieval
               Dimension: tasks
               Description: This cluster investigates methods for retrieving information across different languages, focusing on bridging language barriers in semantic search.
               Level: 3
               # of Papers: 25
               Example Papers: [(60, 'Bridging Cultures in the Kitchen: A Framework and Benchmark for Cross-Cultural Recipe Retrieval'), (308, 'Relevance Is a Guiding Light: Relevance-aware Adaptive Learning for End-to-end Task-oriented Dialogue System'), (735, 'Language Concept Erasure for Language-invariant Dense Retrieval')]
               ----------------------------------------
               Label: semantic_textual_similarity
               Dimension: tasks
               Description: This cluster examines techniques for measuring the similarity between texts based on their semantic meaning, facilitating more relevant search results.
               Level: 3
               # of Papers: 113
               Example Papers: [(35, 'Evaluating Readability and Faithfulness of Concept-based Explanations'), (48, 'Overcome Noise and Bias: Segmentation-Aided Multi-Granularity Denoising and Debiasing for Enhanced Quarduples Extraction in Dialogue'), (57, 'BlendFilter: Advancing Retrieval-Augmented Large Language Models via Query Generation Blending and Knowledge Filtering')]
               ----------------------------------------
          ----------------------------------------
          Label: personalized_information_retrieval
          Dimension: tasks
          Description: This cluster includes tasks that tailor information retrieval processes to individual user preferences and behaviors, improving the relevance of search results.
          Level: 2
          # of Papers: 69
          Example Papers: [(13, 'A Usage-centric Take on Intent Understanding in E-Commerce'), (60, 'Bridging Cultures in the Kitchen: A Framework and Benchmark for Cross-Cultural Recipe Retrieval'), (85, 'Mitigating Matthew Effect: Multi-Hypergraph Boosted Multi-Interest Self-Supervised Learning for Conversational Recommendation')]
          ----------------------------------------
          Children:
               Label: recommender_systems
               Dimension: tasks
               Description: This cluster focuses on systems designed to suggest items or content to users based on their preferences and past behaviors.
               Level: 3
               # of Papers: 21
               Example Papers: [(13, 'A Usage-centric Take on Intent Understanding in E-Commerce'), (85, 'Mitigating Matthew Effect: Multi-Hypergraph Boosted Multi-Interest Self-Supervised Learning for Conversational Recommendation'), (652, 'Enhancing High-order Interaction Awareness in LLM-based Recommender Model')]
               ----------------------------------------
               Label: user_modeling
               Dimension: tasks
               Description: This cluster encompasses techniques for creating and updating user profiles that capture individual preferences and behaviors to enhance information retrieval.
               Level: 3
               # of Papers: 13
               Example Papers: [(13, 'A Usage-centric Take on Intent Understanding in E-Commerce'), (280, 'Crafting Personalized Agents through Retrieval-Augmented Generation on Editable Memory Graphs'), (370, 'Personalized Pieces: Efficient Personalized Large Language Models through Collaborative Efforts')]
               ----------------------------------------
               Label: conversational_recommendation
               Dimension: tasks
               Description: This cluster includes tasks that involve providing personalized recommendations through conversational interfaces, enhancing user engagement and satisfaction.
               Level: 3
               # of Papers: 12
               Example Papers: [(85, 'Mitigating Matthew Effect: Multi-Hypergraph Boosted Multi-Interest Self-Supervised Learning for Conversational Recommendation'), (436, 'MORPHEUS: Modeling Role from Personalized Dialogue History by Exploring and Utilizing Latent Space'), (580, '"In-Dialogues We Learn": Towards Personalized Dialogue Without Pre-defined Profiles through In-Dialogue Learning')]
               ----------------------------------------
               Label: adaptive_feedback
               Dimension: tasks
               Description: This cluster involves methods that adaptively gather user feedback to refine and improve the relevance of information retrieval systems.
               Level: 3
               # of Papers: 9
               Example Papers: [(311, 'Investigating LLMs as Voting Assistants via Contextual Augmentation: A Case Study on the European Parliament Elections 2024'), (477, 'Stepwise Verification and Remediation of Student Reasoning Errors with Large Language Model Tutors'), (783, 'KARL: Knowledge-Aware Retrieval and Representations aid Retention and Learning in Students')]
               ----------------------------------------
               Label: personalized_language_models
               Dimension: tasks
               Description: This cluster focuses on the development of language models that are tailored to individual users, improving the accuracy and relevance of generated content.
               Level: 3
               # of Papers: 50
               Example Papers: [(60, 'Bridging Cultures in the Kitchen: A Framework and Benchmark for Cross-Cultural Recipe Retrieval'), (280, 'Crafting Personalized Agents through Retrieval-Augmented Generation on Editable Memory Graphs'), (311, 'Investigating LLMs as Voting Assistants via Contextual Augmentation: A Case Study on the European Parliament Elections 2024')]
               ----------------------------------------
          ----------------------------------------
          Label: legal_information_retrieval
          Dimension: tasks
          Description: This cluster focuses on tasks related to retrieving legal documents and information, including case law, statutes, and legal opinions based on user queries.
          Level: 2
          # of Papers: 53
          Example Papers: [(72, 'Learning Interpretable Legal Case Retrieval via Knowledge-Guided Case Reformulation'), (216, 'C3PA: An Open Dataset of Expert-Annotated and Regulation-Aware Privacy Policies to Enable Scalable Regulatory Compliance Audits'), (311, 'Investigating LLMs as Voting Assistants via Contextual Augmentation: A Case Study on the European Parliament Elections 2024')]
          ----------------------------------------
          Children:
               Label: case_law_retrieval
               Dimension: tasks
               Description: This subtopic focuses on the retrieval of case law documents, enabling users to find relevant legal precedents based on specific queries.
               Level: 3
               # of Papers: 2
               Example Papers: [(72, 'Learning Interpretable Legal Case Retrieval via Knowledge-Guided Case Reformulation'), (401, 'Enhancing Legal Case Retrieval via Scaling High-quality Synthetic Query-Candidate Pairs')]
               ----------------------------------------
               Label: statute_retrieval
               Dimension: tasks
               Description: This subtopic involves the retrieval of statutes and legislative texts, allowing users to access legal codes and regulations pertinent to their inquiries.
               Level: 3
               # of Papers: 1
               Example Papers: [(2071, 'STARD: A Chinese Statute Retrieval Dataset Derived from Real-life Queries by Non-professionals')]
               ----------------------------------------
               Label: legal_document_retrieval
               Dimension: tasks
               Description: This subtopic encompasses the retrieval of various legal documents, including contracts, briefs, and opinions, tailored to user-defined search criteria.
               Level: 3
               # of Papers: 18
               Example Papers: [(504, 'AssistantBench: Can Web Agents Solve Realistic and Time-Consuming Tasks?'), (992, 'Unveiling and Consulting Core Experts in Retrieval-Augmented MoE-based LLMs'), (1055, 'Link, Synthesize, Retrieve: Universal Document Linking for Zero-Shot Information Retrieval')]
               ----------------------------------------
               Label: legal_reasoning
               Dimension: tasks
               Description: This subtopic explores the application of legal reasoning techniques to enhance the retrieval and interpretation of legal information.
               Level: 3
               # of Papers: 21
               Example Papers: [(311, 'Investigating LLMs as Voting Assistants via Contextual Augmentation: A Case Study on the European Parliament Elections 2024'), (428, 'More Than Catastrophic Forgetting: Integrating General Capabilities For Domain-Specific LLMs'), (647, 'Red Teaming Language Models for Processing Contradictory Dialogues')]
               ----------------------------------------
               Label: regulatory_compliance
               Dimension: tasks
               Description: This subtopic addresses the retrieval of information related to regulatory compliance, helping users understand and adhere to legal requirements.
               Level: 3
               # of Papers: 2
               Example Papers: [(216, 'C3PA: An Open Dataset of Expert-Annotated and Regulation-Aware Privacy Policies to Enable Scalable Regulatory Compliance Audits'), (2654, "LLMs to the Rescue: Explaining DSA Statements of Reason with Platform's Terms of Services")]
               ----------------------------------------
          ----------------------------------------
          Label: medical_information_retrieval
          Dimension: tasks
          Description: This cluster encompasses tasks aimed at retrieving medical literature and patient information, facilitating access to relevant healthcare data based on specific queries.
          Level: 2
          # of Papers: 61
          Example Papers: [(279, 'An Unsupervised Approach to Achieve Supervised-Level Explainability in Healthcare Records'), (311, 'Investigating LLMs as Voting Assistants via Contextual Augmentation: A Case Study on the European Parliament Elections 2024'), (398, 'Generative Models for Automatic Medical Decision Rule Extraction from Text')]
          ----------------------------------------
          Children:
               Label: literature_search
               Dimension: tasks
               Description: This subtopic focuses on the retrieval of relevant medical literature based on specific queries, facilitating access to published research and clinical guidelines.
               Level: 3
               ----------------------------------------
               Label: patient_information_retrieval
               Dimension: tasks
               Description: This subtopic encompasses tasks aimed at retrieving patient-specific information from medical records and databases to support clinical decision-making.
               Level: 3
               # of Papers: 1
               Example Papers: [(1480, 'SMILE: Single-turn to Multi-turn Inclusive Language Expansion via ChatGPT for Mental Health Support')]
               ----------------------------------------
               Label: medical_text_analysis
               Dimension: tasks
               Description: This subtopic involves the analysis of medical texts to extract meaningful information, identify trends, and support various healthcare applications.
               Level: 3
               # of Papers: 35
               Example Papers: [(279, 'An Unsupervised Approach to Achieve Supervised-Level Explainability in Healthcare Records'), (398, 'Generative Models for Automatic Medical Decision Rule Extraction from Text'), (417, 'Towards Injecting Medical Visual Knowledge into Multimodal LLMs at Scale')]
               ----------------------------------------
               Label: medical_information_extraction
               Dimension: tasks
               Description: This subtopic focuses on extracting structured information from unstructured medical texts, such as clinical notes and research articles, to enhance data usability.
               Level: 3
               # of Papers: 35
               Example Papers: [(398, 'Generative Models for Automatic Medical Decision Rule Extraction from Text'), (417, 'Towards Injecting Medical Visual Knowledge into Multimodal LLMs at Scale'), (437, 'KnowledgeSG: Privacy-Preserving Synthetic Text Generation with Knowledge Distillation from Server')]
               ----------------------------------------
               Label: automated_medical_coding
               Dimension: tasks
               Description: This subtopic deals with the automatic assignment of medical codes to diagnoses and procedures based on retrieved medical information, streamlining billing and record-keeping.
               Level: 3
               # of Papers: 3
               Example Papers: [(279, 'An Unsupervised Approach to Achieve Supervised-Level Explainability in Healthcare Records'), (499, 'Beyond Label Attention: Transparency in Language Models for Automated Medical Coding via Dictionary Learning'), (1244, 'EHRAgent: Code Empowers Large Language Models for Few-shot Complex Tabular Reasoning on Electronic Health Records')]
               ----------------------------------------
          ----------------------------------------
          Label: healthcare_information_retrieval
          Dimension: tasks
          Description: This cluster involves retrieving healthcare-related information, including clinical guidelines and research articles, to support medical decision-making and patient care.
          Level: 2
          # of Papers: 50
          Example Papers: [(279, 'An Unsupervised Approach to Achieve Supervised-Level Explainability in Healthcare Records'), (311, 'Investigating LLMs as Voting Assistants via Contextual Augmentation: A Case Study on the European Parliament Elections 2024'), (437, 'KnowledgeSG: Privacy-Preserving Synthetic Text Generation with Knowledge Distillation from Server')]
          ----------------------------------------
          Children:
               Label: clinical_guidelines
               Dimension: tasks
               Description: This subtopic focuses on the retrieval and application of clinical guidelines to support healthcare professionals in making informed medical decisions.
               Level: 3
               ----------------------------------------
               Label: clinical_guidelines_retrieval
               Dimension: tasks
               Description: This area specializes in the techniques and methodologies for efficiently retrieving clinical guidelines from various healthcare databases.
               Level: 3
               # of Papers: 3
               Example Papers: [(1775, 'TriageAgent: Towards Better Multi-Agents Collaborations for Large Language Model-Based Clinical Triage'), (2065, 'MedCare: Advancing Medical LLMs through Decoupling Clinical Alignment and Knowledge Aggregation'), (2764, 'Personalized-ABA: Personalized Treatment Plan Generation for Applied Behavior Analysis using Natural Language Processing')]
               ----------------------------------------
               Label: medical_question_answering
               Dimension: tasks
               Description: This subtopic involves systems designed to answer medical questions by retrieving relevant healthcare information from various sources.
               Level: 3
               # of Papers: 13
               Example Papers: [(311, 'Investigating LLMs as Voting Assistants via Contextual Augmentation: A Case Study on the European Parliament Elections 2024'), (1025, 'CasiMedicos-Arg: A Medical Question Answering Dataset Annotated with Explanatory Argumentative Structures'), (1243, 'MedAdapter: Efficient Test-Time Adaptation of Large Language Models Towards Medical Reasoning')]
               ----------------------------------------
               Label: epidemiological_data_extraction
               Dimension: tasks
               Description: This cluster focuses on the extraction of epidemiological data from healthcare literature to inform public health decisions and research.
               Level: 3
               # of Papers: 3
               Example Papers: [(504, 'AssistantBench: Can Web Agents Solve Realistic and Time-Consuming Tasks?'), (719, 'SPEED++: A Multilingual Event Extraction Framework for Epidemic Prediction and Preparedness'), (2742, 'From Text to Maps: LLM-Driven Extraction and Geotagging of Epidemiological Data')]
               ----------------------------------------
               Label: explanation_methods_in_healthcare_information_retrieval
               Dimension: tasks
               Description: This area explores methods for providing explanations and justifications for the retrieved healthcare information to enhance user understanding.
               Level: 3
               # of Papers: 29
               Example Papers: [(279, 'An Unsupervised Approach to Achieve Supervised-Level Explainability in Healthcare Records'), (437, 'KnowledgeSG: Privacy-Preserving Synthetic Text Generation with Knowledge Distillation from Server'), (494, "Revisiting Who's Harry Potter: Towards Targeted Unlearning from a Causal Intervention Perspective")]
               ----------------------------------------
          ----------------------------------------
          Label: temporal_information_retrieval
          Dimension: tasks
          Description: This cluster focuses on tasks that involve retrieving information based on temporal aspects, such as event timelines and historical data relevant to user queries.
          Level: 2
          # of Papers: 96
          Example Papers: [(50, 'In-context Contrastive Learning for Event Causality Identification'), (85, 'Mitigating Matthew Effect: Multi-Hypergraph Boosted Multi-Interest Self-Supervised Learning for Conversational Recommendation'), (137, 'Direct Multi-Turn Preference Optimization for Language Agents')]
          ----------------------------------------
          Children:
               Label: event_timeline_retrieval
               Dimension: tasks
               Description: This subtopic focuses on retrieving comprehensive timelines of events based on user queries, allowing for a structured understanding of temporal sequences.
               Level: 3
               # of Papers: 4
               Example Papers: [(281, 'EVEDIT: Event-based Knowledge Editing for Deterministic Knowledge Propagation'), (1493, 'Temporal Cognitive Tree: A Hierarchical Modeling Approach for Event Temporal Relation Extraction'), (1665, 'When and Where Did it Happen? An Encoder-Decoder Model to Identify Scenario Context')]
               ----------------------------------------
               Label: event_based_information_retrieval
               Dimension: tasks
               Description: This area emphasizes the retrieval of information that is specifically tied to events, enhancing the relevance of search results in temporal contexts.
               Level: 3
               # of Papers: 45
               Example Papers: [(50, 'In-context Contrastive Learning for Event Causality Identification'), (85, 'Mitigating Matthew Effect: Multi-Hypergraph Boosted Multi-Interest Self-Supervised Learning for Conversational Recommendation'), (281, 'EVEDIT: Event-based Knowledge Editing for Deterministic Knowledge Propagation')]
               ----------------------------------------
               Label: temporal_knowledge_graph_reasoning
               Dimension: tasks
               Description: This subtopic involves reasoning over temporal knowledge graphs to extract insights and relationships that are time-dependent.
               Level: 3
               # of Papers: 8
               Example Papers: [(85, 'Mitigating Matthew Effect: Multi-Hypergraph Boosted Multi-Interest Self-Supervised Learning for Conversational Recommendation'), (921, 'Multi-Level Information Retrieval Augmented Generation for Knowledge-based Visual Question Answering'), (1409, 'Knowledge-augmented Financial Market Analysis and Report Generation')]
               ----------------------------------------
               Label: event_prediction
               Dimension: tasks
               Description: This cluster deals with predicting future events based on historical data and trends, providing foresight into temporal developments.
               Level: 3
               # of Papers: 9
               Example Papers: [(137, 'Direct Multi-Turn Preference Optimization for Language Agents'), (504, 'AssistantBench: Can Web Agents Solve Realistic and Time-Consuming Tasks?'), (700, 'Lifelong Event Detection via Optimal Transport')]
               ----------------------------------------
               Label: temporal_relation_classification
               Dimension: tasks
               Description: This area focuses on classifying relationships between events in terms of their temporal connections, aiding in the understanding of event interactions over time.
               Level: 3
               # of Papers: 52
               Example Papers: [(50, 'In-context Contrastive Learning for Event Causality Identification'), (311, 'Investigating LLMs as Voting Assistants via Contextual Augmentation: A Case Study on the European Parliament Elections 2024'), (413, 'Extending Context Window of Large Language Models from a Distributional Perspective')]
               ----------------------------------------
          ----------------------------------------
          Label: event_temporal_relation_extraction
          Dimension: tasks
          Description: This cluster deals with extracting and retrieving information related to the temporal relationships between events, enhancing the understanding of chronological data.
          Level: 2
          # of Papers: 62
          Example Papers: [(50, 'In-context Contrastive Learning for Event Causality Identification'), (281, 'EVEDIT: Event-based Knowledge Editing for Deterministic Knowledge Propagation'), (311, 'Investigating LLMs as Voting Assistants via Contextual Augmentation: A Case Study on the European Parliament Elections 2024')]
          ----------------------------------------
          Children:
               Label: temporal_relation_extraction
               Dimension: tasks
               Description: This subtopic focuses on the extraction of temporal relationships between events, identifying how events are related in time.
               Level: 3
               # of Papers: 28
               Example Papers: [(50, 'In-context Contrastive Learning for Event Causality Identification'), (281, 'EVEDIT: Event-based Knowledge Editing for Deterministic Knowledge Propagation'), (311, 'Investigating LLMs as Voting Assistants via Contextual Augmentation: A Case Study on the European Parliament Elections 2024')]
               ----------------------------------------
               Label: temporal_relation_extraction_evaluation
               Dimension: tasks
               Description: This subtopic deals with the evaluation methodologies and metrics used to assess the performance of temporal relation extraction systems.
               Level: 3
               # of Papers: 1
               Example Papers: [(504, 'AssistantBench: Can Web Agents Solve Realistic and Time-Consuming Tasks?')]
               ----------------------------------------
               Label: temporal_dependency_extraction
               Dimension: tasks
               Description: This subtopic involves the extraction of dependencies that indicate the temporal order and relationships among events.
               Level: 3
               # of Papers: 12
               Example Papers: [(647, 'Red Teaming Language Models for Processing Contradictory Dialogues'), (672, 'Explicit, Implicit, and Scattered: Revisiting Event Extraction to Capture Complex Arguments'), (862, 'SRF: Enhancing Document-Level Relation Extraction with a Novel Secondary Reasoning Framework')]
               ----------------------------------------
               Label: temporal_relation_prediction
               Dimension: tasks
               Description: This subtopic is concerned with predicting future temporal relationships between events based on existing data.
               Level: 3
               ----------------------------------------
               Label: temporal_graph_generation
               Dimension: tasks
               Description: This subtopic focuses on creating graphical representations of temporal relationships among events to visualize and analyze their interconnections.
               Level: 3
               ----------------------------------------
          ----------------------------------------
     ----------------------------------------
     Label: question_answering
     Dimension: tasks
     Description: The task of automatically answering questions posed by humans in a natural language.
     Level: 1
     # of Papers: 828
     Example Papers: [(4, 'Table Question Answering for Low-resourced Indic Languages'), (5, 'ImageInWords: Unlocking Hyper-Detailed Image Descriptions'), (13, 'A Usage-centric Take on Intent Understanding in E-Commerce')]
     ----------------------------------------
     Children:
          Label: retrieval_based_question_answering
          Dimension: tasks
          Description: This cluster focuses on techniques that enhance question answering by retrieving relevant information from external sources or databases to provide accurate answers.
          Level: 2
          # of Papers: 98
          Example Papers: [(14, 'Fine-Tuning or Retrieval? Comparing Knowledge Injection in LLMs'), (57, 'BlendFilter: Advancing Retrieval-Augmented Large Language Models via Query Generation Blending and Knowledge Filtering'), (100, 'Triad: A Framework Leveraging a Multi-Role LLM-based Agent to Solve Knowledge Base Question Answering')]
          ----------------------------------------
          Children:
               Label: retrieval_augmented_generation
               Dimension: tasks
               Description: This subtopic focuses on enhancing question answering by integrating retrieval mechanisms with generative models to produce more accurate and contextually relevant answers.
               Level: 3
               # of Papers: 61
               Example Papers: [(14, 'Fine-Tuning or Retrieval? Comparing Knowledge Injection in LLMs'), (57, 'BlendFilter: Advancing Retrieval-Augmented Large Language Models via Query Generation Blending and Knowledge Filtering'), (198, 'EfficientRAG: Efficient Retriever for Multi-Hop Question Answering')]
               ----------------------------------------
               Label: knowledge_integration
               Dimension: tasks
               Description: This cluster emphasizes the incorporation of external knowledge sources into the question answering process to improve the accuracy and relevance of the responses.
               Level: 3
               # of Papers: 42
               Example Papers: [(14, 'Fine-Tuning or Retrieval? Comparing Knowledge Injection in LLMs'), (57, 'BlendFilter: Advancing Retrieval-Augmented Large Language Models via Query Generation Blending and Knowledge Filtering'), (100, 'Triad: A Framework Leveraging a Multi-Role LLM-based Agent to Solve Knowledge Base Question Answering')]
               ----------------------------------------
               Label: query_generation
               Dimension: tasks
               Description: This subtopic deals with the techniques for generating effective queries that can retrieve the most relevant information from external databases for question answering.
               Level: 3
               # of Papers: 7
               Example Papers: [(57, 'BlendFilter: Advancing Retrieval-Augmented Large Language Models via Query Generation Blending and Knowledge Filtering'), (241, "I Could've Asked That: Reformulating Unanswerable Questions"), (1139, 'You Make me Feel like a Natural Question: Training QA Systems on Transformed Trivia Questions')]
               ----------------------------------------
               Label: efficient_retrieval
               Dimension: tasks
               Description: This cluster focuses on optimizing retrieval methods to ensure that relevant information is accessed quickly and effectively during the question answering process.
               Level: 3
               # of Papers: 38
               Example Papers: [(57, 'BlendFilter: Advancing Retrieval-Augmented Large Language Models via Query Generation Blending and Knowledge Filtering'), (198, 'EfficientRAG: Efficient Retriever for Multi-Hop Question Answering'), (321, 'Leave No Document Behind: Benchmarking Long-Context LLMs with Extended Multi-Doc QA')]
               ----------------------------------------
               Label: knowledge_graph_based_qa
               Dimension: tasks
               Description: This subtopic explores the use of knowledge graphs to facilitate question answering by providing structured information that can be easily queried and interpreted.
               Level: 3
               # of Papers: 13
               Example Papers: [(100, 'Triad: A Framework Leveraging a Multi-Role LLM-based Agent to Solve Knowledge Base Question Answering'), (321, 'Leave No Document Behind: Benchmarking Long-Context LLMs with Extended Multi-Doc QA'), (1022, 'Generate-on-Graph: Treat LLM as both Agent and KG for Incomplete Knowledge Graph Question Answering')]
               ----------------------------------------
          ----------------------------------------
          Label: dialogue_systems
          Dimension: tasks
          Description: This cluster encompasses systems designed to engage in conversation with users, facilitating question answering through interactive dialogue.
          Level: 2
          # of Papers: 63
          Example Papers: [(48, 'Overcome Noise and Bias: Segmentation-Aided Multi-Granularity Denoising and Debiasing for Enhanced Quarduples Extraction in Dialogue'), (134, 'CHIQ: Contextual History Enhancement for Improving Query Rewriting in Conversational Search'), (262, 'Bootstrapped Policy Learning for Task-oriented Dialogue through Goal Shaping')]
          ----------------------------------------
          Children:
               Label: intent_detection
               Dimension: tasks
               Description: This subtopic focuses on identifying user intentions within dialogues, enabling systems to understand and respond appropriately to user queries.
               Level: 3
               # of Papers: 4
               Example Papers: [(1347, 'Detecting Ambiguous Utterances in an Intelligent Assistant'), (1433, 'Intent Detection in the Age of LLMs'), (1586, 'A Coarse-to-Fine Prototype Learning Approach for Multi-Label Few-Shot Intent Detection')]
               ----------------------------------------
               Label: task-oriented_dialog_systems
               Dimension: tasks
               Description: This subtopic encompasses dialogue systems specifically designed to assist users in completing specific tasks through structured interactions.
               Level: 3
               # of Papers: 49
               Example Papers: [(48, 'Overcome Noise and Bias: Segmentation-Aided Multi-Granularity Denoising and Debiasing for Enhanced Quarduples Extraction in Dialogue'), (134, 'CHIQ: Contextual History Enhancement for Improving Query Rewriting in Conversational Search'), (262, 'Bootstrapped Policy Learning for Task-oriented Dialogue through Goal Shaping')]
               ----------------------------------------
               Label: personalized_dialogue_generation
               Dimension: tasks
               Description: This subtopic involves generating dialogue responses that are tailored to individual user preferences and contexts, enhancing user engagement.
               Level: 3
               # of Papers: 5
               Example Papers: [(436, 'MORPHEUS: Modeling Role from Personalized Dialogue History by Exploring and Utilizing Latent Space'), (580, '"In-Dialogues We Learn": Towards Personalized Dialogue Without Pre-defined Profiles through In-Dialogue Learning'), (2272, 'Active Listening: Personalized Question Generation in Open-Domain Social Conversation with User Model Based Prompting')]
               ----------------------------------------
               Label: dialogue_management
               Dimension: tasks
               Description: This subtopic deals with the strategies and techniques for managing the flow of conversation in dialogue systems, ensuring coherent and contextually relevant interactions.
               Level: 3
               # of Papers: 16
               Example Papers: [(647, 'Red Teaming Language Models for Processing Contradictory Dialogues'), (963, 'Inductive-Deductive Strategy Reuse for Multi-Turn Instructional Dialogues'), (978, 'MP2D: An Automated Topic Shift Dialogue Generation Framework Leveraging Knowledge Graphs')]
               ----------------------------------------
               Label: evaluation_of_dialogue_systems
               Dimension: tasks
               Description: This subtopic focuses on assessing the performance and effectiveness of dialogue systems through various evaluation metrics and methodologies.
               Level: 3
               # of Papers: 23
               Example Papers: [(48, 'Overcome Noise and Bias: Segmentation-Aided Multi-Granularity Denoising and Debiasing for Enhanced Quarduples Extraction in Dialogue'), (307, 'An LLM Feature-based Framework for Dialogue Constructiveness Assessment'), (409, 'Incomplete Utterance Rewriting with Editing Operation Guidance and Utterance Augmentation')]
               ----------------------------------------
          ----------------------------------------
          Label: visual_question_answering
          Dimension: tasks
          Description: This cluster involves methods that enable models to answer questions based on visual inputs, integrating image understanding with natural language processing.
          Level: 2
          # of Papers: 107
          Example Papers: [(5, 'ImageInWords: Unlocking Hyper-Detailed Image Descriptions'), (87, 'Exploring Union and Intersection of Visual Regions for Generating Questions, Answers, and Distractors'), (90, 'MAR: Matching-Augmented Reasoning for Enhancing Visual-based Entity Question Answering')]
          ----------------------------------------
          Children:
               Label: image_understanding
               Dimension: tasks
               Description: This cluster focuses on methods that enhance the understanding of images to facilitate answering questions related to visual content.
               Level: 3
               # of Papers: 21
               Example Papers: [(5, 'ImageInWords: Unlocking Hyper-Detailed Image Descriptions'), (87, 'Exploring Union and Intersection of Visual Regions for Generating Questions, Answers, and Distractors'), (158, 'Does Object Grounding Really Reduce Hallucination of Large Vision-Language Models?')]
               ----------------------------------------
               Label: visual_reasoning
               Dimension: tasks
               Description: This cluster encompasses techniques that involve reasoning about visual information to derive answers to questions posed in natural language.
               Level: 3
               # of Papers: 43
               Example Papers: [(87, 'Exploring Union and Intersection of Visual Regions for Generating Questions, Answers, and Distractors'), (90, 'MAR: Matching-Augmented Reasoning for Enhancing Visual-based Entity Question Answering'), (193, 'Pixology: Probing the Linguistic and Visual Capabilities of Pixel-based Language Models')]
               ----------------------------------------
               Label: video_question_answering
               Dimension: tasks
               Description: This cluster includes approaches that enable models to answer questions based on video inputs, integrating temporal dynamics with visual understanding.
               Level: 3
               # of Papers: 16
               Example Papers: [(226, 'Empowering Large Language Model for Continual Video Question Answering with Collaborative Prompting'), (399, 'Encoding and Controlling Global Semantics for Long-form Video Question Answering'), (543, 'TraveLER: A Modular Multi-LMM Agent Framework for Video Question-Answering')]
               ----------------------------------------
               Label: multimodal_question_answering
               Dimension: tasks
               Description: This cluster involves methods that combine information from multiple modalities, such as text and images, to answer questions effectively.
               Level: 3
               # of Papers: 69
               Example Papers: [(87, 'Exploring Union and Intersection of Visual Regions for Generating Questions, Answers, and Distractors'), (90, 'MAR: Matching-Augmented Reasoning for Enhancing Visual-based Entity Question Answering'), (109, 'Self-Bootstrapped Visual-Language Model for Knowledge Selection and Question Answering')]
               ----------------------------------------
               Label: medical_visual_question_answering
               Dimension: tasks
               Description: This cluster specializes in visual question answering techniques applied in medical contexts, focusing on interpreting medical images and related queries.
               Level: 3
               # of Papers: 5
               Example Papers: [(417, 'Towards Injecting Medical Visual Knowledge into Multimodal LLMs at Scale'), (872, 'ERVQA: A Dataset to Benchmark the Readiness of Large Vision Language Models in Hospital Environments'), (961, 'MedCoT: Medical Chain of Thought via Hierarchical Expert')]
               ----------------------------------------
          ----------------------------------------
          Label: multilingual_question_answering
          Dimension: tasks
          Description: This cluster addresses the challenges of answering questions in multiple languages, ensuring accessibility and usability across diverse linguistic backgrounds.
          Level: 2
          # of Papers: 59
          Example Papers: [(146, 'Seemingly Plausible Distractors in Multi-Hop Reasoning: Are Large Language Models Attentive Readers?'), (160, 'MoDULA: Mixture of Domain-Specific and Universal LoRA for Multi-Task Learning'), (185, 'Cross-lingual Transfer for Automatic Question Generation by Learning Interrogative Structures in Target Languages')]
          ----------------------------------------
          Children:
               Label: evaluation_and_performance
               Dimension: tasks
               Description: This cluster focuses on the evaluation methodologies and performance metrics for multilingual question answering systems, including language model evaluation and assessing model performance across diverse languages.
               Level: 3
               # of Papers: 14
               Example Papers: [(146, 'Seemingly Plausible Distractors in Multi-Hop Reasoning: Are Large Language Models Attentive Readers?'), (160, 'MoDULA: Mixture of Domain-Specific and Universal LoRA for Multi-Task Learning'), (321, 'Leave No Document Behind: Benchmarking Long-Context LLMs with Extended Multi-Doc QA')]
               ----------------------------------------
               Label: dataset_and_resource_development
               Dimension: tasks
               Description: This cluster encompasses the creation and utilization of datasets and resources specifically designed for multilingual question answering, including dataset generation and language resources for low-resource languages.
               Level: 3
               # of Papers: 42
               Example Papers: [(160, 'MoDULA: Mixture of Domain-Specific and Universal LoRA for Multi-Task Learning'), (185, 'Cross-lingual Transfer for Automatic Question Generation by Learning Interrogative Structures in Target Languages'), (235, 'When Is Multilinguality a Curse? Language Modeling for 250 High- and Low-Resource Languages')]
               ----------------------------------------
               Label: cross_lingual_and_transfer_learning
               Dimension: tasks
               Description: This cluster addresses techniques and methodologies related to cross-lingual transfer learning and adaptation, facilitating the application of models across different languages and domains.
               Level: 3
               # of Papers: 29
               Example Papers: [(160, 'MoDULA: Mixture of Domain-Specific and Universal LoRA for Multi-Task Learning'), (185, 'Cross-lingual Transfer for Automatic Question Generation by Learning Interrogative Structures in Target Languages'), (235, 'When Is Multilinguality a Curse? Language Modeling for 250 High- and Low-Resource Languages')]
               ----------------------------------------
               Label: multilingual_reasoning_and_understanding
               Dimension: tasks
               Description: This cluster explores advanced reasoning techniques and understanding mechanisms in multilingual contexts, including multilingual reasoning distillation and multistep reasoning.
               Level: 3
               # of Papers: 19
               Example Papers: [(146, 'Seemingly Plausible Distractors in Multi-Hop Reasoning: Are Large Language Models Attentive Readers?'), (160, 'MoDULA: Mixture of Domain-Specific and Universal LoRA for Multi-Task Learning'), (238, 'Teaching LLMs to Abstain across Languages via Multilingual Feedback')]
               ----------------------------------------
               Label: interactive_and_collaborative_learning
               Dimension: tasks
               Description: This cluster investigates interactive and collaborative learning approaches in multilingual question answering, focusing on methods like cloud-local collaborative learning and interactive learning strategies.
               Level: 3
               # of Papers: 5
               Example Papers: [(160, 'MoDULA: Mixture of Domain-Specific and Universal LoRA for Multi-Task Learning'), (457, 'AdaSwitch: Adaptive Switching between Small and Large Agents for Effective Cloud-Local Collaborative Learning'), (504, 'AssistantBench: Can Web Agents Solve Realistic and Time-Consuming Tasks?')]
               ----------------------------------------
          ----------------------------------------
          Label: explanation_generation
          Dimension: tasks
          Description: This cluster focuses on generating explanations for answers provided by question answering systems, enhancing transparency and user understanding.
          Level: 2
          # of Papers: 91
          Example Papers: [(19, 'Learning Planning-based Reasoning by Trajectories Collection and Process Reward Synthesizing'), (124, 'Advancing Process Verification for Large Language Models via Tree-Based Preference Learning'), (127, 'LogicAsker: Evaluating and Improving the Logical Reasoning Ability of Large Language Models')]
          ----------------------------------------
          Children:
               Label: explanation_generation_for_qa
               Dimension: tasks
               Description: This cluster focuses on generating explanations specifically tailored for answers provided by question answering systems, enhancing the clarity and understanding of the responses.
               Level: 3
               # of Papers: 56
               Example Papers: [(124, 'Advancing Process Verification for Large Language Models via Tree-Based Preference Learning'), (167, 'KB-Plugin: A Plug-and-play Framework for Large Language Models to Induce Programs over Low-resourced Knowledge Bases'), (204, 'CoTKR: Chain-of-Thought Enhanced Knowledge Rewriting for Complex Knowledge Graph Question Answering')]
               ----------------------------------------
               Label: evaluation_of_explanations
               Dimension: tasks
               Description: This cluster encompasses methods and approaches for evaluating the quality and effectiveness of generated explanations in various contexts.
               Level: 3
               # of Papers: 17
               Example Papers: [(124, 'Advancing Process Verification for Large Language Models via Tree-Based Preference Learning'), (127, 'LogicAsker: Evaluating and Improving the Logical Reasoning Ability of Large Language Models'), (171, 'Verification and Refinement of Natural Language Explanations through LLM-Symbolic Theorem Proving')]
               ----------------------------------------
               Label: knowledge_attribution
               Dimension: tasks
               Description: This cluster deals with the processes of attributing knowledge sources to generated explanations, ensuring that the reasoning behind answers is transparent and traceable.
               Level: 3
               # of Papers: 9
               Example Papers: [(190, 'Neuron-Level Knowledge Attribution in Large Language Models'), (346, 'Model Internals-based Answer Attribution for Trustworthy Retrieval-Augmented Generation'), (431, 'XplainLLM: A Knowledge-Augmented Dataset for Reliable Grounded Explanations in LLMs')]
               ----------------------------------------
               Label: generating_explanations_for_reasoning_processes
               Dimension: tasks
               Description: This cluster focuses on creating explanations that elucidate the reasoning processes behind decisions made by AI systems, enhancing interpretability.
               Level: 3
               # of Papers: 31
               Example Papers: [(19, 'Learning Planning-based Reasoning by Trajectories Collection and Process Reward Synthesizing'), (124, 'Advancing Process Verification for Large Language Models via Tree-Based Preference Learning'), (127, 'LogicAsker: Evaluating and Improving the Logical Reasoning Ability of Large Language Models')]
               ----------------------------------------
               Label: explanation_generation_for_specialized_domains
               Dimension: tasks
               Description: This cluster targets the generation of explanations within specialized domains, such as healthcare or legal contexts, ensuring that the explanations are relevant and contextually appropriate.
               Level: 3
               # of Papers: 42
               Example Papers: [(167, 'KB-Plugin: A Plug-and-play Framework for Large Language Models to Induce Programs over Low-resourced Knowledge Bases'), (171, 'Verification and Refinement of Natural Language Explanations through LLM-Symbolic Theorem Proving'), (279, 'An Unsupervised Approach to Achieve Supervised-Level Explainability in Healthcare Records')]
               ----------------------------------------
          ----------------------------------------
          Label: in_context_question_answering
          Dimension: tasks
          Description: This cluster focuses on techniques that leverage contextual information to enhance the accuracy and relevance of answers in question answering tasks.
          Level: 2
          # of Papers: 465
          Example Papers: [(13, 'A Usage-centric Take on Intent Understanding in E-Commerce'), (14, 'Fine-Tuning or Retrieval? Comparing Knowledge Injection in LLMs'), (15, 'Systematic Biases in LLM Simulations of Debates')]
          ----------------------------------------
          Children:
               Label: contextual_learning_techniques
               Dimension: tasks
               Description: This cluster focuses on various learning techniques that utilize contextual information to improve the performance of question answering systems, including in-context learning, few-shot learning, and multi-task learning.
               Level: 3
               # of Papers: 76
               Example Papers: [(50, 'In-context Contrastive Learning for Event Causality Identification'), (63, 'A Survey on In-context Learning'), (101, 'MetaGPT: Merging Large Language Models Using Model Exclusive Task Arithmetic')]
               ----------------------------------------
               Label: enhanced_reasoning_methods
               Dimension: tasks
               Description: This cluster encompasses methods aimed at enhancing reasoning capabilities in question answering, such as multi-step reasoning, causal reasoning, and complex reasoning approaches.
               Level: 3
               # of Papers: 101
               Example Papers: [(19, 'Learning Planning-based Reasoning by Trajectories Collection and Process Reward Synthesizing'), (47, 'Making Large Language Models Better Reasoners with Orchestrated Streaming Experiences'), (50, 'In-context Contrastive Learning for Event Causality Identification')]
               ----------------------------------------
               Label: knowledge_utilization_strategies
               Dimension: tasks
               Description: This cluster highlights strategies for effectively utilizing knowledge in question answering tasks, including knowledge distillation, knowledge injection, and knowledge graph reasoning.
               Level: 3
               # of Papers: 128
               Example Papers: [(13, 'A Usage-centric Take on Intent Understanding in E-Commerce'), (14, 'Fine-Tuning or Retrieval? Comparing Knowledge Injection in LLMs'), (42, 'Parameter-Efficient Sparsity Crafting from Dense to Mixture-of-Experts for Instruction Tuning on General Tasks')]
               ----------------------------------------
               Label: evaluation_and_improvement_approaches
               Dimension: tasks
               Description: This cluster focuses on approaches for evaluating and improving the performance of question answering systems, including confidence calibration, evaluating language models, and assessing answer reliability.
               Level: 3
               # of Papers: 220
               Example Papers: [(15, 'Systematic Biases in LLM Simulations of Debates'), (17, 'Uncertainty in Language Models: Assessment through Rank-Calibration'), (39, 'Tokenization Is More Than Compression')]
               ----------------------------------------
               Label: contextual_information_integration
               Dimension: tasks
               Description: This cluster emphasizes techniques for integrating contextual information into question answering processes, such as leveraging contextual information, contextual reasoning, and contextualized question representation.
               Level: 3
               # of Papers: 110
               Example Papers: [(15, 'Systematic Biases in LLM Simulations of Debates'), (52, 'Language Models Learn Rare Phenomena from Less Rare Phenomena: The Case of the Missing AANNs'), (75, 'QUDSELECT: Selective Decoding for Questions Under Discussion Parsing')]
               ----------------------------------------
          ----------------------------------------
          Label: commonsense_question_answering
          Dimension: tasks
          Description: This cluster addresses the challenges of answering questions that require commonsense reasoning and understanding of everyday knowledge.
          Level: 2
          # of Papers: 66
          Example Papers: [(15, 'Systematic Biases in LLM Simulations of Debates'), (47, 'Making Large Language Models Better Reasoners with Orchestrated Streaming Experiences'), (138, 'Self-Refine Instruction-Tuning for Aligning Reasoning in Language Models')]
          ----------------------------------------
          Children:
               Label: reasoning_evaluation
               Dimension: tasks
               Description: This cluster focuses on evaluating the reasoning abilities of models, including their performance in logical, abstract, and causal reasoning tasks.
               Level: 3
               # of Papers: 29
               Example Papers: [(138, 'Self-Refine Instruction-Tuning for Aligning Reasoning in Language Models'), (139, 'In Search of the Long-Tail: Systematic Generation of Long-Tail Inferential Knowledge via Logical Rule Guided Search'), (312, 'Adaption-of-Thought: Learning Question Difficulty Improves Large Language Models for Reasoning')]
               ----------------------------------------
               Label: knowledge_utilization
               Dimension: tasks
               Description: This cluster addresses how models utilize knowledge, including knowledge representation, integration, and the ability to leverage external knowledge sources in commonsense reasoning.
               Level: 3
               # of Papers: 35
               Example Papers: [(47, 'Making Large Language Models Better Reasoners with Orchestrated Streaming Experiences'), (155, 'To Word Senses and Beyond: Inducing Concepts with Contextualized Language Models'), (166, 'With Ears to See and Eyes to Hear: Sound Symbolism Experiments with Multimodal Large Language Models')]
               ----------------------------------------
               Label: improving_reasoning_ability
               Dimension: tasks
               Description: This cluster encompasses methods and strategies aimed at enhancing the reasoning capabilities of language models, including techniques for controllability and reliability.
               Level: 3
               # of Papers: 33
               Example Papers: [(47, 'Making Large Language Models Better Reasoners with Orchestrated Streaming Experiences'), (138, 'Self-Refine Instruction-Tuning for Aligning Reasoning in Language Models'), (155, 'To Word Senses and Beyond: Inducing Concepts with Contextualized Language Models')]
               ----------------------------------------
               Label: social_and_cultural_reasoning
               Dimension: tasks
               Description: This cluster explores reasoning tasks that involve social prediction and culturally aware language models, focusing on how models understand and generate socially relevant responses.
               Level: 3
               # of Papers: 4
               Example Papers: [(15, 'Systematic Biases in LLM Simulations of Debates'), (1144, 'Can LLM Generate Culturally Relevant Commonsense QA Data? Case Study in Indonesian and Sundanese'), (1599, 'Are Large Language Models (LLMs) Good Social Predictors?')]
               ----------------------------------------
               Label: evaluation_and_debugging
               Dimension: tasks
               Description: This cluster is dedicated to the evaluation and debugging of commonsense reasoning models, including stress testing and long-tail evaluation to ensure robustness and reliability.
               Level: 3
               # of Papers: 22
               Example Papers: [(15, 'Systematic Biases in LLM Simulations of Debates'), (377, 'Right for Right Reasons: Large Language Models for Verifiable Commonsense Knowledge Graph Question Answering'), (378, 'Verifiable, Debuggable, and Repairable Commonsense Logical Reasoning via LLM-based Theory Resolution')]
               ----------------------------------------
          ----------------------------------------
          Label: temporal_relation_question_answering
          Dimension: tasks
          Description: This cluster involves methods for answering questions that pertain to temporal relationships and events, emphasizing the understanding of time in context.
          Level: 2
          # of Papers: 18
          Example Papers: [(360, 'GAMA: A Large Audio-Language Model with Advanced Audio Understanding and Complex Reasoning Abilities'), (393, 'TimeR^4 : Time-aware Retrieval-Augmented Large Language Models for Temporal Knowledge Graph Question Answering'), (555, 'Efficient Temporal Extrapolation of Multimodal Large Language Models with Temporal Grounding Bridge')]
          ----------------------------------------
          Label: free_form_question_answering
          Dimension: tasks
          Description: This cluster encompasses approaches that allow for open-ended and flexible question answering, accommodating a wide range of question formats and types.
          Level: 2
          # of Papers: 36
          Example Papers: [(345, 'Boosting Scientific Concepts Understanding: Can Analogy from Teacher Models Empower Student Models?'), (360, 'GAMA: A Large Audio-Language Model with Advanced Audio Understanding and Complex Reasoning Abilities'), (483, 'Explaining and Improving Contrastive Decoding by Extrapolating the Probabilities of a Huge and Hypothetical LM')]
          ----------------------------------------
          Label: legal_question_answering
          Dimension: tasks
          Description: This cluster specializes in techniques for answering questions related to legal contexts, focusing on the interpretation and application of legal knowledge.
          Level: 2
          # of Papers: 20
          Example Papers: [(843, 'CopyBench: Measuring Literal and Non-Literal Reproduction of Copyright-Protected Text in Language Model Generation'), (1640, 'Divide and Conquer: Legal Concept-guided Criminal Court View Generation'), (1734, 'CultureBank: An Online Community-Driven Knowledge Base Towards Culturally Aware Language Technologies')]
          ----------------------------------------
     ----------------------------------------
     Label: bias_detection
     Dimension: tasks
     Description: The process of identifying and mitigating biases in data and algorithms to ensure fairness and accuracy.
     Level: 1
     # of Papers: 484
     Example Papers: [(5, 'ImageInWords: Unlocking Hyper-Detailed Image Descriptions'), (12, '"Thinking" Fair and Slow: On the Efficacy of Structured Prompts for Debiasing Language Models'), (13, 'A Usage-centric Take on Intent Understanding in E-Commerce')]
     ----------------------------------------
     Children:
          Label: algorithmic_bias
          Dimension: tasks
          Description: The study and identification of biases that arise from algorithms, focusing on how these biases can affect decision-making processes and outcomes.
          Level: 2
          # of Papers: 1
          Example Papers: [(1691, 'A Robust Dual-debiasing VQA Model based on Counterfactual Causal Effect')]
          ----------------------------------------
          Label: bias_in_language_models
          Dimension: tasks
          Description: The examination of biases present in language models, including how these biases manifest in generated text and their implications for fairness.
          Level: 2
          # of Papers: 274
          Example Papers: [(12, '"Thinking" Fair and Slow: On the Efficacy of Structured Prompts for Debiasing Language Models'), (15, 'Systematic Biases in LLM Simulations of Debates'), (17, 'Uncertainty in Language Models: Assessment through Rank-Calibration')]
          ----------------------------------------
          Children:
               Label: bias_manifestation
               Dimension: tasks
               Description: This cluster focuses on the various ways biases manifest in language models, particularly in the generated text, and includes studies on bias manifestation in generated outputs.
               Level: 3
               # of Papers: 92
               Example Papers: [(15, 'Systematic Biases in LLM Simulations of Debates'), (33, 'A Study of Nationality Bias in Names and Perplexity using Off-the-Shelf Affect-related Tweet Classifiers'), (40, 'FLIRT: Feedback Loop In-context Red Teaming')]
               ----------------------------------------
               Label: bias_implications
               Dimension: tasks
               Description: This cluster examines the implications of biases present in language models, including their impact on fairness and societal consequences.
               Level: 3
               # of Papers: 45
               Example Papers: [(15, 'Systematic Biases in LLM Simulations of Debates'), (227, 'Dissecting Fine-Tuning Unlearning in Large Language Models'), (235, 'When Is Multilinguality a Curse? Language Modeling for 250 High- and Low-Resource Languages')]
               ----------------------------------------
               Label: debiasing_methods
               Dimension: tasks
               Description: This cluster encompasses various methods and techniques aimed at reducing or mitigating biases in language models, including approaches to debiasing and calibration.
               Level: 3
               # of Papers: 100
               Example Papers: [(12, '"Thinking" Fair and Slow: On the Efficacy of Structured Prompts for Debiasing Language Models'), (59, 'Eliminating Biased Length Reliance of Direct Preference Optimization via Down-Sampled KL Divergence'), (67, 'Rethinking Pruning Large Language Models: Benefits and Pitfalls of Reconstruction Error Minimization')]
               ----------------------------------------
               Label: evaluation_of_bias
               Dimension: tasks
               Description: This cluster is dedicated to the assessment and evaluation of biases in language models, focusing on methodologies for measuring and analyzing bias levels.
               Level: 3
               # of Papers: 95
               Example Papers: [(38, 'CoCoLoFa: A Dataset of News Comments with Common Logical Fallacies Written by LLM-Assisted Crowds'), (193, 'Pixology: Probing the Linguistic and Visual Capabilities of Pixel-based Language Models'), (235, 'When Is Multilinguality a Curse? Language Modeling for 250 High- and Low-Resource Languages')]
               ----------------------------------------
               Label: specific_bias_types
               Dimension: tasks
               Description: This cluster investigates specific types of biases, such as gender, cultural, and political biases, within language models and their effects on generated content.
               Level: 3
               # of Papers: 79
               Example Papers: [(15, 'Systematic Biases in LLM Simulations of Debates'), (28, 'On the Influence of Gender and Race in Romantic Relationship Prediction from Large Language Models'), (52, 'Language Models Learn Rare Phenomena from Less Rare Phenomena: The Case of the Missing AANNs')]
               ----------------------------------------
          ----------------------------------------
          Label: fairness_in_data
          Dimension: tasks
          Description: The assessment of data quality and representation to ensure that datasets used in machine learning are fair and do not propagate existing biases.
          Level: 2
          # of Papers: 22
          Example Papers: [(186, 'ScalingFilter: Assessing Data Quality through Inverse Utilization of Scaling Laws'), (235, 'When Is Multilinguality a Curse? Language Modeling for 250 High- and Low-Resource Languages'), (383, 'Locating Information Gaps and Narrative Inconsistencies Across Languages: A Case Study of LGBT People Portrayals on Wikipedia')]
          ----------------------------------------
          Label: bias_mitigation
          Dimension: tasks
          Description: The development and implementation of strategies aimed at reducing or eliminating biases in data and algorithms to promote fairness.
          Level: 2
          # of Papers: 354
          Example Papers: [(12, '"Thinking" Fair and Slow: On the Efficacy of Structured Prompts for Debiasing Language Models'), (15, 'Systematic Biases in LLM Simulations of Debates'), (16, 'Studying and Mitigating Biases in Sign Language Understanding Models')]
          ----------------------------------------
          Children:
               Label: bias_reduction
               Dimension: tasks
               Description: Strategies and methods focused on reducing the presence and impact of biases in algorithms and datasets.
               Level: 3
               # of Papers: 220
               Example Papers: [(16, 'Studying and Mitigating Biases in Sign Language Understanding Models'), (21, '"We Demand Justice!": Towards Social Context Grounding of Political Texts'), (30, 'On Fake News Detection with LLM Enhanced Semantics Mining')]
               ----------------------------------------
               Label: debiasing
               Dimension: tasks
               Description: Techniques aimed at correcting or removing biases from models and their outputs to ensure fairness.
               Level: 3
               # of Papers: 70
               Example Papers: [(12, '"Thinking" Fair and Slow: On the Efficacy of Structured Prompts for Debiasing Language Models'), (21, '"We Demand Justice!": Towards Social Context Grounding of Political Texts'), (48, 'Overcome Noise and Bias: Segmentation-Aided Multi-Granularity Denoising and Debiasing for Enhanced Quarduples Extraction in Dialogue')]
               ----------------------------------------
               Label: data_preprocessing
               Dimension: tasks
               Description: Methods applied to data before model training to identify and mitigate biases inherent in the dataset.
               Level: 3
               # of Papers: 49
               Example Papers: [(16, 'Studying and Mitigating Biases in Sign Language Understanding Models'), (39, 'Tokenization Is More Than Compression'), (59, 'Eliminating Biased Length Reliance of Direct Preference Optimization via Down-Sampled KL Divergence')]
               ----------------------------------------
               Label: bias_evaluation
               Dimension: tasks
               Description: Assessment techniques used to measure and analyze the extent of bias present in algorithms and their predictions.
               Level: 3
               # of Papers: 189
               Example Papers: [(15, 'Systematic Biases in LLM Simulations of Debates'), (16, 'Studying and Mitigating Biases in Sign Language Understanding Models'), (33, 'A Study of Nationality Bias in Names and Perplexity using Off-the-Shelf Affect-related Tweet Classifiers')]
               ----------------------------------------
               Label: bias_quantification
               Dimension: tasks
               Description: Approaches for quantifying the level of bias in data and algorithms to facilitate targeted mitigation efforts.
               Level: 3
               # of Papers: 222
               Example Papers: [(15, 'Systematic Biases in LLM Simulations of Debates'), (30, 'On Fake News Detection with LLM Enhanced Semantics Mining'), (33, 'A Study of Nationality Bias in Names and Perplexity using Off-the-Shelf Affect-related Tweet Classifiers')]
               ----------------------------------------
          ----------------------------------------
          Label: fairness_evaluation
          Dimension: tasks
          Description: The process of evaluating the fairness of algorithms and models, ensuring that they perform equitably across different demographic groups.
          Level: 2
          # of Papers: 113
          Example Papers: [(12, '"Thinking" Fair and Slow: On the Efficacy of Structured Prompts for Debiasing Language Models'), (21, '"We Demand Justice!": Towards Social Context Grounding of Political Texts'), (30, 'On Fake News Detection with LLM Enhanced Semantics Mining')]
          ----------------------------------------
          Children:
               Label: evaluation_methods
               Dimension: tasks
               Description: This subtopic focuses on various methodologies and approaches used to assess the fairness of algorithms and models across different demographic groups.
               Level: 3
               # of Papers: 40
               Example Papers: [(225, 'PRompt Optimization in Multi-Step Tasks (PROMST): Integrating Human Feedback and Heuristic-based Sampling'), (242, 'STOP! Benchmarking Large Language Models with Sensitivity Testing on Offensive Progressions'), (258, 'Leveraging Conflicts in Social Media Posts: Unintended Offense Dataset')]
               ----------------------------------------
               Label: bias_amplification
               Dimension: tasks
               Description: This subtopic examines the phenomenon where algorithms exacerbate existing biases in data, leading to unfair outcomes for certain demographic groups.
               Level: 3
               # of Papers: 20
               Example Papers: [(242, 'STOP! Benchmarking Large Language Models with Sensitivity Testing on Offensive Progressions'), (407, 'Python is Not Always the Best Choice: Embracing Multilingual Program of Thoughts'), (493, '"Flex Tape Can\'t Fix That": Bias and Misinformation in Edited Language Models')]
               ----------------------------------------
               Label: algorithmic_fairness_evaluation
               Dimension: tasks
               Description: This subtopic involves the assessment of algorithms specifically designed to ensure fairness in their decision-making processes.
               Level: 3
               # of Papers: 64
               Example Papers: [(12, '"Thinking" Fair and Slow: On the Efficacy of Structured Prompts for Debiasing Language Models'), (21, '"We Demand Justice!": Towards Social Context Grounding of Political Texts'), (30, 'On Fake News Detection with LLM Enhanced Semantics Mining')]
               ----------------------------------------
               Label: bias_evaluation_metrics
               Dimension: tasks
               Description: This subtopic covers the metrics and criteria used to quantitatively measure bias in algorithms and models.
               Level: 3
               # of Papers: 35
               Example Papers: [(48, 'Overcome Noise and Bias: Segmentation-Aided Multi-Granularity Denoising and Debiasing for Enhanced Quarduples Extraction in Dialogue'), (71, 'Fairer Preferences Elicit Improved Human-Aligned Large Language Model Judgments'), (194, 'GoldCoin: Grounding Large Language Models in Privacy Laws via Contextual Integrity Theory')]
               ----------------------------------------
               Label: algorithmic_bias_evaluation
               Dimension: tasks
               Description: This subtopic focuses on the evaluation of biases inherent in algorithms, assessing their impact on fairness and equity.
               Level: 3
               # of Papers: 14
               Example Papers: [(242, 'STOP! Benchmarking Large Language Models with Sensitivity Testing on Offensive Progressions'), (342, 'SaySelf: Teaching LLMs to Express Confidence with Self-Reflective Rationales'), (678, 'Do LLMs Overcome Shortcut Learning? An Evaluation of Shortcut Challenges in Large Language Models')]
               ----------------------------------------
          ----------------------------------------
     ----------------------------------------
     Label: fact_checking
     Dimension: tasks
     Description: The task of verifying the factual accuracy of statements or claims made in various contexts.
     Level: 1
     # of Papers: 477
     Example Papers: [(2, 'FIZZ: Factual Inconsistency Detection by Zoom-in Summary and Zoom-out Document'), (5, 'ImageInWords: Unlocking Hyper-Detailed Image Descriptions'), (13, 'A Usage-centric Take on Intent Understanding in E-Commerce')]
     ----------------------------------------
     Children:
          Label: automated_fact_checking
          Dimension: tasks
          Description: This cluster focuses on the development and application of automated systems and algorithms designed to verify the accuracy of claims and statements without human intervention.
          Level: 2
          # of Papers: 167
          Example Papers: [(2, 'FIZZ: Factual Inconsistency Detection by Zoom-in Summary and Zoom-out Document'), (61, 'RULE: Reliable Multimodal RAG for Factuality in Medical Vision Language Models'), (102, 'Event Causality Identification with Synthetic Control')]
          ----------------------------------------
          Children:
               Label: fact_verification
               Dimension: tasks
               Description: This cluster focuses on the methodologies and algorithms specifically designed for verifying the truthfulness of claims and statements.
               Level: 3
               # of Papers: 48
               Example Papers: [(151, 'Knowledge Verification to Nip Hallucination in the Bud'), (378, 'Verifiable, Debuggable, and Repairable Commonsense Logical Reasoning via LLM-based Theory Resolution'), (383, 'Locating Information Gaps and Narrative Inconsistencies Across Languages: A Case Study of LGBT People Portrayals on Wikipedia')]
               ----------------------------------------
               Label: fact_checking_techniques
               Dimension: tasks
               Description: This cluster encompasses various techniques employed in the automated fact-checking process to assess the validity of information.
               Level: 3
               # of Papers: 116
               Example Papers: [(61, 'RULE: Reliable Multimodal RAG for Factuality in Medical Vision Language Models'), (102, 'Event Causality Identification with Synthetic Control'), (112, 'Do We Need Language-Specific Fact-Checking Models? The Case of Chinese')]
               ----------------------------------------
               Label: factuality_assessment
               Dimension: tasks
               Description: This cluster is dedicated to evaluating the factual accuracy of statements and claims using automated systems.
               Level: 3
               # of Papers: 106
               Example Papers: [(2, 'FIZZ: Factual Inconsistency Detection by Zoom-in Summary and Zoom-out Document'), (61, 'RULE: Reliable Multimodal RAG for Factuality in Medical Vision Language Models'), (112, 'Do We Need Language-Specific Fact-Checking Models? The Case of Chinese')]
               ----------------------------------------
               Label: fact_checking_systems
               Dimension: tasks
               Description: This cluster involves the development and implementation of comprehensive systems that automate the fact-checking process.
               Level: 3
               # of Papers: 96
               Example Papers: [(2, 'FIZZ: Factual Inconsistency Detection by Zoom-in Summary and Zoom-out Document'), (112, 'Do We Need Language-Specific Fact-Checking Models? The Case of Chinese'), (151, 'Knowledge Verification to Nip Hallucination in the Bud')]
               ----------------------------------------
               Label: explainable_fact_checking
               Dimension: tasks
               Description: This cluster emphasizes the creation of transparent and interpretable automated fact-checking methods that provide understandable justifications for their conclusions.
               Level: 3
               # of Papers: 47
               Example Papers: [(2, 'FIZZ: Factual Inconsistency Detection by Zoom-in Summary and Zoom-out Document'), (102, 'Event Causality Identification with Synthetic Control'), (281, 'EVEDIT: Event-based Knowledge Editing for Deterministic Knowledge Propagation')]
               ----------------------------------------
          ----------------------------------------
          Label: claim_verification
          Dimension: tasks
          Description: This cluster encompasses methods and techniques specifically aimed at verifying the truthfulness of individual claims made in various contexts.
          Level: 2
          # of Papers: 69
          Example Papers: [(255, 'Deciphering Rumors: A Multi-Task Learning Approach with Intent-aware Hierarchical Contrastive Learning'), (377, 'Right for Right Reasons: Large Language Models for Verifiable Commonsense Knowledge Graph Question Answering'), (378, 'Verifiable, Debuggable, and Repairable Commonsense Logical Reasoning via LLM-based Theory Resolution')]
          ----------------------------------------
          Children:
               Label: verification_techniques
               Dimension: tasks
               Description: This cluster encompasses various methods and techniques specifically designed for the verification of claims, including automated and manual approaches.
               Level: 3
               # of Papers: 57
               Example Papers: [(255, 'Deciphering Rumors: A Multi-Task Learning Approach with Intent-aware Hierarchical Contrastive Learning'), (377, 'Right for Right Reasons: Large Language Models for Verifiable Commonsense Knowledge Graph Question Answering'), (378, 'Verifiable, Debuggable, and Repairable Commonsense Logical Reasoning via LLM-based Theory Resolution')]
               ----------------------------------------
               Label: evidence_verification
               Dimension: tasks
               Description: This cluster focuses on the assessment and validation of evidence presented in support of claims, ensuring its reliability and relevance.
               Level: 3
               # of Papers: 16
               Example Papers: [(255, 'Deciphering Rumors: A Multi-Task Learning Approach with Intent-aware Hierarchical Contrastive Learning'), (469, 'Pelican: Correcting Hallucination in Vision-LLMs via Claim Decomposition and Program of Thought Verification'), (482, 'Perceptions of Linguistic Uncertainty by Language Models and Humans')]
               ----------------------------------------
               Label: explainable_verification
               Dimension: tasks
               Description: This cluster includes approaches that aim to provide transparent and understandable explanations for the verification process of claims.
               Level: 3
               # of Papers: 18
               Example Papers: [(255, 'Deciphering Rumors: A Multi-Task Learning Approach with Intent-aware Hierarchical Contrastive Learning'), (469, 'Pelican: Correcting Hallucination in Vision-LLMs via Claim Decomposition and Program of Thought Verification'), (482, 'Perceptions of Linguistic Uncertainty by Language Models and Humans')]
               ----------------------------------------
               Label: fact_checking_methods
               Dimension: tasks
               Description: This cluster covers diverse methodologies employed in the fact-checking process, including both traditional and innovative techniques.
               Level: 3
               # of Papers: 51
               Example Papers: [(255, 'Deciphering Rumors: A Multi-Task Learning Approach with Intent-aware Hierarchical Contrastive Learning'), (377, 'Right for Right Reasons: Large Language Models for Verifiable Commonsense Knowledge Graph Question Answering'), (411, 'Aligning Large Language Models with Diverse Political Viewpoints')]
               ----------------------------------------
               Label: evaluation_metrics
          ----------------------------------------
          Label: misinformation_detection
          Dimension: tasks
          Description: This cluster is dedicated to identifying and analyzing false or misleading information across different media and platforms.
          Level: 2
          # of Papers: 125
          Example Papers: [(30, 'On Fake News Detection with LLM Enhanced Semantics Mining'), (38, 'CoCoLoFa: A Dataset of News Comments with Common Logical Fallacies Written by LLM-Assisted Crowds'), (40, 'FLIRT: Feedback Loop In-context Red Teaming')]
          ----------------------------------------
          Children:
               Label: fake_news_detection
               Dimension: tasks
               Description: This subtopic focuses on identifying and analyzing false news articles and reports that spread misinformation across various media platforms.
               Level: 3
               # of Papers: 4
               Example Papers: [(30, 'On Fake News Detection with LLM Enhanced Semantics Mining'), (1907, 'Multilingual Fine-Grained News Headline Hallucination Detection'), (2563, 'RAG-Fusion Based Information Retrieval for Fact-Checking')]
               ----------------------------------------
               Label: rumor_detection
               Dimension: tasks
               Description: This subtopic is dedicated to detecting and analyzing unverified information or rumors that may contribute to the spread of misinformation.
               Level: 3
               # of Papers: 3
               Example Papers: [(255, 'Deciphering Rumors: A Multi-Task Learning Approach with Intent-aware Hierarchical Contrastive Learning'), (621, 'Integrating Argumentation and Hate-Speech-based Techniques for Countering Misinformation'), (2585, 'RAGAR, Your Falsehood Radar: RAG-Augmented Reasoning for Political Fact-Checking using Multimodal Large Language Models')]
               ----------------------------------------
               Label: propaganda_detection
               Dimension: tasks
               Description: This subtopic involves identifying and analyzing biased or misleading information intended to promote a particular political agenda or viewpoint.
               Level: 3
               # of Papers: 2
               Example Papers: [(1172, 'ArMeme: Propagandistic Content in Arabic Memes'), (2296, 'Large Language Models for Propaganda Span Annotation')]
               ----------------------------------------
               Label: toxicity_detection
               Dimension: tasks
               Description: This subtopic focuses on identifying harmful or toxic content that may contribute to misinformation and negatively impact public discourse.
               Level: 3
               # of Papers: 7
               Example Papers: [(114, 'CMD: a framework for Context-aware Model self-Detoxification'), (917, 'Intrinsic Self-correction for Enhanced Morality: An Analysis of Internal Mechanisms and the Superficial Hypothesis'), (1089, 'Adaptable Moral Stances of Large Language Models on Sexist Content: Implications for Society and Gender Discourse')]
               ----------------------------------------
               Label: visual_misinformation_detection
               Dimension: tasks
               Description: This subtopic is dedicated to detecting misleading or false information presented through visual media, including images and videos.
               Level: 3
               # of Papers: 9
               Example Papers: [(447, '"Image, Tell me your story!" Predicting the original meta-context of visual misinformation'), (454, 'Empowering Backbone Models for Visual Text Generation with Input Granularity Control and Glyph-Aware Training'), (512, 'The Factuality Tax of Diversity-Intervened Text-to-Image Generation: Benchmark and Fact-Augmented Intervention')]
               ----------------------------------------
               Label: adversarial_attack_detection
               Dimension: tasks
               Description: This subtopic focuses on identifying and mitigating adversarial attacks that aim to manipulate machine learning models and their outputs.
               Level: 3
               # of Papers: 10
               Example Papers: [(40, 'FLIRT: Feedback Loop In-context Red Teaming'), (95, 'Glue pizza and eat rocks - Exploiting Vulnerabilities in Retrieval-Augmented Generative Models'), (156, 'ASETF: A Novel Method for Jailbreak Attack on LLMs through Translate Suffix Embeddings')]
               ----------------------------------------
               Label: misinformation_spread_detection
               Dimension: tasks
               Description: This subtopic is dedicated to detecting and analyzing the mechanisms and patterns through which misinformation spreads across various platforms.
               Level: 3
               # of Papers: 74
               Example Papers: [(38, 'CoCoLoFa: A Dataset of News Comments with Common Logical Fallacies Written by LLM-Assisted Crowds'), (193, 'Pixology: Probing the Linguistic and Visual Capabilities of Pixel-based Language Models'), (246, 'An Analysis of Multilingual FActScore')]
               ----------------------------------------
               Label: privacy_violation_detection
               Dimension: tasks
               Description: This subtopic involves identifying instances of privacy violations that may arise from the misuse of personal data in the context of misinformation.
               Level: 3
               # of Papers: 6
               Example Papers: [(194, 'GoldCoin: Grounding Large Language Models in Privacy Laws via Contextual Integrity Theory'), (252, 'Order of Magnitude Speedups for LLM Membership Inference'), (323, 'Thinking Outside of the Differential Privacy Box: A Case Study in Text Privatization with Language Model Prompting')]
               ----------------------------------------
               Label: legal_misinformation_detection
               Dimension: tasks
               Description: This subtopic focuses on identifying and analyzing misinformation that pertains to legal matters and its implications on public understanding.
               Level: 3
               # of Papers: 7
               Example Papers: [(1089, 'Adaptable Moral Stances of Large Language Models on Sexist Content: Implications for Society and Gender Discourse'), (2370, 'Misinformation with Legal Consequences (MisLC): A New Task Towards Harnessing Societal Harm of Misinformation'), (2579, 'Improving Explainable Fact-Checking via Sentence-Level Factual Reasoning')]
               ----------------------------------------
               Label: health_advice_detection
               Dimension: tasks
               Description: This subtopic is dedicated to detecting misleading or false health advice that can contribute to the spread of misinformation in health-related contexts.
               Level: 3
               # of Papers: 5
               Example Papers: [(486, 'MisinfoEval: Generative AI in the Era of "Alternative Facts"'), (719, 'SPEED++: A Multilingual Event Extraction Framework for Epidemic Prediction and Preparedness'), (1089, 'Adaptable Moral Stances of Large Language Models on Sexist Content: Implications for Society and Gender Discourse')]
               ----------------------------------------
          ----------------------------------------
          Label: evidence_retrieval
          Dimension: tasks
          Description: This cluster involves techniques for efficiently retrieving relevant evidence and data to support or refute claims during the fact-checking process.
          Level: 2
          # of Papers: 118
          Example Papers: [(14, 'Fine-Tuning or Retrieval? Comparing Knowledge Injection in LLMs'), (30, 'On Fake News Detection with LLM Enhanced Semantics Mining'), (53, 'Large Language Models for Data Annotation and Synthesis: A Survey')]
          ----------------------------------------
          Children:
               Label: efficient_evidence_retrieval
               Dimension: tasks
               Description: This subtopic focuses on techniques and methodologies aimed at enhancing the efficiency of retrieving relevant evidence to support or refute claims in the fact-checking process.
               Level: 3
               # of Papers: 63
               Example Papers: [(14, 'Fine-Tuning or Retrieval? Comparing Knowledge Injection in LLMs'), (30, 'On Fake News Detection with LLM Enhanced Semantics Mining'), (112, 'Do We Need Language-Specific Fact-Checking Models? The Case of Chinese')]
               ----------------------------------------
               Label: reliable_evidence_retrieval
               Dimension: tasks
               Description: This cluster emphasizes the development of methods that ensure the retrieval of trustworthy and credible evidence during fact-checking activities.
               Level: 3
               # of Papers: 37
               Example Papers: [(14, 'Fine-Tuning or Retrieval? Comparing Knowledge Injection in LLMs'), (30, 'On Fake News Detection with LLM Enhanced Semantics Mining'), (61, 'RULE: Reliable Multimodal RAG for Factuality in Medical Vision Language Models')]
               ----------------------------------------
               Label: multi_hop_evidence_retrieval
               Dimension: tasks
               Description: This subtopic involves strategies for retrieving evidence that requires multiple reasoning steps or connections to substantiate claims effectively.
               Level: 3
               # of Papers: 26
               Example Papers: [(30, 'On Fake News Detection with LLM Enhanced Semantics Mining'), (281, 'EVEDIT: Event-based Knowledge Editing for Deterministic Knowledge Propagation'), (323, 'Thinking Outside of the Differential Privacy Box: A Case Study in Text Privatization with Language Model Prompting')]
               ----------------------------------------
               Label: claim_guided_evidence_retrieval
               Dimension: tasks
               Description: This area explores approaches that utilize specific claims to guide the retrieval of pertinent evidence, enhancing the relevance of the information gathered.
               Level: 3
               # of Papers: 29
               Example Papers: [(30, 'On Fake News Detection with LLM Enhanced Semantics Mining'), (254, 'F^2RL: Factuality and Faithfulness Reinforcement Learning Framework for Claim-Guided Evidence-Supported Counterspeech Generation'), (281, 'EVEDIT: Event-based Knowledge Editing for Deterministic Knowledge Propagation')]
               ----------------------------------------
               Label: structured_evidence_retrieval
               Dimension: tasks
               Description: This cluster focuses on the organization and retrieval of evidence in a structured manner, facilitating easier access and analysis during the fact-checking process.
               Level: 3
               # of Papers: 33
               Example Papers: [(30, 'On Fake News Detection with LLM Enhanced Semantics Mining'), (112, 'Do We Need Language-Specific Fact-Checking Models? The Case of Chinese'), (155, 'To Word Senses and Beyond: Inducing Concepts with Contextualized Language Models')]
               ----------------------------------------
          ----------------------------------------
          Label: hallucination_detection
          Dimension: tasks
          Description: This cluster focuses on identifying instances where language models generate false or misleading information that does not correspond to real-world facts.
          Level: 2
          # of Papers: 110
          Example Papers: [(38, 'CoCoLoFa: A Dataset of News Comments with Common Logical Fallacies Written by LLM-Assisted Crowds'), (40, 'FLIRT: Feedback Loop In-context Red Teaming'), (115, 'Embedding and Gradient Say Wrong: A White-Box Method for Hallucination Detection')]
          ----------------------------------------
          Children:
               Label: hallucination_detection_methods
               Dimension: tasks
               Description: This cluster focuses on various techniques and methodologies developed for detecting hallucinations in language models, including both traditional and innovative approaches.
               Level: 3
               # of Papers: 53
               Example Papers: [(38, 'CoCoLoFa: A Dataset of News Comments with Common Logical Fallacies Written by LLM-Assisted Crowds'), (40, 'FLIRT: Feedback Loop In-context Red Teaming'), (115, 'Embedding and Gradient Say Wrong: A White-Box Method for Hallucination Detection')]
               ----------------------------------------
               Label: factuality_evaluation
               Dimension: tasks
               Description: This cluster encompasses methods and metrics used to assess the factual accuracy of information generated by language models, ensuring that outputs align with real-world facts.
               Level: 3
               # of Papers: 47
               Example Papers: [(254, 'F^2RL: Factuality and Faithfulness Reinforcement Learning Framework for Claim-Guided Evidence-Supported Counterspeech Generation'), (271, 'A Peek into Token Bias: Large Language Models Are Not Yet Genuine Reasoners'), (363, 'Personas as a Way to Model Truthfulness in Language Models')]
               ----------------------------------------
               Label: hallucination_mitigation
               Dimension: tasks
               Description: This cluster addresses strategies and techniques aimed at reducing the occurrence of hallucinations in language models, enhancing their reliability and trustworthiness.
               Level: 3
               # of Papers: 64
               Example Papers: [(151, 'Knowledge Verification to Nip Hallucination in the Bud'), (154, 'Whispers that Shake Foundations: Analyzing and Mitigating False Premise Hallucinations in Large Language Models'), (163, 'Alignment-Enhanced Decoding: Defending Jailbreaks via Token-Level Adaptive Refining of Probability Distributions')]
               ----------------------------------------
               Label: knowledge_verification
               Dimension: tasks
               Description: This cluster involves the processes and tools used to verify the knowledge and information presented by language models, ensuring that it is accurate and credible.
               Level: 3
               # of Papers: 29
               Example Papers: [(151, 'Knowledge Verification to Nip Hallucination in the Bud'), (271, 'A Peek into Token Bias: Large Language Models Are Not Yet Genuine Reasoners'), (377, 'Right for Right Reasons: Large Language Models for Verifiable Commonsense Knowledge Graph Question Answering')]
               ----------------------------------------
               Label: explanation_methods
               Dimension: tasks
               Description: This cluster focuses on the development of explanation techniques that help elucidate the reasoning behind language model outputs, particularly in the context of hallucinations.
               Level: 3
               # of Papers: 29
               Example Papers: [(127, 'LogicAsker: Evaluating and Improving the Logical Reasoning Ability of Large Language Models'), (271, 'A Peek into Token Bias: Large Language Models Are Not Yet Genuine Reasoners'), (363, 'Personas as a Way to Model Truthfulness in Language Models')]
               ----------------------------------------
          ----------------------------------------
     ----------------------------------------
     Label: hate_speech_detection
     Dimension: tasks
     Description: The task of identifying and classifying speech that incites violence or prejudicial action against a particular group.
     Level: 1
     # of Papers: 338
     Example Papers: [(5, 'ImageInWords: Unlocking Hyper-Detailed Image Descriptions'), (9, 'Hateful Word in Context Classification'), (10, "Eyes Don't Lie: Subjective Hate Annotation and Detection with Gaze")]
     ----------------------------------------
     Children:
          Label: hate_speech_classification
          Dimension: tasks
          Description: The task of categorizing instances of hate speech into predefined classes based on their content and context.
          Level: 2
          # of Papers: 57
          Example Papers: [(9, 'Hateful Word in Context Classification'), (10, "Eyes Don't Lie: Subjective Hate Annotation and Detection with Gaze"), (33, 'A Study of Nationality Bias in Names and Perplexity using Off-the-Shelf Affect-related Tweet Classifiers')]
          ----------------------------------------
          Children:
               Label: hate_detection
               Dimension: tasks
               Description: The task of identifying and categorizing instances of hate speech based on their content, focusing on the explicit expressions of hate.
               Level: 3
               # of Papers: 14
               Example Papers: [(9, 'Hateful Word in Context Classification'), (10, "Eyes Don't Lie: Subjective Hate Annotation and Detection with Gaze"), (33, 'A Study of Nationality Bias in Names and Perplexity using Off-the-Shelf Affect-related Tweet Classifiers')]
               ----------------------------------------
               Label: implicit_abuse_detection
               Dimension: tasks
               Description: The task of recognizing and classifying subtle or implicit forms of hate speech that may not be overtly aggressive but still convey harmful sentiments.
               Level: 3
               # of Papers: 3
               Example Papers: [(131, 'Oddballs and Misfits: Detecting Implicit Abuse in Which Identity Groups are Depicted as Deviating from the Norm'), (258, 'Leveraging Conflicts in Social Media Posts: Unintended Offense Dataset'), (1852, 'PclGPT: A Large Language Model for Patronizing and Condescending Language Detection')]
               ----------------------------------------
               Label: bias_in_hate_speech_models
               Dimension: tasks
               Description: The examination and classification of biases present in models used for hate speech detection, assessing how these biases affect the outcomes of hate speech classification.
               Level: 3
               # of Papers: 7
               Example Papers: [(33, 'A Study of Nationality Bias in Names and Perplexity using Off-the-Shelf Affect-related Tweet Classifiers'), (242, 'STOP! Benchmarking Large Language Models with Sensitivity Testing on Offensive Progressions'), (613, 'Towards Probing Speech-Specific Risks in Large Multimodal Models: A Taxonomy, Benchmark, and Insights')]
               ----------------------------------------
               Label: hate_speech_mitigation
               Dimension: tasks
               Description: The task of developing strategies and methods to reduce the prevalence and impact of hate speech in various contexts, focusing on intervention techniques.
               Level: 3
               # of Papers: 35
               Example Papers: [(135, 'Towards Low-Resource Harmful Meme Detection with LMM Agents'), (200, 'Is Safer Better? The Impact of Guardrails on the Argumentative Strength of LLMs in Hate Speech Countering'), (242, 'STOP! Benchmarking Large Language Models with Sensitivity Testing on Offensive Progressions')]
               ----------------------------------------
               Label: explainable_hate_speech_detection
               Dimension: tasks
               Description: The task of creating models for hate speech detection that provide interpretable and understandable explanations for their classifications, enhancing transparency.
               Level: 3
               # of Papers: 10
               Example Papers: [(10, "Eyes Don't Lie: Subjective Hate Annotation and Detection with Gaze"), (614, 'Self-AMPLIFY: Improving Small Language Models with Self Post Hoc Explanations'), (691, 'Latent Concept-based Explanation of NLP Models')]
               ----------------------------------------
          ----------------------------------------
          Label: counterspeech_generation
          Dimension: tasks
          Description: The process of creating responses or narratives that counteract hate speech and promote positive dialogue.
          Level: 2
          # of Papers: 9
          Example Papers: [(200, 'Is Safer Better? The Impact of Guardrails on the Argumentative Strength of LLMs in Hate Speech Countering'), (254, 'F^2RL: Factuality and Faithfulness Reinforcement Learning Framework for Claim-Guided Evidence-Supported Counterspeech Generation'), (259, 'Outcome-Constrained Large Language Models for Countering Hate Speech')]
          ----------------------------------------
          Label: misogyny_detection
          Dimension: tasks
          Description: The identification and classification of speech that expresses hatred or prejudice against women.
          Level: 2
          # of Papers: 3
          Example Papers: [(1089, 'Adaptable Moral Stances of Large Language Models on Sexist Content: Implications for Society and Gender Discourse'), (1173, 'Language is Scary when Over-Analyzed: Unpacking Implied Misogynistic Reasoning with Argumentation Theory-Driven Prompts'), (1233, 'M3Hop-CoT: Misogynous Meme Identification with Multimodal Multi-hop Chain-of-Thought')]
          ----------------------------------------
          Label: cross-cultural_offensiveness_detection
          Dimension: tasks
          Description: The task of detecting offensive language that varies in meaning and impact across different cultural contexts.
          Level: 2
          # of Papers: 4
          Example Papers: [(885, 'Hate Personified: Investigating the role of LLMs in content moderation'), (1028, 'D3CODE: Disentangling Disagreements in Data across Cultures on Offensiveness Detection and Evaluation'), (1089, 'Adaptable Moral Stances of Large Language Models on Sexist Content: Implications for Society and Gender Discourse')]
          ----------------------------------------
          Label: toxic_content_mitigation
          Dimension: tasks
          Description: Strategies and methods aimed at reducing the prevalence and impact of toxic language in online communications.
          Level: 2
          # of Papers: 19
          Example Papers: [(114, 'CMD: a framework for Context-aware Model self-Detoxification'), (163, 'Alignment-Enhanced Decoding: Defending Jailbreaks via Token-Level Adaptive Refining of Probability Distributions'), (186, 'ScalingFilter: Assessing Data Quality through Inverse Utilization of Scaling Laws')]
          ----------------------------------------
          Label: backdoor_attack_detection
          Dimension: tasks
          Description: The task of identifying and mitigating backdoor attacks in machine learning models, particularly in the context of hate speech detection.
          Level: 2
          # of Papers: 10
          Example Papers: [(40, 'FLIRT: Feedback Loop In-context Red Teaming'), (156, 'ASETF: A Novel Method for Jailbreak Attack on LLMs through Translate Suffix Embeddings'), (242, 'STOP! Benchmarking Large Language Models with Sensitivity Testing on Offensive Progressions')]
          ----------------------------------------
          Label: multi-task_hate_speech_learning
          Dimension: tasks
          Description: The approach of simultaneously training models to perform multiple related tasks in the domain of hate speech detection and classification.
          Level: 2
          # of Papers: 24
          Example Papers: [(10, "Eyes Don't Lie: Subjective Hate Annotation and Detection with Gaze"), (242, 'STOP! Benchmarking Large Language Models with Sensitivity Testing on Offensive Progressions'), (332, 'Teaching Small Language Models Reasoning through Counterfactual Distillation')]
          ----------------------------------------
          Label: legal_outcome_hate_speech_prediction
          Dimension: tasks
          Description: The task of predicting legal outcomes related to hate speech incidents based on various contextual and textual features.
          Level: 2
          # of Papers: 4
          Example Papers: [(242, 'STOP! Benchmarking Large Language Models with Sensitivity Testing on Offensive Progressions'), (2640, 'Enhancing Legal Expertise in Large Language Models through Composite Model Integration: The Development and Evaluation of Law-Neo'), (2657, 'Comparative Study of Explainability Methods for Legal Outcome Prediction')]
          ----------------------------------------
     ----------------------------------------
----------------------------------------
