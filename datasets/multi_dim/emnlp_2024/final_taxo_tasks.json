{
    "label": "natural_language_processing",
    "description": null,
    "level": 0,
    "example_papers": [
        [
            0,
            "UniGen: Universal Domain Generalization for Sentiment Classification via Zero-shot Dataset Generation"
        ],
        [
            1,
            "Multi-News+: Cost-efficient Dataset Cleansing via LLM-based Data Annotation"
        ],
        [
            2,
            "FIZZ: Factual Inconsistency Detection by Zoom-in Summary and Zoom-out Document"
        ],
        [
            3,
            "Prompts have evil twins"
        ],
        [
            4,
            "Table Question Answering for Low-resourced Indic Languages"
        ],
        [
            5,
            "ImageInWords: Unlocking Hyper-Detailed Image Descriptions"
        ],
        [
            6,
            "LLM-Based Agent Society Investigation: Collaboration and Confrontation in Avalon Gameplay"
        ],
        [
            7,
            "When LLMs Meets Acoustic Landmarks: An Efficient Approach to Integrate Speech into Large Language Models for Depression Detection"
        ],
        [
            8,
            "Speaking in Wavelet Domain: A Simple and Efficient Approach to Speed up Speech Diffusion Model"
        ],
        [
            9,
            "Hateful Word in Context Classification"
        ]
    ],
    "paper_ids": [
        0,
        1,
        2,
        3,
        4,
        5,
        6,
        7,
        8,
        9,
        10,
        11,
        12,
        13,
        14,
        15,
        16,
        17,
        18,
        19,
        20,
        21,
        22,
        23,
        24,
        25,
        26,
        27,
        28,
        29,
        30,
        31,
        32,
        33,
        34,
        35,
        36,
        37,
        38,
        39,
        40,
        41,
        42,
        43,
        44,
        45,
        46,
        47,
        48,
        49,
        50,
        51,
        52,
        53,
        54,
        55,
        56,
        57,
        58,
        59,
        60,
        61,
        62,
        63,
        64,
        65,
        66,
        67,
        68,
        69,
        70,
        71,
        72,
        73,
        74,
        75,
        76,
        77,
        78,
        79,
        80,
        81,
        82,
        83,
        84,
        85,
        86,
        87,
        88,
        89,
        90,
        91,
        92,
        93,
        94,
        95,
        96,
        97,
        98,
        99,
        100,
        101,
        102,
        103,
        104,
        105,
        106,
        107,
        108,
        109,
        110,
        111,
        112,
        113,
        114,
        115,
        116,
        117,
        118,
        119,
        120,
        121,
        122,
        123,
        124,
        125,
        126,
        127,
        128,
        129,
        130,
        131,
        132,
        133,
        134,
        135,
        136,
        137,
        138,
        139,
        140,
        141,
        142,
        143,
        144,
        145,
        146,
        147,
        148,
        149,
        150,
        151,
        152,
        153,
        154,
        155,
        156,
        157,
        158,
        159,
        160,
        161,
        162,
        163,
        164,
        165,
        166,
        167,
        168,
        169,
        170,
        171,
        172,
        173,
        174,
        175,
        176,
        177,
        178,
        179,
        180,
        181,
        182,
        183,
        184,
        185,
        186,
        187,
        188,
        189,
        190,
        191,
        192,
        193,
        194,
        195,
        196,
        197,
        198,
        199,
        200,
        201,
        202,
        203,
        204,
        205,
        206,
        207,
        208,
        209,
        210,
        211,
        212,
        213,
        214,
        215,
        216,
        217,
        218,
        219,
        220,
        221,
        222,
        223,
        224,
        225,
        226,
        227,
        228,
        229,
        230,
        231,
        232,
        233,
        234,
        235,
        236,
        237,
        238,
        239,
        240,
        241,
        242,
        243,
        244,
        245,
        246,
        247,
        248,
        249,
        250,
        251,
        252,
        253,
        254,
        255,
        256,
        257,
        258,
        259,
        260,
        261,
        262,
        263,
        264,
        265,
        266,
        267,
        268,
        269,
        270,
        271,
        272,
        273,
        274,
        275,
        276,
        277,
        278,
        279,
        280,
        281,
        282,
        283,
        284,
        285,
        286,
        287,
        288,
        289,
        290,
        291,
        292,
        293,
        294,
        295,
        296,
        297,
        298,
        299,
        300,
        301,
        302,
        303,
        304,
        305,
        306,
        307,
        308,
        309,
        310,
        311,
        312,
        313,
        314,
        315,
        316,
        317,
        318,
        319,
        320,
        321,
        322,
        323,
        324,
        325,
        326,
        327,
        328,
        329,
        330,
        331,
        332,
        333,
        334,
        335,
        336,
        337,
        338,
        339,
        340,
        341,
        342,
        343,
        344,
        345,
        346,
        347,
        348,
        349,
        350,
        351,
        352,
        353,
        354,
        355,
        356,
        357,
        358,
        359,
        360,
        361,
        362,
        363,
        364,
        365,
        366,
        367,
        368,
        369,
        370,
        371,
        372,
        373,
        374,
        375,
        376,
        377,
        378,
        379,
        380,
        381,
        382,
        383,
        384,
        385,
        386,
        387,
        388,
        389,
        390,
        391,
        392,
        393,
        394,
        395,
        396,
        397,
        398,
        399,
        400,
        401,
        402,
        403,
        404,
        405,
        406,
        407,
        408,
        409,
        410,
        411,
        412,
        413,
        414,
        415,
        416,
        417,
        418,
        419,
        420,
        421,
        422,
        423,
        424,
        425,
        426,
        427,
        428,
        429,
        430,
        431,
        432,
        433,
        434,
        435,
        436,
        437,
        438,
        439,
        440,
        441,
        442,
        443,
        444,
        445,
        446,
        447,
        448,
        449,
        450,
        451,
        452,
        453,
        454,
        455,
        456,
        457,
        458,
        459,
        460,
        461,
        462,
        463,
        464,
        465,
        466,
        467,
        468,
        469,
        470,
        471,
        472,
        473,
        474,
        475,
        476,
        477,
        478,
        479,
        480,
        481,
        482,
        483,
        484,
        485,
        486,
        487,
        488,
        489,
        490,
        491,
        492,
        493,
        494,
        495,
        496,
        497,
        498,
        499,
        500,
        501,
        502,
        503,
        504,
        505,
        506,
        507,
        508,
        509,
        510,
        511,
        512,
        513,
        514,
        515,
        516,
        517,
        518,
        519,
        520,
        521,
        522,
        523,
        524,
        525,
        526,
        527,
        528,
        529,
        530,
        531,
        532,
        533,
        534,
        535,
        536,
        537,
        538,
        539,
        540,
        541,
        542,
        543,
        544,
        545,
        546,
        547,
        548,
        549,
        550,
        551,
        552,
        553,
        554,
        555,
        556,
        557,
        558,
        559,
        560,
        561,
        562,
        563,
        564,
        565,
        566,
        567,
        568,
        569,
        570,
        571,
        572,
        573,
        574,
        575,
        576,
        577,
        578,
        579,
        580,
        581,
        582,
        583,
        584,
        585,
        586,
        587,
        588,
        589,
        590,
        591,
        592,
        593,
        594,
        595,
        596,
        597,
        598,
        599,
        600,
        601,
        602,
        603,
        604,
        605,
        606,
        607,
        608,
        609,
        610,
        611,
        612,
        613,
        614,
        615,
        616,
        617,
        618,
        619,
        620,
        621,
        622,
        623,
        624,
        625,
        626,
        627,
        628,
        629,
        630,
        631,
        632,
        633,
        634,
        635,
        636,
        637,
        638,
        639,
        640,
        641,
        642,
        643,
        644,
        645,
        646,
        647,
        648,
        649,
        650,
        651,
        652,
        653,
        654,
        655,
        656,
        657,
        658,
        659,
        660,
        661,
        662,
        663,
        664,
        665,
        666,
        667,
        668,
        669,
        670,
        671,
        672,
        673,
        674,
        675,
        676,
        677,
        678,
        679,
        680,
        681,
        682,
        683,
        684,
        685,
        686,
        687,
        688,
        689,
        690,
        691,
        692,
        693,
        694,
        695,
        696,
        697,
        698,
        699,
        700,
        701,
        702,
        703,
        704,
        705,
        706,
        707,
        708,
        709,
        710,
        711,
        712,
        713,
        714,
        715,
        716,
        717,
        718,
        719,
        720,
        721,
        722,
        723,
        724,
        725,
        726,
        727,
        728,
        729,
        730,
        731,
        732,
        733,
        734,
        735,
        736,
        737,
        738,
        739,
        740,
        741,
        742,
        743,
        744,
        745,
        746,
        747,
        748,
        749,
        750,
        751,
        752,
        753,
        754,
        755,
        756,
        757,
        758,
        759,
        760,
        761,
        762,
        763,
        764,
        765,
        766,
        767,
        768,
        769,
        770,
        771,
        772,
        773,
        774,
        775,
        776,
        777,
        778,
        779,
        780,
        781,
        782,
        783,
        784,
        785,
        786,
        787,
        788,
        789,
        790,
        791,
        792,
        793,
        794,
        795,
        796,
        797,
        798,
        799,
        800,
        801,
        802,
        803,
        804,
        805,
        806,
        807,
        808,
        809,
        810,
        811,
        812,
        813,
        814,
        815,
        816,
        817,
        818,
        819,
        820,
        821,
        822,
        823,
        824,
        825,
        826,
        827,
        828,
        829,
        830,
        831,
        832,
        833,
        834,
        835,
        836,
        837,
        838,
        839,
        840,
        841,
        842,
        843,
        844,
        845,
        846,
        847,
        848,
        849,
        850,
        851,
        852,
        853,
        854,
        855,
        856,
        857,
        858,
        859,
        860,
        861,
        862,
        863,
        864,
        865,
        866,
        867,
        868,
        869,
        870,
        871,
        872,
        873,
        874,
        875,
        876,
        877,
        878,
        879,
        880,
        881,
        882,
        883,
        884,
        885,
        886,
        887,
        888,
        889,
        890,
        891,
        892,
        893,
        894,
        895,
        896,
        897,
        898,
        899,
        900,
        901,
        902,
        903,
        904,
        905,
        906,
        907,
        908,
        909,
        910,
        911,
        912,
        913,
        914,
        915,
        916,
        917,
        918,
        919,
        920,
        921,
        922,
        923,
        924,
        925,
        926,
        927,
        928,
        929,
        930,
        931,
        932,
        933,
        934,
        935,
        936,
        937,
        938,
        939,
        940,
        941,
        942,
        943,
        944,
        945,
        946,
        947,
        948,
        949,
        950,
        951,
        952,
        953,
        954,
        955,
        956,
        957,
        958,
        959,
        960,
        961,
        962,
        963,
        964,
        965,
        966,
        967,
        968,
        969,
        970,
        971,
        972,
        973,
        974,
        975,
        976,
        977,
        978,
        979,
        980,
        981,
        982,
        983,
        984,
        985,
        986,
        987,
        988,
        989,
        990,
        991,
        992,
        993,
        994,
        995,
        996,
        997,
        998,
        999,
        1000,
        1001,
        1002,
        1003,
        1004,
        1005,
        1006,
        1007,
        1008,
        1009,
        1010,
        1011,
        1012,
        1013,
        1014,
        1015,
        1016,
        1017,
        1018,
        1019,
        1020,
        1021,
        1022,
        1023,
        1024,
        1025,
        1026,
        1027,
        1028,
        1029,
        1030,
        1031,
        1032,
        1033,
        1034,
        1035,
        1036,
        1037,
        1038,
        1039,
        1040,
        1041,
        1042,
        1043,
        1044,
        1045,
        1046,
        1047,
        1048,
        1049,
        1050,
        1051,
        1052,
        1053,
        1054,
        1055,
        1056,
        1057,
        1058,
        1059,
        1060,
        1061,
        1062,
        1063,
        1064,
        1065,
        1066,
        1067,
        1068,
        1069,
        1070,
        1071,
        1072,
        1073,
        1074,
        1075,
        1076,
        1077,
        1078,
        1079,
        1080,
        1081,
        1082,
        1083,
        1084,
        1085,
        1086,
        1087,
        1088,
        1089,
        1090,
        1091,
        1092,
        1093,
        1094,
        1095,
        1096,
        1097,
        1098,
        1099,
        1100,
        1101,
        1102,
        1103,
        1104,
        1105,
        1106,
        1107,
        1108,
        1109,
        1110,
        1111,
        1112,
        1113,
        1114,
        1115,
        1116,
        1117,
        1118,
        1119,
        1120,
        1121,
        1122,
        1123,
        1124,
        1125,
        1126,
        1127,
        1128,
        1129,
        1130,
        1131,
        1132,
        1133,
        1134,
        1135,
        1136,
        1137,
        1138,
        1139,
        1140,
        1141,
        1142,
        1143,
        1144,
        1145,
        1146,
        1147,
        1148,
        1149,
        1150,
        1151,
        1152,
        1153,
        1154,
        1155,
        1156,
        1157,
        1158,
        1159,
        1160,
        1161,
        1162,
        1163,
        1164,
        1165,
        1166,
        1167,
        1168,
        1169,
        1170,
        1171,
        1172,
        1173,
        1174,
        1175,
        1176,
        1177,
        1178,
        1179,
        1180,
        1181,
        1182,
        1183,
        1184,
        1185,
        1186,
        1187,
        1188,
        1189,
        1190,
        1191,
        1192,
        1193,
        1194,
        1195,
        1196,
        1197,
        1198,
        1199,
        1200,
        1201,
        1202,
        1203,
        1204,
        1205,
        1206,
        1207,
        1208,
        1209,
        1210,
        1211,
        1212,
        1213,
        1214,
        1215,
        1216,
        1217,
        1218,
        1219,
        1220,
        1221,
        1222,
        1223,
        1224,
        1225,
        1226,
        1227,
        1228,
        1229,
        1230,
        1231,
        1232,
        1233,
        1234,
        1235,
        1236,
        1237,
        1238,
        1239,
        1240,
        1241,
        1242,
        1243,
        1244,
        1245,
        1246,
        1247,
        1248,
        1249,
        1250,
        1251,
        1252,
        1253,
        1254,
        1255,
        1256,
        1257,
        1258,
        1259,
        1260,
        1261,
        1262,
        1263,
        1264,
        1265,
        1266,
        1267,
        1268,
        1269,
        1270,
        1271,
        1272,
        1273,
        1274,
        1275,
        1276,
        1277,
        1278,
        1279,
        1280,
        1281,
        1282,
        1283,
        1284,
        1285,
        1286,
        1287,
        1288,
        1289,
        1290,
        1291,
        1292,
        1293,
        1294,
        1295,
        1296,
        1297,
        1298,
        1299,
        1300,
        1301,
        1302,
        1303,
        1304,
        1305,
        1306,
        1307,
        1308,
        1309,
        1310,
        1311,
        1312,
        1313,
        1314,
        1315,
        1316,
        1317,
        1318,
        1319,
        1320,
        1321,
        1322,
        1323,
        1324,
        1325,
        1326,
        1327,
        1328,
        1329,
        1330,
        1331,
        1332,
        1333,
        1334,
        1335,
        1336,
        1337,
        1338,
        1339,
        1340,
        1341,
        1342,
        1343,
        1344,
        1345,
        1346,
        1347,
        1348,
        1349,
        1350,
        1351,
        1352,
        1353,
        1354,
        1355,
        1356,
        1357,
        1358,
        1359,
        1360,
        1361,
        1362,
        1363,
        1364,
        1365,
        1366,
        1367,
        1368,
        1369,
        1370,
        1371,
        1372,
        1373,
        1374,
        1375,
        1376,
        1377,
        1378,
        1379,
        1380,
        1381,
        1382,
        1383,
        1384,
        1385,
        1386,
        1387,
        1388,
        1389,
        1390,
        1391,
        1392,
        1393,
        1394,
        1395,
        1396,
        1397,
        1398,
        1399,
        1400,
        1401,
        1402,
        1403,
        1404,
        1405,
        1406,
        1407,
        1408,
        1409,
        1410,
        1411,
        1412,
        1413,
        1414,
        1415,
        1416,
        1417,
        1418,
        1419,
        1420,
        1421,
        1422,
        1423,
        1424,
        1425,
        1426,
        1427,
        1428,
        1429,
        1430,
        1431,
        1432,
        1433,
        1434,
        1435,
        1436,
        1437,
        1438,
        1439,
        1440,
        1441,
        1442,
        1443,
        1444,
        1445,
        1446,
        1447,
        1448,
        1449,
        1450,
        1451,
        1452,
        1453,
        1454,
        1455,
        1456,
        1457,
        1458,
        1459,
        1460,
        1461,
        1462,
        1463,
        1464,
        1465,
        1466,
        1467,
        1468,
        1469,
        1470,
        1471,
        1472,
        1473,
        1474,
        1475,
        1476,
        1477,
        1478,
        1479,
        1480,
        1481,
        1482,
        1483,
        1484,
        1485,
        1486,
        1487,
        1488,
        1489,
        1490,
        1491,
        1492,
        1493,
        1494,
        1495,
        1496,
        1497,
        1498,
        1499,
        1500,
        1501,
        1502,
        1503,
        1504,
        1505,
        1506,
        1507,
        1508,
        1509,
        1510,
        1511,
        1512,
        1513,
        1514,
        1515,
        1516,
        1517,
        1518,
        1519,
        1520,
        1521,
        1522,
        1523,
        1524,
        1525,
        1526,
        1527,
        1528,
        1529,
        1530,
        1531,
        1532,
        1533,
        1534,
        1535,
        1536,
        1537,
        1538,
        1539,
        1540,
        1541,
        1542,
        1543,
        1544,
        1545,
        1546,
        1547,
        1548,
        1549,
        1550,
        1551,
        1552,
        1553,
        1554,
        1555,
        1556,
        1557,
        1558,
        1559,
        1560,
        1561,
        1562,
        1563,
        1564,
        1565,
        1566,
        1567,
        1568,
        1569,
        1570,
        1571,
        1572,
        1573,
        1574,
        1575,
        1576,
        1577,
        1578,
        1579,
        1580,
        1581,
        1582,
        1583,
        1584,
        1585,
        1586,
        1587,
        1588,
        1589,
        1590,
        1591,
        1592,
        1593,
        1594,
        1595,
        1596,
        1597,
        1598,
        1599,
        1600,
        1601,
        1602,
        1603,
        1604,
        1605,
        1606,
        1607,
        1608,
        1609,
        1610,
        1611,
        1612,
        1613,
        1614,
        1615,
        1616,
        1617,
        1618,
        1619,
        1620,
        1621,
        1622,
        1623,
        1624,
        1625,
        1626,
        1627,
        1628,
        1629,
        1630,
        1631,
        1632,
        1633,
        1634,
        1635,
        1636,
        1637,
        1638,
        1639,
        1640,
        1641,
        1642,
        1643,
        1644,
        1645,
        1646,
        1647,
        1648,
        1649,
        1650,
        1651,
        1652,
        1653,
        1654,
        1655,
        1656,
        1657,
        1658,
        1659,
        1660,
        1661,
        1662,
        1663,
        1664,
        1665,
        1666,
        1667,
        1668,
        1669,
        1670,
        1671,
        1672,
        1673,
        1674,
        1675,
        1676,
        1677,
        1678,
        1679,
        1680,
        1681,
        1682,
        1683,
        1684,
        1685,
        1686,
        1687,
        1688,
        1689,
        1690,
        1691,
        1692,
        1693,
        1694,
        1695,
        1696,
        1697,
        1698,
        1699,
        1700,
        1701,
        1702,
        1703,
        1704,
        1705,
        1706,
        1707,
        1708,
        1709,
        1710,
        1711,
        1712,
        1713,
        1714,
        1715,
        1716,
        1717,
        1718,
        1719,
        1720,
        1721,
        1722,
        1723,
        1724,
        1725,
        1726,
        1727,
        1728,
        1729,
        1730,
        1731,
        1732,
        1733,
        1734,
        1735,
        1736,
        1737,
        1738,
        1739,
        1740,
        1741,
        1742,
        1743,
        1744,
        1745,
        1746,
        1747,
        1748,
        1749,
        1750,
        1751,
        1752,
        1753,
        1754,
        1755,
        1756,
        1757,
        1758,
        1759,
        1760,
        1761,
        1762,
        1763,
        1764,
        1765,
        1766,
        1767,
        1768,
        1769,
        1770,
        1771,
        1772,
        1773,
        1774,
        1775,
        1776,
        1777,
        1778,
        1779,
        1780,
        1781,
        1782,
        1783,
        1784,
        1785,
        1786,
        1787,
        1788,
        1789,
        1790,
        1791,
        1792,
        1793,
        1794,
        1795,
        1796,
        1797,
        1798,
        1799,
        1800,
        1801,
        1802,
        1803,
        1804,
        1805,
        1806,
        1807,
        1808,
        1809,
        1810,
        1811,
        1812,
        1813,
        1814,
        1815,
        1816,
        1817,
        1818,
        1819,
        1820,
        1821,
        1822,
        1823,
        1824,
        1825,
        1826,
        1827,
        1828,
        1829,
        1830,
        1831,
        1832,
        1833,
        1834,
        1835,
        1836,
        1837,
        1838,
        1839,
        1840,
        1841,
        1842,
        1843,
        1844,
        1845,
        1846,
        1847,
        1848,
        1849,
        1850,
        1851,
        1852,
        1853,
        1854,
        1855,
        1856,
        1857,
        1858,
        1859,
        1860,
        1861,
        1862,
        1863,
        1864,
        1865,
        1866,
        1867,
        1868,
        1869,
        1870,
        1871,
        1872,
        1873,
        1874,
        1875,
        1876,
        1877,
        1878,
        1879,
        1880,
        1881,
        1882,
        1883,
        1884,
        1885,
        1886,
        1887,
        1888,
        1889,
        1890,
        1891,
        1892,
        1893,
        1894,
        1895,
        1896,
        1897,
        1898,
        1899,
        1900,
        1901,
        1902,
        1903,
        1904,
        1905,
        1906,
        1907,
        1908,
        1909,
        1910,
        1911,
        1912,
        1913,
        1914,
        1915,
        1916,
        1917,
        1918,
        1919,
        1920,
        1921,
        1922,
        1923,
        1924,
        1925,
        1926,
        1927,
        1928,
        1929,
        1930,
        1931,
        1932,
        1933,
        1934,
        1935,
        1936,
        1937,
        1938,
        1939,
        1940,
        1941,
        1942,
        1943,
        1944,
        1945,
        1946,
        1947,
        1948,
        1949,
        1950,
        1951,
        1952,
        1953,
        1954,
        1955,
        1956,
        1957,
        1958,
        1959,
        1960,
        1961,
        1962,
        1963,
        1964,
        1965,
        1966,
        1967,
        1968,
        1969,
        1970,
        1971,
        1972,
        1973,
        1974,
        1975,
        1976,
        1977,
        1978,
        1979,
        1980,
        1981,
        1982,
        1983,
        1984,
        1985,
        1986,
        1987,
        1988,
        1989,
        1990,
        1991,
        1992,
        1993,
        1994,
        1995,
        1996,
        1997,
        1998,
        1999,
        2000,
        2001,
        2002,
        2003,
        2004,
        2005,
        2006,
        2007,
        2008,
        2009,
        2010,
        2011,
        2012,
        2013,
        2014,
        2015,
        2016,
        2017,
        2018,
        2019,
        2020,
        2021,
        2022,
        2023,
        2024,
        2025,
        2026,
        2027,
        2028,
        2029,
        2030,
        2031,
        2032,
        2033,
        2034,
        2035,
        2036,
        2037,
        2038,
        2039,
        2040,
        2041,
        2042,
        2043,
        2044,
        2045,
        2046,
        2047,
        2048,
        2049,
        2050,
        2051,
        2052,
        2053,
        2054,
        2055,
        2056,
        2057,
        2058,
        2059,
        2060,
        2061,
        2062,
        2063,
        2064,
        2065,
        2066,
        2067,
        2068,
        2069,
        2070,
        2071,
        2072,
        2073,
        2074,
        2075,
        2076,
        2077,
        2078,
        2079,
        2080,
        2081,
        2082,
        2083,
        2084,
        2085,
        2086,
        2087,
        2088,
        2089,
        2090,
        2091,
        2092,
        2093,
        2094,
        2095,
        2096,
        2097,
        2098,
        2099,
        2100,
        2101,
        2102,
        2103,
        2104,
        2105,
        2106,
        2107,
        2108,
        2109,
        2110,
        2111,
        2112,
        2113,
        2114,
        2115,
        2116,
        2117,
        2118,
        2119,
        2120,
        2121,
        2122,
        2123,
        2124,
        2125,
        2126,
        2127,
        2128,
        2129,
        2130,
        2131,
        2132,
        2133,
        2134,
        2135,
        2136,
        2137,
        2138,
        2139,
        2140,
        2141,
        2142,
        2143,
        2144,
        2145,
        2146,
        2147,
        2148,
        2149,
        2150,
        2151,
        2152,
        2153,
        2154,
        2155,
        2156,
        2157,
        2158,
        2159,
        2160,
        2161,
        2162,
        2163,
        2164,
        2165,
        2166,
        2167,
        2168,
        2169,
        2170,
        2171,
        2172,
        2173,
        2174,
        2175,
        2176,
        2177,
        2178,
        2179,
        2180,
        2181,
        2182,
        2183,
        2184,
        2185,
        2186,
        2187,
        2188,
        2189,
        2190,
        2191,
        2192,
        2193,
        2194,
        2195,
        2196,
        2197,
        2198,
        2199,
        2200,
        2201,
        2202,
        2203,
        2204,
        2205,
        2206,
        2207,
        2208,
        2209,
        2210,
        2211,
        2212,
        2213,
        2214,
        2215,
        2216,
        2217,
        2218,
        2219,
        2220,
        2221,
        2222,
        2223,
        2224,
        2225,
        2226,
        2227,
        2228,
        2229,
        2230,
        2231,
        2232,
        2233,
        2234,
        2235,
        2236,
        2237,
        2238,
        2239,
        2240,
        2241,
        2242,
        2243,
        2244,
        2245,
        2246,
        2247,
        2248,
        2249,
        2250,
        2251,
        2252,
        2253,
        2254,
        2255,
        2256,
        2257,
        2258,
        2259,
        2260,
        2261,
        2262,
        2263,
        2264,
        2265,
        2266,
        2267,
        2268,
        2269,
        2270,
        2271,
        2272,
        2273,
        2274,
        2275,
        2276,
        2277,
        2278,
        2279,
        2280,
        2281,
        2282,
        2283,
        2284,
        2285,
        2286,
        2287,
        2288,
        2289,
        2290,
        2291,
        2292,
        2293,
        2294,
        2295,
        2296,
        2297,
        2298,
        2299,
        2300,
        2301,
        2302,
        2303,
        2304,
        2305,
        2306,
        2307,
        2308,
        2309,
        2310,
        2311,
        2312,
        2313,
        2314,
        2315,
        2316,
        2317,
        2318,
        2319,
        2320,
        2321,
        2322,
        2323,
        2324,
        2325,
        2326,
        2327,
        2328,
        2329,
        2330,
        2331,
        2332,
        2333,
        2334,
        2335,
        2336,
        2337,
        2338,
        2339,
        2340,
        2341,
        2342,
        2343,
        2344,
        2345,
        2346,
        2347,
        2348,
        2349,
        2350,
        2351,
        2352,
        2353,
        2354,
        2355,
        2356,
        2357,
        2358,
        2359,
        2360,
        2361,
        2362,
        2363,
        2364,
        2365,
        2366,
        2367,
        2368,
        2369,
        2370,
        2371,
        2372,
        2373,
        2374,
        2375,
        2376,
        2377,
        2378,
        2379,
        2380,
        2381,
        2382,
        2383,
        2384,
        2385,
        2386,
        2387,
        2388,
        2389,
        2390,
        2391,
        2392,
        2393,
        2394,
        2395,
        2396,
        2397,
        2398,
        2399,
        2400,
        2401,
        2402,
        2403,
        2404,
        2405,
        2406,
        2407,
        2408,
        2409,
        2410,
        2411,
        2412,
        2413,
        2414,
        2415,
        2416,
        2417,
        2418,
        2419,
        2420,
        2421,
        2422,
        2423,
        2424,
        2425,
        2426,
        2427,
        2428,
        2429,
        2430,
        2431,
        2432,
        2433,
        2434,
        2435,
        2436,
        2437,
        2438,
        2439,
        2440,
        2441,
        2442,
        2443,
        2444,
        2445,
        2446,
        2447,
        2448,
        2449,
        2450,
        2451,
        2452,
        2453,
        2454,
        2455,
        2456,
        2457,
        2458,
        2459,
        2460,
        2461,
        2462,
        2463,
        2464,
        2465,
        2466,
        2467,
        2468,
        2469,
        2470,
        2471,
        2472,
        2473,
        2474,
        2475,
        2476,
        2477,
        2478,
        2479,
        2480,
        2481,
        2482,
        2483,
        2484,
        2485,
        2486,
        2487,
        2488,
        2489,
        2490,
        2491,
        2492,
        2493,
        2494,
        2495,
        2496,
        2497,
        2498,
        2499,
        2500,
        2501,
        2502,
        2503,
        2504,
        2505,
        2506,
        2507,
        2508,
        2509,
        2510,
        2511,
        2512,
        2513,
        2514,
        2515,
        2516,
        2517,
        2518,
        2519,
        2520,
        2521,
        2522,
        2523,
        2524,
        2525,
        2526,
        2527,
        2528,
        2529,
        2530,
        2531,
        2532,
        2533,
        2534,
        2535,
        2536,
        2537,
        2538,
        2539,
        2540,
        2541,
        2542,
        2543,
        2544,
        2545,
        2546,
        2547,
        2548,
        2549,
        2550,
        2551,
        2552,
        2553,
        2554,
        2555,
        2556,
        2557,
        2558,
        2559,
        2560,
        2561,
        2562,
        2563,
        2564,
        2565,
        2566,
        2567,
        2568,
        2569,
        2570,
        2571,
        2572,
        2573,
        2574,
        2575,
        2576,
        2577,
        2578,
        2579,
        2580,
        2581,
        2582,
        2583,
        2584,
        2585,
        2586,
        2587,
        2588,
        2589,
        2590,
        2591,
        2592,
        2593,
        2594,
        2595,
        2596,
        2597,
        2598,
        2599,
        2600,
        2601,
        2602,
        2603,
        2604,
        2605,
        2606,
        2607,
        2608,
        2609,
        2610,
        2611,
        2612,
        2613,
        2614,
        2615,
        2616,
        2617,
        2618,
        2619,
        2620,
        2621,
        2622,
        2623,
        2624,
        2625,
        2626,
        2627,
        2628,
        2629,
        2630,
        2631,
        2632,
        2633,
        2634,
        2635,
        2636,
        2637,
        2638,
        2639,
        2640,
        2641,
        2642,
        2643,
        2644,
        2645,
        2646,
        2647,
        2648,
        2649,
        2650,
        2651,
        2652,
        2653,
        2654,
        2655,
        2656,
        2657,
        2658,
        2659,
        2660,
        2661,
        2662,
        2663,
        2664,
        2665,
        2666,
        2667,
        2668,
        2669,
        2670,
        2671,
        2672,
        2673,
        2674,
        2675,
        2676,
        2677,
        2678,
        2679,
        2680,
        2681,
        2682,
        2683,
        2684,
        2685,
        2686,
        2687,
        2688,
        2689,
        2690,
        2691,
        2692,
        2693,
        2694,
        2695,
        2696,
        2697,
        2698,
        2699,
        2700,
        2701,
        2702,
        2703,
        2704,
        2705,
        2706,
        2707,
        2708,
        2709,
        2710,
        2711,
        2712,
        2713,
        2714,
        2715,
        2716,
        2717,
        2718,
        2719,
        2720,
        2721,
        2722,
        2723,
        2724,
        2725,
        2726,
        2727,
        2728,
        2729,
        2730,
        2731,
        2732,
        2733,
        2734,
        2735,
        2736,
        2737,
        2738,
        2739,
        2740,
        2741,
        2742,
        2743,
        2744,
        2745,
        2746,
        2747,
        2748,
        2749,
        2750,
        2751,
        2752,
        2753,
        2754,
        2755,
        2756,
        2757,
        2758,
        2759,
        2760,
        2761,
        2762,
        2763,
        2764,
        2765,
        2766,
        2767,
        2768,
        2769,
        2770,
        2771,
        2772,
        2773,
        2774,
        2775,
        2776,
        2777,
        2778,
        2779,
        2780,
        2781,
        2782,
        2783,
        2784,
        2785,
        2786,
        2787,
        2788,
        2789,
        2790,
        2791,
        2792,
        2793,
        2794,
        2795,
        2796,
        2797,
        2798,
        2799,
        2800,
        2801,
        2802,
        2803,
        2804,
        2805,
        2806,
        2807,
        2808,
        2809,
        2810,
        2811,
        2812,
        2813,
        2814,
        2815,
        2816,
        2817,
        2818,
        2819,
        2820,
        2821,
        2822,
        2823,
        2824,
        2825,
        2826,
        2827,
        2828,
        2829,
        2830,
        2831,
        2832,
        2833,
        2834,
        2835,
        2836,
        2837,
        2838,
        2839,
        2840,
        2841,
        2842,
        2843,
        2844,
        2845,
        2846,
        2847,
        2848,
        2849,
        2850,
        2851,
        2852,
        2853,
        2854,
        2855,
        2856,
        2857,
        2858,
        2859,
        2860,
        2861,
        2862,
        2863,
        2864,
        2865,
        2866,
        2867,
        2868,
        2869,
        2870,
        2871,
        2872,
        2873,
        2874,
        2875,
        2876,
        2877,
        2878,
        2879,
        2880,
        2881,
        2882,
        2883,
        2884,
        2885,
        2886,
        2887,
        2888,
        2889,
        2890,
        2891,
        2892,
        2893,
        2894,
        2895,
        2896,
        2897,
        2898,
        2899,
        2900,
        2901,
        2902,
        2903,
        2904,
        2905,
        2906,
        2907,
        2908,
        2909,
        2910,
        2911,
        2912,
        2913,
        2914,
        2915,
        2916,
        2917,
        2918,
        2919,
        2920,
        2921,
        2922,
        2923,
        2924,
        2925,
        2926,
        2927,
        2928,
        2929,
        2930,
        2931,
        2932,
        2933,
        2934,
        2935,
        2936,
        2937,
        2938,
        2939,
        2940,
        2941,
        2942,
        2943,
        2944,
        2945,
        2946,
        2947,
        2948,
        2949,
        2950,
        2951,
        2952,
        2953
    ],
    "children": [
        {
            "label": "text_classification",
            "description": "The task of assigning predefined categories to text documents based on their content, often used in applications like spam detection and sentiment analysis.",
            "level": 1,
            "example_papers": [
                [
                    5,
                    "ImageInWords: Unlocking Hyper-Detailed Image Descriptions"
                ],
                [
                    11,
                    "NumeroLogic: Number Encoding for Enhanced LLMs' Numerical Reasoning"
                ],
                [
                    13,
                    "A Usage-centric Take on Intent Understanding in E-Commerce"
                ],
                [
                    17,
                    "Uncertainty in Language Models: Assessment through Rank-Calibration"
                ],
                [
                    39,
                    "Tokenization Is More Than Compression"
                ],
                [
                    42,
                    "Parameter-Efficient Sparsity Crafting from Dense to Mixture-of-Experts for Instruction Tuning on General Tasks"
                ],
                [
                    48,
                    "Overcome Noise and Bias: Segmentation-Aided Multi-Granularity Denoising and Debiasing for Enhanced Quarduples Extraction in Dialogue"
                ],
                [
                    52,
                    "Language Models Learn Rare Phenomena from Less Rare Phenomena: The Case of the Missing AANNs"
                ],
                [
                    53,
                    "Large Language Models for Data Annotation and Synthesis: A Survey"
                ],
                [
                    56,
                    "RoseLoRA: Row and Column-wise Sparse Low-rank Adaptation of Pre-trained Language Model for Knowledge Editing and Fine-tuning"
                ]
            ],
            "paper_ids": [
                5,
                11,
                13,
                17,
                39,
                42,
                48,
                52,
                53,
                56,
                58,
                65,
                67,
                101,
                108,
                141,
                149,
                155,
                163,
                165,
                166,
                169,
                186,
                193,
                199,
                207,
                214,
                218,
                219,
                225,
                235,
                272,
                273,
                276,
                279,
                286,
                292,
                294,
                298,
                299,
                301,
                305,
                315,
                332,
                342,
                349,
                367,
                388,
                390,
                391,
                397,
                402,
                407,
                409,
                422,
                436,
                454,
                460,
                480,
                496,
                508,
                511,
                521,
                523,
                528,
                529,
                530,
                544,
                545,
                549,
                550,
                557,
                561,
                563,
                566,
                570,
                573,
                579,
                591,
                594,
                595,
                604,
                605,
                607,
                614,
                615,
                628,
                631,
                637,
                638,
                639,
                654,
                656,
                658,
                660,
                662,
                663,
                664,
                668,
                675,
                679,
                687,
                689,
                691,
                694,
                702,
                704,
                719,
                732,
                741,
                746,
                748,
                760,
                765,
                773,
                775,
                776,
                790,
                798,
                800,
                803,
                809,
                818,
                823,
                825,
                827,
                833,
                838,
                840,
                843,
                846,
                849,
                875,
                894,
                895,
                901,
                908,
                909,
                912,
                930,
                932,
                938,
                941,
                948,
                954,
                962,
                965,
                970,
                977,
                999,
                1004,
                1006,
                1024,
                1027,
                1030,
                1031,
                1035,
                1036,
                1053,
                1056,
                1063,
                1065,
                1066,
                1069,
                1070,
                1074,
                1090,
                1094,
                1095,
                1096,
                1109,
                1112,
                1117,
                1121,
                1122,
                1124,
                1128,
                1129,
                1134,
                1145,
                1148,
                1155,
                1157,
                1160,
                1170,
                1179,
                1188,
                1191,
                1201,
                1203,
                1215,
                1219,
                1221,
                1226,
                1230,
                1238,
                1239,
                1245,
                1254,
                1259,
                1260,
                1261,
                1265,
                1278,
                1291,
                1292,
                1302,
                1308,
                1311,
                1322,
                1327,
                1330,
                1333,
                1334,
                1339,
                1344,
                1354,
                1357,
                1363,
                1366,
                1374,
                1387,
                1401,
                1417,
                1423,
                1433,
                1436,
                1441,
                1445,
                1450,
                1451,
                1452,
                1454,
                1456,
                1458,
                1462,
                1463,
                1472,
                1474,
                1481,
                1485,
                1486,
                1493,
                1498,
                1532,
                1533,
                1535,
                1539,
                1540,
                1545,
                1555,
                1556,
                1576,
                1586,
                1592,
                1606,
                1611,
                1616,
                1617,
                1618,
                1623,
                1625,
                1628,
                1636,
                1640,
                1646,
                1653,
                1654,
                1672,
                1688,
                1696,
                1703,
                1707,
                1711,
                1722,
                1728,
                1732,
                1734,
                1739,
                1740,
                1746,
                1753,
                1755,
                1759,
                1760,
                1762,
                1764,
                1767,
                1769,
                1770,
                1773,
                1776,
                1787,
                1796,
                1802,
                1810,
                1812,
                1815,
                1848,
                1854,
                1858,
                1861,
                1864,
                1867,
                1875,
                1876,
                1879,
                1907,
                1909,
                1922,
                1935,
                1941,
                1952,
                1954,
                1971,
                1972,
                1977,
                1981,
                1997,
                2000,
                2002,
                2004,
                2005,
                2015,
                2022,
                2029,
                2034,
                2035,
                2041,
                2048,
                2051,
                2054,
                2064,
                2066,
                2081,
                2085,
                2092,
                2100,
                2103,
                2140,
                2155,
                2159,
                2168,
                2171,
                2173,
                2179,
                2184,
                2191,
                2194,
                2198,
                2202,
                2206,
                2214,
                2215,
                2219,
                2228,
                2231,
                2232,
                2245,
                2251,
                2266,
                2267,
                2271,
                2274,
                2282,
                2285,
                2287,
                2291,
                2299,
                2313,
                2317,
                2318,
                2320,
                2326,
                2329,
                2340,
                2341,
                2356,
                2360,
                2361,
                2365,
                2371,
                2376,
                2380,
                2383,
                2387,
                2390,
                2391,
                2420,
                2425,
                2429,
                2443,
                2450,
                2467,
                2481,
                2482,
                2488,
                2496,
                2502,
                2513,
                2516,
                2520,
                2530,
                2533,
                2535,
                2538,
                2540,
                2541,
                2547,
                2550,
                2556,
                2557,
                2588,
                2589,
                2593,
                2595,
                2600,
                2603,
                2628,
                2640,
                2641,
                2650,
                2654,
                2660,
                2661,
                2662,
                2670,
                2679,
                2680,
                2695,
                2697,
                2698,
                2703,
                2707,
                2708,
                2711,
                2721,
                2722,
                2729,
                2730,
                2733,
                2749,
                2752,
                2756,
                2764,
                2767,
                2772,
                2794,
                2809,
                2810,
                2814,
                2948,
                2951,
                2952,
                2953
            ],
            "children": [
                {
                    "label": "sentiment_analysis",
                    "description": "The task of determining the emotional tone behind a body of text, often used to gauge public opinion or customer feedback.",
                    "level": 1,
                    "example_papers": [
                        [
                            48,
                            "Overcome Noise and Bias: Segmentation-Aided Multi-Granularity Denoising and Debiasing for Enhanced Quarduples Extraction in Dialogue"
                        ],
                        [
                            108,
                            "An Effective Deployment of Diffusion LM for Data Augmentation in Low-Resource Sentiment Classification"
                        ],
                        [
                            687,
                            "Leveraging Estimated Transferability Over Human Intuition for Model Selection in Text Ranking"
                        ],
                        [
                            938,
                            "RAFT: Realistic Attacks to Fool Text Detectors"
                        ],
                        [
                            1170,
                            "I love pineapple on pizza != I hate pineapple on pizza: Stance-Aware Sentence Transformers for Opinion Mining"
                        ],
                        [
                            1462,
                            "Ukrainian Resilience: A Dataset for Detection of Help-Seeking Signals Amidst the Chaos of War"
                        ],
                        [
                            1732,
                            "Stanceformer: Target-Aware Transformer for Stance Detection"
                        ],
                        [
                            2450,
                            "Optimal and efficient text counterfactuals using Graph Neural Networks"
                        ],
                        [
                            2695,
                            "A Two-Model Approach for Humour Style Recognition"
                        ]
                    ],
                    "paper_ids": [
                        48,
                        108,
                        687,
                        938,
                        1170,
                        1462,
                        1732,
                        2450,
                        2695
                    ],
                    "children": [
                        {
                            "label": "aspect_based_sentiment_analysis",
                            "description": "This subtopic focuses on analyzing sentiments related to specific aspects or features of products or services, allowing for a more granular understanding of customer opinions.",
                            "level": 2,
                            "example_papers": [
                                [
                                    48,
                                    "Overcome Noise and Bias: Segmentation-Aided Multi-Granularity Denoising and Debiasing for Enhanced Quarduples Extraction in Dialogue"
                                ],
                                [
                                    1170,
                                    "I love pineapple on pizza != I hate pineapple on pizza: Stance-Aware Sentence Transformers for Opinion Mining"
                                ],
                                [
                                    1732,
                                    "Stanceformer: Target-Aware Transformer for Stance Detection"
                                ]
                            ],
                            "paper_ids": [
                                48,
                                1170,
                                1732
                            ]
                        },
                        {
                            "label": "emotion_classification",
                            "description": "This subtopic involves categorizing text based on the emotional states expressed within, such as happiness, sadness, anger, or fear, to better understand the emotional tone of the content.",
                            "level": 2
                        },
                        {
                            "label": "sarcasm_detection",
                            "description": "This subtopic aims to identify and interpret sarcastic remarks in text, which can often convey sentiments that differ from their literal meanings.",
                            "level": 2,
                            "example_papers": [
                                [
                                    1170,
                                    "I love pineapple on pizza != I hate pineapple on pizza: Stance-Aware Sentence Transformers for Opinion Mining"
                                ]
                            ],
                            "paper_ids": [
                                1170
                            ]
                        },
                        {
                            "label": "multimodal_sentiment_analysis",
                            "description": "This subtopic integrates multiple data modalities, such as text, audio, and visual elements, to enhance the accuracy of sentiment detection and analysis.",
                            "level": 2,
                            "example_papers": [
                                [
                                    687,
                                    "Leveraging Estimated Transferability Over Human Intuition for Model Selection in Text Ranking"
                                ],
                                [
                                    1170,
                                    "I love pineapple on pizza != I hate pineapple on pizza: Stance-Aware Sentence Transformers for Opinion Mining"
                                ]
                            ],
                            "paper_ids": [
                                687,
                                1170
                            ]
                        },
                        {
                            "label": "depression_detection",
                            "description": "This subtopic focuses on identifying signs of depression in text, which can be crucial for mental health assessments and interventions.",
                            "level": 2,
                            "example_papers": [
                                [
                                    1170,
                                    "I love pineapple on pizza != I hate pineapple on pizza: Stance-Aware Sentence Transformers for Opinion Mining"
                                ]
                            ],
                            "paper_ids": [
                                1170
                            ]
                        }
                    ]
                },
                {
                    "label": "spam_detection",
                    "description": "The process of identifying and filtering out unwanted or harmful messages, typically in email or messaging systems, based on their content.",
                    "level": 2,
                    "example_papers": [
                        [
                            687,
                            "Leveraging Estimated Transferability Over Human Intuition for Model Selection in Text Ranking"
                        ],
                        [
                            938,
                            "RAFT: Realistic Attacks to Fool Text Detectors"
                        ],
                        [
                            1366,
                            "KorSmishing Explainer: A Korean-centric LLM-based Framework for Smishing Detection and Explanation Generation"
                        ]
                    ],
                    "paper_ids": [
                        687,
                        938,
                        1366
                    ]
                },
                {
                    "label": "multi_label_classification",
                    "description": "A classification task where each instance can be assigned multiple labels, allowing for more complex categorization of text documents.",
                    "level": 2,
                    "example_papers": [
                        [
                            42,
                            "Parameter-Efficient Sparsity Crafting from Dense to Mixture-of-Experts for Instruction Tuning on General Tasks"
                        ],
                        [
                            101,
                            "MetaGPT: Merging Large Language Models Using Model Exclusive Task Arithmetic"
                        ],
                        [
                            108,
                            "An Effective Deployment of Diffusion LM for Data Augmentation in Low-Resource Sentiment Classification"
                        ],
                        [
                            149,
                            "Collaborative Performance Prediction for Large Language Models"
                        ],
                        [
                            163,
                            "Alignment-Enhanced Decoding: Defending Jailbreaks via Token-Level Adaptive Refining of Probability Distributions"
                        ],
                        [
                            169,
                            "DGLF: A Dual Graph-based Learning Framework for Multi-modal Sarcasm Detection"
                        ],
                        [
                            214,
                            "Performance-Guided LLM Knowledge Distillation for Efficient Text Classification at Scale"
                        ],
                        [
                            218,
                            "Text Grafting: Near-Distribution Weak Supervision for Minority Classes in Text Classification"
                        ],
                        [
                            219,
                            "Incubating Text Classifiers Following User Instruction with Nothing but LLM"
                        ],
                        [
                            225,
                            "PRompt Optimization in Multi-Step Tasks (PROMST): Integrating Human Feedback and Heuristic-based Sampling"
                        ]
                    ],
                    "paper_ids": [
                        42,
                        101,
                        108,
                        149,
                        163,
                        169,
                        214,
                        218,
                        219,
                        225,
                        272,
                        305,
                        332,
                        349,
                        388,
                        407,
                        409,
                        480,
                        530,
                        549,
                        557,
                        595,
                        631,
                        639,
                        654,
                        658,
                        663,
                        668,
                        675,
                        687,
                        748,
                        798,
                        823,
                        827,
                        833,
                        840,
                        843,
                        846,
                        849,
                        875,
                        894,
                        908,
                        930,
                        938,
                        948,
                        954,
                        962,
                        970,
                        1024,
                        1030,
                        1035,
                        1036,
                        1053,
                        1056,
                        1065,
                        1070,
                        1090,
                        1112,
                        1122,
                        1129,
                        1157,
                        1179,
                        1188,
                        1201,
                        1254,
                        1261,
                        1265,
                        1291,
                        1302,
                        1311,
                        1333,
                        1354,
                        1363,
                        1374,
                        1401,
                        1417,
                        1454,
                        1456,
                        1458,
                        1472,
                        1539,
                        1540,
                        1545,
                        1586,
                        1592,
                        1606,
                        1611,
                        1616,
                        1623,
                        1653,
                        1654,
                        1672,
                        1688,
                        1696,
                        1722,
                        1732,
                        1755,
                        1767,
                        1770,
                        1773,
                        1787,
                        1796,
                        1815,
                        1848,
                        1854,
                        1858,
                        1867,
                        1935,
                        1971,
                        2004,
                        2066,
                        2081,
                        2085,
                        2092,
                        2100,
                        2103,
                        2155,
                        2179,
                        2191,
                        2194,
                        2198,
                        2232,
                        2245,
                        2271,
                        2274,
                        2285,
                        2287,
                        2317,
                        2320,
                        2326,
                        2365,
                        2390,
                        2425,
                        2450,
                        2502,
                        2520,
                        2533,
                        2538,
                        2541,
                        2557,
                        2595,
                        2600,
                        2641,
                        2708,
                        2730,
                        2951
                    ],
                    "children": [
                        {
                            "label": "adversarial_methods",
                            "description": "This cluster encompasses techniques focused on adversarial attacks and training methods aimed at enhancing the robustness of multi-label classification models.",
                            "level": 3,
                            "example_papers": [
                                [
                                    163,
                                    "Alignment-Enhanced Decoding: Defending Jailbreaks via Token-Level Adaptive Refining of Probability Distributions"
                                ],
                                [
                                    480,
                                    "The Best Defense is Attack: Repairing Semantics in Textual Adversarial Examples"
                                ],
                                [
                                    833,
                                    "Shortcuts Arising from Contrast: Towards Effective and Lightweight Clean-Label Attacks in Prompt-Based Learning"
                                ],
                                [
                                    894,
                                    "MLLM-Protector: Ensuring MLLM's Safety without Hurting Performance"
                                ],
                                [
                                    938,
                                    "RAFT: Realistic Attacks to Fool Text Detectors"
                                ],
                                [
                                    1053,
                                    "Argument Relation Classification through Discourse Markers and Adversarial Training"
                                ],
                                [
                                    1179,
                                    "Adapters Mixup: Mixing Parameter-Efficient Adapters to Enhance the Adversarial Robustness of Fine-tuned Pre-trained Text Classifiers"
                                ],
                                [
                                    1815,
                                    "Authorship Obfuscation in Multilingual Machine-Generated Text Detection"
                                ],
                                [
                                    2081,
                                    "CERT-ED: Certifiably Robust Text Classification for Edit Distance"
                                ],
                                [
                                    2191,
                                    "Robust Text Classification: Analyzing Prototype-Based Networks"
                                ]
                            ],
                            "paper_ids": [
                                163,
                                480,
                                833,
                                894,
                                938,
                                1053,
                                1179,
                                1815,
                                2081,
                                2191
                            ]
                        },
                        {
                            "label": "prompt_based_techniques",
                            "description": "This cluster includes various prompt optimization, engineering, and tuning methods that leverage prompts to improve multi-label classification performance.",
                            "level": 3,
                            "example_papers": [
                                [
                                    219,
                                    "Incubating Text Classifiers Following User Instruction with Nothing but LLM"
                                ],
                                [
                                    225,
                                    "PRompt Optimization in Multi-Step Tasks (PROMST): Integrating Human Feedback and Heuristic-based Sampling"
                                ],
                                [
                                    305,
                                    "How Far Can We Extract Diverse Perspectives from Large Language Models?"
                                ],
                                [
                                    349,
                                    "SciPrompt: Knowledge-augmented Prompting for Fine-grained Categorization of Scientific Topics"
                                ],
                                [
                                    748,
                                    "Leveraging Context-Aware Prompting for Commit Message Generation"
                                ],
                                [
                                    833,
                                    "Shortcuts Arising from Contrast: Towards Effective and Lightweight Clean-Label Attacks in Prompt-Based Learning"
                                ],
                                [
                                    849,
                                    "Control Large Language Models via Divide and Conquer"
                                ],
                                [
                                    1056,
                                    "Efficient Unseen Language Adaptation for Multilingual Pre-Trained Language Models"
                                ],
                                [
                                    1129,
                                    "AMPO: Automatic Multi-Branched Prompt Optimization"
                                ],
                                [
                                    1254,
                                    "Improving Minimum Bayes Risk Decoding with Multi-Prompt"
                                ]
                            ],
                            "paper_ids": [
                                219,
                                225,
                                305,
                                349,
                                748,
                                833,
                                849,
                                1056,
                                1129,
                                1254,
                                1354,
                                1374,
                                1456,
                                1611,
                                2092,
                                2155,
                                2287,
                                2317,
                                2390
                            ]
                        },
                        {
                            "label": "learning_strategies",
                            "description": "This cluster covers diverse learning strategies such as zero-shot learning, few-shot learning, and active learning that facilitate effective multi-label classification in various contexts.",
                            "level": 3,
                            "example_papers": [
                                [
                                    42,
                                    "Parameter-Efficient Sparsity Crafting from Dense to Mixture-of-Experts for Instruction Tuning on General Tasks"
                                ],
                                [
                                    101,
                                    "MetaGPT: Merging Large Language Models Using Model Exclusive Task Arithmetic"
                                ],
                                [
                                    214,
                                    "Performance-Guided LLM Knowledge Distillation for Efficient Text Classification at Scale"
                                ],
                                [
                                    332,
                                    "Teaching Small Language Models Reasoning through Counterfactual Distillation"
                                ],
                                [
                                    407,
                                    "Python is Not Always the Best Choice: Embracing Multilingual Program of Thoughts"
                                ],
                                [
                                    409,
                                    "Incomplete Utterance Rewriting with Editing Operation Guidance and Utterance Augmentation"
                                ],
                                [
                                    549,
                                    "Can Transformers Learn n-gram Language Models?"
                                ],
                                [
                                    557,
                                    "MMoE: Enhancing Multimodal Models with Mixtures of Multimodal Interaction Experts"
                                ],
                                [
                                    639,
                                    "Text2Chart31: Instruction Tuning for Chart Generation with Automatic Feedback"
                                ],
                                [
                                    654,
                                    "MARE: Multi-Aspect Rationale Extractor on Unsupervised Rationale Extraction"
                                ]
                            ],
                            "paper_ids": [
                                42,
                                101,
                                214,
                                332,
                                407,
                                409,
                                549,
                                557,
                                639,
                                654,
                                663,
                                668,
                                675,
                                687,
                                840,
                                846,
                                875,
                                962,
                                1030,
                                1035,
                                1036,
                                1090,
                                1157,
                                1188,
                                1201,
                                1333,
                                1354,
                                1454,
                                1456,
                                1458,
                                1472,
                                1540,
                                1586,
                                1592,
                                1606,
                                1616,
                                1653,
                                1654,
                                1688,
                                1755,
                                1767,
                                1787,
                                1796,
                                1935,
                                1971,
                                2004,
                                2100,
                                2194,
                                2274,
                                2390,
                                2541,
                                2557,
                                2595
                            ]
                        },
                        {
                            "label": "data_handling_and_augmentation",
                            "description": "This cluster focuses on methods related to data augmentation, selection, and preprocessing techniques that enhance the quality and quantity of training data for multi-label classification.",
                            "level": 3,
                            "example_papers": [
                                [
                                    108,
                                    "An Effective Deployment of Diffusion LM for Data Augmentation in Low-Resource Sentiment Classification"
                                ],
                                [
                                    218,
                                    "Text Grafting: Near-Distribution Weak Supervision for Minority Classes in Text Classification"
                                ],
                                [
                                    219,
                                    "Incubating Text Classifiers Following User Instruction with Nothing but LLM"
                                ],
                                [
                                    407,
                                    "Python is Not Always the Best Choice: Embracing Multilingual Program of Thoughts"
                                ],
                                [
                                    409,
                                    "Incomplete Utterance Rewriting with Editing Operation Guidance and Utterance Augmentation"
                                ],
                                [
                                    675,
                                    "TL-CL: Task And Language Incremental Continual Learning"
                                ],
                                [
                                    798,
                                    "Distractor Generation in Multiple-Choice Tasks: A Survey of Methods, Datasets, and Evaluation"
                                ],
                                [
                                    823,
                                    "Building Resources for Emakhuwa: Machine Translation and News Classification Benchmarks"
                                ],
                                [
                                    827,
                                    "Leveraging BERT and TFIDF Features for Short Text Clustering via Alignment-Promoting Co-Training"
                                ],
                                [
                                    840,
                                    "Open-world Multi-label Text Classification with Extremely Weak Supervision"
                                ]
                            ],
                            "paper_ids": [
                                108,
                                218,
                                219,
                                407,
                                409,
                                675,
                                798,
                                823,
                                827,
                                840,
                                846,
                                908,
                                954,
                                1065,
                                1070,
                                1201,
                                1265,
                                1311,
                                1363,
                                1401,
                                1417,
                                1539,
                                1586,
                                1672,
                                1770,
                                1773,
                                1815,
                                1848,
                                2085,
                                2179,
                                2198,
                                2232,
                                2271,
                                2285,
                                2326,
                                2365,
                                2390,
                                2538
                            ]
                        },
                        {
                            "label": "evaluation_and_analysis",
                            "description": "This cluster includes techniques for model evaluation, performance prediction, and analysis methods that assess the effectiveness and fairness of multi-label classification systems.",
                            "level": 3,
                            "example_papers": [
                                [
                                    149,
                                    "Collaborative Performance Prediction for Large Language Models"
                                ],
                                [
                                    214,
                                    "Performance-Guided LLM Knowledge Distillation for Efficient Text Classification at Scale"
                                ],
                                [
                                    219,
                                    "Incubating Text Classifiers Following User Instruction with Nothing but LLM"
                                ],
                                [
                                    272,
                                    "Bayesian Calibration of Win Rate Estimation with LLM Evaluators"
                                ],
                                [
                                    388,
                                    "Efficient LLM Comparative Assessment: A Product of Experts Framework for Pairwise Comparisons"
                                ],
                                [
                                    530,
                                    "Enhancing Systematic Decompositional Natural Language Inference Using Informal Logic"
                                ],
                                [
                                    549,
                                    "Can Transformers Learn n-gram Language Models?"
                                ],
                                [
                                    557,
                                    "MMoE: Enhancing Multimodal Models with Mixtures of Multimodal Interaction Experts"
                                ],
                                [
                                    631,
                                    "CodeAgent: Autonomous Communicative Agents for Code Review"
                                ],
                                [
                                    654,
                                    "MARE: Multi-Aspect Rationale Extractor on Unsupervised Rationale Extraction"
                                ]
                            ],
                            "paper_ids": [
                                149,
                                214,
                                219,
                                272,
                                388,
                                530,
                                549,
                                557,
                                631,
                                654,
                                658,
                                668,
                                687,
                                823,
                                840,
                                843,
                                846,
                                875,
                                930,
                                948,
                                954,
                                962,
                                970,
                                1024,
                                1036,
                                1065,
                                1090,
                                1112,
                                1122,
                                1261,
                                1311,
                                1354,
                                1401,
                                1472,
                                1540,
                                1545,
                                1592,
                                1606,
                                1654,
                                1672,
                                1722,
                                1732,
                                1796,
                                1815,
                                1848,
                                1858,
                                1867,
                                2066,
                                2103,
                                2245,
                                2320,
                                2326,
                                2365,
                                2390,
                                2425,
                                2450,
                                2502,
                                2520,
                                2538,
                                2600,
                                2641,
                                2708,
                                2730,
                                2951
                            ]
                        }
                    ]
                },
                {
                    "label": "document_classification",
                    "description": "The task of categorizing entire documents into predefined categories based on their content, often used in organizing large datasets.",
                    "level": 2,
                    "example_papers": [
                        [
                            39,
                            "Tokenization Is More Than Compression"
                        ],
                        [
                            42,
                            "Parameter-Efficient Sparsity Crafting from Dense to Mixture-of-Experts for Instruction Tuning on General Tasks"
                        ],
                        [
                            149,
                            "Collaborative Performance Prediction for Large Language Models"
                        ],
                        [
                            169,
                            "DGLF: A Dual Graph-based Learning Framework for Multi-modal Sarcasm Detection"
                        ],
                        [
                            186,
                            "ScalingFilter: Assessing Data Quality through Inverse Utilization of Scaling Laws"
                        ],
                        [
                            207,
                            "A Generic Method for Fine-grained Category Discovery in Natural Language Texts"
                        ],
                        [
                            214,
                            "Performance-Guided LLM Knowledge Distillation for Efficient Text Classification at Scale"
                        ],
                        [
                            218,
                            "Text Grafting: Near-Distribution Weak Supervision for Minority Classes in Text Classification"
                        ],
                        [
                            219,
                            "Incubating Text Classifiers Following User Instruction with Nothing but LLM"
                        ],
                        [
                            235,
                            "When Is Multilinguality a Curse? Language Modeling for 250 High- and Low-Resource Languages"
                        ]
                    ],
                    "paper_ids": [
                        39,
                        42,
                        149,
                        169,
                        186,
                        207,
                        214,
                        218,
                        219,
                        235,
                        272,
                        292,
                        349,
                        367,
                        388,
                        391,
                        422,
                        454,
                        480,
                        496,
                        530,
                        549,
                        550,
                        561,
                        566,
                        579,
                        591,
                        607,
                        615,
                        631,
                        637,
                        639,
                        662,
                        663,
                        664,
                        668,
                        687,
                        689,
                        732,
                        741,
                        748,
                        773,
                        776,
                        798,
                        823,
                        827,
                        833,
                        838,
                        840,
                        843,
                        846,
                        849,
                        875,
                        901,
                        908,
                        938,
                        948,
                        954,
                        970,
                        999,
                        1024,
                        1035,
                        1036,
                        1053,
                        1056,
                        1065,
                        1066,
                        1070,
                        1074,
                        1090,
                        1094,
                        1096,
                        1112,
                        1155,
                        1179,
                        1201,
                        1215,
                        1221,
                        1230,
                        1259,
                        1261,
                        1265,
                        1291,
                        1302,
                        1311,
                        1330,
                        1333,
                        1339,
                        1344,
                        1357,
                        1363,
                        1445,
                        1454,
                        1456,
                        1458,
                        1463,
                        1472,
                        1532,
                        1539,
                        1545,
                        1555,
                        1606,
                        1611,
                        1616,
                        1623,
                        1640,
                        1653,
                        1696,
                        1703,
                        1728,
                        1732,
                        1760,
                        1767,
                        1773,
                        1776,
                        1787,
                        1802,
                        1815,
                        1858,
                        1867,
                        1879,
                        1907,
                        1981,
                        2004,
                        2029,
                        2041,
                        2048,
                        2054,
                        2081,
                        2085,
                        2092,
                        2100,
                        2103,
                        2140,
                        2173,
                        2179,
                        2191,
                        2198,
                        2202,
                        2232,
                        2245,
                        2267,
                        2287,
                        2313,
                        2320,
                        2326,
                        2356,
                        2360,
                        2371,
                        2376,
                        2390,
                        2420,
                        2450,
                        2482,
                        2502,
                        2533,
                        2538,
                        2541,
                        2557,
                        2593,
                        2595,
                        2640,
                        2641,
                        2650,
                        2660,
                        2661,
                        2680,
                        2697,
                        2707,
                        2708,
                        2711,
                        2722,
                        2764,
                        2809,
                        2952,
                        2953
                    ],
                    "children": [
                        {
                            "label": "text_quality_evaluation",
                            "description": "The task of assessing the quality of text documents based on various criteria, ensuring that they meet specific standards for classification purposes.",
                            "level": 3,
                            "example_papers": [
                                [
                                    186,
                                    "ScalingFilter: Assessing Data Quality through Inverse Utilization of Scaling Laws"
                                ],
                                [
                                    272,
                                    "Bayesian Calibration of Win Rate Estimation with LLM Evaluators"
                                ],
                                [
                                    480,
                                    "The Best Defense is Attack: Repairing Semantics in Textual Adversarial Examples"
                                ],
                                [
                                    631,
                                    "CodeAgent: Autonomous Communicative Agents for Code Review"
                                ],
                                [
                                    662,
                                    "Advancing Semantic Textual Similarity Modeling: A Regression Framework with Translated ReLU and Smooth K2 Loss"
                                ],
                                [
                                    798,
                                    "Distractor Generation in Multiple-Choice Tasks: A Survey of Methods, Datasets, and Evaluation"
                                ],
                                [
                                    843,
                                    "CopyBench: Measuring Literal and Non-Literal Reproduction of Copyright-Protected Text in Language Model Generation"
                                ],
                                [
                                    938,
                                    "RAFT: Realistic Attacks to Fool Text Detectors"
                                ],
                                [
                                    948,
                                    "Foundational Autoraters: Taming Large Language Models for Better Automatic Evaluation"
                                ],
                                [
                                    1096,
                                    "Evaluating Diversity in Automatic Poetry Generation"
                                ]
                            ],
                            "paper_ids": [
                                186,
                                272,
                                480,
                                631,
                                662,
                                798,
                                843,
                                938,
                                948,
                                1096,
                                1261,
                                1265,
                                1302,
                                1339,
                                1344,
                                1363,
                                1456,
                                1532,
                                1728,
                                1773,
                                2041,
                                2173,
                                2356,
                                2502,
                                2533,
                                2660,
                                2953
                            ]
                        },
                        {
                            "label": "genre_classification",
                            "description": "The process of categorizing documents into distinct genres, such as fiction, non-fiction, academic, or technical, based on their content and style.",
                            "level": 3,
                            "example_papers": [
                                [
                                    1096,
                                    "Evaluating Diversity in Automatic Poetry Generation"
                                ],
                                [
                                    1112,
                                    "The Empirical Variability of Narrative Perceptions of Social Media Texts"
                                ],
                                [
                                    1879,
                                    "HiCuLR: Hierarchical Curriculum Learning for Rhetorical Role Labeling of Legal Documents"
                                ],
                                [
                                    2360,
                                    "Sonnet or Not, Bot? Poetry Evaluation for Large Models and Datasets"
                                ],
                                [
                                    2708,
                                    "Intersecting Register and Genre: Understanding the Contents of Web-Crawled Corpora"
                                ],
                                [
                                    2722,
                                    "CIPHE: A Framework for Document Cluster Interpretation and Precision from Human Exploration"
                                ]
                            ],
                            "paper_ids": [
                                1096,
                                1112,
                                1879,
                                2360,
                                2708,
                                2722
                            ]
                        },
                        {
                            "label": "news_classification",
                            "description": "The task of categorizing news articles into predefined categories, such as politics, sports, entertainment, and technology, to facilitate better organization and retrieval.",
                            "level": 3,
                            "example_papers": [
                                [
                                    823,
                                    "Building Resources for Emakhuwa: Machine Translation and News Classification Benchmarks"
                                ],
                                [
                                    1215,
                                    "Do LLMs Plan Like Human Writers? Comparing Journalist Coverage of Press Releases with LLMs"
                                ],
                                [
                                    1907,
                                    "Multilingual Fine-Grained News Headline Hallucination Detection"
                                ],
                                [
                                    2004,
                                    "Train Once, Use Flexibly: A Modular Framework for Multi-Aspect Neural News Recommendation"
                                ],
                                [
                                    2376,
                                    "Explaining Mixtures of Sources in News Articles"
                                ],
                                [
                                    2952,
                                    "Media Framing through the Lens of Event-Centric Narratives"
                                ]
                            ],
                            "paper_ids": [
                                823,
                                1215,
                                1907,
                                2004,
                                2376,
                                2952
                            ]
                        },
                        {
                            "label": "long_document_classification",
                            "description": "The specialized task of classifying lengthy documents, which may require different techniques and considerations compared to shorter texts.",
                            "level": 3,
                            "example_papers": [
                                [
                                    496,
                                    "Jellyfish: Instruction-Tuning Local Large Language Models for Data Preprocessing"
                                ],
                                [
                                    1036,
                                    "Recurrent Alignment with Hard Attention for Hierarchical Text Rating"
                                ],
                                [
                                    1155,
                                    "Automatic sentence segmentation of clinical record narratives in real-world data"
                                ],
                                [
                                    1640,
                                    "Divide and Conquer: Legal Concept-guided Criminal Court View Generation"
                                ],
                                [
                                    1703,
                                    "Graph-tree Fusion Model with Bidirectional Information Propagation for Long Document Classification"
                                ],
                                [
                                    1760,
                                    "LOCR: Location-Guided Transformer for Optical Character Recognition"
                                ],
                                [
                                    1773,
                                    "LongWanjuan: Towards Systematic Measurement for Long Text Quality"
                                ],
                                [
                                    1879,
                                    "HiCuLR: Hierarchical Curriculum Learning for Rhetorical Role Labeling of Legal Documents"
                                ],
                                [
                                    2054,
                                    "Detecting Machine-Generated Long-Form Content with Latent-Space Variables"
                                ],
                                [
                                    2085,
                                    "Mental Disorder Classification via Temporal Representation of Text"
                                ]
                            ],
                            "paper_ids": [
                                496,
                                1036,
                                1155,
                                1640,
                                1703,
                                1760,
                                1773,
                                1879,
                                2054,
                                2085,
                                2140,
                                2376,
                                2641,
                                2650,
                                2680,
                                2809
                            ]
                        },
                        {
                            "label": "multi_label_text_classification",
                            "description": "The task of assigning multiple labels to a single document, allowing for a more nuanced categorization that reflects the complexity of its content.",
                            "level": 3,
                            "example_papers": [
                                [
                                    39,
                                    "Tokenization Is More Than Compression"
                                ],
                                [
                                    42,
                                    "Parameter-Efficient Sparsity Crafting from Dense to Mixture-of-Experts for Instruction Tuning on General Tasks"
                                ],
                                [
                                    207,
                                    "A Generic Method for Fine-grained Category Discovery in Natural Language Texts"
                                ],
                                [
                                    214,
                                    "Performance-Guided LLM Knowledge Distillation for Efficient Text Classification at Scale"
                                ],
                                [
                                    218,
                                    "Text Grafting: Near-Distribution Weak Supervision for Minority Classes in Text Classification"
                                ],
                                [
                                    219,
                                    "Incubating Text Classifiers Following User Instruction with Nothing but LLM"
                                ],
                                [
                                    292,
                                    "Academics Can Contribute to Domain-Specialized Language Models"
                                ],
                                [
                                    349,
                                    "SciPrompt: Knowledge-augmented Prompting for Fine-grained Categorization of Scientific Topics"
                                ],
                                [
                                    367,
                                    "Detection and Measurement of Syntactic Templates in Generated Text"
                                ],
                                [
                                    388,
                                    "Efficient LLM Comparative Assessment: A Product of Experts Framework for Pairwise Comparisons"
                                ]
                            ],
                            "paper_ids": [
                                39,
                                42,
                                207,
                                214,
                                218,
                                219,
                                292,
                                349,
                                367,
                                388,
                                391,
                                422,
                                454,
                                530,
                                549,
                                550,
                                561,
                                566,
                                579,
                                591,
                                607,
                                615,
                                637,
                                639,
                                663,
                                664,
                                668,
                                687,
                                689,
                                732,
                                741,
                                748,
                                773,
                                776,
                                827,
                                833,
                                838,
                                840,
                                846,
                                849,
                                875,
                                901,
                                908,
                                954,
                                970,
                                999,
                                1024,
                                1035,
                                1036,
                                1053,
                                1056,
                                1065,
                                1066,
                                1070,
                                1074,
                                1090,
                                1094,
                                1096,
                                1112,
                                1201,
                                1215,
                                1230,
                                1259,
                                1311,
                                1330,
                                1333,
                                1357,
                                1445,
                                1454,
                                1458,
                                1463,
                                1472,
                                1539,
                                1545,
                                1555,
                                1606,
                                1611,
                                1616,
                                1623,
                                1640,
                                1696,
                                1767,
                                1776,
                                1787,
                                1802,
                                1815,
                                1858,
                                1867,
                                1879,
                                1981,
                                2029,
                                2041,
                                2048,
                                2081,
                                2085,
                                2092,
                                2100,
                                2103,
                                2179,
                                2191,
                                2198,
                                2202,
                                2232,
                                2267,
                                2287,
                                2313,
                                2320,
                                2371,
                                2390,
                                2420,
                                2450,
                                2482,
                                2502,
                                2538,
                                2541,
                                2557,
                                2595,
                                2640,
                                2641,
                                2661,
                                2707,
                                2708,
                                2711,
                                2722,
                                2764
                            ]
                        }
                    ]
                },
                {
                    "label": "intent_classification",
                    "description": "The process of identifying the intention behind a user's input, commonly used in conversational agents and chatbots to determine appropriate responses.",
                    "level": 2,
                    "example_papers": [
                        [
                            13,
                            "A Usage-centric Take on Intent Understanding in E-Commerce"
                        ],
                        [
                            169,
                            "DGLF: A Dual Graph-based Learning Framework for Multi-modal Sarcasm Detection"
                        ],
                        [
                            214,
                            "Performance-Guided LLM Knowledge Distillation for Efficient Text Classification at Scale"
                        ],
                        [
                            219,
                            "Incubating Text Classifiers Following User Instruction with Nothing but LLM"
                        ],
                        [
                            436,
                            "MORPHEUS: Modeling Role from Personalized Dialogue History by Exploring and Utilizing Latent Space"
                        ],
                        [
                            550,
                            "StablePrompt : Automatic Prompt Tuning using Reinforcement Learning for Large Language Model"
                        ],
                        [
                            594,
                            "Speechworthy Instruction-tuned Language Models"
                        ],
                        [
                            615,
                            "What are the Generator Preferences for End-to-end Task-Oriented Dialog System?"
                        ],
                        [
                            687,
                            "Leveraging Estimated Transferability Over Human Intuition for Model Selection in Text Ranking"
                        ],
                        [
                            704,
                            "Enhancing AI Assisted Writing with One-Shot Implicit Negative Feedback"
                        ]
                    ],
                    "paper_ids": [
                        13,
                        169,
                        214,
                        219,
                        436,
                        550,
                        594,
                        615,
                        687,
                        704,
                        803,
                        833,
                        838,
                        1035,
                        1056,
                        1069,
                        1160,
                        1191,
                        1330,
                        1387,
                        1401,
                        1433,
                        1586,
                        1617,
                        1732,
                        1977,
                        2092,
                        2159,
                        2214,
                        2341,
                        2365,
                        2391,
                        2420,
                        2450,
                        2550,
                        2595,
                        2662
                    ]
                },
                {
                    "label": "event_classification",
                    "description": "The task of categorizing events based on their characteristics and context, often used in information retrieval and content organization.",
                    "level": 2,
                    "example_papers": [
                        [
                            169,
                            "DGLF: A Dual Graph-based Learning Framework for Multi-modal Sarcasm Detection"
                        ],
                        [
                            214,
                            "Performance-Guided LLM Knowledge Distillation for Efficient Text Classification at Scale"
                        ],
                        [
                            219,
                            "Incubating Text Classifiers Following User Instruction with Nothing but LLM"
                        ],
                        [
                            349,
                            "SciPrompt: Knowledge-augmented Prompting for Fine-grained Categorization of Scientific Topics"
                        ],
                        [
                            687,
                            "Leveraging Estimated Transferability Over Human Intuition for Model Selection in Text Ranking"
                        ],
                        [
                            719,
                            "SPEED++: A Multilingual Event Extraction Framework for Epidemic Prediction and Preparedness"
                        ],
                        [
                            833,
                            "Shortcuts Arising from Contrast: Towards Effective and Lightweight Clean-Label Attacks in Prompt-Based Learning"
                        ],
                        [
                            843,
                            "CopyBench: Measuring Literal and Non-Literal Reproduction of Copyright-Protected Text in Language Model Generation"
                        ],
                        [
                            1035,
                            "Instruction Matters: A Simple yet Effective Task Selection for Optimized Instruction Tuning of Specific Tasks"
                        ],
                        [
                            1053,
                            "Argument Relation Classification through Discourse Markers and Adversarial Training"
                        ]
                    ],
                    "paper_ids": [
                        169,
                        214,
                        219,
                        349,
                        687,
                        719,
                        833,
                        843,
                        1035,
                        1053,
                        1056,
                        1094,
                        1481,
                        1493,
                        1732,
                        1922,
                        1972,
                        2092,
                        2219,
                        2380,
                        2450,
                        2540,
                        2589,
                        2595,
                        2733,
                        2952
                    ]
                },
                {
                    "label": "knowledge_extraction",
                    "description": "The process of identifying and extracting relevant knowledge from text, enabling better understanding and utilization of information.",
                    "level": 2,
                    "example_papers": [
                        [
                            48,
                            "Overcome Noise and Bias: Segmentation-Aided Multi-Granularity Denoising and Debiasing for Enhanced Quarduples Extraction in Dialogue"
                        ],
                        [
                            53,
                            "Large Language Models for Data Annotation and Synthesis: A Survey"
                        ],
                        [
                            56,
                            "RoseLoRA: Row and Column-wise Sparse Low-rank Adaptation of Pre-trained Language Model for Knowledge Editing and Fine-tuning"
                        ],
                        [
                            58,
                            "HEART-felt Narratives: Tracing Empathy and Narrative Style in Personal Stories with LLMs"
                        ],
                        [
                            65,
                            "AMR-Evol: Adaptive Modular Response Evolution Elicits Better Knowledge Distillation for Large Language Models in Code Generation"
                        ],
                        [
                            67,
                            "Rethinking Pruning Large Language Models: Benefits and Pitfalls of Reconstruction Error Minimization"
                        ],
                        [
                            155,
                            "To Word Senses and Beyond: Inducing Concepts with Contextualized Language Models"
                        ],
                        [
                            186,
                            "ScalingFilter: Assessing Data Quality through Inverse Utilization of Scaling Laws"
                        ],
                        [
                            193,
                            "Pixology: Probing the Linguistic and Visual Capabilities of Pixel-based Language Models"
                        ],
                        [
                            199,
                            "Unsupervised Human Preference Learning"
                        ]
                    ],
                    "paper_ids": [
                        48,
                        53,
                        56,
                        58,
                        65,
                        67,
                        155,
                        186,
                        193,
                        199,
                        214,
                        218,
                        219,
                        276,
                        279,
                        292,
                        294,
                        298,
                        299,
                        305,
                        315,
                        342,
                        349,
                        367,
                        388,
                        390,
                        391,
                        397,
                        402,
                        422,
                        436,
                        460,
                        496,
                        508,
                        511,
                        521,
                        528,
                        544,
                        563,
                        570,
                        573,
                        579,
                        604,
                        607,
                        615,
                        631,
                        639,
                        654,
                        660,
                        687,
                        702,
                        719,
                        746,
                        765,
                        773,
                        818,
                        825,
                        843,
                        895,
                        912,
                        932,
                        938,
                        962,
                        965,
                        977,
                        1027,
                        1030,
                        1035,
                        1053,
                        1056,
                        1065,
                        1074,
                        1090,
                        1094,
                        1117,
                        1121,
                        1124,
                        1134,
                        1191,
                        1221,
                        1226,
                        1238,
                        1245,
                        1259,
                        1260,
                        1265,
                        1278,
                        1322,
                        1333,
                        1339,
                        1344,
                        1445,
                        1450,
                        1451,
                        1452,
                        1463,
                        1472,
                        1474,
                        1485,
                        1486,
                        1493,
                        1498,
                        1535,
                        1539,
                        1576,
                        1616,
                        1618,
                        1625,
                        1636,
                        1640,
                        1707,
                        1732,
                        1734,
                        1739,
                        1759,
                        1760,
                        1762,
                        1764,
                        1770,
                        1787,
                        1810,
                        1861,
                        1864,
                        1876,
                        1922,
                        1941,
                        1952,
                        2022,
                        2029,
                        2034,
                        2041,
                        2092,
                        2173,
                        2184,
                        2206,
                        2215,
                        2219,
                        2232,
                        2251,
                        2267,
                        2282,
                        2287,
                        2299,
                        2318,
                        2329,
                        2340,
                        2371,
                        2376,
                        2420,
                        2429,
                        2443,
                        2450,
                        2467,
                        2481,
                        2496,
                        2535,
                        2547,
                        2556,
                        2588,
                        2595,
                        2628,
                        2650,
                        2654,
                        2660,
                        2661,
                        2670,
                        2679,
                        2680,
                        2697,
                        2698,
                        2703,
                        2711,
                        2721,
                        2730,
                        2733,
                        2756,
                        2764,
                        2767,
                        2809,
                        2810,
                        2951
                    ],
                    "children": [
                        {
                            "label": "text_analysis",
                            "description": "The process of examining and interpreting text data to extract meaningful insights and knowledge.",
                            "level": 3,
                            "example_papers": [
                                [
                                    48,
                                    "Overcome Noise and Bias: Segmentation-Aided Multi-Granularity Denoising and Debiasing for Enhanced Quarduples Extraction in Dialogue"
                                ],
                                [
                                    56,
                                    "RoseLoRA: Row and Column-wise Sparse Low-rank Adaptation of Pre-trained Language Model for Knowledge Editing and Fine-tuning"
                                ],
                                [
                                    58,
                                    "HEART-felt Narratives: Tracing Empathy and Narrative Style in Personal Stories with LLMs"
                                ],
                                [
                                    65,
                                    "AMR-Evol: Adaptive Modular Response Evolution Elicits Better Knowledge Distillation for Large Language Models in Code Generation"
                                ],
                                [
                                    67,
                                    "Rethinking Pruning Large Language Models: Benefits and Pitfalls of Reconstruction Error Minimization"
                                ],
                                [
                                    155,
                                    "To Word Senses and Beyond: Inducing Concepts with Contextualized Language Models"
                                ],
                                [
                                    193,
                                    "Pixology: Probing the Linguistic and Visual Capabilities of Pixel-based Language Models"
                                ],
                                [
                                    199,
                                    "Unsupervised Human Preference Learning"
                                ],
                                [
                                    214,
                                    "Performance-Guided LLM Knowledge Distillation for Efficient Text Classification at Scale"
                                ],
                                [
                                    218,
                                    "Text Grafting: Near-Distribution Weak Supervision for Minority Classes in Text Classification"
                                ]
                            ],
                            "paper_ids": [
                                48,
                                56,
                                58,
                                65,
                                67,
                                155,
                                193,
                                199,
                                214,
                                218,
                                219,
                                276,
                                279,
                                294,
                                298,
                                299,
                                305,
                                342,
                                349,
                                388,
                                390,
                                391,
                                397,
                                402,
                                422,
                                436,
                                460,
                                511,
                                521,
                                528,
                                544,
                                563,
                                570,
                                573,
                                579,
                                604,
                                607,
                                615,
                                631,
                                639,
                                654,
                                660,
                                687,
                                702,
                                765,
                                773,
                                818,
                                825,
                                843,
                                895,
                                912,
                                932,
                                938,
                                962,
                                977,
                                1027,
                                1035,
                                1090,
                                1094,
                                1117,
                                1121,
                                1124,
                                1134,
                                1191,
                                1221,
                                1226,
                                1238,
                                1245,
                                1259,
                                1260,
                                1265,
                                1322,
                                1333,
                                1344,
                                1445,
                                1450,
                                1451,
                                1452,
                                1472,
                                1485,
                                1486,
                                1498,
                                1535,
                                1539,
                                1576,
                                1636,
                                1640,
                                1707,
                                1732,
                                1734,
                                1759,
                                1760,
                                1762,
                                1764,
                                1770,
                                1861,
                                1864,
                                1941,
                                1952,
                                2022,
                                2029,
                                2041,
                                2173,
                                2184,
                                2206,
                                2232,
                                2267,
                                2282,
                                2299,
                                2318,
                                2329,
                                2340,
                                2371,
                                2376,
                                2420,
                                2429,
                                2443,
                                2450,
                                2467,
                                2496,
                                2535,
                                2556,
                                2588,
                                2628,
                                2650,
                                2654,
                                2660,
                                2661,
                                2670,
                                2679,
                                2680,
                                2698,
                                2703,
                                2711,
                                2721,
                                2730,
                                2733,
                                2756,
                                2764,
                                2767,
                                2809,
                                2810,
                                2951
                            ]
                        },
                        {
                            "label": "relation_extraction",
                            "description": "The task of identifying and extracting relationships between entities mentioned in the text.",
                            "level": 3,
                            "example_papers": [
                                [
                                    305,
                                    "How Far Can We Extract Diverse Perspectives from Large Language Models?"
                                ],
                                [
                                    746,
                                    "Grasping the Essentials: Tailoring Large Language Models for Zero-Shot Relation Extraction"
                                ],
                                [
                                    765,
                                    "Topic-Oriented Open Relation Extraction with A Priori Seed Generation"
                                ],
                                [
                                    1053,
                                    "Argument Relation Classification through Discourse Markers and Adversarial Training"
                                ],
                                [
                                    1450,
                                    "General Collaborative Framework between Large Language Model and Experts for Universal Information Extraction"
                                ],
                                [
                                    1493,
                                    "Temporal Cognitive Tree: A Hierarchical Modeling Approach for Event Temporal Relation Extraction"
                                ],
                                [
                                    1640,
                                    "Divide and Conquer: Legal Concept-guided Criminal Court View Generation"
                                ],
                                [
                                    1787,
                                    "Learning to Generate Rules for Realistic Few-Shot Relation Classification: An Encoder-Decoder Approach"
                                ],
                                [
                                    2215,
                                    "Unleashing the Power of Large Language Models in Zero-shot Relation Extraction via Self-Prompting"
                                ],
                                [
                                    2219,
                                    "The Language of Trauma: Modeling Traumatic Event Descriptions Across Domains with Explainable AI"
                                ]
                            ],
                            "paper_ids": [
                                305,
                                746,
                                765,
                                1053,
                                1450,
                                1493,
                                1640,
                                1787,
                                2215,
                                2219,
                                2376,
                                2670,
                                2698,
                                2810
                            ]
                        },
                        {
                            "label": "text_preprocessing",
                            "description": "The techniques used to prepare and clean text data for further analysis and knowledge extraction.",
                            "level": 3,
                            "example_papers": [
                                [
                                    48,
                                    "Overcome Noise and Bias: Segmentation-Aided Multi-Granularity Denoising and Debiasing for Enhanced Quarduples Extraction in Dialogue"
                                ],
                                [
                                    56,
                                    "RoseLoRA: Row and Column-wise Sparse Low-rank Adaptation of Pre-trained Language Model for Knowledge Editing and Fine-tuning"
                                ],
                                [
                                    65,
                                    "AMR-Evol: Adaptive Modular Response Evolution Elicits Better Knowledge Distillation for Large Language Models in Code Generation"
                                ],
                                [
                                    67,
                                    "Rethinking Pruning Large Language Models: Benefits and Pitfalls of Reconstruction Error Minimization"
                                ],
                                [
                                    186,
                                    "ScalingFilter: Assessing Data Quality through Inverse Utilization of Scaling Laws"
                                ],
                                [
                                    193,
                                    "Pixology: Probing the Linguistic and Visual Capabilities of Pixel-based Language Models"
                                ],
                                [
                                    214,
                                    "Performance-Guided LLM Knowledge Distillation for Efficient Text Classification at Scale"
                                ],
                                [
                                    218,
                                    "Text Grafting: Near-Distribution Weak Supervision for Minority Classes in Text Classification"
                                ],
                                [
                                    219,
                                    "Incubating Text Classifiers Following User Instruction with Nothing but LLM"
                                ],
                                [
                                    276,
                                    "KidLM: Advancing Language Models for Children - Early Insights and Future Directions"
                                ]
                            ],
                            "paper_ids": [
                                48,
                                56,
                                65,
                                67,
                                186,
                                193,
                                214,
                                218,
                                219,
                                276,
                                279,
                                294,
                                299,
                                305,
                                315,
                                367,
                                390,
                                422,
                                460,
                                496,
                                508,
                                511,
                                521,
                                528,
                                579,
                                615,
                                639,
                                654,
                                825,
                                932,
                                938,
                                962,
                                965,
                                1035,
                                1074,
                                1094,
                                1134,
                                1221,
                                1226,
                                1259,
                                1260,
                                1265,
                                1322,
                                1339,
                                1445,
                                1452,
                                1474,
                                1485,
                                1486,
                                1498,
                                1539,
                                1618,
                                1625,
                                1636,
                                1739,
                                1760,
                                1762,
                                1770,
                                1810,
                                1876,
                                1941,
                                1952,
                                2022,
                                2029,
                                2034,
                                2041,
                                2092,
                                2173,
                                2206,
                                2232,
                                2251,
                                2329,
                                2340,
                                2371,
                                2420,
                                2429,
                                2443,
                                2481,
                                2547,
                                2628,
                                2650,
                                2654,
                                2661,
                                2670,
                                2679,
                                2680,
                                2697,
                                2698,
                                2711,
                                2730,
                                2756,
                                2764,
                                2767,
                                2809,
                                2810
                            ]
                        },
                        {
                            "label": "text_annotation",
                            "description": "The process of labeling text data with relevant tags or categories to facilitate knowledge extraction.",
                            "level": 3,
                            "example_papers": [
                                [
                                    53,
                                    "Large Language Models for Data Annotation and Synthesis: A Survey"
                                ],
                                [
                                    155,
                                    "To Word Senses and Beyond: Inducing Concepts with Contextualized Language Models"
                                ],
                                [
                                    193,
                                    "Pixology: Probing the Linguistic and Visual Capabilities of Pixel-based Language Models"
                                ],
                                [
                                    279,
                                    "An Unsupervised Approach to Achieve Supervised-Level Explainability in Healthcare Records"
                                ],
                                [
                                    305,
                                    "How Far Can We Extract Diverse Perspectives from Large Language Models?"
                                ],
                                [
                                    390,
                                    "Beyond Embeddings: The Promise of Visual Table in Visual Reasoning"
                                ],
                                [
                                    391,
                                    "CareCorpus+: Expanding and Augmenting Caregiver Strategy Data to Support Pediatric Rehabilitation"
                                ],
                                [
                                    436,
                                    "MORPHEUS: Modeling Role from Personalized Dialogue History by Exploring and Utilizing Latent Space"
                                ],
                                [
                                    508,
                                    "Can Active Label Correction Improve LLM-based Modular AI Systems?"
                                ],
                                [
                                    521,
                                    "RuBLiMP: Russian Benchmark of Linguistic Minimal Pairs"
                                ]
                            ],
                            "paper_ids": [
                                53,
                                155,
                                193,
                                279,
                                305,
                                390,
                                391,
                                436,
                                508,
                                521,
                                615,
                                631,
                                654,
                                912,
                                1030,
                                1074,
                                1260,
                                1278,
                                1445,
                                1463,
                                1485,
                                1486,
                                1625,
                                1734,
                                1770,
                                1952,
                                2041,
                                2206,
                                2251,
                                2420,
                                2670,
                                2679,
                                2697,
                                2698,
                                2711,
                                2730,
                                2756,
                                2764,
                                2767,
                                2810
                            ]
                        },
                        {
                            "label": "event_extraction",
                            "description": "The identification and extraction of events described in text, including their participants and attributes.",
                            "level": 3,
                            "example_papers": [
                                [
                                    48,
                                    "Overcome Noise and Bias: Segmentation-Aided Multi-Granularity Denoising and Debiasing for Enhanced Quarduples Extraction in Dialogue"
                                ],
                                [
                                    58,
                                    "HEART-felt Narratives: Tracing Empathy and Narrative Style in Personal Stories with LLMs"
                                ],
                                [
                                    219,
                                    "Incubating Text Classifiers Following User Instruction with Nothing but LLM"
                                ],
                                [
                                    305,
                                    "How Far Can We Extract Diverse Perspectives from Large Language Models?"
                                ],
                                [
                                    390,
                                    "Beyond Embeddings: The Promise of Visual Table in Visual Reasoning"
                                ],
                                [
                                    402,
                                    "Does Large Language Model Contain Task-Specific Neurons?"
                                ],
                                [
                                    436,
                                    "MORPHEUS: Modeling Role from Personalized Dialogue History by Exploring and Utilizing Latent Space"
                                ],
                                [
                                    511,
                                    "DiVERT: Distractor Generation with Variational Errors Represented as Text for Math Multiple-choice Questions"
                                ],
                                [
                                    544,
                                    "Evaluating the Effectiveness of Large Language Models in Establishing Conversational Grounding"
                                ],
                                [
                                    579,
                                    "CARER - ClinicAl Reasoning-Enhanced Representation for Temporal Health Risk Prediction"
                                ]
                            ],
                            "paper_ids": [
                                48,
                                58,
                                219,
                                305,
                                390,
                                402,
                                436,
                                511,
                                544,
                                579,
                                719,
                                825,
                                932,
                                977,
                                1094,
                                1221,
                                1450,
                                1493,
                                1640,
                                1922,
                                1952,
                                2219,
                                2318,
                                2376,
                                2496,
                                2661,
                                2670,
                                2679,
                                2680,
                                2698,
                                2730,
                                2810,
                                2951
                            ]
                        }
                    ]
                },
                {
                    "label": "response_evaluation",
                    "description": "The task of assessing the clarity and relevance of responses in various contexts, such as customer service or educational settings.",
                    "level": 2,
                    "example_papers": [
                        [
                            65,
                            "AMR-Evol: Adaptive Modular Response Evolution Elicits Better Knowledge Distillation for Large Language Models in Code Generation"
                        ],
                        [
                            397,
                            "RepEval: Effective Text Evaluation with LLM Representation"
                        ],
                        [
                            570,
                            "I Learn Better If You Speak My Language: Understanding the Superior Performance of Fine-Tuning Large Language Models with LLM-Generated Responses"
                        ],
                        [
                            687,
                            "Leveraging Estimated Transferability Over Human Intuition for Model Selection in Text Ranking"
                        ],
                        [
                            938,
                            "RAFT: Realistic Attacks to Fool Text Detectors"
                        ],
                        [
                            948,
                            "Foundational Autoraters: Taming Large Language Models for Better Automatic Evaluation"
                        ],
                        [
                            1191,
                            "Beyond Turn-Based Interfaces: Synchronous LLMs as Full-Duplex Dialogue Agents"
                        ],
                        [
                            1732,
                            "Stanceformer: Target-Aware Transformer for Stance Detection"
                        ],
                        [
                            1740,
                            "Promoting Constructive Deliberation: Reframing for Receptiveness"
                        ],
                        [
                            1746,
                            "\"I Never Said That\": A dataset, taxonomy and baselines on response clarity classification"
                        ]
                    ],
                    "paper_ids": [
                        65,
                        397,
                        570,
                        687,
                        938,
                        948,
                        1191,
                        1732,
                        1740,
                        1746,
                        2005,
                        2231,
                        2313,
                        2450,
                        2595
                    ]
                },
                {
                    "label": "problem_solving",
                    "description": "The process of identifying and solving mathematical problems through various techniques and methodologies.",
                    "level": 2,
                    "example_papers": [
                        [
                            273,
                            "MuMath-Code: Combining Tool-Use Large Language Models with Multi-perspective Data Augmentation for Mathematical Reasoning"
                        ],
                        [
                            628,
                            "Code Prompting Elicits Conditional Reasoning Abilities in Text+Code LLMs"
                        ],
                        [
                            679,
                            "ControlMath: Controllable Data Generation Promotes Math Generalist Models"
                        ],
                        [
                            687,
                            "Leveraging Estimated Transferability Over Human Intuition for Model Selection in Text Ranking"
                        ],
                        [
                            694,
                            "The Mystery of the Pathological Path-star Task for Language Models"
                        ],
                        [
                            938,
                            "RAFT: Realistic Attacks to Fool Text Detectors"
                        ],
                        [
                            1095,
                            "Pron vs Prompt: Can Large Language Models already Challenge a World-Class Fiction Author at Creative Text Writing?"
                        ],
                        [
                            1292,
                            "To the Globe (TTG): Towards Language-Driven Guaranteed Travel Planning"
                        ],
                        [
                            1322,
                            "The Program Testing Ability of Large Language Models for Code"
                        ],
                        [
                            1334,
                            "SAAS: Solving Ability Amplification Strategy for Enhanced Mathematical Reasoning in Large Language Models"
                        ]
                    ],
                    "paper_ids": [
                        273,
                        628,
                        679,
                        687,
                        694,
                        938,
                        1095,
                        1292,
                        1322,
                        1334,
                        1423,
                        1556,
                        1732,
                        1739,
                        1753,
                        1769,
                        1875,
                        1909,
                        1954,
                        2015,
                        2035,
                        2051,
                        2168,
                        2291,
                        2429
                    ]
                },
                {
                    "label": "language_understanding",
                    "description": "The task of comprehending and interpreting human language in a way that enables effective communication and interaction.",
                    "level": 2,
                    "example_papers": [
                        [
                            11,
                            "NumeroLogic: Number Encoding for Enhanced LLMs' Numerical Reasoning"
                        ],
                        [
                            17,
                            "Uncertainty in Language Models: Assessment through Rank-Calibration"
                        ],
                        [
                            39,
                            "Tokenization Is More Than Compression"
                        ],
                        [
                            42,
                            "Parameter-Efficient Sparsity Crafting from Dense to Mixture-of-Experts for Instruction Tuning on General Tasks"
                        ],
                        [
                            52,
                            "Language Models Learn Rare Phenomena from Less Rare Phenomena: The Case of the Missing AANNs"
                        ],
                        [
                            53,
                            "Large Language Models for Data Annotation and Synthesis: A Survey"
                        ],
                        [
                            58,
                            "HEART-felt Narratives: Tracing Empathy and Narrative Style in Personal Stories with LLMs"
                        ],
                        [
                            67,
                            "Rethinking Pruning Large Language Models: Benefits and Pitfalls of Reconstruction Error Minimization"
                        ],
                        [
                            101,
                            "MetaGPT: Merging Large Language Models Using Model Exclusive Task Arithmetic"
                        ],
                        [
                            141,
                            "Backward Lens: Projecting Language Model Gradients into the Vocabulary Space"
                        ]
                    ],
                    "paper_ids": [
                        11,
                        17,
                        39,
                        42,
                        52,
                        53,
                        58,
                        67,
                        101,
                        141,
                        149,
                        155,
                        165,
                        166,
                        169,
                        186,
                        193,
                        199,
                        214,
                        219,
                        225,
                        235,
                        273,
                        276,
                        279,
                        286,
                        292,
                        294,
                        298,
                        299,
                        301,
                        305,
                        315,
                        332,
                        342,
                        349,
                        367,
                        388,
                        390,
                        402,
                        407,
                        409,
                        422,
                        436,
                        454,
                        460,
                        480,
                        508,
                        511,
                        521,
                        523,
                        528,
                        529,
                        530,
                        544,
                        545,
                        549,
                        550,
                        557,
                        563,
                        566,
                        570,
                        573,
                        579,
                        594,
                        604,
                        605,
                        614,
                        615,
                        628,
                        631,
                        637,
                        638,
                        639,
                        656,
                        662,
                        663,
                        675,
                        679,
                        687,
                        689,
                        691,
                        694,
                        702,
                        704,
                        719,
                        732,
                        741,
                        746,
                        760,
                        765,
                        773,
                        775,
                        776,
                        790,
                        800,
                        803,
                        809,
                        823,
                        833,
                        843,
                        846,
                        849,
                        894,
                        895,
                        909,
                        912,
                        932,
                        938,
                        948,
                        954,
                        965,
                        970,
                        977,
                        1006,
                        1027,
                        1030,
                        1031,
                        1035,
                        1053,
                        1056,
                        1063,
                        1065,
                        1066,
                        1069,
                        1074,
                        1090,
                        1094,
                        1095,
                        1096,
                        1109,
                        1112,
                        1117,
                        1121,
                        1124,
                        1128,
                        1129,
                        1134,
                        1145,
                        1148,
                        1155,
                        1157,
                        1160,
                        1188,
                        1191,
                        1203,
                        1215,
                        1219,
                        1221,
                        1226,
                        1230,
                        1238,
                        1245,
                        1259,
                        1261,
                        1265,
                        1278,
                        1291,
                        1292,
                        1308,
                        1311,
                        1322,
                        1327,
                        1330,
                        1333,
                        1334,
                        1339,
                        1344,
                        1357,
                        1417,
                        1423,
                        1436,
                        1441,
                        1445,
                        1450,
                        1451,
                        1452,
                        1454,
                        1456,
                        1462,
                        1463,
                        1472,
                        1474,
                        1485,
                        1486,
                        1498,
                        1532,
                        1533,
                        1535,
                        1539,
                        1555,
                        1556,
                        1576,
                        1606,
                        1611,
                        1616,
                        1617,
                        1618,
                        1625,
                        1628,
                        1636,
                        1640,
                        1646,
                        1653,
                        1688,
                        1696,
                        1707,
                        1711,
                        1728,
                        1732,
                        1734,
                        1739,
                        1740,
                        1753,
                        1759,
                        1762,
                        1764,
                        1769,
                        1776,
                        1796,
                        1802,
                        1812,
                        1861,
                        1864,
                        1876,
                        1879,
                        1907,
                        1909,
                        1941,
                        1952,
                        1954,
                        1981,
                        1997,
                        2002,
                        2022,
                        2029,
                        2034,
                        2035,
                        2041,
                        2048,
                        2051,
                        2066,
                        2081,
                        2085,
                        2092,
                        2100,
                        2140,
                        2159,
                        2168,
                        2171,
                        2173,
                        2184,
                        2198,
                        2202,
                        2206,
                        2215,
                        2228,
                        2245,
                        2251,
                        2266,
                        2274,
                        2282,
                        2287,
                        2291,
                        2299,
                        2318,
                        2320,
                        2326,
                        2329,
                        2340,
                        2341,
                        2356,
                        2360,
                        2361,
                        2371,
                        2376,
                        2380,
                        2383,
                        2387,
                        2391,
                        2429,
                        2443,
                        2450,
                        2467,
                        2481,
                        2482,
                        2488,
                        2496,
                        2513,
                        2516,
                        2520,
                        2530,
                        2535,
                        2540,
                        2541,
                        2547,
                        2556,
                        2595,
                        2600,
                        2603,
                        2628,
                        2640,
                        2654,
                        2660,
                        2661,
                        2662,
                        2670,
                        2679,
                        2680,
                        2697,
                        2698,
                        2711,
                        2721,
                        2733,
                        2749,
                        2752,
                        2756,
                        2764,
                        2767,
                        2772,
                        2794,
                        2809,
                        2948,
                        2951
                    ],
                    "children": [
                        {
                            "label": "text_generation",
                            "description": "The task of creating coherent and contextually relevant text based on given prompts or input, often used in applications like chatbots and content creation.",
                            "level": 3,
                            "example_papers": [
                                [
                                    17,
                                    "Uncertainty in Language Models: Assessment through Rank-Calibration"
                                ],
                                [
                                    53,
                                    "Large Language Models for Data Annotation and Synthesis: A Survey"
                                ],
                                [
                                    101,
                                    "MetaGPT: Merging Large Language Models Using Model Exclusive Task Arithmetic"
                                ],
                                [
                                    165,
                                    "Evaluating Large Language Models via Linguistic Profiling"
                                ],
                                [
                                    199,
                                    "Unsupervised Human Preference Learning"
                                ],
                                [
                                    219,
                                    "Incubating Text Classifiers Following User Instruction with Nothing but LLM"
                                ],
                                [
                                    298,
                                    "LUQ: Long-text Uncertainty Quantification for LLMs"
                                ],
                                [
                                    349,
                                    "SciPrompt: Knowledge-augmented Prompting for Fine-grained Categorization of Scientific Topics"
                                ],
                                [
                                    367,
                                    "Detection and Measurement of Syntactic Templates in Generated Text"
                                ],
                                [
                                    388,
                                    "Efficient LLM Comparative Assessment: A Product of Experts Framework for Pairwise Comparisons"
                                ]
                            ],
                            "paper_ids": [
                                17,
                                53,
                                101,
                                165,
                                199,
                                219,
                                298,
                                349,
                                367,
                                388,
                                454,
                                460,
                                545,
                                550,
                                563,
                                570,
                                604,
                                605,
                                638,
                                639,
                                704,
                                741,
                                775,
                                843,
                                849,
                                895,
                                954,
                                970,
                                977,
                                1006,
                                1074,
                                1095,
                                1096,
                                1117,
                                1121,
                                1124,
                                1129,
                                1134,
                                1221,
                                1226,
                                1238,
                                1245,
                                1259,
                                1261,
                                1265,
                                1322,
                                1327,
                                1330,
                                1344,
                                1417,
                                1436,
                                1445,
                                1498,
                                1539,
                                1611,
                                1617,
                                1618,
                                1688,
                                1707,
                                1728,
                                1762,
                                1907,
                                2022,
                                2035,
                                2100,
                                2140,
                                2168,
                                2173,
                                2184,
                                2198,
                                2202,
                                2206,
                                2282,
                                2287,
                                2329,
                                2340,
                                2387,
                                2429,
                                2450,
                                2535,
                                2660,
                                2711,
                                2764,
                                2794,
                                2951
                            ]
                        },
                        {
                            "label": "spoken_language_understanding",
                            "description": "The process of interpreting and comprehending spoken language, enabling systems to understand and respond to verbal communication effectively.",
                            "level": 3,
                            "example_papers": [
                                [
                                    52,
                                    "Language Models Learn Rare Phenomena from Less Rare Phenomena: The Case of the Missing AANNs"
                                ],
                                [
                                    141,
                                    "Backward Lens: Projecting Language Model Gradients into the Vocabulary Space"
                                ],
                                [
                                    166,
                                    "With Ears to See and Eyes to Hear: Sound Symbolism Experiments with Multimodal Large Language Models"
                                ],
                                [
                                    169,
                                    "DGLF: A Dual Graph-based Learning Framework for Multi-modal Sarcasm Detection"
                                ],
                                [
                                    235,
                                    "When Is Multilinguality a Curse? Language Modeling for 250 High- and Low-Resource Languages"
                                ],
                                [
                                    276,
                                    "KidLM: Advancing Language Models for Children - Early Insights and Future Directions"
                                ],
                                [
                                    301,
                                    "Improving Spoken Language Modeling with Phoneme Classification: A Simple Fine-tuning Approach"
                                ],
                                [
                                    409,
                                    "Incomplete Utterance Rewriting with Editing Operation Guidance and Utterance Augmentation"
                                ],
                                [
                                    436,
                                    "MORPHEUS: Modeling Role from Personalized Dialogue History by Exploring and Utilizing Latent Space"
                                ],
                                [
                                    521,
                                    "RuBLiMP: Russian Benchmark of Linguistic Minimal Pairs"
                                ]
                            ],
                            "paper_ids": [
                                52,
                                141,
                                166,
                                169,
                                235,
                                276,
                                301,
                                409,
                                436,
                                521,
                                529,
                                557,
                                594,
                                615,
                                637,
                                662,
                                689,
                                691,
                                800,
                                803,
                                823,
                                846,
                                894,
                                1063,
                                1066,
                                1069,
                                1112,
                                1148,
                                1157,
                                1191,
                                1230,
                                1308,
                                1339,
                                1462,
                                1463,
                                1646,
                                1732,
                                1734,
                                1802,
                                1864,
                                1879,
                                2168,
                                2228,
                                2251,
                                2266,
                                2341,
                                2356,
                                2360,
                                2371,
                                2380,
                                2383,
                                2467,
                                2488,
                                2513,
                                2516,
                                2520,
                                2530,
                                2540,
                                2628,
                                2679,
                                2698,
                                2756,
                                2772
                            ]
                        },
                        {
                            "label": "textual_inference",
                            "description": "The task of deriving logical conclusions from text, which involves understanding relationships and implications within the written content.",
                            "level": 3,
                            "example_papers": [
                                [
                                    11,
                                    "NumeroLogic: Number Encoding for Enhanced LLMs' Numerical Reasoning"
                                ],
                                [
                                    39,
                                    "Tokenization Is More Than Compression"
                                ],
                                [
                                    42,
                                    "Parameter-Efficient Sparsity Crafting from Dense to Mixture-of-Experts for Instruction Tuning on General Tasks"
                                ],
                                [
                                    52,
                                    "Language Models Learn Rare Phenomena from Less Rare Phenomena: The Case of the Missing AANNs"
                                ],
                                [
                                    58,
                                    "HEART-felt Narratives: Tracing Empathy and Narrative Style in Personal Stories with LLMs"
                                ],
                                [
                                    67,
                                    "Rethinking Pruning Large Language Models: Benefits and Pitfalls of Reconstruction Error Minimization"
                                ],
                                [
                                    141,
                                    "Backward Lens: Projecting Language Model Gradients into the Vocabulary Space"
                                ],
                                [
                                    149,
                                    "Collaborative Performance Prediction for Large Language Models"
                                ],
                                [
                                    155,
                                    "To Word Senses and Beyond: Inducing Concepts with Contextualized Language Models"
                                ],
                                [
                                    186,
                                    "ScalingFilter: Assessing Data Quality through Inverse Utilization of Scaling Laws"
                                ]
                            ],
                            "paper_ids": [
                                11,
                                39,
                                42,
                                52,
                                58,
                                67,
                                141,
                                149,
                                155,
                                186,
                                193,
                                214,
                                219,
                                225,
                                273,
                                276,
                                279,
                                286,
                                294,
                                299,
                                305,
                                315,
                                332,
                                342,
                                349,
                                390,
                                402,
                                407,
                                422,
                                480,
                                511,
                                523,
                                528,
                                530,
                                549,
                                566,
                                573,
                                579,
                                614,
                                628,
                                638,
                                656,
                                662,
                                663,
                                675,
                                679,
                                687,
                                691,
                                694,
                                702,
                                719,
                                732,
                                746,
                                760,
                                765,
                                773,
                                775,
                                776,
                                790,
                                809,
                                823,
                                833,
                                846,
                                912,
                                932,
                                938,
                                948,
                                965,
                                1027,
                                1030,
                                1031,
                                1053,
                                1056,
                                1065,
                                1090,
                                1094,
                                1112,
                                1145,
                                1155,
                                1157,
                                1160,
                                1188,
                                1203,
                                1215,
                                1219,
                                1278,
                                1291,
                                1333,
                                1334,
                                1357,
                                1441,
                                1450,
                                1451,
                                1452,
                                1454,
                                1456,
                                1472,
                                1474,
                                1485,
                                1486,
                                1532,
                                1535,
                                1555,
                                1556,
                                1576,
                                1616,
                                1625,
                                1628,
                                1636,
                                1640,
                                1653,
                                1711,
                                1732,
                                1739,
                                1740,
                                1753,
                                1759,
                                1764,
                                1769,
                                1776,
                                1796,
                                1812,
                                1861,
                                1879,
                                1909,
                                1952,
                                1954,
                                1981,
                                1997,
                                2002,
                                2029,
                                2034,
                                2041,
                                2048,
                                2066,
                                2081,
                                2085,
                                2092,
                                2171,
                                2198,
                                2215,
                                2245,
                                2251,
                                2274,
                                2291,
                                2318,
                                2320,
                                2326,
                                2340,
                                2356,
                                2360,
                                2361,
                                2376,
                                2443,
                                2450,
                                2481,
                                2482,
                                2496,
                                2513,
                                2541,
                                2595,
                                2600,
                                2603,
                                2628,
                                2640,
                                2654,
                                2661,
                                2662,
                                2670,
                                2679,
                                2680,
                                2698,
                                2721,
                                2749,
                                2809,
                                2948,
                                2951
                            ]
                        },
                        {
                            "label": "conversational_ai",
                            "description": "The development of systems that can engage in human-like dialogue, understanding context and intent to facilitate meaningful interactions.",
                            "level": 3,
                            "example_papers": [
                                [
                                    11,
                                    "NumeroLogic: Number Encoding for Enhanced LLMs' Numerical Reasoning"
                                ],
                                [
                                    39,
                                    "Tokenization Is More Than Compression"
                                ],
                                [
                                    42,
                                    "Parameter-Efficient Sparsity Crafting from Dense to Mixture-of-Experts for Instruction Tuning on General Tasks"
                                ],
                                [
                                    53,
                                    "Large Language Models for Data Annotation and Synthesis: A Survey"
                                ],
                                [
                                    58,
                                    "HEART-felt Narratives: Tracing Empathy and Narrative Style in Personal Stories with LLMs"
                                ],
                                [
                                    67,
                                    "Rethinking Pruning Large Language Models: Benefits and Pitfalls of Reconstruction Error Minimization"
                                ],
                                [
                                    101,
                                    "MetaGPT: Merging Large Language Models Using Model Exclusive Task Arithmetic"
                                ],
                                [
                                    149,
                                    "Collaborative Performance Prediction for Large Language Models"
                                ],
                                [
                                    155,
                                    "To Word Senses and Beyond: Inducing Concepts with Contextualized Language Models"
                                ],
                                [
                                    186,
                                    "ScalingFilter: Assessing Data Quality through Inverse Utilization of Scaling Laws"
                                ]
                            ],
                            "paper_ids": [
                                11,
                                39,
                                42,
                                53,
                                58,
                                67,
                                101,
                                149,
                                155,
                                186,
                                193,
                                199,
                                225,
                                273,
                                276,
                                279,
                                286,
                                294,
                                299,
                                305,
                                315,
                                342,
                                349,
                                390,
                                402,
                                407,
                                409,
                                422,
                                436,
                                508,
                                511,
                                523,
                                528,
                                544,
                                549,
                                550,
                                557,
                                566,
                                570,
                                573,
                                579,
                                594,
                                614,
                                615,
                                628,
                                631,
                                656,
                                663,
                                675,
                                679,
                                687,
                                694,
                                702,
                                704,
                                719,
                                732,
                                746,
                                765,
                                773,
                                776,
                                790,
                                803,
                                809,
                                846,
                                894,
                                895,
                                912,
                                932,
                                938,
                                948,
                                965,
                                1027,
                                1030,
                                1035,
                                1056,
                                1065,
                                1066,
                                1069,
                                1090,
                                1094,
                                1109,
                                1128,
                                1155,
                                1157,
                                1160,
                                1188,
                                1191,
                                1203,
                                1215,
                                1219,
                                1221,
                                1226,
                                1278,
                                1291,
                                1292,
                                1333,
                                1334,
                                1357,
                                1423,
                                1441,
                                1445,
                                1450,
                                1452,
                                1454,
                                1456,
                                1463,
                                1472,
                                1485,
                                1486,
                                1535,
                                1555,
                                1556,
                                1576,
                                1616,
                                1617,
                                1625,
                                1628,
                                1636,
                                1640,
                                1711,
                                1732,
                                1734,
                                1739,
                                1740,
                                1753,
                                1759,
                                1764,
                                1769,
                                1776,
                                1796,
                                1812,
                                1861,
                                1876,
                                1909,
                                1952,
                                1954,
                                1997,
                                2002,
                                2029,
                                2034,
                                2041,
                                2051,
                                2066,
                                2085,
                                2092,
                                2159,
                                2171,
                                2215,
                                2251,
                                2274,
                                2291,
                                2299,
                                2318,
                                2320,
                                2341,
                                2361,
                                2371,
                                2376,
                                2387,
                                2391,
                                2443,
                                2482,
                                2496,
                                2541,
                                2556,
                                2600,
                                2628,
                                2640,
                                2654,
                                2661,
                                2670,
                                2680,
                                2721,
                                2749,
                                2752,
                                2767,
                                2772,
                                2809,
                                2948
                            ]
                        },
                        {
                            "label": "text_style_transfer",
                            "description": "The task of transforming text from one stylistic form to another while preserving its original meaning, often used in creative writing and content adaptation.",
                            "level": 3,
                            "example_papers": [
                                [
                                    1278,
                                    "Commentator: A Code-mixed Multilingual Text Annotation Framework"
                                ],
                                [
                                    1941,
                                    "PSST: A Benchmark for Evaluation-driven Text Public-Speaking Style Transfer"
                                ],
                                [
                                    1981,
                                    "Are ELECTRA's Sentence Embeddings Beyond Repair? The Case of Semantic Textual Similarity"
                                ],
                                [
                                    2547,
                                    "Customized Style Transfer using Discrete Sampling"
                                ],
                                [
                                    2794,
                                    "Measuring and Modifying the Readability of English Texts with GPT-4"
                                ]
                            ],
                            "paper_ids": [
                                1278,
                                1941,
                                1981,
                                2547,
                                2794
                            ]
                        }
                    ]
                }
            ]
        },
        {
            "label": "named_entity_recognition",
            "description": "The process of identifying and classifying key entities in text, such as names of people, organizations, locations, and dates, to extract meaningful information.",
            "level": 1,
            "example_papers": [
                [
                    5,
                    "ImageInWords: Unlocking Hyper-Detailed Image Descriptions"
                ],
                [
                    13,
                    "A Usage-centric Take on Intent Understanding in E-Commerce"
                ],
                [
                    17,
                    "Uncertainty in Language Models: Assessment through Rank-Calibration"
                ],
                [
                    25,
                    "Strength Lies in Differences! Improving Strategy Planning for Non-collaborative Dialogues via Diversified User Simulation"
                ],
                [
                    26,
                    "Impeding LLM-assisted Cheating in Introductory Programming Assignments via Adversarial Perturbation"
                ],
                [
                    39,
                    "Tokenization Is More Than Compression"
                ],
                [
                    42,
                    "Parameter-Efficient Sparsity Crafting from Dense to Mixture-of-Experts for Instruction Tuning on General Tasks"
                ],
                [
                    48,
                    "Overcome Noise and Bias: Segmentation-Aided Multi-Granularity Denoising and Debiasing for Enhanced Quarduples Extraction in Dialogue"
                ],
                [
                    52,
                    "Language Models Learn Rare Phenomena from Less Rare Phenomena: The Case of the Missing AANNs"
                ],
                [
                    53,
                    "Large Language Models for Data Annotation and Synthesis: A Survey"
                ]
            ],
            "paper_ids": [
                5,
                13,
                17,
                25,
                26,
                39,
                42,
                48,
                52,
                53,
                56,
                67,
                85,
                94,
                101,
                119,
                128,
                141,
                143,
                149,
                155,
                163,
                165,
                166,
                169,
                186,
                193,
                215,
                225,
                234,
                235,
                256,
                273,
                276,
                279,
                286,
                299,
                313,
                315,
                332,
                342,
                351,
                354,
                387,
                390,
                402,
                407,
                409,
                425,
                436,
                454,
                460,
                480,
                491,
                508,
                511,
                521,
                523,
                529,
                530,
                531,
                544,
                545,
                549,
                557,
                563,
                570,
                573,
                579,
                587,
                594,
                605,
                614,
                615,
                628,
                631,
                637,
                651,
                656,
                658,
                659,
                662,
                664,
                666,
                667,
                669,
                672,
                675,
                679,
                689,
                691,
                702,
                719,
                725,
                730,
                732,
                741,
                746,
                752,
                755,
                760,
                762,
                763,
                765,
                775,
                776,
                800,
                803,
                809,
                825,
                829,
                831,
                835,
                843,
                846,
                849,
                854,
                862,
                894,
                895,
                909,
                929,
                932,
                941,
                948,
                965,
                966,
                977,
                987,
                1006,
                1010,
                1015,
                1023,
                1027,
                1031,
                1035,
                1041,
                1048,
                1049,
                1053,
                1069,
                1086,
                1095,
                1096,
                1107,
                1109,
                1112,
                1127,
                1129,
                1132,
                1145,
                1148,
                1156,
                1157,
                1166,
                1170,
                1191,
                1203,
                1212,
                1219,
                1230,
                1254,
                1260,
                1278,
                1295,
                1308,
                1320,
                1324,
                1334,
                1344,
                1347,
                1357,
                1370,
                1374,
                1393,
                1433,
                1441,
                1443,
                1450,
                1472,
                1474,
                1481,
                1485,
                1493,
                1498,
                1504,
                1513,
                1532,
                1533,
                1539,
                1540,
                1542,
                1555,
                1556,
                1576,
                1586,
                1616,
                1618,
                1626,
                1628,
                1629,
                1636,
                1640,
                1646,
                1653,
                1696,
                1707,
                1734,
                1739,
                1741,
                1753,
                1755,
                1764,
                1767,
                1769,
                1787,
                1794,
                1796,
                1802,
                1812,
                1819,
                1821,
                1845,
                1846,
                1854,
                1858,
                1861,
                1863,
                1875,
                1876,
                1879,
                1880,
                1902,
                1909,
                1921,
                1941,
                1949,
                1952,
                1954,
                1971,
                1997,
                2002,
                2005,
                2015,
                2022,
                2034,
                2035,
                2036,
                2048,
                2051,
                2055,
                2062,
                2064,
                2066,
                2072,
                2086,
                2088,
                2100,
                2101,
                2164,
                2177,
                2184,
                2190,
                2208,
                2215,
                2228,
                2231,
                2245,
                2251,
                2252,
                2256,
                2266,
                2267,
                2289,
                2298,
                2313,
                2318,
                2329,
                2340,
                2341,
                2355,
                2356,
                2361,
                2365,
                2368,
                2380,
                2385,
                2387,
                2391,
                2395,
                2404,
                2429,
                2443,
                2452,
                2467,
                2470,
                2477,
                2481,
                2482,
                2488,
                2496,
                2500,
                2510,
                2511,
                2513,
                2516,
                2522,
                2525,
                2531,
                2532,
                2534,
                2535,
                2556,
                2593,
                2594,
                2600,
                2619,
                2628,
                2636,
                2640,
                2641,
                2645,
                2658,
                2664,
                2665,
                2667,
                2668,
                2670,
                2673,
                2675,
                2678,
                2679,
                2680,
                2698,
                2702,
                2709,
                2711,
                2715,
                2721,
                2742,
                2749,
                2752,
                2763,
                2764,
                2772,
                2807,
                2809,
                2810,
                2945,
                2948
            ],
            "children": [
                {
                    "label": "entity_extraction",
                    "description": "This cluster focuses on the techniques and methodologies for extracting entities from text, including named entities such as people, organizations, and locations.",
                    "level": 2,
                    "example_papers": [
                        [
                            48,
                            "Overcome Noise and Bias: Segmentation-Aided Multi-Granularity Denoising and Debiasing for Enhanced Quarduples Extraction in Dialogue"
                        ],
                        [
                            52,
                            "Language Models Learn Rare Phenomena from Less Rare Phenomena: The Case of the Missing AANNs"
                        ],
                        [
                            53,
                            "Large Language Models for Data Annotation and Synthesis: A Survey"
                        ],
                        [
                            56,
                            "RoseLoRA: Row and Column-wise Sparse Low-rank Adaptation of Pre-trained Language Model for Knowledge Editing and Fine-tuning"
                        ],
                        [
                            67,
                            "Rethinking Pruning Large Language Models: Benefits and Pitfalls of Reconstruction Error Minimization"
                        ],
                        [
                            85,
                            "Mitigating Matthew Effect: Multi-Hypergraph Boosted Multi-Interest Self-Supervised Learning for Conversational Recommendation"
                        ],
                        [
                            119,
                            "Tag-grounded Visual Instruction Tuning with Retrieval Augmentation"
                        ],
                        [
                            128,
                            "Integrating Structural Semantic Knowledge for Enhanced Information Extraction Pre-training"
                        ],
                        [
                            155,
                            "To Word Senses and Beyond: Inducing Concepts with Contextualized Language Models"
                        ],
                        [
                            163,
                            "Alignment-Enhanced Decoding: Defending Jailbreaks via Token-Level Adaptive Refining of Probability Distributions"
                        ]
                    ],
                    "paper_ids": [
                        48,
                        52,
                        53,
                        56,
                        67,
                        85,
                        119,
                        128,
                        155,
                        163,
                        193,
                        215,
                        234,
                        256,
                        276,
                        279,
                        286,
                        299,
                        313,
                        315,
                        332,
                        351,
                        387,
                        390,
                        402,
                        409,
                        425,
                        454,
                        460,
                        491,
                        529,
                        544,
                        549,
                        570,
                        579,
                        587,
                        614,
                        615,
                        628,
                        637,
                        651,
                        659,
                        669,
                        672,
                        679,
                        689,
                        691,
                        719,
                        725,
                        730,
                        732,
                        755,
                        762,
                        765,
                        776,
                        800,
                        803,
                        809,
                        831,
                        849,
                        862,
                        894,
                        909,
                        932,
                        966,
                        987,
                        1010,
                        1015,
                        1023,
                        1041,
                        1048,
                        1049,
                        1069,
                        1086,
                        1109,
                        1127,
                        1166,
                        1219,
                        1230,
                        1260,
                        1278,
                        1320,
                        1324,
                        1334,
                        1357,
                        1370,
                        1374,
                        1393,
                        1433,
                        1450,
                        1472,
                        1474,
                        1481,
                        1485,
                        1493,
                        1504,
                        1513,
                        1539,
                        1556,
                        1626,
                        1629,
                        1636,
                        1640,
                        1646,
                        1653,
                        1741,
                        1755,
                        1764,
                        1787,
                        1794,
                        1821,
                        1846,
                        1861,
                        1863,
                        1876,
                        1879,
                        1949,
                        1952,
                        2015,
                        2022,
                        2035,
                        2036,
                        2048,
                        2051,
                        2055,
                        2062,
                        2066,
                        2072,
                        2101,
                        2190,
                        2251,
                        2252,
                        2318,
                        2340,
                        2341,
                        2361,
                        2365,
                        2368,
                        2380,
                        2387,
                        2391,
                        2395,
                        2404,
                        2429,
                        2443,
                        2481,
                        2500,
                        2511,
                        2513,
                        2516,
                        2525,
                        2593,
                        2594,
                        2636,
                        2640,
                        2641,
                        2645,
                        2658,
                        2664,
                        2665,
                        2667,
                        2668,
                        2670,
                        2675,
                        2678,
                        2679,
                        2680,
                        2711,
                        2721,
                        2742,
                        2752,
                        2807,
                        2809,
                        2810,
                        2945,
                        2948
                    ],
                    "children": [
                        {
                            "label": "entity_matching",
                            "description": "This subtopic focuses on techniques for identifying and matching entities across different datasets or contexts, ensuring consistency and accuracy in entity representation.",
                            "level": 3,
                            "example_papers": [
                                [
                                    52,
                                    "Language Models Learn Rare Phenomena from Less Rare Phenomena: The Case of the Missing AANNs"
                                ],
                                [
                                    155,
                                    "To Word Senses and Beyond: Inducing Concepts with Contextualized Language Models"
                                ],
                                [
                                    193,
                                    "Pixology: Probing the Linguistic and Visual Capabilities of Pixel-based Language Models"
                                ],
                                [
                                    351,
                                    "Learning from Natural Language Explanations for Generalizable Entity Matching"
                                ],
                                [
                                    1278,
                                    "Commentator: A Code-mixed Multilingual Text Annotation Framework"
                                ],
                                [
                                    1450,
                                    "General Collaborative Framework between Large Language Model and Experts for Universal Information Extraction"
                                ],
                                [
                                    1629,
                                    "Granular Entity Mapper: Advancing Fine-grained Multimodal Named Entity Recognition and Grounding"
                                ],
                                [
                                    2055,
                                    "Learning to Match Representations is Better for End-to-End Task-Oriented Dialog System"
                                ],
                                [
                                    2252,
                                    "NALA: an Effective and Interpretable Entity Alignment Method"
                                ],
                                [
                                    2636,
                                    "CUNI and LMU Submission to the MRL 2024 Shared Task on Multi-lingual Multi-task Information Retrieval"
                                ]
                            ],
                            "paper_ids": [
                                52,
                                155,
                                193,
                                351,
                                1278,
                                1450,
                                1629,
                                2055,
                                2252,
                                2636,
                                2658,
                                2664,
                                2665,
                                2667
                            ]
                        },
                        {
                            "label": "structured_entity_extraction",
                            "description": "This subtopic involves extracting entities from structured data formats, such as tables or databases, to facilitate better information retrieval and analysis.",
                            "level": 3,
                            "example_papers": [
                                [
                                    387,
                                    "Learning to Extract Structured Entities Using Language Models"
                                ],
                                [
                                    2645,
                                    "Information Extraction for Planning Court Cases"
                                ]
                            ],
                            "paper_ids": [
                                387,
                                2645
                            ]
                        },
                        {
                            "label": "entity_relation_extraction",
                            "description": "This subtopic deals with identifying and extracting relationships between entities within text, enhancing the understanding of how entities interact with one another.",
                            "level": 3,
                            "example_papers": [
                                [
                                    52,
                                    "Language Models Learn Rare Phenomena from Less Rare Phenomena: The Case of the Missing AANNs"
                                ],
                                [
                                    163,
                                    "Alignment-Enhanced Decoding: Defending Jailbreaks via Token-Level Adaptive Refining of Probability Distributions"
                                ],
                                [
                                    193,
                                    "Pixology: Probing the Linguistic and Visual Capabilities of Pixel-based Language Models"
                                ],
                                [
                                    215,
                                    "External Knowledge-Driven Argument Mining: Leveraging Attention-Enhanced Multi-Network Models"
                                ],
                                [
                                    256,
                                    "Visual Prompting in LLMs for Enhancing Emotion Recognition"
                                ],
                                [
                                    286,
                                    "MaPPER: Multimodal Prior-guided Parameter Efficient Tuning for Referring Expression Comprehension"
                                ],
                                [
                                    313,
                                    "LogicST: A Logical Self-Training Framework for Document-Level Relation Extraction with Incomplete Annotations"
                                ],
                                [
                                    332,
                                    "Teaching Small Language Models Reasoning through Counterfactual Distillation"
                                ],
                                [
                                    402,
                                    "Does Large Language Model Contain Task-Specific Neurons?"
                                ],
                                [
                                    529,
                                    "The effects of distance on NPI illusive effects in BERT"
                                ]
                            ],
                            "paper_ids": [
                                52,
                                163,
                                193,
                                215,
                                256,
                                286,
                                313,
                                332,
                                402,
                                529,
                                587,
                                628,
                                691,
                                725,
                                730,
                                762,
                                765,
                                803,
                                809,
                                831,
                                862,
                                1023,
                                1041,
                                1166,
                                1260,
                                1393,
                                1450,
                                1474,
                                1481,
                                1493,
                                1629,
                                1741,
                                1787,
                                1794,
                                1949,
                                1952,
                                2036,
                                2101,
                                2252,
                                2318,
                                2341,
                                2500,
                                2516,
                                2636,
                                2664,
                                2665,
                                2667,
                                2675,
                                2721
                            ]
                        },
                        {
                            "label": "entity_resolution",
                            "description": "This subtopic focuses on the process of determining when different representations refer to the same entity, thereby consolidating information and reducing redundancy.",
                            "level": 3,
                            "example_papers": [
                                [
                                    67,
                                    "Rethinking Pruning Large Language Models: Benefits and Pitfalls of Reconstruction Error Minimization"
                                ],
                                [
                                    163,
                                    "Alignment-Enhanced Decoding: Defending Jailbreaks via Token-Level Adaptive Refining of Probability Distributions"
                                ],
                                [
                                    193,
                                    "Pixology: Probing the Linguistic and Visual Capabilities of Pixel-based Language Models"
                                ],
                                [
                                    215,
                                    "External Knowledge-Driven Argument Mining: Leveraging Attention-Enhanced Multi-Network Models"
                                ],
                                [
                                    256,
                                    "Visual Prompting in LLMs for Enhancing Emotion Recognition"
                                ],
                                [
                                    286,
                                    "MaPPER: Multimodal Prior-guided Parameter Efficient Tuning for Referring Expression Comprehension"
                                ],
                                [
                                    313,
                                    "LogicST: A Logical Self-Training Framework for Document-Level Relation Extraction with Incomplete Annotations"
                                ],
                                [
                                    332,
                                    "Teaching Small Language Models Reasoning through Counterfactual Distillation"
                                ],
                                [
                                    351,
                                    "Learning from Natural Language Explanations for Generalizable Entity Matching"
                                ],
                                [
                                    390,
                                    "Beyond Embeddings: The Promise of Visual Table in Visual Reasoning"
                                ]
                            ],
                            "paper_ids": [
                                67,
                                163,
                                193,
                                215,
                                256,
                                286,
                                313,
                                332,
                                351,
                                390,
                                454,
                                544,
                                549,
                                570,
                                579,
                                615,
                                651,
                                691,
                                765,
                                803,
                                809,
                                849,
                                862,
                                987,
                                1015,
                                1023,
                                1069,
                                1109,
                                1127,
                                1219,
                                1320,
                                1334,
                                1357,
                                1450,
                                1472,
                                1493,
                                1629,
                                1640,
                                1755,
                                1821,
                                1861,
                                1863,
                                1952,
                                2015,
                                2055,
                                2066,
                                2101,
                                2252,
                                2318,
                                2341,
                                2361,
                                2380,
                                2500,
                                2511,
                                2640,
                                2645,
                                2658,
                                2665,
                                2670,
                                2680,
                                2711,
                                2721,
                                2742
                            ]
                        },
                        {
                            "label": "nested_named_entity_recognition",
                            "description": "This subtopic addresses the challenge of recognizing entities that are nested within other entities, allowing for a more nuanced extraction of complex information.",
                            "level": 3,
                            "example_papers": [
                                [
                                    491,
                                    "Exploring Nested Named Entity Recognition with Large Language Models: Methods, Challenges, and Insights"
                                ],
                                [
                                    628,
                                    "Code Prompting Elicits Conditional Reasoning Abilities in Text+Code LLMs"
                                ],
                                [
                                    1166,
                                    "TokenVerse: Towards Unifying Speech and NLP Tasks via Transducer-based ASR"
                                ],
                                [
                                    1629,
                                    "Granular Entity Mapper: Advancing Fine-grained Multimodal Named Entity Recognition and Grounding"
                                ],
                                [
                                    2636,
                                    "CUNI and LMU Submission to the MRL 2024 Shared Task on Multi-lingual Multi-task Information Retrieval"
                                ],
                                [
                                    2664,
                                    "Enhancing Legal Violation Identification with LLMs and Deep Learning Techniques: Achievements in the LegalLens 2024 Competition"
                                ],
                                [
                                    2667,
                                    "LegalLens Shared Task 2024: Legal Violation Identification in Unstructured Text"
                                ]
                            ],
                            "paper_ids": [
                                491,
                                628,
                                1166,
                                1629,
                                2636,
                                2664,
                                2667
                            ]
                        }
                    ]
                },
                {
                    "label": "entity_linking",
                    "description": "This cluster encompasses methods for linking extracted entities to their corresponding entries in knowledge bases or databases, ensuring accurate identification and context.",
                    "level": 2,
                    "example_papers": [
                        [
                            67,
                            "Rethinking Pruning Large Language Models: Benefits and Pitfalls of Reconstruction Error Minimization"
                        ],
                        [
                            163,
                            "Alignment-Enhanced Decoding: Defending Jailbreaks via Token-Level Adaptive Refining of Probability Distributions"
                        ],
                        [
                            193,
                            "Pixology: Probing the Linguistic and Visual Capabilities of Pixel-based Language Models"
                        ],
                        [
                            215,
                            "External Knowledge-Driven Argument Mining: Leveraging Attention-Enhanced Multi-Network Models"
                        ],
                        [
                            234,
                            "Semantic Training Signals Promote Hierarchical Syntactic Generalization in Transformers"
                        ],
                        [
                            256,
                            "Visual Prompting in LLMs for Enhancing Emotion Recognition"
                        ],
                        [
                            276,
                            "KidLM: Advancing Language Models for Children - Early Insights and Future Directions"
                        ],
                        [
                            279,
                            "An Unsupervised Approach to Achieve Supervised-Level Explainability in Healthcare Records"
                        ],
                        [
                            286,
                            "MaPPER: Multimodal Prior-guided Parameter Efficient Tuning for Referring Expression Comprehension"
                        ],
                        [
                            299,
                            "Pretraining Data Detection for Large Language Models: A Divergence-based Calibration Method"
                        ]
                    ],
                    "paper_ids": [
                        67,
                        163,
                        193,
                        215,
                        234,
                        256,
                        276,
                        279,
                        286,
                        299,
                        313,
                        332,
                        351,
                        390,
                        425,
                        454,
                        460,
                        544,
                        549,
                        570,
                        579,
                        615,
                        628,
                        651,
                        659,
                        679,
                        689,
                        691,
                        732,
                        755,
                        762,
                        765,
                        776,
                        800,
                        803,
                        809,
                        831,
                        849,
                        862,
                        894,
                        932,
                        987,
                        1015,
                        1023,
                        1069,
                        1109,
                        1127,
                        1166,
                        1219,
                        1230,
                        1260,
                        1320,
                        1334,
                        1357,
                        1450,
                        1472,
                        1493,
                        1513,
                        1556,
                        1629,
                        1636,
                        1640,
                        1741,
                        1755,
                        1787,
                        1821,
                        1861,
                        1863,
                        1952,
                        2015,
                        2022,
                        2035,
                        2036,
                        2048,
                        2051,
                        2055,
                        2066,
                        2101,
                        2251,
                        2252,
                        2318,
                        2340,
                        2341,
                        2361,
                        2368,
                        2380,
                        2429,
                        2500,
                        2511,
                        2593,
                        2640,
                        2645,
                        2658,
                        2665,
                        2670,
                        2680,
                        2711,
                        2721,
                        2742,
                        2752,
                        2807,
                        2810
                    ],
                    "children": [
                        {
                            "label": "knowledge_graph_enhancement",
                            "description": "This subtopic focuses on methods and techniques for improving the quality and utility of knowledge graphs, which are essential for effective entity linking.",
                            "level": 3,
                            "example_papers": [
                                [
                                    831,
                                    "MoCoKGC: Momentum Contrast Entity Encoding for Knowledge Graph Completion"
                                ],
                                [
                                    1260,
                                    "Knowledge Graph Enhanced Large Language Model Editing"
                                ],
                                [
                                    1320,
                                    "Optimizing Entity Resolution in Voice Interfaces: An ASR-Aware Entity Reference Expansion Approach"
                                ]
                            ],
                            "paper_ids": [
                                831,
                                1260,
                                1320
                            ]
                        },
                        {
                            "label": "data_quality_improvement",
                            "description": "This subtopic involves strategies and methodologies for enhancing the quality of data used in entity linking tasks, ensuring better accuracy and reliability.",
                            "level": 3,
                            "example_papers": [
                                [
                                    276,
                                    "KidLM: Advancing Language Models for Children - Early Insights and Future Directions"
                                ],
                                [
                                    279,
                                    "An Unsupervised Approach to Achieve Supervised-Level Explainability in Healthcare Records"
                                ],
                                [
                                    299,
                                    "Pretraining Data Detection for Large Language Models: A Divergence-based Calibration Method"
                                ],
                                [
                                    313,
                                    "LogicST: A Logical Self-Training Framework for Document-Level Relation Extraction with Incomplete Annotations"
                                ],
                                [
                                    425,
                                    "Multi-Dialect Vietnamese: Task, Dataset, Baseline Models and Challenges"
                                ],
                                [
                                    460,
                                    "Data Advisor: Dynamic Data Curation for Safety Alignment of Large Language Models"
                                ],
                                [
                                    615,
                                    "What are the Generator Preferences for End-to-end Task-Oriented Dialog System?"
                                ],
                                [
                                    679,
                                    "ControlMath: Controllable Data Generation Promotes Math Generalist Models"
                                ],
                                [
                                    776,
                                    "How Do Your Code LLMs perform? Empowering Code Instruction Tuning with Really Good Data"
                                ],
                                [
                                    1230,
                                    "Is Child-Directed Speech Effective Training Data for Language Models?"
                                ]
                            ],
                            "paper_ids": [
                                276,
                                279,
                                299,
                                313,
                                425,
                                460,
                                615,
                                679,
                                776,
                                1230,
                                1450,
                                1952,
                                2055,
                                2251,
                                2340,
                                2500,
                                2511,
                                2645,
                                2670,
                                2711,
                                2742,
                                2810
                            ]
                        },
                        {
                            "label": "few_shot_entity_linking",
                            "description": "This cluster focuses on techniques that enable effective entity linking with minimal labeled data, leveraging few-shot learning paradigms.",
                            "level": 3,
                            "example_papers": [
                                [
                                    351,
                                    "Learning from Natural Language Explanations for Generalizable Entity Matching"
                                ],
                                [
                                    628,
                                    "Code Prompting Elicits Conditional Reasoning Abilities in Text+Code LLMs"
                                ],
                                [
                                    651,
                                    "Major Entity Identification: A Generalizable Alternative to Coreference Resolution"
                                ],
                                [
                                    659,
                                    "NuNER: Entity Recognition Encoder Pre-training via LLM-Annotated Data"
                                ],
                                [
                                    732,
                                    "A Bayesian Approach to Harnessing the Power of LLMs in Authorship Attribution"
                                ],
                                [
                                    755,
                                    "OneNet: A Fine-Tuning Free Framework for Few-Shot Entity Linking via Large Language Model Prompting"
                                ],
                                [
                                    762,
                                    "Preserving Generalization of Language models in Few-shot Continual Relation Extraction"
                                ],
                                [
                                    765,
                                    "Topic-Oriented Open Relation Extraction with A Priori Seed Generation"
                                ],
                                [
                                    1166,
                                    "TokenVerse: Towards Unifying Speech and NLP Tasks via Transducer-based ASR"
                                ],
                                [
                                    1450,
                                    "General Collaborative Framework between Large Language Model and Experts for Universal Information Extraction"
                                ]
                            ],
                            "paper_ids": [
                                351,
                                628,
                                651,
                                659,
                                732,
                                755,
                                762,
                                765,
                                1166,
                                1450,
                                1556,
                                1629,
                                1787,
                                2022,
                                2035,
                                2036,
                                2101,
                                2251
                            ]
                        },
                        {
                            "label": "wikification",
                            "description": "This subtopic pertains to the process of linking textual mentions to their corresponding entries in Wikipedia, facilitating enhanced contextual understanding of entities.",
                            "level": 3,
                            "example_papers": [
                                [
                                    800,
                                    "ASL STEM Wiki: Dataset and Benchmark for Interpreting STEM Articles"
                                ],
                                [
                                    1127,
                                    "VIEWS: Entity-Aware News Video Captioning"
                                ],
                                [
                                    1166,
                                    "TokenVerse: Towards Unifying Speech and NLP Tasks via Transducer-based ASR"
                                ],
                                [
                                    1629,
                                    "Granular Entity Mapper: Advancing Fine-grained Multimodal Named Entity Recognition and Grounding"
                                ],
                                [
                                    1755,
                                    "Using RL to Identify Divisive Perspectives Improves LLMs Abilities to Identify Communities on Social Media"
                                ],
                                [
                                    1952,
                                    "Exploring the Capability of Multimodal LLMs with Yonkoma Manga: The YManga Dataset and Its Challenging Tasks"
                                ],
                                [
                                    2101,
                                    "ITER: Iterative Transformer-based Entity Recognition and Relation Extraction"
                                ],
                                [
                                    2511,
                                    "Text2Afford: Probing Object Affordance Prediction abilities of Language Models solely from Text"
                                ],
                                [
                                    2645,
                                    "Information Extraction for Planning Court Cases"
                                ],
                                [
                                    2665,
                                    "LegalLens 2024 Shared Task: Masala-chai Submission"
                                ]
                            ],
                            "paper_ids": [
                                800,
                                1127,
                                1166,
                                1629,
                                1755,
                                1952,
                                2101,
                                2511,
                                2645,
                                2665,
                                2711,
                                2752,
                                2807
                            ]
                        }
                    ]
                },
                {
                    "label": "entity_disambiguation",
                    "description": "This cluster deals with resolving ambiguities in entity recognition, determining the correct entity when multiple candidates exist for the same mention in text.",
                    "level": 2,
                    "example_papers": [
                        [
                            67,
                            "Rethinking Pruning Large Language Models: Benefits and Pitfalls of Reconstruction Error Minimization"
                        ],
                        [
                            143,
                            "Can visual language models resolve textual ambiguity with visual cues? Let visual puns tell you!"
                        ],
                        [
                            155,
                            "To Word Senses and Beyond: Inducing Concepts with Contextualized Language Models"
                        ],
                        [
                            163,
                            "Alignment-Enhanced Decoding: Defending Jailbreaks via Token-Level Adaptive Refining of Probability Distributions"
                        ],
                        [
                            193,
                            "Pixology: Probing the Linguistic and Visual Capabilities of Pixel-based Language Models"
                        ],
                        [
                            215,
                            "External Knowledge-Driven Argument Mining: Leveraging Attention-Enhanced Multi-Network Models"
                        ],
                        [
                            234,
                            "Semantic Training Signals Promote Hierarchical Syntactic Generalization in Transformers"
                        ],
                        [
                            256,
                            "Visual Prompting in LLMs for Enhancing Emotion Recognition"
                        ],
                        [
                            276,
                            "KidLM: Advancing Language Models for Children - Early Insights and Future Directions"
                        ],
                        [
                            279,
                            "An Unsupervised Approach to Achieve Supervised-Level Explainability in Healthcare Records"
                        ]
                    ],
                    "paper_ids": [
                        67,
                        143,
                        155,
                        163,
                        193,
                        215,
                        234,
                        256,
                        276,
                        279,
                        286,
                        299,
                        313,
                        332,
                        354,
                        390,
                        425,
                        454,
                        460,
                        544,
                        549,
                        570,
                        579,
                        615,
                        628,
                        651,
                        659,
                        669,
                        679,
                        689,
                        691,
                        732,
                        762,
                        765,
                        776,
                        803,
                        809,
                        829,
                        831,
                        849,
                        854,
                        862,
                        894,
                        932,
                        987,
                        1010,
                        1015,
                        1023,
                        1069,
                        1109,
                        1127,
                        1166,
                        1219,
                        1230,
                        1260,
                        1308,
                        1320,
                        1334,
                        1357,
                        1450,
                        1472,
                        1485,
                        1493,
                        1513,
                        1556,
                        1626,
                        1629,
                        1636,
                        1640,
                        1741,
                        1755,
                        1787,
                        1821,
                        1861,
                        1863,
                        1952,
                        2015,
                        2022,
                        2035,
                        2036,
                        2048,
                        2051,
                        2066,
                        2101,
                        2251,
                        2256,
                        2318,
                        2340,
                        2341,
                        2361,
                        2368,
                        2380,
                        2391,
                        2429,
                        2443,
                        2470,
                        2496,
                        2500,
                        2511,
                        2522,
                        2593,
                        2640,
                        2658,
                        2665,
                        2670,
                        2680,
                        2711,
                        2721,
                        2752,
                        2807,
                        2810
                    ],
                    "children": [
                        {
                            "label": "word_sense_disambiguation",
                            "description": "This subtopic focuses on resolving ambiguities in word meanings, determining the correct sense of a word based on its context in the text.",
                            "level": 3,
                            "example_papers": [
                                [
                                    143,
                                    "Can visual language models resolve textual ambiguity with visual cues? Let visual puns tell you!"
                                ],
                                [
                                    155,
                                    "To Word Senses and Beyond: Inducing Concepts with Contextualized Language Models"
                                ],
                                [
                                    691,
                                    "Latent Concept-based Explanation of NLP Models"
                                ],
                                [
                                    1308,
                                    "Generative Dictionary: Improving Language Learner Understanding with Contextual Definitions"
                                ],
                                [
                                    2496,
                                    "On Functional Competence of LLMs for Linguistic Disambiguation"
                                ]
                            ],
                            "paper_ids": [
                                143,
                                155,
                                691,
                                1308,
                                2496
                            ]
                        },
                        {
                            "label": "named_entity_disambiguation",
                            "description": "This subtopic deals with identifying and resolving ambiguities in named entities, ensuring the correct entity is recognized when multiple candidates exist.",
                            "level": 3,
                            "example_papers": [
                                [
                                    67,
                                    "Rethinking Pruning Large Language Models: Benefits and Pitfalls of Reconstruction Error Minimization"
                                ],
                                [
                                    163,
                                    "Alignment-Enhanced Decoding: Defending Jailbreaks via Token-Level Adaptive Refining of Probability Distributions"
                                ],
                                [
                                    193,
                                    "Pixology: Probing the Linguistic and Visual Capabilities of Pixel-based Language Models"
                                ],
                                [
                                    215,
                                    "External Knowledge-Driven Argument Mining: Leveraging Attention-Enhanced Multi-Network Models"
                                ],
                                [
                                    276,
                                    "KidLM: Advancing Language Models for Children - Early Insights and Future Directions"
                                ],
                                [
                                    279,
                                    "An Unsupervised Approach to Achieve Supervised-Level Explainability in Healthcare Records"
                                ],
                                [
                                    286,
                                    "MaPPER: Multimodal Prior-guided Parameter Efficient Tuning for Referring Expression Comprehension"
                                ],
                                [
                                    299,
                                    "Pretraining Data Detection for Large Language Models: A Divergence-based Calibration Method"
                                ],
                                [
                                    313,
                                    "LogicST: A Logical Self-Training Framework for Document-Level Relation Extraction with Incomplete Annotations"
                                ],
                                [
                                    354,
                                    "Contrastive Entity Coreference and Disambiguation for Historical Texts"
                                ]
                            ],
                            "paper_ids": [
                                67,
                                163,
                                193,
                                215,
                                276,
                                279,
                                286,
                                299,
                                313,
                                354,
                                390,
                                425,
                                454,
                                460,
                                549,
                                570,
                                579,
                                615,
                                628,
                                651,
                                659,
                                679,
                                689,
                                732,
                                762,
                                765,
                                776,
                                803,
                                809,
                                829,
                                831,
                                849,
                                854,
                                862,
                                932,
                                987,
                                1010,
                                1015,
                                1023,
                                1069,
                                1109,
                                1127,
                                1166,
                                1219,
                                1230,
                                1320,
                                1334,
                                1450,
                                1472,
                                1485,
                                1513,
                                1556,
                                1626,
                                1629,
                                1636,
                                1640,
                                1755,
                                1787,
                                1821,
                                1861,
                                1863,
                                1952,
                                2022,
                                2035,
                                2036,
                                2101,
                                2251,
                                2256,
                                2340,
                                2361,
                                2368,
                                2391,
                                2429,
                                2500,
                                2511,
                                2593,
                                2640,
                                2658,
                                2665,
                                2680,
                                2711,
                                2721,
                                2752,
                                2807,
                                2810
                            ]
                        },
                        {
                            "label": "extractive_disambiguation",
                            "description": "This subtopic involves the extraction of relevant information to clarify ambiguities in entity recognition, enhancing the accuracy of identified entities.",
                            "level": 3,
                            "example_papers": [
                                [
                                    67,
                                    "Rethinking Pruning Large Language Models: Benefits and Pitfalls of Reconstruction Error Minimization"
                                ],
                                [
                                    163,
                                    "Alignment-Enhanced Decoding: Defending Jailbreaks via Token-Level Adaptive Refining of Probability Distributions"
                                ],
                                [
                                    279,
                                    "An Unsupervised Approach to Achieve Supervised-Level Explainability in Healthcare Records"
                                ],
                                [
                                    299,
                                    "Pretraining Data Detection for Large Language Models: A Divergence-based Calibration Method"
                                ],
                                [
                                    313,
                                    "LogicST: A Logical Self-Training Framework for Document-Level Relation Extraction with Incomplete Annotations"
                                ],
                                [
                                    454,
                                    "Empowering Backbone Models for Visual Text Generation with Input Granularity Control and Glyph-Aware Training"
                                ],
                                [
                                    460,
                                    "Data Advisor: Dynamic Data Curation for Safety Alignment of Large Language Models"
                                ],
                                [
                                    579,
                                    "CARER - ClinicAl Reasoning-Enhanced Representation for Temporal Health Risk Prediction"
                                ],
                                [
                                    765,
                                    "Topic-Oriented Open Relation Extraction with A Priori Seed Generation"
                                ],
                                [
                                    809,
                                    "Interpretable Composition Attribution Enhancement for Visio-linguistic Compositional Understanding"
                                ]
                            ],
                            "paper_ids": [
                                67,
                                163,
                                279,
                                299,
                                313,
                                454,
                                460,
                                579,
                                765,
                                809,
                                849,
                                862,
                                932,
                                1015,
                                1023,
                                1109,
                                1334,
                                1450,
                                1485,
                                1556,
                                1636,
                                1640,
                                1755,
                                1787,
                                1861,
                                1863,
                                2101,
                                2251,
                                2256,
                                2340,
                                2429,
                                2500,
                                2593,
                                2640,
                                2680,
                                2711
                            ]
                        },
                        {
                            "label": "pronoun_resolution",
                            "description": "This subtopic addresses the challenge of determining the correct entities that pronouns refer to in a given text, resolving potential ambiguities.",
                            "level": 3,
                            "example_papers": [
                                [
                                    193,
                                    "Pixology: Probing the Linguistic and Visual Capabilities of Pixel-based Language Models"
                                ],
                                [
                                    276,
                                    "KidLM: Advancing Language Models for Children - Early Insights and Future Directions"
                                ],
                                [
                                    390,
                                    "Beyond Embeddings: The Promise of Visual Table in Visual Reasoning"
                                ],
                                [
                                    570,
                                    "I Learn Better If You Speak My Language: Understanding the Superior Performance of Fine-Tuning Large Language Models with LLM-Generated Responses"
                                ],
                                [
                                    628,
                                    "Code Prompting Elicits Conditional Reasoning Abilities in Text+Code LLMs"
                                ],
                                [
                                    776,
                                    "How Do Your Code LLMs perform? Empowering Code Instruction Tuning with Really Good Data"
                                ],
                                [
                                    803,
                                    "DC-Instruct: An Effective Framework for Generative Multi-intent Spoken Language Understanding"
                                ],
                                [
                                    932,
                                    "Investigating Large Language Models for Complex Word Identification in Multilingual and Multidomain Setups"
                                ],
                                [
                                    1069,
                                    "BLSP-Emo: Towards Empathetic Large Speech-Language Models"
                                ],
                                [
                                    1230,
                                    "Is Child-Directed Speech Effective Training Data for Language Models?"
                                ]
                            ],
                            "paper_ids": [
                                193,
                                276,
                                390,
                                570,
                                628,
                                776,
                                803,
                                932,
                                1069,
                                1230,
                                1472,
                                1556,
                                1863,
                                2022,
                                2035,
                                2251,
                                2391,
                                2429,
                                2470,
                                2511,
                                2522,
                                2752
                            ]
                        },
                        {
                            "label": "cross_document_coreference",
                            "description": "This subtopic focuses on resolving ambiguities in entity references across multiple documents, ensuring consistent identification of entities throughout a corpus.",
                            "level": 3,
                            "example_papers": [
                                [
                                    215,
                                    "External Knowledge-Driven Argument Mining: Leveraging Attention-Enhanced Multi-Network Models"
                                ],
                                [
                                    354,
                                    "Contrastive Entity Coreference and Disambiguation for Historical Texts"
                                ],
                                [
                                    732,
                                    "A Bayesian Approach to Harnessing the Power of LLMs in Authorship Attribution"
                                ],
                                [
                                    932,
                                    "Investigating Large Language Models for Complex Word Identification in Multilingual and Multidomain Setups"
                                ],
                                [
                                    1219,
                                    "Dynamic Rewarding with Prompt Optimization Enables Tuning-free Self-Alignment of Language Models"
                                ],
                                [
                                    1556,
                                    "Abstraction-of-Thought Makes Language Models Better Reasoners"
                                ],
                                [
                                    1821,
                                    "Improving Referring Ability for Biomedical Language Models"
                                ],
                                [
                                    1863,
                                    "LongHeads: Multi-Head Attention is Secretly a Long Context Processor"
                                ],
                                [
                                    2251,
                                    "One Model is All You Need: ByT5-Sanskrit, a Unified Model for Sanskrit NLP Tasks"
                                ],
                                [
                                    2429,
                                    "PositionID: LLMs can Control Lengths, Copy and Paste with Explicit Positional Awareness"
                                ]
                            ],
                            "paper_ids": [
                                215,
                                354,
                                732,
                                932,
                                1219,
                                1556,
                                1821,
                                1863,
                                2251,
                                2429,
                                2721
                            ]
                        }
                    ]
                },
                {
                    "label": "evaluation_metrics",
                    "description": "This cluster is dedicated to the assessment and evaluation of named entity recognition systems, focusing on metrics and methodologies to measure their performance.",
                    "level": 2,
                    "example_papers": [
                        [
                            17,
                            "Uncertainty in Language Models: Assessment through Rank-Calibration"
                        ],
                        [
                            67,
                            "Rethinking Pruning Large Language Models: Benefits and Pitfalls of Reconstruction Error Minimization"
                        ],
                        [
                            165,
                            "Evaluating Large Language Models via Linguistic Profiling"
                        ],
                        [
                            186,
                            "ScalingFilter: Assessing Data Quality through Inverse Utilization of Scaling Laws"
                        ],
                        [
                            193,
                            "Pixology: Probing the Linguistic and Visual Capabilities of Pixel-based Language Models"
                        ],
                        [
                            279,
                            "An Unsupervised Approach to Achieve Supervised-Level Explainability in Healthcare Records"
                        ],
                        [
                            332,
                            "Teaching Small Language Models Reasoning through Counterfactual Distillation"
                        ],
                        [
                            342,
                            "SaySelf: Teaching LLMs to Express Confidence with Self-Reflective Rationales"
                        ],
                        [
                            425,
                            "Multi-Dialect Vietnamese: Task, Dataset, Baseline Models and Challenges"
                        ],
                        [
                            508,
                            "Can Active Label Correction Improve LLM-based Modular AI Systems?"
                        ]
                    ],
                    "paper_ids": [
                        17,
                        67,
                        165,
                        186,
                        193,
                        279,
                        332,
                        342,
                        425,
                        508,
                        521,
                        544,
                        549,
                        563,
                        570,
                        573,
                        614,
                        651,
                        656,
                        679,
                        760,
                        776,
                        835,
                        849,
                        895,
                        932,
                        977,
                        1010,
                        1096,
                        1107,
                        1148,
                        1166,
                        1170,
                        1203,
                        1230,
                        1334,
                        1344,
                        1357,
                        1472,
                        1513,
                        1532,
                        1556,
                        1576,
                        1618,
                        1628,
                        1636,
                        1741,
                        1767,
                        1769,
                        1858,
                        1909,
                        1952,
                        1971,
                        1997,
                        2002,
                        2005,
                        2015,
                        2022,
                        2035,
                        2051,
                        2101,
                        2184,
                        2228,
                        2245,
                        2251,
                        2267,
                        2289,
                        2298,
                        2329,
                        2340,
                        2404,
                        2429,
                        2452,
                        2467,
                        2477,
                        2482,
                        2522,
                        2641,
                        2645,
                        2658,
                        2665,
                        2670,
                        2673,
                        2679,
                        2698,
                        2711,
                        2749,
                        2752,
                        2763,
                        518,
                        556,
                        1077,
                        1084,
                        1673,
                        1963,
                        2024,
                        2543,
                        674,
                        886,
                        1053,
                        1290,
                        1998,
                        2210,
                        2573
                    ],
                    "children": [
                        {
                            "label": "evaluation_metrics_methods",
                            "description": "This cluster focuses on the various methodologies and techniques used to evaluate the performance of named entity recognition systems.",
                            "level": 3,
                            "example_papers": [
                                [
                                    165,
                                    "Evaluating Large Language Models via Linguistic Profiling"
                                ],
                                [
                                    186,
                                    "ScalingFilter: Assessing Data Quality through Inverse Utilization of Scaling Laws"
                                ],
                                [
                                    332,
                                    "Teaching Small Language Models Reasoning through Counterfactual Distillation"
                                ],
                                [
                                    342,
                                    "SaySelf: Teaching LLMs to Express Confidence with Self-Reflective Rationales"
                                ],
                                [
                                    651,
                                    "Major Entity Identification: A Generalizable Alternative to Coreference Resolution"
                                ],
                                [
                                    656,
                                    "\"A good pun is its own reword\": Can Large Language Models Understand Puns?"
                                ],
                                [
                                    835,
                                    "RaTEScore: A Metric for Radiology Report Generation"
                                ],
                                [
                                    895,
                                    "Leveraging Large Language Models for NLG Evaluation: Advances and Challenges"
                                ],
                                [
                                    1344,
                                    "Divide-Conquer-Reasoning for Consistency Evaluation and Automatic Improvement of Large Language Models"
                                ],
                                [
                                    1357,
                                    "FanLoRA: Fantastic LoRAs and Where to Find Them in Large Language Model Fine-tuning"
                                ]
                            ],
                            "paper_ids": [
                                165,
                                186,
                                332,
                                342,
                                651,
                                656,
                                835,
                                895,
                                1344,
                                1357,
                                1513,
                                1532,
                                1576,
                                1618,
                                1741,
                                1767,
                                1858,
                                1997,
                                2002,
                                2101,
                                2429,
                                2467,
                                2477,
                                2641,
                                2645,
                                2658,
                                2698,
                                2711
                            ]
                        },
                        {
                            "label": "evaluation_of_performance",
                            "description": "This cluster is dedicated to assessing the overall performance of named entity recognition systems through various evaluation metrics.",
                            "level": 3,
                            "example_papers": [
                                [
                                    17,
                                    "Uncertainty in Language Models: Assessment through Rank-Calibration"
                                ],
                                [
                                    67,
                                    "Rethinking Pruning Large Language Models: Benefits and Pitfalls of Reconstruction Error Minimization"
                                ],
                                [
                                    186,
                                    "ScalingFilter: Assessing Data Quality through Inverse Utilization of Scaling Laws"
                                ],
                                [
                                    193,
                                    "Pixology: Probing the Linguistic and Visual Capabilities of Pixel-based Language Models"
                                ],
                                [
                                    332,
                                    "Teaching Small Language Models Reasoning through Counterfactual Distillation"
                                ],
                                [
                                    425,
                                    "Multi-Dialect Vietnamese: Task, Dataset, Baseline Models and Challenges"
                                ],
                                [
                                    521,
                                    "RuBLiMP: Russian Benchmark of Linguistic Minimal Pairs"
                                ],
                                [
                                    544,
                                    "Evaluating the Effectiveness of Large Language Models in Establishing Conversational Grounding"
                                ],
                                [
                                    549,
                                    "Can Transformers Learn n-gram Language Models?"
                                ],
                                [
                                    563,
                                    "Detecting Subtle Differences between Human and Model Languages Using Spectrum of Relative Likelihood"
                                ]
                            ],
                            "paper_ids": [
                                17,
                                67,
                                186,
                                193,
                                332,
                                425,
                                521,
                                544,
                                549,
                                563,
                                570,
                                573,
                                614,
                                651,
                                656,
                                679,
                                760,
                                776,
                                849,
                                895,
                                932,
                                977,
                                1096,
                                1107,
                                1166,
                                1170,
                                1203,
                                1230,
                                1334,
                                1344,
                                1472,
                                1576,
                                1628,
                                1636,
                                1769,
                                1858,
                                1909,
                                1952,
                                1971,
                                2005,
                                2015,
                                2022,
                                2035,
                                2101,
                                2184,
                                2228,
                                2245,
                                2251,
                                2267,
                                2289,
                                2298,
                                2329,
                                2340,
                                2404,
                                2452,
                                2482,
                                2522,
                                2665,
                                2670,
                                2673,
                                2679,
                                2698,
                                2711,
                                2763
                            ]
                        },
                        {
                            "label": "data_quality",
                            "description": "This cluster examines the impact of data quality on the performance of named entity recognition systems and the metrics used to evaluate it.",
                            "level": 3,
                            "example_papers": [
                                [
                                    186,
                                    "ScalingFilter: Assessing Data Quality through Inverse Utilization of Scaling Laws"
                                ],
                                [
                                    776,
                                    "How Do Your Code LLMs perform? Empowering Code Instruction Tuning with Really Good Data"
                                ],
                                [
                                    2340,
                                    "Evaluating Differentially Private Synthetic Data Generation in High-Stakes Domains"
                                ],
                                [
                                    2711,
                                    "Exploring Large Language Models for Qualitative Data Analysis"
                                ]
                            ],
                            "paper_ids": [
                                186,
                                776,
                                2340,
                                2711
                            ]
                        },
                        {
                            "label": "interpretability",
                            "description": "This cluster explores the interpretability of evaluation metrics in named entity recognition, focusing on how well these metrics can be understood and applied.",
                            "level": 3,
                            "example_papers": [
                                [
                                    279,
                                    "An Unsupervised Approach to Achieve Supervised-Level Explainability in Healthcare Records"
                                ],
                                [
                                    1472,
                                    "Can Large Language Models Identify Authorship?"
                                ],
                                [
                                    1576,
                                    "Faithful and Plausible Natural Language Explanations for Image Classification: A Pipeline Approach"
                                ],
                                [
                                    2002,
                                    "LLM Explainability via Attributive Masking Learning"
                                ],
                                [
                                    2452,
                                    "Are there identifiable structural parts in the sentence embedding whole?"
                                ],
                                [
                                    2482,
                                    "Wrapper Boxes for Faithful Attribution of Model Predictions to Training Data"
                                ],
                                [
                                    2522,
                                    "Solving the Challenge Set without Solving the Task: On Winograd Schemas as a Test of Pronominal Coreference Resolution"
                                ],
                                [
                                    2711,
                                    "Exploring Large Language Models for Qualitative Data Analysis"
                                ],
                                [
                                    2749,
                                    "TokenSHAP: Interpreting Large Language Models with Monte Carlo Shapley Value Estimation"
                                ]
                            ],
                            "paper_ids": [
                                279,
                                1472,
                                1576,
                                2002,
                                2452,
                                2482,
                                2522,
                                2711,
                                2749
                            ]
                        },
                        {
                            "label": "evaluation_of_noise_impact",
                            "description": "This cluster investigates how noise in data affects the performance of named entity recognition systems and the corresponding evaluation metrics.",
                            "level": 3,
                            "example_papers": [
                                [
                                    67,
                                    "Rethinking Pruning Large Language Models: Benefits and Pitfalls of Reconstruction Error Minimization"
                                ],
                                [
                                    193,
                                    "Pixology: Probing the Linguistic and Visual Capabilities of Pixel-based Language Models"
                                ],
                                [
                                    425,
                                    "Multi-Dialect Vietnamese: Task, Dataset, Baseline Models and Challenges"
                                ],
                                [
                                    508,
                                    "Can Active Label Correction Improve LLM-based Modular AI Systems?"
                                ],
                                [
                                    1010,
                                    "NoiseBench: Benchmarking the Impact of Real Label Noise on Named Entity Recognition"
                                ],
                                [
                                    1148,
                                    "Interventional Speech Noise Injection for ASR Generalizable Spoken Language Understanding"
                                ],
                                [
                                    1230,
                                    "Is Child-Directed Speech Effective Training Data for Language Models?"
                                ],
                                [
                                    2184,
                                    "Pre-trained Language Models Return Distinguishable Probability Distributions to Unfaithfully Hallucinated Texts"
                                ],
                                [
                                    2251,
                                    "One Model is All You Need: ByT5-Sanskrit, a Unified Model for Sanskrit NLP Tasks"
                                ],
                                [
                                    2267,
                                    "Downstream Trade-offs of a Family of Text Watermarks"
                                ]
                            ],
                            "paper_ids": [
                                67,
                                193,
                                425,
                                508,
                                1010,
                                1148,
                                1230,
                                2184,
                                2251,
                                2267,
                                2711
                            ]
                        }
                    ]
                },
                {
                    "label": "cross-lingual_ner",
                    "description": "This cluster explores named entity recognition across different languages, addressing the challenges and techniques for recognizing entities in multilingual contexts.",
                    "level": 2,
                    "example_papers": [
                        [
                            67,
                            "Rethinking Pruning Large Language Models: Benefits and Pitfalls of Reconstruction Error Minimization"
                        ],
                        [
                            94,
                            "Cross-domain NER with Generated Task-Oriented Knowledge: An Empirical Study from Information Density Perspective"
                        ],
                        [
                            193,
                            "Pixology: Probing the Linguistic and Visual Capabilities of Pixel-based Language Models"
                        ],
                        [
                            279,
                            "An Unsupervised Approach to Achieve Supervised-Level Explainability in Healthcare Records"
                        ],
                        [
                            332,
                            "Teaching Small Language Models Reasoning through Counterfactual Distillation"
                        ],
                        [
                            407,
                            "Python is Not Always the Best Choice: Embracing Multilingual Program of Thoughts"
                        ],
                        [
                            425,
                            "Multi-Dialect Vietnamese: Task, Dataset, Baseline Models and Challenges"
                        ],
                        [
                            544,
                            "Evaluating the Effectiveness of Large Language Models in Establishing Conversational Grounding"
                        ],
                        [
                            549,
                            "Can Transformers Learn n-gram Language Models?"
                        ],
                        [
                            570,
                            "I Learn Better If You Speak My Language: Understanding the Superior Performance of Fine-Tuning Large Language Models with LLM-Generated Responses"
                        ]
                    ],
                    "paper_ids": [
                        67,
                        94,
                        193,
                        279,
                        332,
                        407,
                        425,
                        544,
                        549,
                        570,
                        637,
                        651,
                        659,
                        675,
                        679,
                        719,
                        752,
                        776,
                        849,
                        932,
                        1010,
                        1035,
                        1048,
                        1166,
                        1230,
                        1334,
                        1357,
                        1370,
                        1472,
                        1513,
                        1542,
                        1556,
                        1636,
                        1741,
                        1845,
                        1846,
                        1921,
                        1952,
                        1954,
                        2015,
                        2022,
                        2035,
                        2051,
                        2101,
                        2251,
                        2340,
                        2429,
                        2510,
                        2600,
                        2619,
                        2628,
                        2636,
                        2658,
                        2665,
                        2670,
                        2711,
                        2752
                    ],
                    "children": [
                        {
                            "label": "transfer_learning",
                            "description": "This subtopic focuses on leveraging knowledge from one or more source languages to improve named entity recognition performance in target languages, particularly in cross-lingual contexts.",
                            "level": 3,
                            "example_papers": [
                                [
                                    332,
                                    "Teaching Small Language Models Reasoning through Counterfactual Distillation"
                                ],
                                [
                                    570,
                                    "I Learn Better If You Speak My Language: Understanding the Superior Performance of Fine-Tuning Large Language Models with LLM-Generated Responses"
                                ],
                                [
                                    637,
                                    "TEMA: Token Embeddings Mapping for Enriching Low-Resource Language Models"
                                ],
                                [
                                    659,
                                    "NuNER: Entity Recognition Encoder Pre-training via LLM-Annotated Data"
                                ],
                                [
                                    675,
                                    "TL-CL: Task And Language Incremental Continual Learning"
                                ],
                                [
                                    1035,
                                    "Instruction Matters: A Simple yet Effective Task Selection for Optimized Instruction Tuning of Specific Tasks"
                                ],
                                [
                                    1357,
                                    "FanLoRA: Fantastic LoRAs and Where to Find Them in Large Language Model Fine-tuning"
                                ],
                                [
                                    1370,
                                    "Improving Few-Shot Cross-Domain Named Entity Recognition by Instruction Tuning a Word-Embedding based Retrieval Augmented Large Language Model"
                                ],
                                [
                                    1472,
                                    "Can Large Language Models Identify Authorship?"
                                ],
                                [
                                    1954,
                                    "Unlocking the Potential of Model Merging for Low-Resource Languages"
                                ]
                            ],
                            "paper_ids": [
                                332,
                                570,
                                637,
                                659,
                                675,
                                1035,
                                1357,
                                1370,
                                1472,
                                1954,
                                2022,
                                2035,
                                2251,
                                2619,
                                2628,
                                2711
                            ]
                        },
                        {
                            "label": "low_resource_languages",
                            "description": "This subtopic addresses the challenges and methodologies for performing named entity recognition in languages that have limited annotated data available.",
                            "level": 3,
                            "example_papers": [
                                [
                                    637,
                                    "TEMA: Token Embeddings Mapping for Enriching Low-Resource Language Models"
                                ],
                                [
                                    752,
                                    "Zero-Shot Cross-Lingual NER Using Phonemic Representations for Low-Resource Languages"
                                ],
                                [
                                    1230,
                                    "Is Child-Directed Speech Effective Training Data for Language Models?"
                                ],
                                [
                                    1846,
                                    "Few-shot clinical entity recognition in English, French and Spanish: masked language models outperform generative model prompting"
                                ],
                                [
                                    1954,
                                    "Unlocking the Potential of Model Merging for Low-Resource Languages"
                                ],
                                [
                                    2251,
                                    "One Model is All You Need: ByT5-Sanskrit, a Unified Model for Sanskrit NLP Tasks"
                                ],
                                [
                                    2619,
                                    "Cross-Lingual Named Entity Recognition for Low-Resource Languages: A Hindi-Nepali Case Study Using Multilingual BERT Models"
                                ],
                                [
                                    2628,
                                    "Bridging the Bosphorus: Advancing Turkish Large Language Models through Strategies for Low-Resource Language Adaptation and Benchmarking"
                                ],
                                [
                                    2636,
                                    "CUNI and LMU Submission to the MRL 2024 Shared Task on Multi-lingual Multi-task Information Retrieval"
                                ]
                            ],
                            "paper_ids": [
                                637,
                                752,
                                1230,
                                1846,
                                1954,
                                2251,
                                2619,
                                2628,
                                2636
                            ]
                        },
                        {
                            "label": "multimodal_ner",
                            "description": "This subtopic explores the integration of multiple data modalities, such as text and images, to enhance named entity recognition across different languages.",
                            "level": 3,
                            "example_papers": [
                                [
                                    1166,
                                    "TokenVerse: Towards Unifying Speech and NLP Tasks via Transducer-based ASR"
                                ],
                                [
                                    1513,
                                    "Breaking the Boundaries: A Unified Framework for Chinese Named Entity Recognition Across Text and Speech"
                                ],
                                [
                                    1952,
                                    "Exploring the Capability of Multimodal LLMs with Yonkoma Manga: The YManga Dataset and Its Challenging Tasks"
                                ]
                            ],
                            "paper_ids": [
                                1166,
                                1513,
                                1952
                            ]
                        },
                        {
                            "label": "domain_adaptation",
                            "description": "This subtopic investigates techniques for adapting named entity recognition models to perform effectively in specific domains or contexts across various languages.",
                            "level": 3,
                            "example_papers": [
                                [
                                    67,
                                    "Rethinking Pruning Large Language Models: Benefits and Pitfalls of Reconstruction Error Minimization"
                                ],
                                [
                                    94,
                                    "Cross-domain NER with Generated Task-Oriented Knowledge: An Empirical Study from Information Density Perspective"
                                ],
                                [
                                    279,
                                    "An Unsupervised Approach to Achieve Supervised-Level Explainability in Healthcare Records"
                                ],
                                [
                                    679,
                                    "ControlMath: Controllable Data Generation Promotes Math Generalist Models"
                                ],
                                [
                                    719,
                                    "SPEED++: A Multilingual Event Extraction Framework for Epidemic Prediction and Preparedness"
                                ],
                                [
                                    1048,
                                    "Are Data Augmentation Methods in Named Entity Recognition Applicable for Uncertainty Estimation?"
                                ],
                                [
                                    1370,
                                    "Improving Few-Shot Cross-Domain Named Entity Recognition by Instruction Tuning a Word-Embedding based Retrieval Augmented Large Language Model"
                                ],
                                [
                                    1636,
                                    "Multi-Stage Balanced Distillation: Addressing Long-Tail Challenges in Sequence-Level Knowledge Distillation"
                                ],
                                [
                                    1741,
                                    "A Simple but Effective Approach to Improve Structured Language Model Output for Information Extraction"
                                ],
                                [
                                    1845,
                                    "Beyond Common Words: Enhancing ASR Cross-Lingual Proper Noun Recognition Using Large Language Models"
                                ]
                            ],
                            "paper_ids": [
                                67,
                                94,
                                279,
                                679,
                                719,
                                1048,
                                1370,
                                1636,
                                1741,
                                1845,
                                2101,
                                2340,
                                2665
                            ]
                        },
                        {
                            "label": "cross-lingual_entity_alignment",
                            "description": "This subtopic focuses on aligning named entities across different languages, ensuring that entities are recognized and linked correctly in multilingual datasets.",
                            "level": 3,
                            "example_papers": [
                                [
                                    94,
                                    "Cross-domain NER with Generated Task-Oriented Knowledge: An Empirical Study from Information Density Perspective"
                                ],
                                [
                                    193,
                                    "Pixology: Probing the Linguistic and Visual Capabilities of Pixel-based Language Models"
                                ],
                                [
                                    407,
                                    "Python is Not Always the Best Choice: Embracing Multilingual Program of Thoughts"
                                ],
                                [
                                    544,
                                    "Evaluating the Effectiveness of Large Language Models in Establishing Conversational Grounding"
                                ],
                                [
                                    651,
                                    "Major Entity Identification: A Generalizable Alternative to Coreference Resolution"
                                ],
                                [
                                    675,
                                    "TL-CL: Task And Language Incremental Continual Learning"
                                ],
                                [
                                    719,
                                    "SPEED++: A Multilingual Event Extraction Framework for Epidemic Prediction and Preparedness"
                                ],
                                [
                                    752,
                                    "Zero-Shot Cross-Lingual NER Using Phonemic Representations for Low-Resource Languages"
                                ],
                                [
                                    776,
                                    "How Do Your Code LLMs perform? Empowering Code Instruction Tuning with Really Good Data"
                                ],
                                [
                                    932,
                                    "Investigating Large Language Models for Complex Word Identification in Multilingual and Multidomain Setups"
                                ]
                            ],
                            "paper_ids": [
                                94,
                                193,
                                407,
                                544,
                                651,
                                675,
                                719,
                                752,
                                776,
                                932,
                                1010,
                                1048,
                                1542,
                                1556,
                                1845,
                                1846,
                                1921,
                                2429,
                                2510,
                                2600,
                                2619,
                                2636,
                                2658,
                                2665,
                                2752
                            ]
                        }
                    ]
                }
            ]
        },
        {
            "label": "machine_translation",
            "description": "The task of automatically translating text from one language to another while preserving its meaning and context, facilitating cross-lingual communication.",
            "level": 1,
            "example_papers": [
                [
                    5,
                    "ImageInWords: Unlocking Hyper-Detailed Image Descriptions"
                ],
                [
                    17,
                    "Uncertainty in Language Models: Assessment through Rank-Calibration"
                ],
                [
                    23,
                    "Fine-Tuning Large Language Models to Translate: Will a Touch of Noisy Data in Misaligned Languages Suffice?"
                ],
                [
                    29,
                    "EmphAssess : a Prosodic Benchmark on Assessing Emphasis Transfer in Speech-to-Speech Models"
                ],
                [
                    39,
                    "Tokenization Is More Than Compression"
                ],
                [
                    42,
                    "Parameter-Efficient Sparsity Crafting from Dense to Mixture-of-Experts for Instruction Tuning on General Tasks"
                ],
                [
                    52,
                    "Language Models Learn Rare Phenomena from Less Rare Phenomena: The Case of the Missing AANNs"
                ],
                [
                    53,
                    "Large Language Models for Data Annotation and Synthesis: A Survey"
                ],
                [
                    54,
                    "Chain-of-Dictionary Prompting Elicits Translation in Large Language Models"
                ],
                [
                    56,
                    "RoseLoRA: Row and Column-wise Sparse Low-rank Adaptation of Pre-trained Language Model for Knowledge Editing and Fine-tuning"
                ]
            ],
            "paper_ids": [
                5,
                17,
                23,
                29,
                39,
                42,
                52,
                53,
                54,
                56,
                67,
                68,
                78,
                101,
                110,
                141,
                147,
                149,
                155,
                159,
                163,
                165,
                181,
                186,
                187,
                190,
                193,
                203,
                205,
                213,
                231,
                235,
                237,
                247,
                250,
                268,
                270,
                273,
                276,
                277,
                286,
                288,
                293,
                299,
                314,
                315,
                316,
                318,
                327,
                332,
                333,
                334,
                340,
                341,
                342,
                359,
                373,
                379,
                395,
                396,
                402,
                407,
                408,
                409,
                413,
                416,
                420,
                436,
                440,
                450,
                454,
                456,
                460,
                461,
                480,
                491,
                495,
                508,
                511,
                521,
                529,
                541,
                545,
                549,
                552,
                554,
                557,
                571,
                572,
                573,
                576,
                594,
                599,
                601,
                603,
                605,
                614,
                616,
                617,
                625,
                628,
                629,
                631,
                633,
                637,
                640,
                643,
                656,
                658,
                662,
                664,
                671,
                675,
                677,
                679,
                689,
                691,
                692,
                702,
                703,
                707,
                717,
                728,
                732,
                741,
                742,
                743,
                760,
                763,
                767,
                775,
                776,
                791,
                796,
                800,
                801,
                802,
                803,
                807,
                809,
                823,
                825,
                828,
                843,
                846,
                849,
                856,
                859,
                878,
                887,
                889,
                894,
                895,
                909,
                913,
                932,
                940,
                948,
                965,
                977,
                991,
                1001,
                1006,
                1009,
                1016,
                1027,
                1032,
                1035,
                1053,
                1054,
                1069,
                1080,
                1095,
                1096,
                1101,
                1109,
                1112,
                1123,
                1126,
                1129,
                1130,
                1145,
                1151,
                1157,
                1158,
                1163,
                1170,
                1176,
                1211,
                1216,
                1217,
                1222,
                1230,
                1237,
                1247,
                1254,
                1260,
                1263,
                1278,
                1281,
                1286,
                1301,
                1303,
                1308,
                1312,
                1334,
                1344,
                1357,
                1374,
                1411,
                1417,
                1437,
                1441,
                1443,
                1448,
                1449,
                1471,
                1472,
                1473,
                1474,
                1475,
                1497,
                1498,
                1532,
                1539,
                1540,
                1555,
                1556,
                1560,
                1583,
                1586,
                1600,
                1615,
                1618,
                1625,
                1631,
                1636,
                1640,
                1646,
                1653,
                1671,
                1684,
                1689,
                1696,
                1705,
                1707,
                1734,
                1739,
                1753,
                1761,
                1763,
                1764,
                1766,
                1767,
                1774,
                1796,
                1797,
                1802,
                1803,
                1807,
                1812,
                1829,
                1840,
                1842,
                1844,
                1854,
                1858,
                1861,
                1868,
                1872,
                1875,
                1879,
                1898,
                1901,
                1909,
                1919,
                1924,
                1925,
                1941,
                1952,
                1958,
                1960,
                1964,
                1966,
                1971,
                1979,
                1984,
                1990,
                1997,
                2002,
                2005,
                2010,
                2015,
                2022,
                2023,
                2034,
                2035,
                2048,
                2077,
                2080,
                2089,
                2100,
                2106,
                2112,
                2127,
                2184,
                2200,
                2211,
                2212,
                2215,
                2223,
                2231,
                2238,
                2251,
                2263,
                2267,
                2269,
                2273,
                2305,
                2306,
                2312,
                2313,
                2314,
                2317,
                2318,
                2321,
                2322,
                2329,
                2332,
                2338,
                2339,
                2340,
                2356,
                2361,
                2364,
                2366,
                2378,
                2387,
                2389,
                2393,
                2397,
                2402,
                2429,
                2435,
                2440,
                2443,
                2446,
                2448,
                2459,
                2467,
                2481,
                2492,
                2513,
                2514,
                2535,
                2556,
                2600,
                2608,
                2610,
                2611,
                2612,
                2613,
                2615,
                2617,
                2622,
                2623,
                2624,
                2628,
                2631,
                2633,
                2634,
                2670,
                2680,
                2696,
                2698,
                2710,
                2714,
                2721,
                2749,
                2764,
                2772,
                2792,
                2795,
                2796,
                2797,
                2798,
                2799,
                2809,
                2810,
                2812,
                2813,
                2814,
                2815,
                2816,
                2817,
                2818,
                2819,
                2820,
                2821,
                2822,
                2823,
                2824,
                2825,
                2826,
                2827,
                2828,
                2829,
                2830,
                2831,
                2832,
                2833,
                2834,
                2835,
                2837,
                2838,
                2839,
                2840,
                2842,
                2843,
                2844,
                2845,
                2846,
                2847,
                2848,
                2849,
                2850,
                2851,
                2853,
                2854,
                2855,
                2856,
                2857,
                2858,
                2859,
                2860,
                2861,
                2862,
                2863,
                2864,
                2865,
                2866,
                2867,
                2868,
                2869,
                2870,
                2871,
                2872,
                2873,
                2874,
                2875,
                2876,
                2877,
                2878,
                2879,
                2880,
                2881,
                2882,
                2883,
                2884,
                2885,
                2886,
                2887,
                2888,
                2889,
                2890,
                2891,
                2892,
                2893,
                2894,
                2895,
                2896,
                2897,
                2898,
                2899,
                2900,
                2901,
                2902,
                2903,
                2904,
                2905,
                2906,
                2907,
                2908,
                2909,
                2910,
                2911,
                2912,
                2913,
                2914,
                2915,
                2916,
                2917,
                2918,
                2919,
                2920,
                2921,
                2922,
                2923,
                2924,
                2925,
                2926,
                2927,
                2928,
                2929,
                2930,
                2931,
                2932,
                2933,
                2934,
                2935,
                2936,
                2937,
                2938,
                2939,
                2940,
                2941,
                2942,
                2943,
                2944,
                2948
            ],
            "children": [
                {
                    "label": "evaluation",
                    "description": "This cluster encompasses various methods and metrics for assessing the quality and effectiveness of machine translation systems, including evaluation benchmarks and translation quality estimation.",
                    "level": 2,
                    "example_papers": [
                        [
                            17,
                            "Uncertainty in Language Models: Assessment through Rank-Calibration"
                        ],
                        [
                            29,
                            "EmphAssess : a Prosodic Benchmark on Assessing Emphasis Transfer in Speech-to-Speech Models"
                        ],
                        [
                            149,
                            "Collaborative Performance Prediction for Large Language Models"
                        ],
                        [
                            165,
                            "Evaluating Large Language Models via Linguistic Profiling"
                        ],
                        [
                            186,
                            "ScalingFilter: Assessing Data Quality through Inverse Utilization of Scaling Laws"
                        ],
                        [
                            213,
                            "What do Large Language Models Need for Machine Translation Evaluation?"
                        ],
                        [
                            237,
                            "MiTTenS: A Dataset for Evaluating Gender Mistranslation"
                        ],
                        [
                            247,
                            "Prometheus 2: An Open Source Language Model Specialized in Evaluating Other Language Models"
                        ],
                        [
                            268,
                            "Forgetting Curve: A Reliable Method for Evaluating Memorization Capability for Long-Context Models"
                        ],
                        [
                            276,
                            "KidLM: Advancing Language Models for Children - Early Insights and Future Directions"
                        ]
                    ],
                    "paper_ids": [
                        17,
                        29,
                        149,
                        165,
                        186,
                        213,
                        237,
                        247,
                        268,
                        276,
                        277,
                        293,
                        299,
                        316,
                        379,
                        396,
                        450,
                        491,
                        495,
                        521,
                        594,
                        617,
                        633,
                        640,
                        656,
                        763,
                        775,
                        801,
                        802,
                        843,
                        895,
                        948,
                        977,
                        1095,
                        1096,
                        1101,
                        1112,
                        1123,
                        1126,
                        1151,
                        1170,
                        1217,
                        1222,
                        1303,
                        1344,
                        1472,
                        1498,
                        1600,
                        1615,
                        1646,
                        1696,
                        1734,
                        1761,
                        1796,
                        1802,
                        1803,
                        1858,
                        1872,
                        1875,
                        1909,
                        1941,
                        1966,
                        1984,
                        1990,
                        1997,
                        2005,
                        2211,
                        2223,
                        2231,
                        2267,
                        2318,
                        2321,
                        2338,
                        2340,
                        2356,
                        2378,
                        2389,
                        2467,
                        2556,
                        2612,
                        2615,
                        2698,
                        2714,
                        2721,
                        2792,
                        2795,
                        2798,
                        2813,
                        2814,
                        2816,
                        2818,
                        2832,
                        2834,
                        2835,
                        2837,
                        2838,
                        2839,
                        2840,
                        2842,
                        2843,
                        2844,
                        2845,
                        2846,
                        2847,
                        2848,
                        2849,
                        2850,
                        2855,
                        2856,
                        2860,
                        2869,
                        2870,
                        2871,
                        2887,
                        2903,
                        2920,
                        2921,
                        2923,
                        2924,
                        2926,
                        2928,
                        2929,
                        2930,
                        2932,
                        2938,
                        2941,
                        2942
                    ],
                    "children": [
                        {
                            "label": "translation_quality_estimation",
                            "description": "This subtopic focuses on methods and metrics used to estimate the quality of translations produced by machine translation systems, providing a quantitative assessment of translation outputs.",
                            "level": 3,
                            "example_papers": [
                                [
                                    2814,
                                    "Findings of the Quality Estimation Shared Task at WMT 2024: Are LLMs Closing the Gap in QE?"
                                ],
                                [
                                    2850,
                                    "HW-TSC 2024 Submission for the Quality Estimation Shared Task"
                                ],
                                [
                                    2860,
                                    "FLORES+ Translation and Machine Translation Evaluation for the Erzya Language"
                                ],
                                [
                                    2924,
                                    "A Multi-task Learning Framework for Evaluating Machine Translation of Emotion-loaded User-generated Content"
                                ]
                            ],
                            "paper_ids": [
                                2814,
                                2850,
                                2860,
                                2924
                            ]
                        },
                        {
                            "label": "machine_translation_evaluation",
                            "description": "This subtopic encompasses various evaluation techniques specifically designed to assess the performance and effectiveness of machine translation systems.",
                            "level": 3,
                            "example_papers": [
                                [
                                    17,
                                    "Uncertainty in Language Models: Assessment through Rank-Calibration"
                                ],
                                [
                                    149,
                                    "Collaborative Performance Prediction for Large Language Models"
                                ],
                                [
                                    165,
                                    "Evaluating Large Language Models via Linguistic Profiling"
                                ],
                                [
                                    186,
                                    "ScalingFilter: Assessing Data Quality through Inverse Utilization of Scaling Laws"
                                ],
                                [
                                    213,
                                    "What do Large Language Models Need for Machine Translation Evaluation?"
                                ],
                                [
                                    237,
                                    "MiTTenS: A Dataset for Evaluating Gender Mistranslation"
                                ],
                                [
                                    247,
                                    "Prometheus 2: An Open Source Language Model Specialized in Evaluating Other Language Models"
                                ],
                                [
                                    268,
                                    "Forgetting Curve: A Reliable Method for Evaluating Memorization Capability for Long-Context Models"
                                ],
                                [
                                    276,
                                    "KidLM: Advancing Language Models for Children - Early Insights and Future Directions"
                                ],
                                [
                                    277,
                                    "Using Language Models to Disambiguate Lexical Choices in Translation"
                                ]
                            ],
                            "paper_ids": [
                                17,
                                149,
                                165,
                                186,
                                213,
                                237,
                                247,
                                268,
                                276,
                                277,
                                293,
                                299,
                                316,
                                396,
                                450,
                                491,
                                495,
                                594,
                                617,
                                633,
                                640,
                                656,
                                763,
                                801,
                                802,
                                843,
                                895,
                                948,
                                977,
                                1095,
                                1096,
                                1101,
                                1112,
                                1123,
                                1126,
                                1151,
                                1170,
                                1222,
                                1303,
                                1344,
                                1472,
                                1498,
                                1615,
                                1646,
                                1734,
                                1796,
                                1802,
                                1803,
                                1858,
                                1875,
                                1941,
                                1984,
                                1990,
                                1997,
                                2005,
                                2211,
                                2223,
                                2231,
                                2267,
                                2318,
                                2338,
                                2340,
                                2378,
                                2389,
                                2467,
                                2556,
                                2612,
                                2615,
                                2698,
                                2714,
                                2721,
                                2792,
                                2795,
                                2813,
                                2814,
                                2816,
                                2818,
                                2832,
                                2834,
                                2835,
                                2837,
                                2838,
                                2839,
                                2840,
                                2842,
                                2843,
                                2844,
                                2845,
                                2846,
                                2847,
                                2848,
                                2855,
                                2856,
                                2860,
                                2869,
                                2870,
                                2871,
                                2887,
                                2903,
                                2920,
                                2921,
                                2923,
                                2924,
                                2926,
                                2928,
                                2929,
                                2930,
                                2932,
                                2938,
                                2941,
                                2942
                            ]
                        },
                        {
                            "label": "evaluation_benchmarks",
                            "description": "This subtopic includes standardized datasets and benchmarks used to evaluate and compare the performance of different machine translation systems.",
                            "level": 3,
                            "example_papers": [
                                [
                                    17,
                                    "Uncertainty in Language Models: Assessment through Rank-Calibration"
                                ],
                                [
                                    29,
                                    "EmphAssess : a Prosodic Benchmark on Assessing Emphasis Transfer in Speech-to-Speech Models"
                                ],
                                [
                                    165,
                                    "Evaluating Large Language Models via Linguistic Profiling"
                                ],
                                [
                                    247,
                                    "Prometheus 2: An Open Source Language Model Specialized in Evaluating Other Language Models"
                                ],
                                [
                                    276,
                                    "KidLM: Advancing Language Models for Children - Early Insights and Future Directions"
                                ],
                                [
                                    299,
                                    "Pretraining Data Detection for Large Language Models: A Divergence-based Calibration Method"
                                ],
                                [
                                    316,
                                    "NLEBench+NorGLM: A Comprehensive Empirical Analysis and Benchmark Dataset for Generative Language Models in Norwegian"
                                ],
                                [
                                    396,
                                    "Automatic Instruction Evolving for Large Language Models"
                                ],
                                [
                                    450,
                                    "PARIKSHA: A Large-Scale Investigation of Human-LLM Evaluator Agreement on Multilingual and Multi-Cultural Data"
                                ],
                                [
                                    491,
                                    "Exploring Nested Named Entity Recognition with Large Language Models: Methods, Challenges, and Insights"
                                ]
                            ],
                            "paper_ids": [
                                17,
                                29,
                                165,
                                247,
                                276,
                                299,
                                316,
                                396,
                                450,
                                491,
                                521,
                                640,
                                763,
                                843,
                                895,
                                948,
                                977,
                                1123,
                                1344,
                                1498,
                                1696,
                                1734,
                                1802,
                                1858,
                                1941,
                                2005,
                                2321,
                                2340,
                                2467,
                                2612,
                                2698,
                                2792,
                                2818,
                                2837,
                                2838,
                                2842,
                                2855,
                                2923,
                                2928,
                                2930
                            ]
                        },
                        {
                            "label": "machine_translation_quality_evaluation",
                            "description": "This subtopic deals with the assessment of the overall quality of translations generated by machine translation systems, focusing on various quality dimensions.",
                            "level": 3,
                            "example_papers": [
                                [
                                    633,
                                    "MMTE: Corpus and Metrics for Evaluating Machine Translation Quality of Metaphorical Language"
                                ],
                                [
                                    802,
                                    "Modeling User Preferences with Automatic Metrics: Creating a High-Quality Preference Dataset for Machine Translation"
                                ],
                                [
                                    1101,
                                    "Error Analysis of Multilingual Language Models in Machine Translation: A Case Study of English-Amharic Translation"
                                ],
                                [
                                    1303,
                                    "Translation Canvas: An Explainable Interface to Pinpoint and Analyze Translation Systems"
                                ],
                                [
                                    1615,
                                    "Evaluating Automatic Metrics with Incremental Machine Translation Systems"
                                ],
                                [
                                    1761,
                                    "Sing it, Narrate it: Quality Musical Lyrics Translation"
                                ],
                                [
                                    1984,
                                    "On Diversified Preferences of Large Language Model Alignment"
                                ],
                                [
                                    2267,
                                    "Downstream Trade-offs of a Family of Text Watermarks"
                                ],
                                [
                                    2389,
                                    "BLASER 2.0: a metric for evaluation and quality estimation of massively multilingual speech and text translation"
                                ],
                                [
                                    2714,
                                    "Assessing Large Language Models in Translating Coptic and Ancient Greek Ostraca"
                                ]
                            ],
                            "paper_ids": [
                                633,
                                802,
                                1101,
                                1303,
                                1615,
                                1761,
                                1984,
                                2267,
                                2389,
                                2714,
                                2798,
                                2813,
                                2816,
                                2835,
                                2839,
                                2856,
                                2870,
                                2903,
                                2932,
                                2942
                            ]
                        },
                        {
                            "label": "machine_translation_quality_estimation",
                            "description": "This subtopic involves techniques for estimating the quality of machine translations without relying on human judgment, often using automated metrics.",
                            "level": 3,
                            "example_papers": [
                                [
                                    186,
                                    "ScalingFilter: Assessing Data Quality through Inverse Utilization of Scaling Laws"
                                ],
                                [
                                    213,
                                    "What do Large Language Models Need for Machine Translation Evaluation?"
                                ],
                                [
                                    277,
                                    "Using Language Models to Disambiguate Lexical Choices in Translation"
                                ],
                                [
                                    293,
                                    "Beyond Reference: Evaluating High Quality Translations Better than Human References"
                                ],
                                [
                                    594,
                                    "Speechworthy Instruction-tuned Language Models"
                                ],
                                [
                                    801,
                                    "Can Automatic Metrics Assess High-Quality Translations?"
                                ],
                                [
                                    1151,
                                    "Beyond Correlation: Interpretable Evaluation of Machine Translation Metrics"
                                ],
                                [
                                    1217,
                                    "SpeechQE: Estimating the Quality of Direct Speech Translation"
                                ],
                                [
                                    1222,
                                    "xCOMET-lite: Bridging the Gap Between Efficiency and Quality in Learned MT Evaluation Metrics"
                                ],
                                [
                                    1761,
                                    "Sing it, Narrate it: Quality Musical Lyrics Translation"
                                ]
                            ],
                            "paper_ids": [
                                186,
                                213,
                                277,
                                293,
                                594,
                                801,
                                1151,
                                1217,
                                1222,
                                1761,
                                1909,
                                1990,
                                1997,
                                2338,
                                2378,
                                2389,
                                2795,
                                2798,
                                2840,
                                2843,
                                2844,
                                2845,
                                2846,
                                2847,
                                2848,
                                2849,
                                2850,
                                2920,
                                2929,
                                2938
                            ]
                        }
                    ]
                },
                {
                    "label": "model_improvement",
                    "description": "This cluster focuses on techniques and strategies aimed at enhancing the performance and accuracy of machine translation models, including model adaptation and optimization methods.",
                    "level": 2,
                    "example_papers": [
                        [
                            5,
                            "ImageInWords: Unlocking Hyper-Detailed Image Descriptions"
                        ],
                        [
                            23,
                            "Fine-Tuning Large Language Models to Translate: Will a Touch of Noisy Data in Misaligned Languages Suffice?"
                        ],
                        [
                            29,
                            "EmphAssess : a Prosodic Benchmark on Assessing Emphasis Transfer in Speech-to-Speech Models"
                        ],
                        [
                            39,
                            "Tokenization Is More Than Compression"
                        ],
                        [
                            42,
                            "Parameter-Efficient Sparsity Crafting from Dense to Mixture-of-Experts for Instruction Tuning on General Tasks"
                        ],
                        [
                            54,
                            "Chain-of-Dictionary Prompting Elicits Translation in Large Language Models"
                        ],
                        [
                            56,
                            "RoseLoRA: Row and Column-wise Sparse Low-rank Adaptation of Pre-trained Language Model for Knowledge Editing and Fine-tuning"
                        ],
                        [
                            67,
                            "Rethinking Pruning Large Language Models: Benefits and Pitfalls of Reconstruction Error Minimization"
                        ],
                        [
                            68,
                            "LLMs Are Zero-Shot Context-Aware Simultaneous Translators"
                        ],
                        [
                            78,
                            "Reuse Your Rewards: Reward Model Transfer for Zero-Shot Cross-Lingual Alignment"
                        ]
                    ],
                    "paper_ids": [
                        5,
                        23,
                        29,
                        39,
                        42,
                        54,
                        56,
                        67,
                        68,
                        78,
                        101,
                        110,
                        147,
                        149,
                        159,
                        163,
                        181,
                        186,
                        187,
                        193,
                        203,
                        205,
                        213,
                        268,
                        270,
                        273,
                        276,
                        277,
                        286,
                        288,
                        299,
                        314,
                        315,
                        318,
                        327,
                        332,
                        334,
                        340,
                        342,
                        359,
                        373,
                        379,
                        396,
                        407,
                        408,
                        409,
                        413,
                        416,
                        420,
                        436,
                        440,
                        454,
                        456,
                        460,
                        461,
                        480,
                        491,
                        495,
                        508,
                        511,
                        541,
                        545,
                        552,
                        554,
                        557,
                        571,
                        572,
                        573,
                        576,
                        594,
                        599,
                        601,
                        603,
                        605,
                        614,
                        616,
                        625,
                        628,
                        629,
                        631,
                        637,
                        643,
                        664,
                        671,
                        675,
                        679,
                        689,
                        692,
                        702,
                        703,
                        707,
                        717,
                        741,
                        742,
                        743,
                        760,
                        767,
                        775,
                        776,
                        791,
                        796,
                        802,
                        803,
                        807,
                        809,
                        825,
                        846,
                        849,
                        856,
                        859,
                        878,
                        887,
                        889,
                        894,
                        913,
                        940,
                        948,
                        965,
                        977,
                        991,
                        1006,
                        1009,
                        1016,
                        1027,
                        1035,
                        1054,
                        1069,
                        1080,
                        1109,
                        1129,
                        1130,
                        1145,
                        1157,
                        1158,
                        1163,
                        1170,
                        1176,
                        1211,
                        1216,
                        1217,
                        1222,
                        1230,
                        1247,
                        1254,
                        1260,
                        1263,
                        1281,
                        1308,
                        1334,
                        1344,
                        1357,
                        1374,
                        1411,
                        1437,
                        1441,
                        1449,
                        1471,
                        1473,
                        1474,
                        1497,
                        1532,
                        1539,
                        1540,
                        1555,
                        1556,
                        1560,
                        1586,
                        1600,
                        1618,
                        1625,
                        1631,
                        1636,
                        1640,
                        1646,
                        1653,
                        1671,
                        1684,
                        1689,
                        1705,
                        1707,
                        1734,
                        1739,
                        1753,
                        1761,
                        1763,
                        1767,
                        1774,
                        1796,
                        1797,
                        1807,
                        1812,
                        1840,
                        1842,
                        1844,
                        1861,
                        1868,
                        1875,
                        1898,
                        1901,
                        1909,
                        1924,
                        1925,
                        1941,
                        1958,
                        1964,
                        1966,
                        1971,
                        1979,
                        1984,
                        1990,
                        1997,
                        2002,
                        2015,
                        2022,
                        2023,
                        2034,
                        2035,
                        2048,
                        2077,
                        2100,
                        2106,
                        2112,
                        2200,
                        2215,
                        2223,
                        2231,
                        2238,
                        2251,
                        2269,
                        2273,
                        2305,
                        2312,
                        2313,
                        2317,
                        2318,
                        2321,
                        2322,
                        2329,
                        2338,
                        2339,
                        2361,
                        2364,
                        2366,
                        2378,
                        2393,
                        2402,
                        2429,
                        2435,
                        2440,
                        2443,
                        2446,
                        2448,
                        2467,
                        2481,
                        2492,
                        2513,
                        2600,
                        2608,
                        2610,
                        2611,
                        2612,
                        2615,
                        2617,
                        2622,
                        2623,
                        2624,
                        2634,
                        2670,
                        2680,
                        2749,
                        2764,
                        2772,
                        2795,
                        2798,
                        2810,
                        2819,
                        2822,
                        2823,
                        2827,
                        2828,
                        2829,
                        2831,
                        2832,
                        2833,
                        2834,
                        2838,
                        2842,
                        2851,
                        2858,
                        2862,
                        2864,
                        2871,
                        2878,
                        2902,
                        2903,
                        2906,
                        2908,
                        2910,
                        2911,
                        2912,
                        2913,
                        2914,
                        2915,
                        2918,
                        2920,
                        2921,
                        2922,
                        2923,
                        2924,
                        2925,
                        2931,
                        2932,
                        2933,
                        2934,
                        2937,
                        2938,
                        2939,
                        2940,
                        2941,
                        2943,
                        2944
                    ],
                    "children": [
                        {
                            "label": "model_adaptation",
                            "description": "This subtopic focuses on techniques that adjust machine translation models to better fit specific domains or datasets, enhancing their performance in targeted applications.",
                            "level": 3,
                            "example_papers": [
                                [
                                    54,
                                    "Chain-of-Dictionary Prompting Elicits Translation in Large Language Models"
                                ],
                                [
                                    78,
                                    "Reuse Your Rewards: Reward Model Transfer for Zero-Shot Cross-Lingual Alignment"
                                ],
                                [
                                    101,
                                    "MetaGPT: Merging Large Language Models Using Model Exclusive Task Arithmetic"
                                ],
                                [
                                    110,
                                    "PsFuture: A Pseudo-Future-based Zero-Shot Adaptive Policy for Simultaneous Machine Translation"
                                ],
                                [
                                    270,
                                    "CoEvol: Constructing Better Responses for Instruction Finetuning through Multi-Agent Cooperation"
                                ],
                                [
                                    277,
                                    "Using Language Models to Disambiguate Lexical Choices in Translation"
                                ],
                                [
                                    334,
                                    "Quantifying the Gaps Between Translation and Native Perception in Training for Multimodal, Multilingual Retrieval"
                                ],
                                [
                                    379,
                                    "Understanding and Mitigating Language Confusion in LLMs"
                                ],
                                [
                                    456,
                                    "Getting More from Less: Large Language Models are Good Spontaneous Multilingual Learners"
                                ],
                                [
                                    460,
                                    "Data Advisor: Dynamic Data Curation for Safety Alignment of Large Language Models"
                                ]
                            ],
                            "paper_ids": [
                                54,
                                78,
                                101,
                                110,
                                270,
                                277,
                                334,
                                379,
                                456,
                                460,
                                572,
                                625,
                                675,
                                703,
                                707,
                                743,
                                791,
                                859,
                                878,
                                1009,
                                1130,
                                1449,
                                1471,
                                1473,
                                1539,
                                1625,
                                1684,
                                1707,
                                1767,
                                1774,
                                1796,
                                1797,
                                1842,
                                1844,
                                1898,
                                1901,
                                1984,
                                2015,
                                2106,
                                2269,
                                2322,
                                2361,
                                2364,
                                2366,
                                2402,
                                2446,
                                2492,
                                2608,
                                2610,
                                2611,
                                2622,
                                2624,
                                2822,
                                2827,
                                2833,
                                2838,
                                2851,
                                2862,
                                2878,
                                2903,
                                2911,
                                2912,
                                2914,
                                2915,
                                2924,
                                2925,
                                2931,
                                2939
                            ]
                        },
                        {
                            "label": "prompt_optimization",
                            "description": "This subtopic involves refining the input prompts given to machine translation models to improve their output quality and relevance.",
                            "level": 3,
                            "example_papers": [
                                [
                                    594,
                                    "Speechworthy Instruction-tuned Language Models"
                                ],
                                [
                                    1129,
                                    "AMPO: Automatic Multi-Branched Prompt Optimization"
                                ],
                                [
                                    2022,
                                    "Monotonic Paraphrasing Improves Generalization of Language Model Prompting"
                                ],
                                [
                                    2023,
                                    "MORL-Prompt: An Empirical Analysis of Multi-Objective Reinforcement Learning for Discrete Prompt Optimization"
                                ],
                                [
                                    2034,
                                    "StraGo: Harnessing Strategic Guidance for Prompt Optimization"
                                ],
                                [
                                    2317,
                                    "Unlocking Black-Box Prompt Tuning Efficiency via Zeroth-Order Optimization"
                                ],
                                [
                                    2772,
                                    "Should We Respect LLMs? A Cross-Lingual Study on the Influence of Prompt Politeness on LLM Performance"
                                ],
                                [
                                    2795,
                                    "Creative and Context-Aware Translation of East Asian Idioms with GPT-4"
                                ],
                                [
                                    2910,
                                    "LinChance-NTU for Unconstrained WMT2024 Literary Translation"
                                ],
                                [
                                    2915,
                                    "The SETU-ADAPT Submissions to WMT 2024 Chat Translation Tasks"
                                ]
                            ],
                            "paper_ids": [
                                594,
                                1129,
                                2022,
                                2023,
                                2034,
                                2317,
                                2772,
                                2795,
                                2910,
                                2915
                            ]
                        },
                        {
                            "label": "model_optimization",
                            "description": "This subtopic encompasses various strategies aimed at improving the efficiency and effectiveness of machine translation models, including algorithmic enhancements and resource management.",
                            "level": 3,
                            "example_papers": [
                                [
                                    5,
                                    "ImageInWords: Unlocking Hyper-Detailed Image Descriptions"
                                ],
                                [
                                    42,
                                    "Parameter-Efficient Sparsity Crafting from Dense to Mixture-of-Experts for Instruction Tuning on General Tasks"
                                ],
                                [
                                    54,
                                    "Chain-of-Dictionary Prompting Elicits Translation in Large Language Models"
                                ],
                                [
                                    67,
                                    "Rethinking Pruning Large Language Models: Benefits and Pitfalls of Reconstruction Error Minimization"
                                ],
                                [
                                    101,
                                    "MetaGPT: Merging Large Language Models Using Model Exclusive Task Arithmetic"
                                ],
                                [
                                    110,
                                    "PsFuture: A Pseudo-Future-based Zero-Shot Adaptive Policy for Simultaneous Machine Translation"
                                ],
                                [
                                    149,
                                    "Collaborative Performance Prediction for Large Language Models"
                                ],
                                [
                                    163,
                                    "Alignment-Enhanced Decoding: Defending Jailbreaks via Token-Level Adaptive Refining of Probability Distributions"
                                ],
                                [
                                    186,
                                    "ScalingFilter: Assessing Data Quality through Inverse Utilization of Scaling Laws"
                                ],
                                [
                                    187,
                                    "Word Alignment as Preference for Machine Translation"
                                ]
                            ],
                            "paper_ids": [
                                5,
                                42,
                                54,
                                67,
                                101,
                                110,
                                149,
                                163,
                                186,
                                187,
                                276,
                                277,
                                288,
                                315,
                                318,
                                340,
                                373,
                                413,
                                436,
                                454,
                                460,
                                491,
                                495,
                                508,
                                557,
                                573,
                                601,
                                605,
                                614,
                                625,
                                629,
                                664,
                                702,
                                717,
                                743,
                                760,
                                767,
                                775,
                                776,
                                802,
                                807,
                                809,
                                856,
                                859,
                                878,
                                887,
                                889,
                                913,
                                940,
                                977,
                                1006,
                                1009,
                                1016,
                                1054,
                                1130,
                                1163,
                                1216,
                                1222,
                                1230,
                                1247,
                                1263,
                                1334,
                                1357,
                                1437,
                                1449,
                                1474,
                                1540,
                                1555,
                                1586,
                                1618,
                                1625,
                                1636,
                                1684,
                                1689,
                                1734,
                                1739,
                                1761,
                                1763,
                                1767,
                                1774,
                                1807,
                                1844,
                                1868,
                                1909,
                                1924,
                                1958,
                                1971,
                                1984,
                                2015,
                                2048,
                                2077,
                                2106,
                                2231,
                                2238,
                                2269,
                                2273,
                                2322,
                                2339,
                                2361,
                                2378,
                                2393,
                                2440,
                                2443,
                                2448,
                                2467,
                                2481,
                                2513,
                                2600,
                                2622,
                                2680,
                                2795,
                                2819,
                                2822,
                                2832,
                                2842,
                                2851,
                                2862,
                                2871,
                                2903,
                                2906,
                                2908,
                                2910,
                                2911,
                                2912,
                                2915,
                                2918,
                                2920,
                                2922,
                                2923,
                                2924,
                                2931,
                                2932,
                                2934,
                                2938,
                                2941,
                                2944
                            ]
                        },
                        {
                            "label": "adversarial_attack",
                            "description": "This subtopic examines methods to test and improve the robustness of machine translation models against adversarial inputs that may degrade their performance.",
                            "level": 3,
                            "example_papers": [
                                [
                                    163,
                                    "Alignment-Enhanced Decoding: Defending Jailbreaks via Token-Level Adaptive Refining of Probability Distributions"
                                ],
                                [
                                    480,
                                    "The Best Defense is Attack: Repairing Semantics in Textual Adversarial Examples"
                                ],
                                [
                                    894,
                                    "MLLM-Protector: Ensuring MLLM's Safety without Hurting Performance"
                                ],
                                [
                                    1739,
                                    "Defending Large Language Models Against Jailbreak Attacks via Layer-specific Editing"
                                ],
                                [
                                    1898,
                                    "Representation Alignment and Adversarial Networks for Cross-lingual Dependency Parsing"
                                ]
                            ],
                            "paper_ids": [
                                163,
                                480,
                                894,
                                1739,
                                1898
                            ]
                        },
                        {
                            "label": "instruction_tuning",
                            "description": "This subtopic focuses on fine-tuning machine translation models based on specific instructions or guidelines to enhance their accuracy and contextual understanding.",
                            "level": 3,
                            "example_papers": [
                                [
                                    42,
                                    "Parameter-Efficient Sparsity Crafting from Dense to Mixture-of-Experts for Instruction Tuning on General Tasks"
                                ],
                                [
                                    270,
                                    "CoEvol: Constructing Better Responses for Instruction Finetuning through Multi-Agent Cooperation"
                                ],
                                [
                                    491,
                                    "Exploring Nested Named Entity Recognition with Large Language Models: Methods, Challenges, and Insights"
                                ],
                                [
                                    495,
                                    "LIONs: An Empirically Optimized Approach to Align Language Models"
                                ],
                                [
                                    541,
                                    "Is It Good Data for Multilingual Instruction Tuning or Just Bad Multilingual Evaluation for Large Language Models?"
                                ],
                                [
                                    594,
                                    "Speechworthy Instruction-tuned Language Models"
                                ],
                                [
                                    767,
                                    "Curriculum Consistency Learning for Conditional Sentence Generation"
                                ],
                                [
                                    776,
                                    "How Do Your Code LLMs perform? Empowering Code Instruction Tuning with Really Good Data"
                                ],
                                [
                                    846,
                                    "Layer by Layer: Uncovering Where Multi-Task Learning Happens in Instruction-Tuned Large Language Models"
                                ],
                                [
                                    1035,
                                    "Instruction Matters: A Simple yet Effective Task Selection for Optimized Instruction Tuning of Specific Tasks"
                                ]
                            ],
                            "paper_ids": [
                                42,
                                270,
                                491,
                                495,
                                541,
                                594,
                                767,
                                776,
                                846,
                                1035,
                                1158,
                                1471,
                                1539,
                                1540,
                                1689,
                                1796,
                                1971,
                                2223,
                                2622,
                                2925
                            ]
                        },
                        {
                            "label": "parameter_efficient_fine_tuning",
                            "description": "This subtopic explores techniques that allow for effective fine-tuning of machine translation models with minimal adjustments to their parameters, optimizing resource usage.",
                            "level": 3,
                            "example_papers": [
                                [
                                    42,
                                    "Parameter-Efficient Sparsity Crafting from Dense to Mixture-of-Experts for Instruction Tuning on General Tasks"
                                ],
                                [
                                    56,
                                    "RoseLoRA: Row and Column-wise Sparse Low-rank Adaptation of Pre-trained Language Model for Knowledge Editing and Fine-tuning"
                                ],
                                [
                                    203,
                                    "From Bottom to Top: Extending the Potential of Parameter Efficient Fine-Tuning"
                                ],
                                [
                                    286,
                                    "MaPPER: Multimodal Prior-guided Parameter Efficient Tuning for Referring Expression Comprehension"
                                ],
                                [
                                    436,
                                    "MORPHEUS: Modeling Role from Personalized Dialogue History by Exploring and Utilizing Latent Space"
                                ],
                                [
                                    664,
                                    "Segment Any Text: A Universal Approach for Robust, Efficient and Adaptable Sentence Segmentation"
                                ],
                                [
                                    675,
                                    "TL-CL: Task And Language Incremental Continual Learning"
                                ],
                                [
                                    796,
                                    "Vision-Language Model Fine-Tuning via Simple Parameter-Efficient Modification"
                                ],
                                [
                                    1080,
                                    "GPT vs RETRO: Exploring the Intersection of Retrieval and Parameter-Efficient Fine-Tuning"
                                ],
                                [
                                    1176,
                                    "Exploring Intrinsic Language-specific Subspaces in Fine-tuning Multilingual Neural Machine Translation"
                                ]
                            ],
                            "paper_ids": [
                                42,
                                56,
                                203,
                                286,
                                436,
                                664,
                                675,
                                796,
                                1080,
                                1176,
                                1357,
                                1374,
                                1555,
                                1767,
                                1964,
                                2048,
                                2106,
                                2440,
                                2448,
                                2624,
                                2798,
                                2833,
                                2915
                            ]
                        },
                        {
                            "label": "prompt_engineering",
                            "description": "This subtopic focuses on the design and development of effective prompts to guide machine translation models in generating high-quality outputs tailored to specific tasks.",
                            "level": 3,
                            "example_papers": [
                                [
                                    54,
                                    "Chain-of-Dictionary Prompting Elicits Translation in Large Language Models"
                                ],
                                [
                                    379,
                                    "Understanding and Mitigating Language Confusion in LLMs"
                                ],
                                [
                                    416,
                                    "Position Engineering: Boosting Large Language Models through Positional Information Manipulation"
                                ],
                                [
                                    614,
                                    "Self-AMPLIFY: Improving Small Language Models with Self Post Hoc Explanations"
                                ],
                                [
                                    616,
                                    "Paraphrase Types Elicit Prompt Engineering Capabilities"
                                ],
                                [
                                    977,
                                    "Are Large Language Models Capable of Generating Human-Level Narratives?"
                                ],
                                [
                                    1129,
                                    "AMPO: Automatic Multi-Branched Prompt Optimization"
                                ],
                                [
                                    1130,
                                    "DeMPT: Decoding-enhanced Multi-phase Prompt Tuning for Making LLMs Be Better Context-aware Translators"
                                ],
                                [
                                    1990,
                                    "Creative and Context-Aware Translation of East Asian Idioms with GPT-4"
                                ],
                                [
                                    2034,
                                    "StraGo: Harnessing Strategic Guidance for Prompt Optimization"
                                ]
                            ],
                            "paper_ids": [
                                54,
                                379,
                                416,
                                614,
                                616,
                                977,
                                1129,
                                1130,
                                1990,
                                2034,
                                2215,
                                2339,
                                2617,
                                2680,
                                2906,
                                2914,
                                2915,
                                2934
                            ]
                        }
                    ]
                },
                {
                    "label": "low_resource_machine_translation",
                    "description": "This cluster addresses the challenges and solutions related to translating languages with limited resources, including low-resource languages and low-resource translation techniques.",
                    "level": 2,
                    "example_papers": [
                        [
                            235,
                            "When Is Multilinguality a Curse? Language Modeling for 250 High- and Low-Resource Languages"
                        ],
                        [
                            250,
                            "Voices Unheard: NLP Resources and Models for Yoruba Regional Dialects"
                        ],
                        [
                            316,
                            "NLEBench+NorGLM: A Comprehensive Empirical Analysis and Benchmark Dataset for Generative Language Models in Norwegian"
                        ],
                        [
                            333,
                            "Pretraining Language Models Using Translationese"
                        ],
                        [
                            461,
                            "Language-to-Code Translation with a Single Labeled Example"
                        ],
                        [
                            637,
                            "TEMA: Token Embeddings Mapping for Enriching Low-Resource Language Models"
                        ],
                        [
                            707,
                            "Optimizing Rare Word Accuracy in Direct Speech Translation with a Retrieval-and-Demonstration Approach"
                        ],
                        [
                            800,
                            "ASL STEM Wiki: Dataset and Benchmark for Interpreting STEM Articles"
                        ],
                        [
                            823,
                            "Building Resources for Emakhuwa: Machine Translation and News Classification Benchmarks"
                        ],
                        [
                            1101,
                            "Error Analysis of Multilingual Language Models in Machine Translation: A Case Study of English-Amharic Translation"
                        ]
                    ],
                    "paper_ids": [
                        235,
                        250,
                        316,
                        333,
                        461,
                        637,
                        707,
                        800,
                        823,
                        1101,
                        1126,
                        1471,
                        1560,
                        1707,
                        1766,
                        1872,
                        1898,
                        1924,
                        1960,
                        2010,
                        2080,
                        2106,
                        2127,
                        2251,
                        2263,
                        2305,
                        2306,
                        2332,
                        2364,
                        2366,
                        2387,
                        2397,
                        2608,
                        2610,
                        2623,
                        2624,
                        2628,
                        2696,
                        2698,
                        2710,
                        2797,
                        2799,
                        2809,
                        2821,
                        2831,
                        2838,
                        2847,
                        2851,
                        2853,
                        2854,
                        2855,
                        2856,
                        2857,
                        2858,
                        2859,
                        2860,
                        2861,
                        2862,
                        2865,
                        2866,
                        2867,
                        2868,
                        2872,
                        2873,
                        2874,
                        2875,
                        2876,
                        2877,
                        2878,
                        2879,
                        2880,
                        2881,
                        2882,
                        2883,
                        2884,
                        2886,
                        2887,
                        2888,
                        2889,
                        2890,
                        2892,
                        2893,
                        2894,
                        2895,
                        2896,
                        2897,
                        2898,
                        2899,
                        2900,
                        2901,
                        2902,
                        2903,
                        2904,
                        2905,
                        2921,
                        2936,
                        2939
                    ],
                    "children": [
                        {
                            "label": "low_resource_translation_techniques",
                            "description": "This subtopic focuses on various techniques specifically designed for translating low-resource languages, addressing the unique challenges posed by limited linguistic data.",
                            "level": 3,
                            "example_papers": [
                                [
                                    461,
                                    "Language-to-Code Translation with a Single Labeled Example"
                                ],
                                [
                                    707,
                                    "Optimizing Rare Word Accuracy in Direct Speech Translation with a Retrieval-and-Demonstration Approach"
                                ],
                                [
                                    1101,
                                    "Error Analysis of Multilingual Language Models in Machine Translation: A Case Study of English-Amharic Translation"
                                ],
                                [
                                    1126,
                                    "Back to School: Translation Using Grammar Books"
                                ],
                                [
                                    1560,
                                    "Translation of Multifaceted Data without Re-Training of Machine Translation Systems"
                                ],
                                [
                                    1766,
                                    "Visual Pivoting Unsupervised Multimodal Machine Translation in Low-Resource Distant Language Pairs"
                                ],
                                [
                                    1960,
                                    "Low-Resource Machine Translation through the Lens of Personalized Federated Learning"
                                ],
                                [
                                    2010,
                                    "Machine Translation Hallucination Detection for Low and High Resource Languages using Large Language Models"
                                ],
                                [
                                    2080,
                                    "Together We Can: Multilingual Automatic Post-Editing for Low-Resource Languages"
                                ],
                                [
                                    2251,
                                    "One Model is All You Need: ByT5-Sanskrit, a Unified Model for Sanskrit NLP Tasks"
                                ]
                            ],
                            "paper_ids": [
                                461,
                                707,
                                1101,
                                1126,
                                1560,
                                1766,
                                1960,
                                2010,
                                2080,
                                2251,
                                2263,
                                2305,
                                2306,
                                2332,
                                2397,
                                2623,
                                2624,
                                2710,
                                2799,
                                2821,
                                2851,
                                2854,
                                2860,
                                2861,
                                2862,
                                2865,
                                2867,
                                2868,
                                2873,
                                2874,
                                2876,
                                2877,
                                2878,
                                2879,
                                2880,
                                2881,
                                2882,
                                2883,
                                2884,
                                2886,
                                2887,
                                2888,
                                2889,
                                2890,
                                2892,
                                2893,
                                2894,
                                2895,
                                2896,
                                2897,
                                2898,
                                2899,
                                2900,
                                2901,
                                2902,
                                2903,
                                2904,
                                2905,
                                2921,
                                2936
                            ]
                        },
                        {
                            "label": "low_resource_language_evaluation",
                            "description": "This subtopic encompasses methods and metrics for evaluating the quality and effectiveness of translations in low-resource languages.",
                            "level": 3,
                            "example_papers": [
                                [
                                    316,
                                    "NLEBench+NorGLM: A Comprehensive Empirical Analysis and Benchmark Dataset for Generative Language Models in Norwegian"
                                ],
                                [
                                    800,
                                    "ASL STEM Wiki: Dataset and Benchmark for Interpreting STEM Articles"
                                ],
                                [
                                    1101,
                                    "Error Analysis of Multilingual Language Models in Machine Translation: A Case Study of English-Amharic Translation"
                                ],
                                [
                                    2698,
                                    "Evaluating Open-Source LLMs in Low-Resource Languages: Insights from Latvian High School Exams"
                                ],
                                [
                                    2847,
                                    "Evaluating WMT 2024 Metrics Shared Task Submissions on AfriMTE (the African Challenge Set)"
                                ],
                                [
                                    2855,
                                    "Correcting FLORES Evaluation Dataset for Four African Languages"
                                ],
                                [
                                    2856,
                                    "Expanding FLORES+ Benchmark for More Low-Resource Settings: Portuguese-Emakhuwa Machine Translation Evaluation"
                                ],
                                [
                                    2857,
                                    "Enhancing Tuvan Language Resources through the FLORES Dataset"
                                ],
                                [
                                    2858,
                                    "Machine Translation Evaluation Benchmark for Wu Chinese: Workflow and Analysis"
                                ],
                                [
                                    2865,
                                    "Findings of WMT 2024 Shared Task on Low-Resource Indic Languages Translation"
                                ]
                            ],
                            "paper_ids": [
                                316,
                                800,
                                1101,
                                2698,
                                2847,
                                2855,
                                2856,
                                2857,
                                2858,
                                2865,
                                2866
                            ]
                        },
                        {
                            "label": "low_resource_language_modeling",
                            "description": "This subtopic deals with the development and application of language models tailored for low-resource languages, enhancing translation accuracy and fluency.",
                            "level": 3,
                            "example_papers": [
                                [
                                    235,
                                    "When Is Multilinguality a Curse? Language Modeling for 250 High- and Low-Resource Languages"
                                ],
                                [
                                    250,
                                    "Voices Unheard: NLP Resources and Models for Yoruba Regional Dialects"
                                ],
                                [
                                    316,
                                    "NLEBench+NorGLM: A Comprehensive Empirical Analysis and Benchmark Dataset for Generative Language Models in Norwegian"
                                ],
                                [
                                    333,
                                    "Pretraining Language Models Using Translationese"
                                ],
                                [
                                    637,
                                    "TEMA: Token Embeddings Mapping for Enriching Low-Resource Language Models"
                                ],
                                [
                                    800,
                                    "ASL STEM Wiki: Dataset and Benchmark for Interpreting STEM Articles"
                                ],
                                [
                                    823,
                                    "Building Resources for Emakhuwa: Machine Translation and News Classification Benchmarks"
                                ],
                                [
                                    1471,
                                    "Walia-LLM: Enhancing Amharic-LLaMA by Integrating Task-Specific and Generative Datasets"
                                ],
                                [
                                    1707,
                                    "RoQLlama: A Lightweight Romanian Adapted Language Model"
                                ],
                                [
                                    1872,
                                    "Generalists vs. Specialists: Evaluating Large Language Models for Urdu"
                                ]
                            ],
                            "paper_ids": [
                                235,
                                250,
                                316,
                                333,
                                637,
                                800,
                                823,
                                1471,
                                1707,
                                1872,
                                1898,
                                2010,
                                2127,
                                2251,
                                2306,
                                2332,
                                2366,
                                2387,
                                2608,
                                2610,
                                2623,
                                2696,
                                2698,
                                2797,
                                2838,
                                2851,
                                2858,
                                2859,
                                2860,
                                2865,
                                2875,
                                2882,
                                2896,
                                2902,
                                2936,
                                2939
                            ]
                        },
                        {
                            "label": "language_adaptation",
                            "description": "This subtopic explores strategies for adapting existing machine translation systems to better handle low-resource languages and their specific linguistic features.",
                            "level": 3,
                            "example_papers": [
                                [
                                    250,
                                    "Voices Unheard: NLP Resources and Models for Yoruba Regional Dialects"
                                ],
                                [
                                    707,
                                    "Optimizing Rare Word Accuracy in Direct Speech Translation with a Retrieval-and-Demonstration Approach"
                                ],
                                [
                                    823,
                                    "Building Resources for Emakhuwa: Machine Translation and News Classification Benchmarks"
                                ],
                                [
                                    1560,
                                    "Translation of Multifaceted Data without Re-Training of Machine Translation Systems"
                                ],
                                [
                                    1707,
                                    "RoQLlama: A Lightweight Romanian Adapted Language Model"
                                ],
                                [
                                    1766,
                                    "Visual Pivoting Unsupervised Multimodal Machine Translation in Low-Resource Distant Language Pairs"
                                ],
                                [
                                    1898,
                                    "Representation Alignment and Adversarial Networks for Cross-lingual Dependency Parsing"
                                ],
                                [
                                    2010,
                                    "Machine Translation Hallucination Detection for Low and High Resource Languages using Large Language Models"
                                ],
                                [
                                    2251,
                                    "One Model is All You Need: ByT5-Sanskrit, a Unified Model for Sanskrit NLP Tasks"
                                ],
                                [
                                    2263,
                                    "Audio-Based Linguistic Feature Extraction for Enhancing Multi-lingual and Low-Resource Text-to-Speech"
                                ]
                            ],
                            "paper_ids": [
                                250,
                                707,
                                823,
                                1560,
                                1707,
                                1766,
                                1898,
                                2010,
                                2251,
                                2263,
                                2364,
                                2608,
                                2610,
                                2623,
                                2624,
                                2628,
                                2710,
                                2799,
                                2838,
                                2847,
                                2859,
                                2868,
                                2875,
                                2878,
                                2893,
                                2895,
                                2921,
                                2936,
                                2939
                            ]
                        },
                        {
                            "label": "training_low_resource_languages",
                            "description": "This subtopic focuses on the methodologies and practices for training machine translation models specifically for low-resource languages.",
                            "level": 3,
                            "example_papers": [
                                [
                                    235,
                                    "When Is Multilinguality a Curse? Language Modeling for 250 High- and Low-Resource Languages"
                                ],
                                [
                                    250,
                                    "Voices Unheard: NLP Resources and Models for Yoruba Regional Dialects"
                                ],
                                [
                                    316,
                                    "NLEBench+NorGLM: A Comprehensive Empirical Analysis and Benchmark Dataset for Generative Language Models in Norwegian"
                                ],
                                [
                                    333,
                                    "Pretraining Language Models Using Translationese"
                                ],
                                [
                                    823,
                                    "Building Resources for Emakhuwa: Machine Translation and News Classification Benchmarks"
                                ],
                                [
                                    1707,
                                    "RoQLlama: A Lightweight Romanian Adapted Language Model"
                                ],
                                [
                                    1872,
                                    "Generalists vs. Specialists: Evaluating Large Language Models for Urdu"
                                ],
                                [
                                    1898,
                                    "Representation Alignment and Adversarial Networks for Cross-lingual Dependency Parsing"
                                ],
                                [
                                    2010,
                                    "Machine Translation Hallucination Detection for Low and High Resource Languages using Large Language Models"
                                ],
                                [
                                    2127,
                                    "\"Vorbesti Romaneste?\" A Recipe to Train Powerful Romanian LLMs with English Instructions"
                                ]
                            ],
                            "paper_ids": [
                                235,
                                250,
                                316,
                                333,
                                823,
                                1707,
                                1872,
                                1898,
                                2010,
                                2127,
                                2251,
                                2263,
                                2305,
                                2332,
                                2387,
                                2608,
                                2610,
                                2623,
                                2624,
                                2797,
                                2799,
                                2847,
                                2851,
                                2854,
                                2856,
                                2857,
                                2858,
                                2859,
                                2860,
                                2861,
                                2865,
                                2866,
                                2867,
                                2868,
                                2873,
                                2874,
                                2875,
                                2876,
                                2878,
                                2879,
                                2881,
                                2882,
                                2883,
                                2884,
                                2888,
                                2889,
                                2893,
                                2894,
                                2896,
                                2897,
                                2899,
                                2900,
                                2901,
                                2902,
                                2903,
                                2905,
                                2921,
                                2936,
                                2939
                            ]
                        }
                    ]
                },
                {
                    "label": "multilingual_machine_translation",
                    "description": "This cluster explores approaches for translating multiple languages simultaneously, including multilingual learning and multilingual translation strategies.",
                    "level": 2,
                    "example_papers": [
                        [
                            23,
                            "Fine-Tuning Large Language Models to Translate: Will a Touch of Noisy Data in Misaligned Languages Suffice?"
                        ],
                        [
                            54,
                            "Chain-of-Dictionary Prompting Elicits Translation in Large Language Models"
                        ],
                        [
                            68,
                            "LLMs Are Zero-Shot Context-Aware Simultaneous Translators"
                        ],
                        [
                            78,
                            "Reuse Your Rewards: Reward Model Transfer for Zero-Shot Cross-Lingual Alignment"
                        ],
                        [
                            205,
                            "MTLS: Making Texts into Linguistic Symbols"
                        ],
                        [
                            213,
                            "What do Large Language Models Need for Machine Translation Evaluation?"
                        ],
                        [
                            235,
                            "When Is Multilinguality a Curse? Language Modeling for 250 High- and Low-Resource Languages"
                        ],
                        [
                            314,
                            "Concept Space Alignment in Multilingual LLMs"
                        ],
                        [
                            334,
                            "Quantifying the Gaps Between Translation and Native Perception in Training for Multimodal, Multilingual Retrieval"
                        ],
                        [
                            373,
                            "Neuron Specialization: Leveraging Intrinsic Task Modularity for Multilingual Machine Translation"
                        ]
                    ],
                    "paper_ids": [
                        23,
                        54,
                        68,
                        78,
                        205,
                        213,
                        235,
                        314,
                        334,
                        373,
                        395,
                        407,
                        440,
                        450,
                        456,
                        541,
                        571,
                        601,
                        603,
                        675,
                        677,
                        728,
                        742,
                        791,
                        823,
                        846,
                        887,
                        913,
                        1101,
                        1158,
                        1176,
                        1237,
                        1278,
                        1281,
                        1286,
                        1312,
                        1448,
                        1449,
                        1473,
                        1583,
                        1586,
                        1671,
                        1696,
                        1766,
                        1829,
                        1840,
                        1842,
                        1958,
                        2010,
                        2077,
                        2080,
                        2211,
                        2212,
                        2263,
                        2269,
                        2332,
                        2364,
                        2378,
                        2389,
                        2435,
                        2446,
                        2492,
                        2514,
                        2535,
                        2600,
                        2608,
                        2611,
                        2613,
                        2622,
                        2623,
                        2631,
                        2633,
                        2634,
                        2680,
                        2714,
                        2772,
                        2792,
                        2796,
                        2799,
                        2810,
                        2817,
                        2819,
                        2824,
                        2826,
                        2830,
                        2847,
                        2860,
                        2863,
                        2865,
                        2866,
                        2867,
                        2870,
                        2873,
                        2880,
                        2882,
                        2885,
                        2886,
                        2888,
                        2891,
                        2892,
                        2896,
                        2904,
                        2909,
                        2912,
                        2917,
                        2931,
                        2935,
                        2943
                    ],
                    "children": [
                        {
                            "label": "multilingual_translation_strategies",
                            "description": "This subtopic focuses on various strategies and methodologies for effectively translating multiple languages simultaneously, emphasizing the development of robust multilingual translation systems.",
                            "level": 3,
                            "example_papers": [
                                [
                                    23,
                                    "Fine-Tuning Large Language Models to Translate: Will a Touch of Noisy Data in Misaligned Languages Suffice?"
                                ],
                                [
                                    54,
                                    "Chain-of-Dictionary Prompting Elicits Translation in Large Language Models"
                                ],
                                [
                                    68,
                                    "LLMs Are Zero-Shot Context-Aware Simultaneous Translators"
                                ],
                                [
                                    205,
                                    "MTLS: Making Texts into Linguistic Symbols"
                                ],
                                [
                                    334,
                                    "Quantifying the Gaps Between Translation and Native Perception in Training for Multimodal, Multilingual Retrieval"
                                ],
                                [
                                    373,
                                    "Neuron Specialization: Leveraging Intrinsic Task Modularity for Multilingual Machine Translation"
                                ],
                                [
                                    407,
                                    "Python is Not Always the Best Choice: Embracing Multilingual Program of Thoughts"
                                ],
                                [
                                    440,
                                    "Breaking Language Barriers: Cross-Lingual Continual Pre-Training at Scale"
                                ],
                                [
                                    541,
                                    "Is It Good Data for Multilingual Instruction Tuning or Just Bad Multilingual Evaluation for Large Language Models?"
                                ],
                                [
                                    571,
                                    "PreAlign: Boosting Cross-Lingual Transfer by Early Establishment of Multilingual Alignment"
                                ]
                            ],
                            "paper_ids": [
                                23,
                                54,
                                68,
                                205,
                                334,
                                373,
                                407,
                                440,
                                541,
                                571,
                                601,
                                603,
                                675,
                                677,
                                728,
                                742,
                                887,
                                913,
                                1158,
                                1176,
                                1237,
                                1281,
                                1286,
                                1312,
                                1473,
                                1583,
                                1671,
                                1766,
                                1829,
                                1840,
                                1842,
                                1958,
                                2010,
                                2077,
                                2080,
                                2211,
                                2364,
                                2389,
                                2435,
                                2446,
                                2492,
                                2514,
                                2608,
                                2613,
                                2622,
                                2623,
                                2633,
                                2634,
                                2714,
                                2792,
                                2796,
                                2799,
                                2817,
                                2819,
                                2824,
                                2826,
                                2830,
                                2860,
                                2863,
                                2866,
                                2867,
                                2870,
                                2873,
                                2880,
                                2882,
                                2885,
                                2886,
                                2888,
                                2891,
                                2892,
                                2896,
                                2909,
                                2912,
                                2917,
                                2931,
                                2935,
                                2943
                            ]
                        },
                        {
                            "label": "multilingual_learning",
                            "description": "This subtopic explores techniques and approaches for learning representations and models that can handle multiple languages, enhancing the efficiency of multilingual machine translation.",
                            "level": 3,
                            "example_papers": [
                                [
                                    68,
                                    "LLMs Are Zero-Shot Context-Aware Simultaneous Translators"
                                ],
                                [
                                    205,
                                    "MTLS: Making Texts into Linguistic Symbols"
                                ],
                                [
                                    235,
                                    "When Is Multilinguality a Curse? Language Modeling for 250 High- and Low-Resource Languages"
                                ],
                                [
                                    314,
                                    "Concept Space Alignment in Multilingual LLMs"
                                ],
                                [
                                    373,
                                    "Neuron Specialization: Leveraging Intrinsic Task Modularity for Multilingual Machine Translation"
                                ],
                                [
                                    395,
                                    "Revealing the Parallel Multilingual Learning within Large Language Models"
                                ],
                                [
                                    407,
                                    "Python is Not Always the Best Choice: Embracing Multilingual Program of Thoughts"
                                ],
                                [
                                    456,
                                    "Getting More from Less: Large Language Models are Good Spontaneous Multilingual Learners"
                                ],
                                [
                                    603,
                                    "Breaking the Curse of Multilinguality with Cross-lingual Expert Language Models"
                                ],
                                [
                                    675,
                                    "TL-CL: Task And Language Incremental Continual Learning"
                                ]
                            ],
                            "paper_ids": [
                                68,
                                205,
                                235,
                                314,
                                373,
                                395,
                                407,
                                456,
                                603,
                                675,
                                728,
                                823,
                                846,
                                887,
                                1176,
                                1278,
                                1286,
                                1312,
                                1449,
                                1586,
                                1842,
                                2077,
                                2212,
                                2263,
                                2269,
                                2435,
                                2446,
                                2492,
                                2535,
                                2611,
                                2613,
                                2631,
                                2633,
                                2634,
                                2796,
                                2810,
                                2817,
                                2819,
                                2826,
                                2830,
                                2860,
                                2863,
                                2885,
                                2896,
                                2935,
                                2943
                            ]
                        },
                        {
                            "label": "cross-lingual_transfer",
                            "description": "This subtopic investigates methods for transferring knowledge across languages, enabling the application of models trained on high-resource languages to low-resource languages in multilingual translation tasks.",
                            "level": 3,
                            "example_papers": [
                                [
                                    54,
                                    "Chain-of-Dictionary Prompting Elicits Translation in Large Language Models"
                                ],
                                [
                                    68,
                                    "LLMs Are Zero-Shot Context-Aware Simultaneous Translators"
                                ],
                                [
                                    78,
                                    "Reuse Your Rewards: Reward Model Transfer for Zero-Shot Cross-Lingual Alignment"
                                ],
                                [
                                    235,
                                    "When Is Multilinguality a Curse? Language Modeling for 250 High- and Low-Resource Languages"
                                ],
                                [
                                    314,
                                    "Concept Space Alignment in Multilingual LLMs"
                                ],
                                [
                                    373,
                                    "Neuron Specialization: Leveraging Intrinsic Task Modularity for Multilingual Machine Translation"
                                ],
                                [
                                    407,
                                    "Python is Not Always the Best Choice: Embracing Multilingual Program of Thoughts"
                                ],
                                [
                                    440,
                                    "Breaking Language Barriers: Cross-Lingual Continual Pre-Training at Scale"
                                ],
                                [
                                    456,
                                    "Getting More from Less: Large Language Models are Good Spontaneous Multilingual Learners"
                                ],
                                [
                                    571,
                                    "PreAlign: Boosting Cross-Lingual Transfer by Early Establishment of Multilingual Alignment"
                                ]
                            ],
                            "paper_ids": [
                                54,
                                68,
                                78,
                                235,
                                314,
                                373,
                                407,
                                440,
                                456,
                                571,
                                603,
                                675,
                                677,
                                728,
                                742,
                                791,
                                887,
                                913,
                                1176,
                                1286,
                                1312,
                                1448,
                                1449,
                                1586,
                                1671,
                                1766,
                                1829,
                                1840,
                                1842,
                                2010,
                                2077,
                                2211,
                                2212,
                                2269,
                                2332,
                                2378,
                                2435,
                                2446,
                                2492,
                                2608,
                                2611,
                                2613,
                                2623,
                                2631,
                                2633,
                                2634,
                                2772,
                                2796,
                                2817,
                                2819,
                                2830,
                                2847,
                                2860,
                                2863,
                                2870,
                                2880,
                                2885,
                                2892,
                                2896,
                                2917,
                                2935,
                                2943
                            ]
                        },
                        {
                            "label": "low_resource_translation",
                            "description": "This subtopic addresses the challenges and solutions related to translating languages with limited available data, focusing on techniques that improve translation quality in low-resource scenarios.",
                            "level": 3,
                            "example_papers": [
                                [
                                    23,
                                    "Fine-Tuning Large Language Models to Translate: Will a Touch of Noisy Data in Misaligned Languages Suffice?"
                                ],
                                [
                                    54,
                                    "Chain-of-Dictionary Prompting Elicits Translation in Large Language Models"
                                ],
                                [
                                    68,
                                    "LLMs Are Zero-Shot Context-Aware Simultaneous Translators"
                                ],
                                [
                                    235,
                                    "When Is Multilinguality a Curse? Language Modeling for 250 High- and Low-Resource Languages"
                                ],
                                [
                                    373,
                                    "Neuron Specialization: Leveraging Intrinsic Task Modularity for Multilingual Machine Translation"
                                ],
                                [
                                    407,
                                    "Python is Not Always the Best Choice: Embracing Multilingual Program of Thoughts"
                                ],
                                [
                                    603,
                                    "Breaking the Curse of Multilinguality with Cross-lingual Expert Language Models"
                                ],
                                [
                                    675,
                                    "TL-CL: Task And Language Incremental Continual Learning"
                                ],
                                [
                                    742,
                                    "1+12: Can Large Language Models Serve as Cross-Lingual Knowledge Aggregators?"
                                ],
                                [
                                    791,
                                    "Cross-lingual Back-Parsing: Utterance Synthesis from Meaning Representation for Zero-Resource Semantic Parsing"
                                ]
                            ],
                            "paper_ids": [
                                23,
                                54,
                                68,
                                235,
                                373,
                                407,
                                603,
                                675,
                                742,
                                791,
                                823,
                                1101,
                                1176,
                                1286,
                                1312,
                                1586,
                                1671,
                                1766,
                                1840,
                                1842,
                                2010,
                                2077,
                                2080,
                                2263,
                                2332,
                                2435,
                                2446,
                                2492,
                                2608,
                                2799,
                                2817,
                                2847,
                                2860,
                                2863,
                                2865,
                                2867,
                                2870,
                                2873,
                                2880,
                                2882,
                                2885,
                                2886,
                                2888,
                                2892,
                                2896,
                                2904,
                                2943
                            ]
                        },
                        {
                            "label": "evaluation_of_multilingual_llms",
                            "description": "This subtopic examines the evaluation metrics and methodologies specifically designed for assessing the performance of multilingual large language models in translation tasks.",
                            "level": 3,
                            "example_papers": [
                                [
                                    68,
                                    "LLMs Are Zero-Shot Context-Aware Simultaneous Translators"
                                ],
                                [
                                    213,
                                    "What do Large Language Models Need for Machine Translation Evaluation?"
                                ],
                                [
                                    334,
                                    "Quantifying the Gaps Between Translation and Native Perception in Training for Multimodal, Multilingual Retrieval"
                                ],
                                [
                                    395,
                                    "Revealing the Parallel Multilingual Learning within Large Language Models"
                                ],
                                [
                                    407,
                                    "Python is Not Always the Best Choice: Embracing Multilingual Program of Thoughts"
                                ],
                                [
                                    450,
                                    "PARIKSHA: A Large-Scale Investigation of Human-LLM Evaluator Agreement on Multilingual and Multi-Cultural Data"
                                ],
                                [
                                    456,
                                    "Getting More from Less: Large Language Models are Good Spontaneous Multilingual Learners"
                                ],
                                [
                                    541,
                                    "Is It Good Data for Multilingual Instruction Tuning or Just Bad Multilingual Evaluation for Large Language Models?"
                                ],
                                [
                                    728,
                                    "RLHF Can Speak Many Languages: Unlocking Multilingual Preference Optimization for LLMs"
                                ],
                                [
                                    823,
                                    "Building Resources for Emakhuwa: Machine Translation and News Classification Benchmarks"
                                ]
                            ],
                            "paper_ids": [
                                68,
                                213,
                                334,
                                395,
                                407,
                                450,
                                456,
                                541,
                                728,
                                823,
                                887,
                                1101,
                                1237,
                                1286,
                                1312,
                                1473,
                                1696,
                                1842,
                                2010,
                                2077,
                                2211,
                                2269,
                                2378,
                                2389,
                                2435,
                                2514,
                                2600,
                                2608,
                                2613,
                                2631,
                                2633,
                                2634,
                                2714,
                                2772,
                                2792,
                                2796,
                                2817,
                                2819,
                                2830,
                                2847,
                                2860,
                                2865,
                                2882,
                                2896,
                                2931,
                                2935
                            ]
                        }
                    ]
                },
                {
                    "label": "neural_machine_translation",
                    "description": "This cluster is dedicated to the use of neural network architectures in machine translation, focusing on advancements in neural machine translation techniques and their applications.",
                    "level": 2,
                    "example_papers": [
                        [
                            23,
                            "Fine-Tuning Large Language Models to Translate: Will a Touch of Noisy Data in Misaligned Languages Suffice?"
                        ],
                        [
                            39,
                            "Tokenization Is More Than Compression"
                        ],
                        [
                            52,
                            "Language Models Learn Rare Phenomena from Less Rare Phenomena: The Case of the Missing AANNs"
                        ],
                        [
                            54,
                            "Chain-of-Dictionary Prompting Elicits Translation in Large Language Models"
                        ],
                        [
                            67,
                            "Rethinking Pruning Large Language Models: Benefits and Pitfalls of Reconstruction Error Minimization"
                        ],
                        [
                            68,
                            "LLMs Are Zero-Shot Context-Aware Simultaneous Translators"
                        ],
                        [
                            78,
                            "Reuse Your Rewards: Reward Model Transfer for Zero-Shot Cross-Lingual Alignment"
                        ],
                        [
                            101,
                            "MetaGPT: Merging Large Language Models Using Model Exclusive Task Arithmetic"
                        ],
                        [
                            110,
                            "PsFuture: A Pseudo-Future-based Zero-Shot Adaptive Policy for Simultaneous Machine Translation"
                        ],
                        [
                            141,
                            "Backward Lens: Projecting Language Model Gradients into the Vocabulary Space"
                        ]
                    ],
                    "paper_ids": [
                        23,
                        39,
                        52,
                        54,
                        67,
                        68,
                        78,
                        101,
                        110,
                        141,
                        147,
                        155,
                        159,
                        163,
                        181,
                        186,
                        187,
                        190,
                        193,
                        203,
                        213,
                        237,
                        250,
                        270,
                        273,
                        277,
                        286,
                        288,
                        299,
                        318,
                        327,
                        332,
                        333,
                        341,
                        342,
                        359,
                        373,
                        395,
                        402,
                        409,
                        413,
                        420,
                        436,
                        440,
                        454,
                        460,
                        461,
                        480,
                        511,
                        529,
                        545,
                        549,
                        552,
                        554,
                        557,
                        571,
                        572,
                        625,
                        629,
                        631,
                        637,
                        643,
                        662,
                        664,
                        671,
                        675,
                        679,
                        689,
                        691,
                        702,
                        703,
                        707,
                        717,
                        732,
                        741,
                        743,
                        767,
                        775,
                        791,
                        802,
                        803,
                        807,
                        823,
                        828,
                        846,
                        856,
                        859,
                        889,
                        894,
                        913,
                        932,
                        977,
                        991,
                        1009,
                        1016,
                        1027,
                        1032,
                        1054,
                        1069,
                        1080,
                        1101,
                        1145,
                        1157,
                        1163,
                        1176,
                        1211,
                        1216,
                        1217,
                        1230,
                        1247,
                        1254,
                        1281,
                        1301,
                        1308,
                        1411,
                        1417,
                        1437,
                        1449,
                        1473,
                        1475,
                        1497,
                        1539,
                        1540,
                        1556,
                        1615,
                        1618,
                        1631,
                        1636,
                        1671,
                        1684,
                        1689,
                        1705,
                        1707,
                        1763,
                        1764,
                        1766,
                        1774,
                        1797,
                        1807,
                        1812,
                        1829,
                        1840,
                        1842,
                        1854,
                        1898,
                        1901,
                        1925,
                        1952,
                        1958,
                        1964,
                        1979,
                        1997,
                        2002,
                        2010,
                        2022,
                        2023,
                        2035,
                        2077,
                        2089,
                        2112,
                        2184,
                        2211,
                        2215,
                        2251,
                        2273,
                        2305,
                        2306,
                        2312,
                        2313,
                        2314,
                        2317,
                        2321,
                        2322,
                        2332,
                        2338,
                        2339,
                        2378,
                        2389,
                        2393,
                        2397,
                        2402,
                        2429,
                        2435,
                        2440,
                        2443,
                        2446,
                        2459,
                        2467,
                        2608,
                        2615,
                        2617,
                        2622,
                        2624,
                        2633,
                        2670,
                        2680,
                        2710,
                        2714,
                        2764,
                        2772,
                        2795,
                        2810,
                        2814,
                        2818,
                        2819,
                        2820,
                        2821,
                        2822,
                        2823,
                        2824,
                        2825,
                        2826,
                        2827,
                        2828,
                        2829,
                        2830,
                        2831,
                        2832,
                        2833,
                        2834,
                        2838,
                        2839,
                        2851,
                        2853,
                        2854,
                        2859,
                        2860,
                        2861,
                        2862,
                        2863,
                        2864,
                        2865,
                        2866,
                        2868,
                        2872,
                        2873,
                        2875,
                        2876,
                        2877,
                        2879,
                        2882,
                        2883,
                        2884,
                        2886,
                        2888,
                        2889,
                        2891,
                        2892,
                        2896,
                        2897,
                        2898,
                        2900,
                        2901,
                        2902,
                        2905,
                        2906,
                        2909,
                        2910,
                        2911,
                        2912,
                        2913,
                        2914,
                        2915,
                        2916,
                        2917,
                        2918,
                        2919,
                        2921,
                        2922,
                        2923,
                        2925,
                        2926,
                        2927,
                        2931,
                        2934,
                        2935,
                        2936,
                        2937,
                        2940,
                        2941,
                        2943,
                        2944,
                        2948
                    ],
                    "children": [
                        {
                            "label": "neural_machine_translation_techniques",
                            "description": "This cluster focuses on various techniques specifically developed for neural machine translation, including advancements in architectures and methodologies.",
                            "level": 3,
                            "example_papers": [
                                [
                                    23,
                                    "Fine-Tuning Large Language Models to Translate: Will a Touch of Noisy Data in Misaligned Languages Suffice?"
                                ],
                                [
                                    39,
                                    "Tokenization Is More Than Compression"
                                ],
                                [
                                    52,
                                    "Language Models Learn Rare Phenomena from Less Rare Phenomena: The Case of the Missing AANNs"
                                ],
                                [
                                    54,
                                    "Chain-of-Dictionary Prompting Elicits Translation in Large Language Models"
                                ],
                                [
                                    67,
                                    "Rethinking Pruning Large Language Models: Benefits and Pitfalls of Reconstruction Error Minimization"
                                ],
                                [
                                    68,
                                    "LLMs Are Zero-Shot Context-Aware Simultaneous Translators"
                                ],
                                [
                                    101,
                                    "MetaGPT: Merging Large Language Models Using Model Exclusive Task Arithmetic"
                                ],
                                [
                                    110,
                                    "PsFuture: A Pseudo-Future-based Zero-Shot Adaptive Policy for Simultaneous Machine Translation"
                                ],
                                [
                                    141,
                                    "Backward Lens: Projecting Language Model Gradients into the Vocabulary Space"
                                ],
                                [
                                    147,
                                    "Instruction Pre-Training: Language Models are Supervised Multitask Learners"
                                ]
                            ],
                            "paper_ids": [
                                23,
                                39,
                                52,
                                54,
                                67,
                                68,
                                101,
                                110,
                                141,
                                147,
                                155,
                                159,
                                163,
                                187,
                                190,
                                193,
                                203,
                                213,
                                237,
                                250,
                                270,
                                273,
                                277,
                                288,
                                299,
                                318,
                                327,
                                332,
                                342,
                                359,
                                373,
                                395,
                                402,
                                409,
                                413,
                                420,
                                436,
                                454,
                                461,
                                480,
                                529,
                                545,
                                549,
                                552,
                                554,
                                571,
                                625,
                                629,
                                643,
                                662,
                                664,
                                671,
                                675,
                                679,
                                691,
                                702,
                                703,
                                707,
                                717,
                                732,
                                741,
                                743,
                                767,
                                802,
                                803,
                                807,
                                823,
                                828,
                                846,
                                856,
                                859,
                                889,
                                913,
                                977,
                                991,
                                1009,
                                1016,
                                1032,
                                1054,
                                1080,
                                1101,
                                1145,
                                1157,
                                1163,
                                1176,
                                1211,
                                1216,
                                1217,
                                1247,
                                1254,
                                1281,
                                1301,
                                1411,
                                1437,
                                1473,
                                1475,
                                1497,
                                1539,
                                1540,
                                1556,
                                1618,
                                1631,
                                1636,
                                1684,
                                1705,
                                1763,
                                1764,
                                1766,
                                1774,
                                1797,
                                1807,
                                1840,
                                1842,
                                1901,
                                1925,
                                1958,
                                1964,
                                1979,
                                1997,
                                2002,
                                2010,
                                2022,
                                2023,
                                2035,
                                2077,
                                2089,
                                2112,
                                2184,
                                2211,
                                2215,
                                2251,
                                2273,
                                2305,
                                2306,
                                2312,
                                2313,
                                2314,
                                2317,
                                2322,
                                2332,
                                2338,
                                2393,
                                2397,
                                2402,
                                2429,
                                2440,
                                2443,
                                2446,
                                2459,
                                2467,
                                2608,
                                2617,
                                2622,
                                2624,
                                2633,
                                2710,
                                2714,
                                2795,
                                2818,
                                2819,
                                2820,
                                2821,
                                2822,
                                2823,
                                2824,
                                2825,
                                2826,
                                2827,
                                2828,
                                2829,
                                2830,
                                2831,
                                2832,
                                2833,
                                2834,
                                2838,
                                2839,
                                2851,
                                2854,
                                2860,
                                2861,
                                2862,
                                2863,
                                2864,
                                2875,
                                2879,
                                2883,
                                2884,
                                2888,
                                2889,
                                2892,
                                2896,
                                2900,
                                2905,
                                2906,
                                2909,
                                2910,
                                2911,
                                2912,
                                2913,
                                2914,
                                2915,
                                2916,
                                2917,
                                2918,
                                2919,
                                2921,
                                2922,
                                2923,
                                2925,
                                2927,
                                2931,
                                2934,
                                2935,
                                2936,
                                2937,
                                2940,
                                2943,
                                2944
                            ]
                        },
                        {
                            "label": "low_resource_neural_machine_translation",
                            "description": "This cluster addresses the challenges and solutions related to neural machine translation in low-resource language settings, emphasizing techniques that enhance translation quality despite limited data.",
                            "level": 3,
                            "example_papers": [
                                [
                                    23,
                                    "Fine-Tuning Large Language Models to Translate: Will a Touch of Noisy Data in Misaligned Languages Suffice?"
                                ],
                                [
                                    54,
                                    "Chain-of-Dictionary Prompting Elicits Translation in Large Language Models"
                                ],
                                [
                                    68,
                                    "LLMs Are Zero-Shot Context-Aware Simultaneous Translators"
                                ],
                                [
                                    250,
                                    "Voices Unheard: NLP Resources and Models for Yoruba Regional Dialects"
                                ],
                                [
                                    333,
                                    "Pretraining Language Models Using Translationese"
                                ],
                                [
                                    637,
                                    "TEMA: Token Embeddings Mapping for Enriching Low-Resource Language Models"
                                ],
                                [
                                    703,
                                    "Domain adapted machine translation: What does catastrophic forgetting forget and why?"
                                ],
                                [
                                    707,
                                    "Optimizing Rare Word Accuracy in Direct Speech Translation with a Retrieval-and-Demonstration Approach"
                                ],
                                [
                                    791,
                                    "Cross-lingual Back-Parsing: Utterance Synthesis from Meaning Representation for Zero-Resource Semantic Parsing"
                                ],
                                [
                                    823,
                                    "Building Resources for Emakhuwa: Machine Translation and News Classification Benchmarks"
                                ]
                            ],
                            "paper_ids": [
                                23,
                                54,
                                68,
                                250,
                                333,
                                637,
                                703,
                                707,
                                791,
                                823,
                                1176,
                                1230,
                                1636,
                                1763,
                                1766,
                                1774,
                                1840,
                                1898,
                                2010,
                                2077,
                                2306,
                                2332,
                                2397,
                                2608,
                                2624,
                                2710,
                                2819,
                                2827,
                                2832,
                                2853,
                                2859,
                                2864,
                                2865,
                                2868,
                                2872,
                                2873,
                                2875,
                                2876,
                                2877,
                                2879,
                                2882,
                                2883,
                                2886,
                                2888,
                                2889,
                                2896,
                                2897,
                                2898,
                                2900,
                                2901,
                                2902,
                                2905,
                                2936,
                                2943
                            ]
                        },
                        {
                            "label": "multimodal_neural_machine_translation",
                            "description": "This cluster explores the integration of multiple modalities, such as text and images, in neural machine translation to improve contextual understanding and translation accuracy.",
                            "level": 3,
                            "example_papers": [
                                [
                                    181,
                                    "Autoregressive Pre-Training on Pixels and Texts"
                                ],
                                [
                                    286,
                                    "MaPPER: Multimodal Prior-guided Parameter Efficient Tuning for Referring Expression Comprehension"
                                ],
                                [
                                    341,
                                    "Video-LLaVA: Learning United Visual Representation by Alignment Before Projection"
                                ],
                                [
                                    557,
                                    "MMoE: Enhancing Multimodal Models with Mixtures of Multimodal Interaction Experts"
                                ],
                                [
                                    572,
                                    "An image speaks a thousand words, but can everyone listen? On image transcreation for cultural relevance"
                                ],
                                [
                                    689,
                                    "Self-Powered LLM Modality Expansion for Large Speech-Text Models"
                                ],
                                [
                                    894,
                                    "MLLM-Protector: Ensuring MLLM's Safety without Hurting Performance"
                                ],
                                [
                                    1027,
                                    "GOME: Grounding-based Metaphor Binding With Conceptual Elaboration For Figurative Language Illustration"
                                ],
                                [
                                    1069,
                                    "BLSP-Emo: Towards Empathetic Large Speech-Language Models"
                                ],
                                [
                                    1417,
                                    "AnyMAL: An Efficient and Scalable Any-Modality Augmented Language Model"
                                ]
                            ],
                            "paper_ids": [
                                181,
                                286,
                                341,
                                557,
                                572,
                                689,
                                894,
                                1027,
                                1069,
                                1417,
                                1766,
                                1812,
                                1952,
                                2112,
                                2339,
                                2810,
                                2886,
                                2888,
                                2891,
                                2892,
                                2926,
                                2941,
                                2944
                            ]
                        },
                        {
                            "label": "translation_quality_evaluation",
                            "description": "This cluster is dedicated to methods and metrics for evaluating the quality of translations produced by neural machine translation systems, ensuring reliability and effectiveness.",
                            "level": 3,
                            "example_papers": [
                                [
                                    186,
                                    "ScalingFilter: Assessing Data Quality through Inverse Utilization of Scaling Laws"
                                ],
                                [
                                    213,
                                    "What do Large Language Models Need for Machine Translation Evaluation?"
                                ],
                                [
                                    237,
                                    "MiTTenS: A Dataset for Evaluating Gender Mistranslation"
                                ],
                                [
                                    823,
                                    "Building Resources for Emakhuwa: Machine Translation and News Classification Benchmarks"
                                ],
                                [
                                    1217,
                                    "SpeechQE: Estimating the Quality of Direct Speech Translation"
                                ],
                                [
                                    1615,
                                    "Evaluating Automatic Metrics with Incremental Machine Translation Systems"
                                ],
                                [
                                    2338,
                                    "xTower: A Multilingual LLM for Explaining and Correcting Translation Errors"
                                ],
                                [
                                    2389,
                                    "BLASER 2.0: a metric for evaluation and quality estimation of massively multilingual speech and text translation"
                                ],
                                [
                                    2435,
                                    "BiMediX: Bilingual Medical Mixture of Experts LLM"
                                ],
                                [
                                    2714,
                                    "Assessing Large Language Models in Translating Coptic and Ancient Greek Ostraca"
                                ]
                            ],
                            "paper_ids": [
                                186,
                                213,
                                237,
                                823,
                                1217,
                                1615,
                                2338,
                                2389,
                                2435,
                                2714,
                                2814,
                                2834,
                                2838,
                                2860,
                                2861,
                                2865,
                                2921,
                                2923
                            ]
                        },
                        {
                            "label": "cross-lingual_learning",
                            "description": "This cluster investigates techniques that leverage knowledge from multiple languages to improve neural machine translation performance across different language pairs.",
                            "level": 3,
                            "example_papers": [
                                [
                                    54,
                                    "Chain-of-Dictionary Prompting Elicits Translation in Large Language Models"
                                ],
                                [
                                    78,
                                    "Reuse Your Rewards: Reward Model Transfer for Zero-Shot Cross-Lingual Alignment"
                                ],
                                [
                                    395,
                                    "Revealing the Parallel Multilingual Learning within Large Language Models"
                                ],
                                [
                                    440,
                                    "Breaking Language Barriers: Cross-Lingual Continual Pre-Training at Scale"
                                ],
                                [
                                    571,
                                    "PreAlign: Boosting Cross-Lingual Transfer by Early Establishment of Multilingual Alignment"
                                ],
                                [
                                    675,
                                    "TL-CL: Task And Language Incremental Continual Learning"
                                ],
                                [
                                    791,
                                    "Cross-lingual Back-Parsing: Utterance Synthesis from Meaning Representation for Zero-Resource Semantic Parsing"
                                ],
                                [
                                    823,
                                    "Building Resources for Emakhuwa: Machine Translation and News Classification Benchmarks"
                                ],
                                [
                                    913,
                                    "Towards Cross-Cultural Machine Translation with Retrieval-Augmented Generation from Multilingual Knowledge Graphs"
                                ],
                                [
                                    1449,
                                    "Should Cross-Lingual AMR Parsing go Meta? An Empirical Assessment of Meta-Learning and Joint Learning AMR Parsing"
                                ]
                            ],
                            "paper_ids": [
                                54,
                                78,
                                395,
                                440,
                                571,
                                675,
                                791,
                                823,
                                913,
                                1449,
                                1671,
                                1829,
                                1840,
                                1842,
                                1898,
                                2314,
                                2321,
                                2332,
                                2378,
                                2435,
                                2608,
                                2615,
                                2624,
                                2714,
                                2772,
                                2892
                            ]
                        }
                    ]
                }
            ]
        },
        {
            "label": "text_summarization",
            "description": "The process of generating a concise and coherent summary of a longer text document, capturing the main ideas and essential information.",
            "level": 1,
            "example_papers": [
                [
                    1,
                    "Multi-News+: Cost-efficient Dataset Cleansing via LLM-based Data Annotation"
                ],
                [
                    5,
                    "ImageInWords: Unlocking Hyper-Detailed Image Descriptions"
                ],
                [
                    13,
                    "A Usage-centric Take on Intent Understanding in E-Commerce"
                ],
                [
                    17,
                    "Uncertainty in Language Models: Assessment through Rank-Calibration"
                ],
                [
                    35,
                    "Evaluating Readability and Faithfulness of Concept-based Explanations"
                ],
                [
                    37,
                    "MSI-Agent: Incorporating Multi-Scale Insight into Embodied Agents for Superior Planning and Decision-Making"
                ],
                [
                    39,
                    "Tokenization Is More Than Compression"
                ],
                [
                    42,
                    "Parameter-Efficient Sparsity Crafting from Dense to Mixture-of-Experts for Instruction Tuning on General Tasks"
                ],
                [
                    48,
                    "Overcome Noise and Bias: Segmentation-Aided Multi-Granularity Denoising and Debiasing for Enhanced Quarduples Extraction in Dialogue"
                ],
                [
                    52,
                    "Language Models Learn Rare Phenomena from Less Rare Phenomena: The Case of the Missing AANNs"
                ]
            ],
            "paper_ids": [
                1,
                5,
                13,
                17,
                35,
                37,
                39,
                42,
                48,
                52,
                53,
                56,
                63,
                65,
                67,
                83,
                93,
                101,
                141,
                149,
                155,
                163,
                165,
                166,
                169,
                177,
                186,
                193,
                225,
                235,
                245,
                273,
                276,
                279,
                286,
                299,
                315,
                332,
                342,
                356,
                364,
                381,
                388,
                390,
                402,
                407,
                409,
                432,
                436,
                454,
                455,
                460,
                462,
                480,
                483,
                496,
                508,
                511,
                514,
                518,
                521,
                522,
                523,
                529,
                537,
                544,
                545,
                547,
                549,
                551,
                556,
                557,
                570,
                573,
                579,
                593,
                594,
                602,
                605,
                614,
                623,
                628,
                631,
                637,
                640,
                656,
                658,
                662,
                664,
                675,
                679,
                689,
                691,
                702,
                727,
                732,
                741,
                746,
                760,
                763,
                766,
                775,
                776,
                800,
                803,
                809,
                825,
                837,
                843,
                846,
                848,
                849,
                869,
                890,
                894,
                895,
                897,
                898,
                900,
                901,
                909,
                922,
                928,
                932,
                934,
                940,
                941,
                948,
                950,
                954,
                965,
                975,
                977,
                983,
                998,
                1006,
                1027,
                1031,
                1035,
                1038,
                1045,
                1047,
                1052,
                1053,
                1069,
                1072,
                1077,
                1084,
                1095,
                1096,
                1105,
                1109,
                1112,
                1119,
                1127,
                1129,
                1131,
                1145,
                1148,
                1153,
                1157,
                1170,
                1189,
                1191,
                1203,
                1219,
                1230,
                1254,
                1260,
                1278,
                1280,
                1294,
                1308,
                1310,
                1311,
                1313,
                1323,
                1334,
                1337,
                1344,
                1357,
                1358,
                1373,
                1374,
                1381,
                1384,
                1385,
                1386,
                1388,
                1405,
                1409,
                1417,
                1430,
                1441,
                1445,
                1450,
                1470,
                1472,
                1474,
                1479,
                1481,
                1485,
                1493,
                1494,
                1498,
                1532,
                1533,
                1539,
                1540,
                1555,
                1556,
                1564,
                1570,
                1574,
                1576,
                1586,
                1589,
                1595,
                1616,
                1618,
                1620,
                1625,
                1628,
                1636,
                1637,
                1640,
                1646,
                1653,
                1656,
                1666,
                1673,
                1677,
                1679,
                1683,
                1688,
                1696,
                1707,
                1724,
                1734,
                1739,
                1753,
                1755,
                1764,
                1767,
                1769,
                1773,
                1783,
                1796,
                1802,
                1812,
                1818,
                1823,
                1835,
                1839,
                1854,
                1858,
                1860,
                1861,
                1863,
                1865,
                1875,
                1876,
                1877,
                1879,
                1886,
                1908,
                1909,
                1920,
                1940,
                1941,
                1944,
                1945,
                1952,
                1954,
                1962,
                1963,
                1969,
                1971,
                1976,
                1986,
                1997,
                2002,
                2005,
                2009,
                2015,
                2022,
                2024,
                2027,
                2034,
                2035,
                2041,
                2048,
                2051,
                2064,
                2065,
                2066,
                2094,
                2100,
                2121,
                2123,
                2133,
                2165,
                2168,
                2184,
                2186,
                2201,
                2215,
                2226,
                2231,
                2236,
                2242,
                2245,
                2250,
                2251,
                2253,
                2266,
                2267,
                2270,
                2297,
                2310,
                2313,
                2315,
                2317,
                2318,
                2323,
                2324,
                2329,
                2331,
                2340,
                2341,
                2352,
                2356,
                2361,
                2363,
                2382,
                2387,
                2390,
                2391,
                2409,
                2411,
                2429,
                2443,
                2445,
                2467,
                2481,
                2482,
                2486,
                2488,
                2496,
                2499,
                2513,
                2516,
                2535,
                2543,
                2548,
                2551,
                2556,
                2580,
                2593,
                2600,
                2614,
                2628,
                2639,
                2640,
                2647,
                2653,
                2669,
                2670,
                2677,
                2679,
                2680,
                2698,
                2716,
                2720,
                2721,
                2732,
                2749,
                2752,
                2753,
                2754,
                2755,
                2764,
                2772,
                2786,
                2788,
                2791,
                2792,
                2793,
                2809,
                2810,
                2811,
                2946,
                2948
            ],
            "children": [
                {
                    "label": "extractive_summarization",
                    "description": "The process of selecting and extracting key sentences or phrases from a text document to create a summary that retains the original wording and structure.",
                    "level": 2,
                    "example_papers": [
                        [
                            177,
                            "SEER: Self-Aligned Evidence Extraction for Retrieval-Augmented Generation"
                        ],
                        [
                            432,
                            "Divide and Conquer Radiology Report Generation via Observation Level Fine-grained Pretraining and Prompt Tuning"
                        ],
                        [
                            518,
                            "APPLS: Evaluating Evaluation Metrics for Plain Language Summarization"
                        ],
                        [
                            593,
                            "Evidence-Focused Fact Summarization for Knowledge-Augmented Zero-Shot Question Answering"
                        ],
                        [
                            1105,
                            "Towards Enhancing Coherence in Extractive Summarization: Dataset and Experiments with LLMs"
                        ],
                        [
                            1470,
                            "Disordered-DABS: A Benchmark for Dynamic Aspect-Based Summarization in Disordered Texts"
                        ],
                        [
                            1673,
                            "UniSumEval: Towards Unified, Fine-grained, Multi-dimensional Summarization Evaluation for LLMs"
                        ],
                        [
                            1835,
                            "Hope `The Paragraph Guy' explains the rest : Introducing MeSum, the Meme Summarizer"
                        ],
                        [
                            1877,
                            "Event-Keyed Summarization"
                        ],
                        [
                            2486,
                            "Investigating large language models for their competence in extracting grammatically sound sentences from transcribed noisy utterances"
                        ]
                    ],
                    "paper_ids": [
                        177,
                        432,
                        518,
                        593,
                        1105,
                        1470,
                        1673,
                        1835,
                        1877,
                        2486,
                        2580,
                        2639,
                        2753
                    ]
                },
                {
                    "label": "abstractive_summarization",
                    "description": "The generation of new sentences that convey the main ideas of a text document, often paraphrasing and rephrasing the original content to create a coherent summary.",
                    "level": 2,
                    "example_papers": [
                        [
                            342,
                            "SaySelf: Teaching LLMs to Express Confidence with Self-Reflective Rationales"
                        ],
                        [
                            364,
                            "Satyrn: A Platform for Analytics Augmented Generation"
                        ],
                        [
                            514,
                            "Enhancing Reinforcement Learning with Dense Rewards from Language Model Critic"
                        ],
                        [
                            518,
                            "APPLS: Evaluating Evaluation Metrics for Plain Language Summarization"
                        ],
                        [
                            556,
                            "STORYSUMM: Evaluating Faithfulness in Story Summarization"
                        ],
                        [
                            950,
                            "GDPO: Learning to Directly Align Language Models with Diversity Using GFlowNets"
                        ],
                        [
                            975,
                            "Don't Forget Your Reward Values: Language Model Alignment via Value-based Calibration"
                        ],
                        [
                            983,
                            "Knowledge Planning in Large Language Models for Domain-Aligned Counseling Summarization"
                        ],
                        [
                            1038,
                            "Semformer: Transformer Language Models with Semantic Planning"
                        ],
                        [
                            1047,
                            "Model-based Preference Optimization in Abstractive Summarization without Human Feedback"
                        ]
                    ],
                    "paper_ids": [
                        342,
                        364,
                        514,
                        518,
                        556,
                        950,
                        975,
                        983,
                        1038,
                        1047,
                        1077,
                        1084,
                        1119,
                        1189,
                        1310,
                        1323,
                        1386,
                        1388,
                        1417,
                        1470,
                        1540,
                        1556,
                        1564,
                        1656,
                        1673,
                        1688,
                        1835,
                        1877,
                        1944,
                        1963,
                        1969,
                        2024,
                        2094,
                        2121,
                        2123,
                        2297,
                        2313,
                        2499,
                        2543,
                        2614,
                        2639,
                        2653,
                        2669,
                        2732,
                        2753,
                        2811
                    ],
                    "children": [
                        {
                            "label": "learning_techniques",
                            "description": "This cluster encompasses various learning methodologies applied to abstractive summarization, such as reinforcement learning, multi-objective finetuning, and active learning.",
                            "level": 3,
                            "example_papers": [
                                [
                                    514,
                                    "Enhancing Reinforcement Learning with Dense Rewards from Language Model Critic"
                                ],
                                [
                                    950,
                                    "GDPO: Learning to Directly Align Language Models with Diversity Using GFlowNets"
                                ],
                                [
                                    975,
                                    "Don't Forget Your Reward Values: Language Model Alignment via Value-based Calibration"
                                ],
                                [
                                    1047,
                                    "Model-based Preference Optimization in Abstractive Summarization without Human Feedback"
                                ],
                                [
                                    1189,
                                    "Contrastive Policy Gradient: Aligning LLMs on sequence-level scores in a supervised-friendly fashion"
                                ],
                                [
                                    1564,
                                    "Conditional Language Policy: A General Framework For Steerable Multi-Objective Finetuning"
                                ],
                                [
                                    1969,
                                    "Active Learning for Abstractive Text Summarization via LLM-Determined Curriculum and Certainty Gain Maximization"
                                ],
                                [
                                    2297,
                                    "Style-Compress: An LLM-Based Prompt Compression Framework Considering Task-Specific Styles"
                                ],
                                [
                                    2499,
                                    "Global Learning with Triplet Relations in Abstractive Summarization"
                                ],
                                [
                                    2543,
                                    "AdaptEval: Evaluating Large Language Models on Domain Adaptation for Text Summarization"
                                ]
                            ],
                            "paper_ids": [
                                514,
                                950,
                                975,
                                1047,
                                1189,
                                1564,
                                1969,
                                2297,
                                2499,
                                2543,
                                2653
                            ]
                        },
                        {
                            "label": "alignment_and_consistency",
                            "description": "This cluster addresses the alignment of generated summaries with factual content and user preferences, including factual consistency detection, language model alignment, and reward alignment.",
                            "level": 3,
                            "example_papers": [
                                [
                                    556,
                                    "STORYSUMM: Evaluating Faithfulness in Story Summarization"
                                ],
                                [
                                    950,
                                    "GDPO: Learning to Directly Align Language Models with Diversity Using GFlowNets"
                                ],
                                [
                                    975,
                                    "Don't Forget Your Reward Values: Language Model Alignment via Value-based Calibration"
                                ],
                                [
                                    983,
                                    "Knowledge Planning in Large Language Models for Domain-Aligned Counseling Summarization"
                                ],
                                [
                                    1119,
                                    "SYNFAC-EDIT: Synthetic Imitation Edit Feedback for Factual Alignment in Clinical Summarization"
                                ],
                                [
                                    1189,
                                    "Contrastive Policy Gradient: Aligning LLMs on sequence-level scores in a supervised-friendly fashion"
                                ],
                                [
                                    1470,
                                    "Disordered-DABS: A Benchmark for Dynamic Aspect-Based Summarization in Disordered Texts"
                                ],
                                [
                                    1656,
                                    "SummaCoz: A Dataset for Improving the Interpretability of Factual Consistency Detection for Summarization"
                                ],
                                [
                                    1688,
                                    "Inference-Time Language Model Alignment via Integrated Value Guidance"
                                ],
                                [
                                    1944,
                                    "AlignSum: Data Pyramid Hierarchical Fine-tuning for Aligning with Human Summarization Preference"
                                ]
                            ],
                            "paper_ids": [
                                556,
                                950,
                                975,
                                983,
                                1119,
                                1189,
                                1470,
                                1656,
                                1688,
                                1944,
                                2024,
                                2094,
                                2121,
                                2732
                            ]
                        },
                        {
                            "label": "multimodal_and_multilingual_summarization",
                            "description": "This cluster includes techniques for generating summaries from multiple sources or modalities, such as multilingual aspect-centric review summarization, multimodal summarization, and multi-source summarization.",
                            "level": 3,
                            "example_papers": [
                                [
                                    1386,
                                    "MARS: Multilingual Aspect-centric Review Summarisation"
                                ],
                                [
                                    1388,
                                    "Tell me what I need to know: Exploring LLM-based (Personalized) Abstractive Multi-Source Meeting Summarization"
                                ],
                                [
                                    1417,
                                    "AnyMAL: An Efficient and Scalable Any-Modality Augmented Language Model"
                                ],
                                [
                                    2121,
                                    "HealthAlignSumm : Utilizing Alignment for Multimodal Summarization of Code-Mixed Healthcare Dialogues"
                                ]
                            ],
                            "paper_ids": [
                                1386,
                                1388,
                                1417,
                                2121
                            ]
                        },
                        {
                            "label": "advanced_generation_techniques",
                            "description": "This cluster explores innovative generation strategies in abstractive summarization, including prompting techniques, structured reasoning, and zero-shot summarization.",
                            "level": 3,
                            "example_papers": [
                                [
                                    364,
                                    "Satyrn: A Platform for Analytics Augmented Generation"
                                ],
                                [
                                    983,
                                    "Knowledge Planning in Large Language Models for Domain-Aligned Counseling Summarization"
                                ],
                                [
                                    1038,
                                    "Semformer: Transformer Language Models with Semantic Planning"
                                ],
                                [
                                    1047,
                                    "Model-based Preference Optimization in Abstractive Summarization without Human Feedback"
                                ],
                                [
                                    1310,
                                    "RAGLAB: A Modular and Research-Oriented Unified Framework for Retrieval-Augmented Generation"
                                ],
                                [
                                    1323,
                                    "Salient Information Prompting to Steer Content in Prompt-based Abstractive Summarization"
                                ],
                                [
                                    1470,
                                    "Disordered-DABS: A Benchmark for Dynamic Aspect-Based Summarization in Disordered Texts"
                                ],
                                [
                                    1540,
                                    "Suri: Multi-constraint Instruction Following in Long-form Text Generation"
                                ],
                                [
                                    1556,
                                    "Abstraction-of-Thought Makes Language Models Better Reasoners"
                                ],
                                [
                                    1835,
                                    "Hope `The Paragraph Guy' explains the rest : Introducing MeSum, the Meme Summarizer"
                                ]
                            ],
                            "paper_ids": [
                                364,
                                983,
                                1038,
                                1047,
                                1310,
                                1323,
                                1470,
                                1540,
                                1556,
                                1835,
                                1877,
                                1963,
                                2123,
                                2313,
                                2499,
                                2614,
                                2639,
                                2653,
                                2732,
                                2753,
                                2811
                            ]
                        }
                    ]
                },
                {
                    "label": "multi_document_summarization",
                    "description": "The task of summarizing information from multiple documents into a single concise summary, capturing the essential points from each source.",
                    "level": 2,
                    "example_papers": [
                        [
                            1,
                            "Multi-News+: Cost-efficient Dataset Cleansing via LLM-based Data Annotation"
                        ],
                        [
                            551,
                            "Summary of a Haystack: A Challenge to Long-Context LLMs and RAG Systems"
                        ],
                        [
                            602,
                            "GlobeSumm: A Challenging Benchmark Towards Unifying Multi-lingual, Cross-lingual and Multi-document News Summarization"
                        ],
                        [
                            846,
                            "Layer by Layer: Uncovering Where Multi-Task Learning Happens in Instruction-Tuned Large Language Models"
                        ],
                        [
                            1084,
                            "Re-Evaluating Evaluation for Multilingual Summarization"
                        ],
                        [
                            1310,
                            "RAGLAB: A Modular and Research-Oriented Unified Framework for Retrieval-Augmented Generation"
                        ],
                        [
                            1385,
                            "Retrieval Augmented Generation or Long-Context LLMs? A Comprehensive Study and Hybrid Approach"
                        ],
                        [
                            1388,
                            "Tell me what I need to know: Exploring LLM-based (Personalized) Abstractive Multi-Source Meeting Summarization"
                        ],
                        [
                            1470,
                            "Disordered-DABS: A Benchmark for Dynamic Aspect-Based Summarization in Disordered Texts"
                        ],
                        [
                            1564,
                            "Conditional Language Policy: A General Framework For Steerable Multi-Objective Finetuning"
                        ]
                    ],
                    "paper_ids": [
                        1,
                        551,
                        602,
                        846,
                        1084,
                        1310,
                        1385,
                        1388,
                        1470,
                        1564,
                        1673,
                        1724,
                        1877,
                        1879,
                        1962,
                        2253,
                        2310,
                        2390,
                        2653,
                        2753
                    ]
                },
                {
                    "label": "query-focused_summarization",
                    "description": "A specialized form of summarization that generates summaries based on specific queries or information needs, ensuring relevance to the user's request.",
                    "level": 2,
                    "example_papers": [
                        [
                            837,
                            "Learning to Rank Salient Content for Query-focused Summarization"
                        ],
                        [
                            1405,
                            "Query-OPT: Optimizing Inference of Large Language Models via Multi-Query Instructions in Meeting Summarization"
                        ],
                        [
                            1470,
                            "Disordered-DABS: A Benchmark for Dynamic Aspect-Based Summarization in Disordered Texts"
                        ],
                        [
                            1673,
                            "UniSumEval: Towards Unified, Fine-grained, Multi-dimensional Summarization Evaluation for LLMs"
                        ],
                        [
                            1877,
                            "Event-Keyed Summarization"
                        ],
                        [
                            2253,
                            "ConTReGen: Context-driven Tree-structured Retrieval for Open-domain Long-form Text Generation"
                        ],
                        [
                            2653,
                            "Cross Examine: An Ensemble-based approach to leverage Large Language Models for Legal Text Analytics"
                        ]
                    ],
                    "paper_ids": [
                        837,
                        1405,
                        1470,
                        1673,
                        1877,
                        2253,
                        2653
                    ]
                },
                {
                    "label": "incremental_summarization",
                    "description": "The process of continuously updating a summary as new information becomes available, allowing for real-time summarization of ongoing content.",
                    "level": 2,
                    "example_papers": [
                        [
                            409,
                            "Incomplete Utterance Rewriting with Editing Operation Guidance and Utterance Augmentation"
                        ],
                        [
                            675,
                            "TL-CL: Task And Language Incremental Continual Learning"
                        ],
                        [
                            983,
                            "Knowledge Planning in Large Language Models for Domain-Aligned Counseling Summarization"
                        ],
                        [
                            1191,
                            "Beyond Turn-Based Interfaces: Synchronous LLMs as Full-Duplex Dialogue Agents"
                        ],
                        [
                            1388,
                            "Tell me what I need to know: Exploring LLM-based (Personalized) Abstractive Multi-Source Meeting Summarization"
                        ],
                        [
                            1470,
                            "Disordered-DABS: A Benchmark for Dynamic Aspect-Based Summarization in Disordered Texts"
                        ],
                        [
                            1666,
                            "Enhancing Incremental Summarization with Structured Representations"
                        ],
                        [
                            1673,
                            "UniSumEval: Towards Unified, Fine-grained, Multi-dimensional Summarization Evaluation for LLMs"
                        ],
                        [
                            1877,
                            "Event-Keyed Summarization"
                        ],
                        [
                            2653,
                            "Cross Examine: An Ensemble-based approach to leverage Large Language Models for Legal Text Analytics"
                        ]
                    ],
                    "paper_ids": [
                        409,
                        675,
                        983,
                        1191,
                        1388,
                        1470,
                        1666,
                        1673,
                        1877,
                        2653,
                        2809
                    ]
                },
                {
                    "label": "text_simplification",
                    "description": "The process of modifying text to make it easier to read and understand while retaining the original meaning.",
                    "level": 2,
                    "example_papers": [
                        [
                            35,
                            "Evaluating Readability and Faithfulness of Concept-based Explanations"
                        ],
                        [
                            37,
                            "MSI-Agent: Incorporating Multi-Scale Insight into Embodied Agents for Superior Planning and Decision-Making"
                        ],
                        [
                            42,
                            "Parameter-Efficient Sparsity Crafting from Dense to Mixture-of-Experts for Instruction Tuning on General Tasks"
                        ],
                        [
                            52,
                            "Language Models Learn Rare Phenomena from Less Rare Phenomena: The Case of the Missing AANNs"
                        ],
                        [
                            67,
                            "Rethinking Pruning Large Language Models: Benefits and Pitfalls of Reconstruction Error Minimization"
                        ],
                        [
                            83,
                            "Lookback Lens: Detecting and Mitigating Contextual Hallucinations in Large Language Models Using Only Attention Maps"
                        ],
                        [
                            93,
                            "Standardize: Aligning Language Models with Expert-Defined Standards for Content Generation"
                        ],
                        [
                            101,
                            "MetaGPT: Merging Large Language Models Using Model Exclusive Task Arithmetic"
                        ],
                        [
                            149,
                            "Collaborative Performance Prediction for Large Language Models"
                        ],
                        [
                            155,
                            "To Word Senses and Beyond: Inducing Concepts with Contextualized Language Models"
                        ]
                    ],
                    "paper_ids": [
                        35,
                        37,
                        42,
                        52,
                        67,
                        83,
                        93,
                        101,
                        149,
                        155,
                        163,
                        186,
                        245,
                        273,
                        276,
                        299,
                        315,
                        332,
                        356,
                        388,
                        407,
                        454,
                        455,
                        460,
                        483,
                        496,
                        518,
                        556,
                        570,
                        594,
                        614,
                        637,
                        640,
                        658,
                        662,
                        679,
                        689,
                        741,
                        776,
                        809,
                        848,
                        849,
                        869,
                        890,
                        894,
                        895,
                        901,
                        940,
                        948,
                        954,
                        977,
                        998,
                        1006,
                        1035,
                        1045,
                        1052,
                        1069,
                        1072,
                        1077,
                        1084,
                        1096,
                        1131,
                        1145,
                        1157,
                        1219,
                        1230,
                        1334,
                        1337,
                        1344,
                        1357,
                        1358,
                        1374,
                        1381,
                        1384,
                        1385,
                        1409,
                        1470,
                        1474,
                        1485,
                        1532,
                        1539,
                        1555,
                        1570,
                        1574,
                        1576,
                        1595,
                        1618,
                        1625,
                        1653,
                        1673,
                        1739,
                        1753,
                        1764,
                        1773,
                        1783,
                        1835,
                        1858,
                        1860,
                        1865,
                        1876,
                        1877,
                        1920,
                        1941,
                        1954,
                        1971,
                        1976,
                        1986,
                        2005,
                        2009,
                        2015,
                        2022,
                        2034,
                        2041,
                        2048,
                        2066,
                        2100,
                        2123,
                        2184,
                        2242,
                        2270,
                        2315,
                        2317,
                        2318,
                        2323,
                        2324,
                        2329,
                        2331,
                        2352,
                        2356,
                        2361,
                        2363,
                        2387,
                        2409,
                        2411,
                        2429,
                        2443,
                        2445,
                        2481,
                        2482,
                        2551,
                        2600,
                        2716,
                        2721,
                        2749,
                        2755,
                        2786,
                        2788,
                        2791,
                        2792,
                        2793
                    ],
                    "children": [
                        {
                            "label": "text_simplification_techniques",
                            "description": "This cluster encompasses various methods and approaches used to simplify text, ensuring that the original meaning is preserved while enhancing readability.",
                            "level": 3,
                            "example_papers": [
                                [
                                    37,
                                    "MSI-Agent: Incorporating Multi-Scale Insight into Embodied Agents for Superior Planning and Decision-Making"
                                ],
                                [
                                    52,
                                    "Language Models Learn Rare Phenomena from Less Rare Phenomena: The Case of the Missing AANNs"
                                ],
                                [
                                    93,
                                    "Standardize: Aligning Language Models with Expert-Defined Standards for Content Generation"
                                ],
                                [
                                    101,
                                    "MetaGPT: Merging Large Language Models Using Model Exclusive Task Arithmetic"
                                ],
                                [
                                    163,
                                    "Alignment-Enhanced Decoding: Defending Jailbreaks via Token-Level Adaptive Refining of Probability Distributions"
                                ],
                                [
                                    276,
                                    "KidLM: Advancing Language Models for Children - Early Insights and Future Directions"
                                ],
                                [
                                    299,
                                    "Pretraining Data Detection for Large Language Models: A Divergence-based Calibration Method"
                                ],
                                [
                                    315,
                                    "Predicting Rewards Alongside Tokens: Non-disruptive Parameter Insertion for Efficient Inference Intervention in Large Language Model"
                                ],
                                [
                                    332,
                                    "Teaching Small Language Models Reasoning through Counterfactual Distillation"
                                ],
                                [
                                    407,
                                    "Python is Not Always the Best Choice: Embracing Multilingual Program of Thoughts"
                                ]
                            ],
                            "paper_ids": [
                                37,
                                52,
                                93,
                                101,
                                163,
                                276,
                                299,
                                315,
                                332,
                                407,
                                454,
                                460,
                                483,
                                496,
                                570,
                                594,
                                614,
                                637,
                                679,
                                689,
                                741,
                                809,
                                848,
                                849,
                                869,
                                901,
                                940,
                                954,
                                998,
                                1035,
                                1045,
                                1052,
                                1131,
                                1157,
                                1219,
                                1334,
                                1374,
                                1384,
                                1409,
                                1474,
                                1485,
                                1539,
                                1555,
                                1576,
                                1595,
                                1625,
                                1653,
                                1739,
                                1753,
                                1783,
                                1835,
                                1860,
                                1865,
                                1877,
                                1920,
                                1954,
                                1971,
                                1976,
                                1986,
                                2009,
                                2022,
                                2034,
                                2123,
                                2242,
                                2270,
                                2317,
                                2329,
                                2331,
                                2361,
                                2363,
                                2429,
                                2443,
                                2445,
                                2481,
                                2482,
                                2551,
                                2716,
                                2749,
                                2786,
                                2788,
                                2792
                            ]
                        },
                        {
                            "label": "sentence_simplification",
                            "description": "This cluster focuses on techniques specifically aimed at simplifying individual sentences to improve comprehension without losing essential information.",
                            "level": 3,
                            "example_papers": [
                                [
                                    52,
                                    "Language Models Learn Rare Phenomena from Less Rare Phenomena: The Case of the Missing AANNs"
                                ],
                                [
                                    998,
                                    "Label Confidence Weighted Learning for Target-level Sentence Simplification"
                                ],
                                [
                                    1485,
                                    "LLM-supertagger: Categorial Grammar Supertagging via Large Language Models"
                                ],
                                [
                                    1764,
                                    "A Simple Angle-based Approach for Contrastive Learning of Unsupervised Sentence Representation"
                                ],
                                [
                                    1865,
                                    "Edit-Constrained Decoding for Sentence Simplification"
                                ],
                                [
                                    1986,
                                    "Improving Diversity of Commonsense Generation by Large Language Models via In-Context Learning"
                                ]
                            ],
                            "paper_ids": [
                                52,
                                998,
                                1485,
                                1764,
                                1865,
                                1986
                            ]
                        },
                        {
                            "label": "text_simplification_evaluation",
                            "description": "This cluster includes methods and metrics for assessing the effectiveness of text simplification processes, ensuring that the simplified text meets desired readability standards.",
                            "level": 3,
                            "example_papers": [
                                [
                                    35,
                                    "Evaluating Readability and Faithfulness of Concept-based Explanations"
                                ],
                                [
                                    52,
                                    "Language Models Learn Rare Phenomena from Less Rare Phenomena: The Case of the Missing AANNs"
                                ],
                                [
                                    149,
                                    "Collaborative Performance Prediction for Large Language Models"
                                ],
                                [
                                    186,
                                    "ScalingFilter: Assessing Data Quality through Inverse Utilization of Scaling Laws"
                                ],
                                [
                                    276,
                                    "KidLM: Advancing Language Models for Children - Early Insights and Future Directions"
                                ],
                                [
                                    356,
                                    "Evaluating LLMs for Targeted Concept Simplification for Domain-Specific Texts"
                                ],
                                [
                                    483,
                                    "Explaining and Improving Contrastive Decoding by Extrapolating the Probabilities of a Huge and Hypothetical LM"
                                ],
                                [
                                    518,
                                    "APPLS: Evaluating Evaluation Metrics for Plain Language Summarization"
                                ],
                                [
                                    849,
                                    "Control Large Language Models via Divide and Conquer"
                                ],
                                [
                                    890,
                                    "Themis: A Reference-free NLG Evaluation Language Model with Flexibility and Interpretability"
                                ]
                            ],
                            "paper_ids": [
                                35,
                                52,
                                149,
                                186,
                                276,
                                356,
                                483,
                                518,
                                849,
                                890,
                                895,
                                948,
                                954,
                                977,
                                998,
                                1077,
                                1084,
                                1096,
                                1131,
                                1145,
                                1230,
                                1344,
                                1384,
                                1385,
                                1485,
                                1532,
                                1595,
                                1673,
                                1860,
                                1876,
                                1986,
                                2041,
                                2184,
                                2242,
                                2315,
                                2318,
                                2323,
                                2324,
                                2356,
                                2387,
                                2482,
                                2600,
                                2721,
                                2788,
                                2791,
                                2792,
                                2793
                            ]
                        },
                        {
                            "label": "length_control",
                            "description": "This cluster involves strategies for managing the length of simplified text, balancing brevity with clarity to enhance reader understanding.",
                            "level": 3,
                            "example_papers": [
                                [
                                    52,
                                    "Language Models Learn Rare Phenomena from Less Rare Phenomena: The Case of the Missing AANNs"
                                ],
                                [
                                    1131,
                                    "DEFT-UCS: Data Efficient Fine-Tuning for Pre-Trained Language Models via Unsupervised Core-Set Selection for Text-Editing"
                                ],
                                [
                                    1385,
                                    "Retrieval Augmented Generation or Long-Context LLMs? A Comprehensive Study and Hybrid Approach"
                                ],
                                [
                                    1485,
                                    "LLM-supertagger: Categorial Grammar Supertagging via Large Language Models"
                                ],
                                [
                                    1618,
                                    "Ruler: A Model-Agnostic Method to Control Generated Length for Large Language Models"
                                ],
                                [
                                    1986,
                                    "Improving Diversity of Commonsense Generation by Large Language Models via In-Context Learning"
                                ],
                                [
                                    2123,
                                    "A Decoding Algorithm for Length-Control Summarization Based on Directed Acyclic Transformers"
                                ],
                                [
                                    2429,
                                    "PositionID: LLMs can Control Lengths, Copy and Paste with Explicit Positional Awareness"
                                ],
                                [
                                    2600,
                                    "MLissard: Multilingual Long and Simple Sequential Reasoning Benchmarks"
                                ]
                            ],
                            "paper_ids": [
                                52,
                                1131,
                                1385,
                                1485,
                                1618,
                                1986,
                                2123,
                                2429,
                                2600
                            ]
                        },
                        {
                            "label": "lexical_simplification",
                            "description": "This cluster is dedicated to the simplification of vocabulary and phrasing within texts, making complex words and expressions more accessible to a broader audience.",
                            "level": 3,
                            "example_papers": [
                                [
                                    52,
                                    "Language Models Learn Rare Phenomena from Less Rare Phenomena: The Case of the Missing AANNs"
                                ],
                                [
                                    848,
                                    "Optimizing Chinese Lexical Simplification Across Word Types: A Hybrid Approach"
                                ],
                                [
                                    849,
                                    "Control Large Language Models via Divide and Conquer"
                                ],
                                [
                                    1131,
                                    "DEFT-UCS: Data Efficient Fine-Tuning for Pre-Trained Language Models via Unsupervised Core-Set Selection for Text-Editing"
                                ],
                                [
                                    1485,
                                    "LLM-supertagger: Categorial Grammar Supertagging via Large Language Models"
                                ],
                                [
                                    1865,
                                    "Edit-Constrained Decoding for Sentence Simplification"
                                ],
                                [
                                    1986,
                                    "Improving Diversity of Commonsense Generation by Large Language Models via In-Context Learning"
                                ]
                            ],
                            "paper_ids": [
                                52,
                                848,
                                849,
                                1131,
                                1485,
                                1865,
                                1986
                            ]
                        }
                    ]
                },
                {
                    "label": "knowledge_editing",
                    "description": "The task of refining and updating knowledge representations to improve accuracy and relevance in information retrieval.",
                    "level": 2,
                    "example_papers": [
                        [
                            53,
                            "Large Language Models for Data Annotation and Synthesis: A Survey"
                        ],
                        [
                            56,
                            "RoseLoRA: Row and Column-wise Sparse Low-rank Adaptation of Pre-trained Language Model for Knowledge Editing and Fine-tuning"
                        ],
                        [
                            547,
                            "Extract, Define, Canonicalize: An LLM-based Framework for Knowledge Graph Construction"
                        ],
                        [
                            825,
                            "Commonsense Knowledge Editing Based on Free-Text in LLMs"
                        ],
                        [
                            977,
                            "Are Large Language Models Capable of Generating Human-Level Narratives?"
                        ],
                        [
                            1131,
                            "DEFT-UCS: Data Efficient Fine-Tuning for Pre-Trained Language Models via Unsupervised Core-Set Selection for Text-Editing"
                        ],
                        [
                            1260,
                            "Knowledge Graph Enhanced Large Language Model Editing"
                        ],
                        [
                            1441,
                            "Enhancing LLM Capabilities Beyond Scaling Up"
                        ],
                        [
                            1470,
                            "Disordered-DABS: A Benchmark for Dynamic Aspect-Based Summarization in Disordered Texts"
                        ],
                        [
                            1636,
                            "Multi-Stage Balanced Distillation: Addressing Long-Tail Challenges in Sequence-Level Knowledge Distillation"
                        ]
                    ],
                    "paper_ids": [
                        53,
                        56,
                        547,
                        825,
                        977,
                        1131,
                        1260,
                        1441,
                        1470,
                        1636,
                        1673,
                        1877,
                        2548,
                        2670,
                        2810
                    ]
                },
                {
                    "label": "keyphrase_generation",
                    "description": "The automated identification of key phrases within a text that capture the main topics and themes.",
                    "level": 2,
                    "example_papers": [
                        [
                            623,
                            "One2Set + Large Language Model: Best Partners for Keyphrase Generation"
                        ],
                        [
                            977,
                            "Are Large Language Models Capable of Generating Human-Level Narratives?"
                        ],
                        [
                            1052,
                            "Generation with Dynamic Vocabulary"
                        ],
                        [
                            1072,
                            "DataNarrative: Automated Data-Driven Storytelling with Visualizations and Texts"
                        ],
                        [
                            1323,
                            "Salient Information Prompting to Steer Content in Prompt-based Abstractive Summarization"
                        ],
                        [
                            1358,
                            "ReportGPT: Human-in-the-loop Verifiable Table-to-Text Generation"
                        ],
                        [
                            1470,
                            "Disordered-DABS: A Benchmark for Dynamic Aspect-Based Summarization in Disordered Texts"
                        ],
                        [
                            1479,
                            "Unsupervised Domain Adaptation for Keyphrase Generation using Citation Contexts"
                        ],
                        [
                            1673,
                            "UniSumEval: Towards Unified, Fine-grained, Multi-dimensional Summarization Evaluation for LLMs"
                        ],
                        [
                            1677,
                            "Guided Profile Generation Improves Personalization with Large Language Models"
                        ]
                    ],
                    "paper_ids": [
                        623,
                        977,
                        1052,
                        1072,
                        1323,
                        1358,
                        1470,
                        1479,
                        1673,
                        1677,
                        1835,
                        1877,
                        1940,
                        2315,
                        2352,
                        2593,
                        2653,
                        2752,
                        2764,
                        2772
                    ]
                },
                {
                    "label": "text_segmentation",
                    "description": "The division of text into meaningful segments or units to facilitate better understanding and processing.",
                    "level": 2,
                    "example_papers": [
                        [
                            39,
                            "Tokenization Is More Than Compression"
                        ],
                        [
                            166,
                            "With Ears to See and Eyes to Hear: Sound Symbolism Experiments with Multimodal Large Language Models"
                        ],
                        [
                            390,
                            "Beyond Embeddings: The Promise of Visual Table in Visual Reasoning"
                        ],
                        [
                            402,
                            "Does Large Language Model Contain Task-Specific Neurons?"
                        ],
                        [
                            521,
                            "RuBLiMP: Russian Benchmark of Linguistic Minimal Pairs"
                        ],
                        [
                            523,
                            "Toward Compositional Behavior in Neural Models: A Survey of Current Views"
                        ],
                        [
                            537,
                            "ArxivDIGESTables: Synthesizing Scientific Literature into Tables using Language Models"
                        ],
                        [
                            557,
                            "MMoE: Enhancing Multimodal Models with Mixtures of Multimodal Interaction Experts"
                        ],
                        [
                            628,
                            "Code Prompting Elicits Conditional Reasoning Abilities in Text+Code LLMs"
                        ],
                        [
                            664,
                            "Segment Any Text: A Universal Approach for Robust, Efficient and Adaptable Sentence Segmentation"
                        ]
                    ],
                    "paper_ids": [
                        39,
                        166,
                        390,
                        402,
                        521,
                        523,
                        537,
                        557,
                        628,
                        664,
                        803,
                        897,
                        900,
                        928,
                        977,
                        1109,
                        1112,
                        1127,
                        1148,
                        1153,
                        1278,
                        1294,
                        1373,
                        1470,
                        1472,
                        1589,
                        1620,
                        1640,
                        1673,
                        1679,
                        1683,
                        1823,
                        1835,
                        1863,
                        1877,
                        1908,
                        1945,
                        1963,
                        2027,
                        2035,
                        2186,
                        2236,
                        2251,
                        2352,
                        2391,
                        2496,
                        2593,
                        2680,
                        2754,
                        2764,
                        2809
                    ],
                    "children": [
                        {
                            "label": "text_representation",
                            "description": "This cluster focuses on various methods and techniques for representing text in a structured format to enhance segmentation and understanding.",
                            "level": 3,
                            "example_papers": [
                                [
                                    39,
                                    "Tokenization Is More Than Compression"
                                ]
                            ],
                            "paper_ids": [
                                39
                            ]
                        },
                        {
                            "label": "text_segmentation_techniques",
                            "description": "This cluster encompasses different methodologies and approaches specifically designed for effective text segmentation.",
                            "level": 3,
                            "example_papers": [
                                [
                                    39,
                                    "Tokenization Is More Than Compression"
                                ],
                                [
                                    390,
                                    "Beyond Embeddings: The Promise of Visual Table in Visual Reasoning"
                                ],
                                [
                                    402,
                                    "Does Large Language Model Contain Task-Specific Neurons?"
                                ],
                                [
                                    521,
                                    "RuBLiMP: Russian Benchmark of Linguistic Minimal Pairs"
                                ],
                                [
                                    523,
                                    "Toward Compositional Behavior in Neural Models: A Survey of Current Views"
                                ],
                                [
                                    537,
                                    "ArxivDIGESTables: Synthesizing Scientific Literature into Tables using Language Models"
                                ],
                                [
                                    628,
                                    "Code Prompting Elicits Conditional Reasoning Abilities in Text+Code LLMs"
                                ],
                                [
                                    664,
                                    "Segment Any Text: A Universal Approach for Robust, Efficient and Adaptable Sentence Segmentation"
                                ],
                                [
                                    803,
                                    "DC-Instruct: An Effective Framework for Generative Multi-intent Spoken Language Understanding"
                                ],
                                [
                                    897,
                                    "VideoCLIP-XL: Advancing Long Description Understanding for Video CLIP Models"
                                ]
                            ],
                            "paper_ids": [
                                39,
                                390,
                                402,
                                521,
                                523,
                                537,
                                628,
                                664,
                                803,
                                897,
                                900,
                                928,
                                977,
                                1127,
                                1153,
                                1278,
                                1294,
                                1373,
                                1470,
                                1472,
                                1589,
                                1620,
                                1640,
                                1673,
                                1679,
                                1683,
                                1823,
                                1863,
                                1877,
                                1908,
                                1963,
                                2027,
                                2035,
                                2186,
                                2236,
                                2251,
                                2391,
                                2496,
                                2680,
                                2754,
                                2764,
                                2809
                            ]
                        },
                        {
                            "label": "sentence_segmentation",
                            "description": "This cluster is dedicated to the task of dividing text into individual sentences, which is a fundamental aspect of text segmentation.",
                            "level": 3,
                            "example_papers": [
                                [
                                    664,
                                    "Segment Any Text: A Universal Approach for Robust, Efficient and Adaptable Sentence Segmentation"
                                ]
                            ],
                            "paper_ids": [
                                664
                            ]
                        },
                        {
                            "label": "document_segmentation",
                            "description": "This cluster involves the segmentation of entire documents into coherent sections or units, facilitating better processing and comprehension.",
                            "level": 3,
                            "example_papers": [
                                [
                                    1620,
                                    "Recent Trends in Linear Text Segmentation: A Survey"
                                ],
                                [
                                    1823,
                                    "LumberChunker: Long-Form Narrative Document Segmentation"
                                ],
                                [
                                    2186,
                                    "Problem-Oriented Segmentation and Retrieval: Case Study on Tutoring Conversations"
                                ],
                                [
                                    2236,
                                    "Topic Modeling: Contextual Token Embeddings Are All You Need"
                                ],
                                [
                                    2352,
                                    "Knowledge-Centric Templatic Views of Documents"
                                ],
                                [
                                    2593,
                                    "A Comprehensive Survey on Document-Level Information Extraction"
                                ]
                            ],
                            "paper_ids": [
                                1620,
                                1823,
                                2186,
                                2236,
                                2352,
                                2593
                            ]
                        },
                        {
                            "label": "word_segmentation",
                            "description": "This cluster focuses on the task of identifying and separating individual words within a continuous stream of text, crucial for languages without clear word boundaries.",
                            "level": 3,
                            "example_papers": [
                                [
                                    2251,
                                    "One Model is All You Need: ByT5-Sanskrit, a Unified Model for Sanskrit NLP Tasks"
                                ]
                            ],
                            "paper_ids": [
                                2251
                            ]
                        }
                    ]
                },
                {
                    "label": "information_extraction",
                    "description": "The process of automatically extracting structured information from unstructured text, such as identifying entities and relationships.",
                    "level": 2,
                    "example_papers": [
                        [
                            48,
                            "Overcome Noise and Bias: Segmentation-Aided Multi-Granularity Denoising and Debiasing for Enhanced Quarduples Extraction in Dialogue"
                        ],
                        [
                            53,
                            "Large Language Models for Data Annotation and Synthesis: A Survey"
                        ],
                        [
                            155,
                            "To Word Senses and Beyond: Inducing Concepts with Contextualized Language Models"
                        ],
                        [
                            166,
                            "With Ears to See and Eyes to Hear: Sound Symbolism Experiments with Multimodal Large Language Models"
                        ],
                        [
                            279,
                            "An Unsupervised Approach to Achieve Supervised-Level Explainability in Healthcare Records"
                        ],
                        [
                            402,
                            "Does Large Language Model Contain Task-Specific Neurons?"
                        ],
                        [
                            436,
                            "MORPHEUS: Modeling Role from Personalized Dialogue History by Exploring and Utilizing Latent Space"
                        ],
                        [
                            483,
                            "Explaining and Improving Contrastive Decoding by Extrapolating the Probabilities of a Huge and Hypothetical LM"
                        ],
                        [
                            508,
                            "Can Active Label Correction Improve LLM-based Modular AI Systems?"
                        ],
                        [
                            521,
                            "RuBLiMP: Russian Benchmark of Linguistic Minimal Pairs"
                        ]
                    ],
                    "paper_ids": [
                        48,
                        53,
                        155,
                        166,
                        279,
                        402,
                        436,
                        483,
                        508,
                        521,
                        522,
                        529,
                        537,
                        544,
                        547,
                        557,
                        573,
                        628,
                        640,
                        656,
                        691,
                        732,
                        803,
                        897,
                        900,
                        977,
                        1052,
                        1053,
                        1072,
                        1112,
                        1127,
                        1148,
                        1203,
                        1278,
                        1294,
                        1373,
                        1430,
                        1450,
                        1470,
                        1472,
                        1640,
                        1673,
                        1755,
                        1767,
                        1769,
                        1835,
                        1861,
                        1877,
                        1879,
                        1909,
                        1945,
                        1997,
                        2002,
                        2027,
                        2051,
                        2064,
                        2215,
                        2236,
                        2251,
                        2340,
                        2341,
                        2352,
                        2356,
                        2390,
                        2496,
                        2593,
                        2653,
                        2670,
                        2679,
                        2680,
                        2721,
                        2752,
                        2764,
                        2772,
                        2809
                    ],
                    "children": [
                        {
                            "label": "entity_recognition",
                            "description": "The task of identifying and classifying key entities in text, such as names of people, organizations, locations, and other relevant items.",
                            "level": 3,
                            "example_papers": [
                                [
                                    1127,
                                    "VIEWS: Entity-Aware News Video Captioning"
                                ]
                            ],
                            "paper_ids": [
                                1127
                            ]
                        },
                        {
                            "label": "knowledge_graph_construction",
                            "description": "The process of creating a structured representation of knowledge by extracting entities and their relationships from unstructured text.",
                            "level": 3,
                            "example_papers": [
                                [
                                    547,
                                    "Extract, Define, Canonicalize: An LLM-based Framework for Knowledge Graph Construction"
                                ],
                                [
                                    2653,
                                    "Cross Examine: An Ensemble-based approach to leverage Large Language Models for Legal Text Analytics"
                                ]
                            ],
                            "paper_ids": [
                                547,
                                2653
                            ]
                        },
                        {
                            "label": "role_extraction",
                            "description": "The task of identifying and categorizing the roles that entities play within a given context or relationship in the text.",
                            "level": 3,
                            "example_papers": [
                                [
                                    436,
                                    "MORPHEUS: Modeling Role from Personalized Dialogue History by Exploring and Utilizing Latent Space"
                                ],
                                [
                                    1879,
                                    "HiCuLR: Hierarchical Curriculum Learning for Rhetorical Role Labeling of Legal Documents"
                                ],
                                [
                                    2215,
                                    "Unleashing the Power of Large Language Models in Zero-shot Relation Extraction via Self-Prompting"
                                ]
                            ],
                            "paper_ids": [
                                436,
                                1879,
                                2215
                            ]
                        },
                        {
                            "label": "text_to_table_generation",
                            "description": "The process of converting unstructured text data into structured tabular formats, facilitating easier data analysis and retrieval.",
                            "level": 3,
                            "example_papers": [
                                [
                                    522,
                                    "Text-Tuple-Table: Towards Information Integration in Text-to-Table Generation via Global Tuple Extraction"
                                ],
                                [
                                    537,
                                    "ArxivDIGESTables: Synthesizing Scientific Literature into Tables using Language Models"
                                ],
                                [
                                    900,
                                    "TKGT: Redefinition and A New Way of Text-to-Table Tasks Based on Real World Demands and Knowledge Graphs Augmented LLMs"
                                ],
                                [
                                    1294,
                                    "OpenT2T: An Open-Source Toolkit for Table-to-Text Generation"
                                ]
                            ],
                            "paper_ids": [
                                522,
                                537,
                                900,
                                1294
                            ]
                        },
                        {
                            "label": "document_level_information_extraction",
                            "description": "The extraction of structured information from entire documents, focusing on capturing comprehensive insights rather than isolated data points.",
                            "level": 3,
                            "example_papers": [
                                [
                                    48,
                                    "Overcome Noise and Bias: Segmentation-Aided Multi-Granularity Denoising and Debiasing for Enhanced Quarduples Extraction in Dialogue"
                                ],
                                [
                                    53,
                                    "Large Language Models for Data Annotation and Synthesis: A Survey"
                                ],
                                [
                                    155,
                                    "To Word Senses and Beyond: Inducing Concepts with Contextualized Language Models"
                                ],
                                [
                                    166,
                                    "With Ears to See and Eyes to Hear: Sound Symbolism Experiments with Multimodal Large Language Models"
                                ],
                                [
                                    279,
                                    "An Unsupervised Approach to Achieve Supervised-Level Explainability in Healthcare Records"
                                ],
                                [
                                    402,
                                    "Does Large Language Model Contain Task-Specific Neurons?"
                                ],
                                [
                                    483,
                                    "Explaining and Improving Contrastive Decoding by Extrapolating the Probabilities of a Huge and Hypothetical LM"
                                ],
                                [
                                    508,
                                    "Can Active Label Correction Improve LLM-based Modular AI Systems?"
                                ],
                                [
                                    521,
                                    "RuBLiMP: Russian Benchmark of Linguistic Minimal Pairs"
                                ],
                                [
                                    522,
                                    "Text-Tuple-Table: Towards Information Integration in Text-to-Table Generation via Global Tuple Extraction"
                                ]
                            ],
                            "paper_ids": [
                                48,
                                53,
                                155,
                                166,
                                279,
                                402,
                                483,
                                508,
                                521,
                                522,
                                529,
                                537,
                                544,
                                557,
                                573,
                                628,
                                640,
                                656,
                                691,
                                732,
                                803,
                                897,
                                977,
                                1052,
                                1053,
                                1072,
                                1112,
                                1127,
                                1148,
                                1203,
                                1278,
                                1294,
                                1373,
                                1430,
                                1450,
                                1470,
                                1472,
                                1640,
                                1673,
                                1755,
                                1767,
                                1769,
                                1861,
                                1877,
                                1879,
                                1909,
                                1945,
                                1997,
                                2002,
                                2064,
                                2215,
                                2236,
                                2251,
                                2340,
                                2341,
                                2352,
                                2356,
                                2390,
                                2496,
                                2593,
                                2653,
                                2670,
                                2679,
                                2680,
                                2721,
                                2752,
                                2772,
                                2809
                            ]
                        }
                    ]
                }
            ]
        },
        {
            "label": "information_retrieval",
            "description": "The task of obtaining information system resources that are relevant to an information need from a collection of those resources.",
            "level": 1,
            "example_papers": [
                [
                    5,
                    "ImageInWords: Unlocking Hyper-Detailed Image Descriptions"
                ],
                [
                    8,
                    "Speaking in Wavelet Domain: A Simple and Efficient Approach to Speed up Speech Diffusion Model"
                ],
                [
                    13,
                    "A Usage-centric Take on Intent Understanding in E-Commerce"
                ],
                [
                    14,
                    "Fine-Tuning or Retrieval? Comparing Knowledge Injection in LLMs"
                ],
                [
                    15,
                    "Systematic Biases in LLM Simulations of Debates"
                ],
                [
                    17,
                    "Uncertainty in Language Models: Assessment through Rank-Calibration"
                ],
                [
                    19,
                    "Learning Planning-based Reasoning by Trajectories Collection and Process Reward Synthesizing"
                ],
                [
                    24,
                    "Consolidating Ranking and Relevance Predictions of Large Language Models through Post-Processing"
                ],
                [
                    25,
                    "Strength Lies in Differences! Improving Strategy Planning for Non-collaborative Dialogues via Diversified User Simulation"
                ],
                [
                    26,
                    "Impeding LLM-assisted Cheating in Introductory Programming Assignments via Adversarial Perturbation"
                ]
            ],
            "paper_ids": [
                5,
                8,
                13,
                14,
                15,
                17,
                19,
                24,
                25,
                26,
                27,
                35,
                39,
                42,
                43,
                44,
                46,
                47,
                48,
                50,
                52,
                53,
                56,
                57,
                60,
                63,
                65,
                66,
                67,
                70,
                72,
                73,
                74,
                79,
                80,
                82,
                85,
                88,
                89,
                91,
                95,
                101,
                102,
                103,
                105,
                106,
                111,
                113,
                117,
                119,
                120,
                122,
                123,
                124,
                125,
                126,
                128,
                129,
                134,
                137,
                138,
                139,
                141,
                143,
                145,
                146,
                148,
                149,
                155,
                156,
                157,
                160,
                163,
                165,
                166,
                168,
                169,
                170,
                171,
                173,
                174,
                176,
                177,
                178,
                183,
                186,
                193,
                197,
                198,
                215,
                216,
                222,
                224,
                225,
                228,
                229,
                230,
                232,
                234,
                235,
                236,
                238,
                245,
                247,
                249,
                250,
                251,
                252,
                253,
                262,
                264,
                266,
                267,
                269,
                273,
                274,
                276,
                279,
                280,
                281,
                284,
                286,
                290,
                292,
                294,
                296,
                299,
                300,
                302,
                304,
                307,
                308,
                309,
                311,
                313,
                315,
                318,
                319,
                320,
                321,
                331,
                332,
                334,
                335,
                337,
                342,
                347,
                349,
                350,
                351,
                352,
                358,
                360,
                364,
                366,
                368,
                369,
                370,
                372,
                375,
                376,
                378,
                379,
                380,
                384,
                386,
                387,
                388,
                390,
                398,
                401,
                402,
                404,
                405,
                406,
                407,
                408,
                409,
                413,
                416,
                417,
                418,
                421,
                422,
                425,
                426,
                428,
                430,
                431,
                433,
                434,
                436,
                437,
                439,
                446,
                449,
                450,
                453,
                454,
                457,
                459,
                460,
                461,
                462,
                467,
                472,
                474,
                476,
                477,
                478,
                480,
                481,
                483,
                484,
                487,
                489,
                490,
                492,
                494,
                496,
                499,
                500,
                501,
                504,
                505,
                506,
                508,
                511,
                513,
                521,
                522,
                523,
                526,
                527,
                529,
                530,
                531,
                532,
                533,
                534,
                537,
                540,
                544,
                545,
                547,
                548,
                549,
                551,
                553,
                555,
                556,
                557,
                562,
                563,
                567,
                570,
                573,
                575,
                579,
                580,
                585,
                586,
                588,
                589,
                590,
                594,
                595,
                596,
                601,
                604,
                605,
                607,
                609,
                612,
                614,
                615,
                616,
                627,
                628,
                631,
                632,
                635,
                636,
                637,
                639,
                645,
                647,
                649,
                652,
                653,
                654,
                656,
                658,
                660,
                662,
                664,
                665,
                666,
                667,
                672,
                673,
                675,
                679,
                684,
                686,
                687,
                688,
                689,
                691,
                693,
                700,
                702,
                705,
                709,
                714,
                716,
                718,
                719,
                721,
                724,
                725,
                726,
                732,
                733,
                734,
                735,
                738,
                739,
                741,
                745,
                746,
                750,
                751,
                754,
                758,
                760,
                761,
                762,
                763,
                764,
                765,
                771,
                772,
                773,
                774,
                775,
                776,
                777,
                778,
                779,
                780,
                782,
                783,
                789,
                792,
                794,
                796,
                797,
                799,
                800,
                803,
                805,
                806,
                808,
                809,
                812,
                813,
                820,
                822,
                824,
                825,
                827,
                831,
                832,
                838,
                839,
                841,
                842,
                843,
                844,
                846,
                849,
                850,
                852,
                853,
                854,
                857,
                860,
                862,
                863,
                864,
                866,
                867,
                871,
                879,
                880,
                882,
                891,
                892,
                894,
                895,
                896,
                897,
                898,
                900,
                901,
                906,
                909,
                914,
                918,
                919,
                920,
                921,
                923,
                925,
                928,
                929,
                932,
                937,
                939,
                941,
                942,
                944,
                946,
                947,
                948,
                954,
                956,
                962,
                963,
                964,
                965,
                968,
                971,
                973,
                976,
                977,
                978,
                980,
                982,
                986,
                988,
                992,
                994,
                997,
                1000,
                1003,
                1006,
                1008,
                1012,
                1014,
                1015,
                1017,
                1019,
                1020,
                1021,
                1022,
                1023,
                1025,
                1026,
                1027,
                1031,
                1035,
                1036,
                1037,
                1039,
                1041,
                1050,
                1053,
                1055,
                1059,
                1061,
                1064,
                1067,
                1069,
                1070,
                1071,
                1073,
                1076,
                1080,
                1082,
                1085,
                1088,
                1091,
                1094,
                1095,
                1096,
                1099,
                1100,
                1104,
                1106,
                1107,
                1108,
                1109,
                1110,
                1111,
                1112,
                1115,
                1117,
                1120,
                1121,
                1129,
                1132,
                1135,
                1139,
                1140,
                1145,
                1148,
                1152,
                1153,
                1156,
                1157,
                1159,
                1161,
                1162,
                1166,
                1167,
                1168,
                1169,
                1170,
                1174,
                1175,
                1178,
                1180,
                1181,
                1183,
                1184,
                1185,
                1186,
                1190,
                1191,
                1193,
                1198,
                1203,
                1204,
                1209,
                1211,
                1212,
                1213,
                1215,
                1219,
                1228,
                1229,
                1230,
                1232,
                1238,
                1240,
                1241,
                1243,
                1244,
                1246,
                1249,
                1252,
                1254,
                1256,
                1260,
                1265,
                1267,
                1269,
                1277,
                1278,
                1280,
                1285,
                1288,
                1289,
                1292,
                1295,
                1305,
                1308,
                1310,
                1311,
                1312,
                1317,
                1320,
                1321,
                1322,
                1325,
                1326,
                1328,
                1329,
                1330,
                1332,
                1334,
                1336,
                1337,
                1340,
                1342,
                1344,
                1345,
                1346,
                1349,
                1357,
                1359,
                1360,
                1361,
                1362,
                1365,
                1369,
                1373,
                1374,
                1377,
                1379,
                1380,
                1385,
                1392,
                1393,
                1394,
                1396,
                1397,
                1398,
                1401,
                1403,
                1404,
                1406,
                1408,
                1409,
                1412,
                1414,
                1417,
                1419,
                1421,
                1422,
                1423,
                1424,
                1425,
                1427,
                1428,
                1430,
                1432,
                1433,
                1441,
                1443,
                1445,
                1446,
                1450,
                1452,
                1453,
                1457,
                1460,
                1461,
                1463,
                1464,
                1468,
                1472,
                1474,
                1480,
                1481,
                1483,
                1484,
                1485,
                1486,
                1487,
                1490,
                1491,
                1492,
                1493,
                1494,
                1495,
                1496,
                1497,
                1498,
                1500,
                1503,
                1506,
                1507,
                1508,
                1509,
                1515,
                1517,
                1519,
                1521,
                1522,
                1526,
                1527,
                1529,
                1532,
                1533,
                1534,
                1538,
                1539,
                1540,
                1542,
                1543,
                1546,
                1548,
                1549,
                1550,
                1552,
                1555,
                1556,
                1559,
                1562,
                1569,
                1572,
                1573,
                1576,
                1578,
                1579,
                1581,
                1584,
                1586,
                1588,
                1589,
                1591,
                1596,
                1597,
                1599,
                1601,
                1602,
                1603,
                1607,
                1608,
                1609,
                1610,
                1613,
                1614,
                1616,
                1618,
                1620,
                1625,
                1627,
                1628,
                1636,
                1637,
                1638,
                1640,
                1641,
                1646,
                1648,
                1649,
                1651,
                1653,
                1655,
                1659,
                1665,
                1667,
                1675,
                1678,
                1680,
                1682,
                1683,
                1686,
                1688,
                1690,
                1693,
                1694,
                1696,
                1699,
                1702,
                1707,
                1710,
                1714,
                1717,
                1720,
                1721,
                1725,
                1727,
                1730,
                1734,
                1738,
                1739,
                1744,
                1750,
                1753,
                1755,
                1764,
                1767,
                1769,
                1771,
                1772,
                1773,
                1775,
                1776,
                1784,
                1787,
                1788,
                1791,
                1794,
                1796,
                1801,
                1802,
                1805,
                1808,
                1809,
                1812,
                1815,
                1819,
                1820,
                1821,
                1822,
                1823,
                1827,
                1828,
                1829,
                1837,
                1838,
                1843,
                1847,
                1848,
                1854,
                1858,
                1860,
                1861,
                1863,
                1869,
                1873,
                1874,
                1875,
                1876,
                1879,
                1880,
                1881,
                1882,
                1885,
                1887,
                1891,
                1892,
                1893,
                1894,
                1895,
                1902,
                1903,
                1904,
                1905,
                1907,
                1909,
                1911,
                1913,
                1914,
                1915,
                1916,
                1918,
                1921,
                1929,
                1931,
                1935,
                1936,
                1937,
                1938,
                1939,
                1941,
                1942,
                1947,
                1950,
                1952,
                1954,
                1955,
                1956,
                1957,
                1962,
                1963,
                1965,
                1968,
                1970,
                1971,
                1973,
                1974,
                1975,
                1976,
                1981,
                1983,
                1985,
                1989,
                1995,
                1997,
                2002,
                2004,
                2005,
                2007,
                2012,
                2015,
                2021,
                2022,
                2029,
                2033,
                2034,
                2035,
                2036,
                2039,
                2041,
                2044,
                2045,
                2046,
                2047,
                2048,
                2049,
                2050,
                2051,
                2053,
                2055,
                2058,
                2061,
                2064,
                2065,
                2066,
                2068,
                2069,
                2070,
                2071,
                2072,
                2073,
                2074,
                2083,
                2086,
                2087,
                2088,
                2095,
                2096,
                2098,
                2100,
                2102,
                2113,
                2115,
                2124,
                2128,
                2130,
                2132,
                2134,
                2138,
                2139,
                2148,
                2153,
                2160,
                2164,
                2166,
                2167,
                2168,
                2169,
                2176,
                2177,
                2178,
                2184,
                2186,
                2189,
                2193,
                2195,
                2196,
                2203,
                2204,
                2206,
                2207,
                2208,
                2209,
                2213,
                2215,
                2216,
                2218,
                2222,
                2224,
                2226,
                2228,
                2231,
                2232,
                2233,
                2236,
                2237,
                2240,
                2243,
                2245,
                2246,
                2247,
                2251,
                2252,
                2253,
                2254,
                2255,
                2257,
                2266,
                2267,
                2273,
                2275,
                2277,
                2280,
                2281,
                2283,
                2288,
                2289,
                2290,
                2295,
                2298,
                2302,
                2313,
                2317,
                2318,
                2325,
                2329,
                2340,
                2341,
                2345,
                2348,
                2350,
                2352,
                2355,
                2356,
                2357,
                2359,
                2361,
                2365,
                2366,
                2368,
                2369,
                2373,
                2376,
                2378,
                2380,
                2385,
                2386,
                2387,
                2390,
                2391,
                2392,
                2396,
                2399,
                2404,
                2409,
                2410,
                2412,
                2418,
                2419,
                2420,
                2422,
                2423,
                2426,
                2429,
                2430,
                2432,
                2433,
                2434,
                2436,
                2440,
                2442,
                2443,
                2444,
                2445,
                2452,
                2457,
                2458,
                2462,
                2463,
                2464,
                2467,
                2472,
                2473,
                2474,
                2475,
                2477,
                2478,
                2480,
                2481,
                2482,
                2484,
                2486,
                2487,
                2488,
                2489,
                2490,
                2494,
                2496,
                2500,
                2501,
                2507,
                2508,
                2510,
                2511,
                2513,
                2516,
                2518,
                2524,
                2535,
                2536,
                2538,
                2539,
                2540,
                2542,
                2543,
                2544,
                2548,
                2549,
                2551,
                2553,
                2556,
                2558,
                2563,
                2565,
                2577,
                2578,
                2581,
                2590,
                2591,
                2593,
                2594,
                2596,
                2600,
                2602,
                2605,
                2612,
                2618,
                2620,
                2625,
                2626,
                2628,
                2629,
                2630,
                2634,
                2635,
                2636,
                2637,
                2638,
                2640,
                2641,
                2643,
                2644,
                2645,
                2648,
                2652,
                2654,
                2656,
                2657,
                2659,
                2661,
                2663,
                2664,
                2670,
                2671,
                2672,
                2677,
                2679,
                2680,
                2683,
                2685,
                2687,
                2697,
                2698,
                2702,
                2703,
                2709,
                2711,
                2713,
                2715,
                2718,
                2719,
                2721,
                2722,
                2732,
                2733,
                2735,
                2738,
                2742,
                2743,
                2749,
                2752,
                2754,
                2755,
                2763,
                2764,
                2767,
                2769,
                2772,
                2775,
                2780,
                2792,
                2794,
                2800,
                2801,
                2802,
                2803,
                2807,
                2809,
                2810,
                2811,
                2815,
                2945,
                2948,
                2949,
                2951,
                2952
            ],
            "children": [
                {
                    "label": "document_retrieval",
                    "description": "This cluster focuses on tasks related to retrieving documents from a collection based on user queries, including techniques for document ranking and relevance assessment.",
                    "level": 2,
                    "example_papers": [
                        [
                            14,
                            "Fine-Tuning or Retrieval? Comparing Knowledge Injection in LLMs"
                        ],
                        [
                            24,
                            "Consolidating Ranking and Relevance Predictions of Large Language Models through Post-Processing"
                        ],
                        [
                            27,
                            "Clustering and Ranking: Diversity-preserved Instruction Selection through Expert-aligned Quality Estimation"
                        ],
                        [
                            35,
                            "Evaluating Readability and Faithfulness of Concept-based Explanations"
                        ],
                        [
                            44,
                            "DyVo: Dynamic Vocabularies for Learned Sparse Retrieval with Entities"
                        ],
                        [
                            46,
                            "LongEmbed: Extending Embedding Models for Long Context Retrieval"
                        ],
                        [
                            48,
                            "Overcome Noise and Bias: Segmentation-Aided Multi-Granularity Denoising and Debiasing for Enhanced Quarduples Extraction in Dialogue"
                        ],
                        [
                            57,
                            "BlendFilter: Advancing Retrieval-Augmented Large Language Models via Query Generation Blending and Knowledge Filtering"
                        ],
                        [
                            60,
                            "Bridging Cultures in the Kitchen: A Framework and Benchmark for Cross-Cultural Recipe Retrieval"
                        ],
                        [
                            65,
                            "AMR-Evol: Adaptive Modular Response Evolution Elicits Better Knowledge Distillation for Large Language Models in Code Generation"
                        ]
                    ],
                    "paper_ids": [
                        14,
                        24,
                        27,
                        35,
                        44,
                        46,
                        48,
                        57,
                        60,
                        65,
                        70,
                        79,
                        82,
                        95,
                        120,
                        122,
                        134,
                        138,
                        163,
                        170,
                        177,
                        198,
                        249,
                        269,
                        308,
                        311,
                        313,
                        320,
                        321,
                        332,
                        335,
                        337,
                        347,
                        349,
                        351,
                        352,
                        358,
                        364,
                        372,
                        388,
                        405,
                        408,
                        416,
                        418,
                        426,
                        430,
                        462,
                        472,
                        489,
                        490,
                        494,
                        496,
                        501,
                        504,
                        506,
                        521,
                        526,
                        529,
                        533,
                        540,
                        551,
                        556,
                        575,
                        609,
                        615,
                        635,
                        637,
                        647,
                        658,
                        684,
                        687,
                        705,
                        709,
                        714,
                        716,
                        718,
                        725,
                        726,
                        735,
                        745,
                        746,
                        750,
                        754,
                        761,
                        764,
                        772,
                        774,
                        777,
                        780,
                        782,
                        783,
                        812,
                        827,
                        839,
                        844,
                        862,
                        896,
                        901,
                        906,
                        923,
                        925,
                        942,
                        947,
                        948,
                        968,
                        978,
                        992,
                        1012,
                        1014,
                        1026,
                        1036,
                        1039,
                        1053,
                        1055,
                        1064,
                        1070,
                        1073,
                        1080,
                        1088,
                        1100,
                        1108,
                        1139,
                        1161,
                        1174,
                        1184,
                        1193,
                        1198,
                        1204,
                        1215,
                        1219,
                        1238,
                        1240,
                        1241,
                        1277,
                        1289,
                        1310,
                        1321,
                        1326,
                        1328,
                        1330,
                        1332,
                        1336,
                        1342,
                        1345,
                        1357,
                        1361,
                        1362,
                        1365,
                        1369,
                        1385,
                        1392,
                        1393,
                        1397,
                        1398,
                        1401,
                        1406,
                        1419,
                        1422,
                        1424,
                        1425,
                        1427,
                        1428,
                        1432,
                        1452,
                        1464,
                        1481,
                        1487,
                        1494,
                        1496,
                        1497,
                        1500,
                        1508,
                        1509,
                        1517,
                        1540,
                        1550,
                        1555,
                        1579,
                        1584,
                        1589,
                        1596,
                        1602,
                        1603,
                        1607,
                        1618,
                        1625,
                        1636,
                        1683,
                        1694,
                        1710,
                        1720,
                        1725,
                        1727,
                        1772,
                        1791,
                        1823,
                        1829,
                        1838,
                        1848,
                        1863,
                        1874,
                        1893,
                        1895,
                        1903,
                        1904,
                        1905,
                        1909,
                        1935,
                        1942,
                        1962,
                        1963,
                        1968,
                        1971,
                        1973,
                        1976,
                        2005,
                        2007,
                        2039,
                        2041,
                        2053,
                        2055,
                        2058,
                        2068,
                        2074,
                        2083,
                        2113,
                        2124,
                        2134,
                        2153,
                        2160,
                        2166,
                        2176,
                        2178,
                        2186,
                        2203,
                        2204,
                        2207,
                        2215,
                        2216,
                        2224,
                        2236,
                        2237,
                        2240,
                        2251,
                        2253,
                        2257,
                        2277,
                        2281,
                        2290,
                        2313,
                        2317,
                        2352,
                        2361,
                        2373,
                        2376,
                        2386,
                        2420,
                        2430,
                        2434,
                        2445,
                        2452,
                        2473,
                        2486,
                        2489,
                        2535,
                        2543,
                        2548,
                        2565,
                        2578,
                        2581,
                        2593,
                        2618,
                        2625,
                        2626,
                        2629,
                        2630,
                        2634,
                        2635,
                        2636,
                        2637,
                        2656,
                        2663,
                        2672,
                        2677,
                        2683,
                        2697,
                        2702,
                        2703,
                        2711,
                        2719,
                        2722,
                        2735,
                        2767,
                        2792,
                        2800,
                        2809,
                        2811
                    ],
                    "children": [
                        {
                            "label": "document_ranking",
                            "description": "This subtopic focuses on techniques and algorithms for ranking documents based on their relevance to user queries, ensuring that the most pertinent documents are presented first.",
                            "level": 3,
                            "example_papers": [
                                [
                                    24,
                                    "Consolidating Ranking and Relevance Predictions of Large Language Models through Post-Processing"
                                ],
                                [
                                    44,
                                    "DyVo: Dynamic Vocabularies for Learned Sparse Retrieval with Entities"
                                ],
                                [
                                    46,
                                    "LongEmbed: Extending Embedding Models for Long Context Retrieval"
                                ],
                                [
                                    249,
                                    "PromptReps: Prompting Large Language Models to Generate Dense and Sparse Representations for Zero-Shot Document Retrieval"
                                ],
                                [
                                    358,
                                    "Focused Large Language Models are Stable Many-Shot Learners"
                                ],
                                [
                                    388,
                                    "Efficient LLM Comparative Assessment: A Product of Experts Framework for Pairwise Comparisons"
                                ],
                                [
                                    430,
                                    "GENRA: Enhancing Zero-shot Retrieval with Rank Aggregation"
                                ],
                                [
                                    489,
                                    "AGRaME: Any-Granularity Ranking with Multi-Vector Embeddings"
                                ],
                                [
                                    490,
                                    "FIRST: Faster Improved Listwise Reranking with Single Token Decoding"
                                ],
                                [
                                    533,
                                    "Ranking Manipulation for Conversational Search Engines"
                                ]
                            ],
                            "paper_ids": [
                                24,
                                44,
                                46,
                                249,
                                358,
                                388,
                                430,
                                489,
                                490,
                                533,
                                615,
                                658,
                                687,
                                1036,
                                1100,
                                1241,
                                1277,
                                1336,
                                1365,
                                1385,
                                1406,
                                1422,
                                1497,
                                1596,
                                1720,
                                2005,
                                2153,
                                2166,
                                2203,
                                2207,
                                2445,
                                2593,
                                2630,
                                2635,
                                2811
                            ]
                        },
                        {
                            "label": "relevance_assessment",
                            "description": "This subtopic involves evaluating the relevance of retrieved documents to user queries, utilizing various metrics and methodologies to assess how well documents meet user needs.",
                            "level": 3,
                            "example_papers": [
                                [
                                    24,
                                    "Consolidating Ranking and Relevance Predictions of Large Language Models through Post-Processing"
                                ],
                                [
                                    120,
                                    "GLaPE: Gold Label-agnostic Prompt Evaluation for Large Language Models"
                                ],
                                [
                                    320,
                                    "REAR: A Relevance-Aware Retrieval-Augmented Framework for Open-Domain Question Answering"
                                ],
                                [
                                    321,
                                    "Leave No Document Behind: Benchmarking Long-Context LLMs with Extended Multi-Doc QA"
                                ],
                                [
                                    335,
                                    "MTA4DPR: Multi-Teaching-Assistants Based Iterative Knowledge Distillation for Dense Passage Retrieval"
                                ],
                                [
                                    349,
                                    "SciPrompt: Knowledge-augmented Prompting for Fine-grained Categorization of Scientific Topics"
                                ],
                                [
                                    352,
                                    "Do You Know What You Are Talking About? Characterizing Query-Knowledge Relevance For Reliable Retrieval Augmented Generation"
                                ],
                                [
                                    358,
                                    "Focused Large Language Models are Stable Many-Shot Learners"
                                ],
                                [
                                    388,
                                    "Efficient LLM Comparative Assessment: A Product of Experts Framework for Pairwise Comparisons"
                                ],
                                [
                                    426,
                                    "Is LLM-as-a-Judge Robust? Investigating Universal Adversarial Attacks on Zero-shot LLM Assessment"
                                ]
                            ],
                            "paper_ids": [
                                24,
                                120,
                                320,
                                321,
                                335,
                                349,
                                352,
                                358,
                                388,
                                426,
                                430,
                                521,
                                556,
                                615,
                                647,
                                705,
                                839,
                                947,
                                948,
                                978,
                                1036,
                                1088,
                                1100,
                                1204,
                                1215,
                                1238,
                                1241,
                                1277,
                                1336,
                                1362,
                                1406,
                                1428,
                                1496,
                                1838,
                                2153,
                                2160,
                                2176,
                                2386,
                                2420,
                                2543,
                                2593,
                                2625,
                                2630,
                                2719,
                                2767,
                                2792
                            ]
                        },
                        {
                            "label": "dense_retrieval",
                            "description": "This subtopic explores methods for retrieving documents using dense representations, leveraging advanced embedding techniques to improve retrieval effectiveness.",
                            "level": 3,
                            "example_papers": [
                                [
                                    44,
                                    "DyVo: Dynamic Vocabularies for Learned Sparse Retrieval with Entities"
                                ],
                                [
                                    46,
                                    "LongEmbed: Extending Embedding Models for Long Context Retrieval"
                                ],
                                [
                                    48,
                                    "Overcome Noise and Bias: Segmentation-Aided Multi-Granularity Denoising and Debiasing for Enhanced Quarduples Extraction in Dialogue"
                                ],
                                [
                                    70,
                                    "ChatRetriever: Adapting Large Language Models for Generalized and Robust Conversational Dense Retrieval"
                                ],
                                [
                                    79,
                                    "Large Language Models as Foundations for Next-Gen Dense Retrieval: A Comprehensive Empirical Assessment"
                                ],
                                [
                                    120,
                                    "GLaPE: Gold Label-agnostic Prompt Evaluation for Large Language Models"
                                ],
                                [
                                    249,
                                    "PromptReps: Prompting Large Language Models to Generate Dense and Sparse Representations for Zero-Shot Document Retrieval"
                                ],
                                [
                                    313,
                                    "LogicST: A Logical Self-Training Framework for Document-Level Relation Extraction with Incomplete Annotations"
                                ],
                                [
                                    321,
                                    "Leave No Document Behind: Benchmarking Long-Context LLMs with Extended Multi-Doc QA"
                                ],
                                [
                                    332,
                                    "Teaching Small Language Models Reasoning through Counterfactual Distillation"
                                ]
                            ],
                            "paper_ids": [
                                44,
                                46,
                                48,
                                70,
                                79,
                                120,
                                249,
                                313,
                                321,
                                332,
                                335,
                                337,
                                349,
                                358,
                                372,
                                388,
                                405,
                                408,
                                418,
                                430,
                                489,
                                490,
                                496,
                                501,
                                521,
                                540,
                                575,
                                615,
                                635,
                                637,
                                658,
                                687,
                                705,
                                735,
                                754,
                                774,
                                780,
                                827,
                                839,
                                844,
                                896,
                                906,
                                925,
                                947,
                                978,
                                1012,
                                1014,
                                1026,
                                1036,
                                1055,
                                1064,
                                1073,
                                1100,
                                1240,
                                1241,
                                1277,
                                1328,
                                1342,
                                1345,
                                1357,
                                1369,
                                1419,
                                1422,
                                1428,
                                1464,
                                1509,
                                1584,
                                1596,
                                1602,
                                1603,
                                1636,
                                1683,
                                1694,
                                1720,
                                1772,
                                1823,
                                1829,
                                1838,
                                1863,
                                1874,
                                1903,
                                1963,
                                2055,
                                2058,
                                2113,
                                2153,
                                2160,
                                2166,
                                2215,
                                2216,
                                2224,
                                2236,
                                2237,
                                2251,
                                2253,
                                2257,
                                2281,
                                2290,
                                2373,
                                2420,
                                2452,
                                2486,
                                2489,
                                2535,
                                2543,
                                2581,
                                2593,
                                2618,
                                2625,
                                2629,
                                2630,
                                2634,
                                2635,
                                2656,
                                2672,
                                2677,
                                2719,
                                2792,
                                2811
                            ]
                        },
                        {
                            "label": "query_rewriting",
                            "description": "This subtopic deals with transforming user queries into more effective forms to enhance the retrieval of relevant documents, often involving synonym expansion and query optimization.",
                            "level": 3,
                            "example_papers": [
                                [
                                    134,
                                    "CHIQ: Contextual History Enhancement for Improving Query Rewriting in Conversational Search"
                                ],
                                [
                                    745,
                                    "Adaptive Query Rewriting: Aligning Rewriters through Marginal Probability of Conversational Answers"
                                ],
                                [
                                    1427,
                                    "RAC: Retrieval-augmented Conversation Dataset for Open-domain Question Answering in Conversational Settings"
                                ],
                                [
                                    1550,
                                    "Chain-of-Rewrite: Aligning Question and Documents for Open-Domain Question Answering"
                                ],
                                [
                                    1720,
                                    "Disentangling Questions from Query Generation for Task-Adaptive Retrieval"
                                ]
                            ],
                            "paper_ids": [
                                134,
                                745,
                                1427,
                                1550,
                                1720
                            ]
                        },
                        {
                            "label": "retrieval_augmentation",
                            "description": "This subtopic focuses on enhancing document retrieval processes by integrating additional information or techniques, such as using external knowledge sources to improve retrieval outcomes.",
                            "level": 3,
                            "example_papers": [
                                [
                                    14,
                                    "Fine-Tuning or Retrieval? Comparing Knowledge Injection in LLMs"
                                ],
                                [
                                    44,
                                    "DyVo: Dynamic Vocabularies for Learned Sparse Retrieval with Entities"
                                ],
                                [
                                    57,
                                    "BlendFilter: Advancing Retrieval-Augmented Large Language Models via Query Generation Blending and Knowledge Filtering"
                                ],
                                [
                                    82,
                                    "DecorateLM: Data Engineering through Corpus Rating, Tagging, and Editing with Language Models"
                                ],
                                [
                                    95,
                                    "Glue pizza and eat rocks - Exploiting Vulnerabilities in Retrieval-Augmented Generative Models"
                                ],
                                [
                                    177,
                                    "SEER: Self-Aligned Evidence Extraction for Retrieval-Augmented Generation"
                                ],
                                [
                                    198,
                                    "EfficientRAG: Efficient Retriever for Multi-Hop Question Answering"
                                ],
                                [
                                    269,
                                    "Retrieve-Plan-Generation: An Iterative Planning and Answering Framework for Knowledge-Intensive LLM Generation"
                                ],
                                [
                                    311,
                                    "Investigating LLMs as Voting Assistants via Contextual Augmentation: A Case Study on the European Parliament Elections 2024"
                                ],
                                [
                                    320,
                                    "REAR: A Relevance-Aware Retrieval-Augmented Framework for Open-Domain Question Answering"
                                ]
                            ],
                            "paper_ids": [
                                14,
                                44,
                                57,
                                82,
                                95,
                                177,
                                198,
                                269,
                                311,
                                320,
                                352,
                                358,
                                364,
                                405,
                                416,
                                489,
                                501,
                                504,
                                506,
                                526,
                                609,
                                615,
                                647,
                                684,
                                726,
                                750,
                                761,
                                812,
                                844,
                                901,
                                942,
                                968,
                                992,
                                1055,
                                1070,
                                1080,
                                1088,
                                1108,
                                1161,
                                1198,
                                1204,
                                1277,
                                1289,
                                1310,
                                1321,
                                1326,
                                1328,
                                1330,
                                1332,
                                1342,
                                1385,
                                1393,
                                1401,
                                1419,
                                1424,
                                1425,
                                1427,
                                1428,
                                1432,
                                1452,
                                1487,
                                1496,
                                1508,
                                1517,
                                1550,
                                1579,
                                1589,
                                1596,
                                1683,
                                1720,
                                1725,
                                1727,
                                1823,
                                1874,
                                1895,
                                1905,
                                1942,
                                1963,
                                1973,
                                2007,
                                2039,
                                2053,
                                2068,
                                2074,
                                2113,
                                2124,
                                2176,
                                2178,
                                2207,
                                2237,
                                2240,
                                2253,
                                2277,
                                2281,
                                2290,
                                2313,
                                2352,
                                2373,
                                2445,
                                2473,
                                2548,
                                2581,
                                2635,
                                2656,
                                2677,
                                2719,
                                2735,
                                2792,
                                2800
                            ]
                        },
                        {
                            "label": "cross_cultural_document_retrieval",
                            "description": "This subtopic examines the methodologies and challenges involved in retrieving documents that are relevant across different cultural contexts, focusing on the nuances of language and cultural references.",
                            "level": 3,
                            "example_papers": [
                                [
                                    60,
                                    "Bridging Cultures in the Kitchen: A Framework and Benchmark for Cross-Cultural Recipe Retrieval"
                                ],
                                [
                                    1603,
                                    "McCrolin: Multi-consistency Cross-lingual Training for Retrieval Question Answering"
                                ],
                                [
                                    1829,
                                    "Cross-lingual Contextualized Phrase Retrieval"
                                ],
                                [
                                    2672,
                                    "Tracing the Genealogies of Ideas with Sentence Embeddings"
                                ],
                                [
                                    2719,
                                    "Corpus Development Based on Conflict Structures in the Security Field and LLM Bias Verification"
                                ],
                                [
                                    2800,
                                    "BordIRlines: A Dataset for Evaluating Cross-lingual Retrieval Augmented Generation"
                                ]
                            ],
                            "paper_ids": [
                                60,
                                1603,
                                1829,
                                2672,
                                2719,
                                2800
                            ]
                        }
                    ]
                },
                {
                    "label": "query_expansion",
                    "description": "This cluster encompasses methods aimed at enhancing user queries to improve retrieval performance, including techniques for query reformulation and synonym generation.",
                    "level": 2,
                    "example_papers": [
                        [
                            57,
                            "BlendFilter: Advancing Retrieval-Augmented Large Language Models via Query Generation Blending and Knowledge Filtering"
                        ],
                        [
                            120,
                            "GLaPE: Gold Label-agnostic Prompt Evaluation for Large Language Models"
                        ],
                        [
                            134,
                            "CHIQ: Contextual History Enhancement for Improving Query Rewriting in Conversational Search"
                        ],
                        [
                            494,
                            "Revisiting Who's Harry Potter: Towards Targeted Unlearning from a Causal Intervention Perspective"
                        ],
                        [
                            647,
                            "Red Teaming Language Models for Processing Contradictory Dialogues"
                        ],
                        [
                            745,
                            "Adaptive Query Rewriting: Aligning Rewriters through Marginal Probability of Conversational Answers"
                        ],
                        [
                            921,
                            "Multi-Level Information Retrieval Augmented Generation for Knowledge-based Visual Question Answering"
                        ],
                        [
                            1055,
                            "Link, Synthesize, Retrieve: Universal Document Linking for Zero-Shot Information Retrieval"
                        ],
                        [
                            1070,
                            "SynthesizRR: Generating Diverse Datasets with Retrieval Augmentation"
                        ],
                        [
                            1139,
                            "You Make me Feel like a Natural Question: Training QA Systems on Transformed Trivia Questions"
                        ]
                    ],
                    "paper_ids": [
                        57,
                        120,
                        134,
                        494,
                        647,
                        745,
                        921,
                        1055,
                        1070,
                        1139,
                        1193,
                        1215,
                        1397,
                        1401,
                        1406,
                        1419,
                        1424,
                        1427,
                        1428,
                        1495,
                        1549,
                        1955,
                        1973,
                        2565,
                        2677,
                        2735
                    ]
                },
                {
                    "label": "multimodal_information_retrieval",
                    "description": "This cluster involves retrieving information from multiple modalities, such as text, images, and audio, to provide comprehensive responses to user queries.",
                    "level": 2,
                    "example_papers": [
                        [
                            5,
                            "ImageInWords: Unlocking Hyper-Detailed Image Descriptions"
                        ],
                        [
                            43,
                            "GeoGPT4V: Towards Geometric Multi-modal Large Language Models with Geometric Image Generation"
                        ],
                        [
                            60,
                            "Bridging Cultures in the Kitchen: A Framework and Benchmark for Cross-Cultural Recipe Retrieval"
                        ],
                        [
                            66,
                            "EFUF: Efficient Fine-Grained Unlearning Framework for Mitigating Hallucinations in Multimodal Large Language Models"
                        ],
                        [
                            74,
                            "Pre-trained Language Models Do Not Help Auto-regressive Text-to-Image Generation"
                        ],
                        [
                            88,
                            "UniFashion: A Unified Vision-Language Model for Multimodal Fashion Retrieval and Generation"
                        ],
                        [
                            105,
                            "TopViewRS: Vision-Language Models as Top-View Spatial Reasoners"
                        ],
                        [
                            111,
                            "TinyChart: Efficient Chart Understanding with Program-of-Thoughts Learning and Visual Token Merging"
                        ],
                        [
                            113,
                            "Enhancing Advanced Visual Reasoning Ability of Large Language Models"
                        ],
                        [
                            119,
                            "Tag-grounded Visual Instruction Tuning with Retrieval Augmentation"
                        ]
                    ],
                    "paper_ids": [
                        5,
                        43,
                        60,
                        66,
                        74,
                        88,
                        105,
                        111,
                        113,
                        119,
                        123,
                        126,
                        143,
                        160,
                        166,
                        169,
                        197,
                        236,
                        251,
                        253,
                        264,
                        286,
                        290,
                        304,
                        311,
                        334,
                        350,
                        360,
                        366,
                        368,
                        372,
                        384,
                        386,
                        390,
                        407,
                        417,
                        433,
                        449,
                        450,
                        453,
                        454,
                        459,
                        487,
                        494,
                        500,
                        504,
                        521,
                        527,
                        532,
                        555,
                        557,
                        594,
                        612,
                        632,
                        639,
                        647,
                        667,
                        689,
                        734,
                        777,
                        789,
                        792,
                        796,
                        797,
                        803,
                        806,
                        809,
                        820,
                        822,
                        832,
                        860,
                        863,
                        866,
                        880,
                        892,
                        894,
                        897,
                        921,
                        942,
                        944,
                        946,
                        956,
                        971,
                        980,
                        988,
                        992,
                        997,
                        1027,
                        1041,
                        1055,
                        1061,
                        1069,
                        1070,
                        1071,
                        1085,
                        1091,
                        1132,
                        1148,
                        1152,
                        1153,
                        1157,
                        1162,
                        1166,
                        1170,
                        1178,
                        1185,
                        1186,
                        1190,
                        1215,
                        1246,
                        1249,
                        1256,
                        1267,
                        1269,
                        1289,
                        1295,
                        1310,
                        1317,
                        1320,
                        1332,
                        1360,
                        1394,
                        1401,
                        1406,
                        1408,
                        1417,
                        1419,
                        1424,
                        1427,
                        1445,
                        1460,
                        1464,
                        1490,
                        1508,
                        1519,
                        1521,
                        1527,
                        1529,
                        1534,
                        1548,
                        1576,
                        1586,
                        1589,
                        1597,
                        1616,
                        1637,
                        1638,
                        1648,
                        1653,
                        1667,
                        1696,
                        1714,
                        1734,
                        1772,
                        1788,
                        1801,
                        1812,
                        1820,
                        1822,
                        1827,
                        1873,
                        1894,
                        1903,
                        1911,
                        1914,
                        1921,
                        1929,
                        1931,
                        1939,
                        1947,
                        1952,
                        1954,
                        1962,
                        1975,
                        1983,
                        2004,
                        2021,
                        2029,
                        2045,
                        2049,
                        2072,
                        2083,
                        2087,
                        2095,
                        2113,
                        2115,
                        2148,
                        2204,
                        2209,
                        2216,
                        2222,
                        2226,
                        2232,
                        2251,
                        2273,
                        2283,
                        2350,
                        2361,
                        2369,
                        2376,
                        2380,
                        2419,
                        2436,
                        2473,
                        2511,
                        2516,
                        2518,
                        2536,
                        2544,
                        2565,
                        2591,
                        2600,
                        2618,
                        2620,
                        2626,
                        2634,
                        2635,
                        2677,
                        2713,
                        2735,
                        2755,
                        2769,
                        2792,
                        2800,
                        2803,
                        2810
                    ],
                    "children": [
                        {
                            "label": "multimodal_retrieval",
                            "description": "This cluster focuses on techniques and methodologies for retrieving information from multiple modalities, including text, images, and audio, to enhance the quality and relevance of search results.",
                            "level": 3,
                            "example_papers": [
                                [
                                    5,
                                    "ImageInWords: Unlocking Hyper-Detailed Image Descriptions"
                                ],
                                [
                                    43,
                                    "GeoGPT4V: Towards Geometric Multi-modal Large Language Models with Geometric Image Generation"
                                ],
                                [
                                    60,
                                    "Bridging Cultures in the Kitchen: A Framework and Benchmark for Cross-Cultural Recipe Retrieval"
                                ],
                                [
                                    66,
                                    "EFUF: Efficient Fine-Grained Unlearning Framework for Mitigating Hallucinations in Multimodal Large Language Models"
                                ],
                                [
                                    74,
                                    "Pre-trained Language Models Do Not Help Auto-regressive Text-to-Image Generation"
                                ],
                                [
                                    88,
                                    "UniFashion: A Unified Vision-Language Model for Multimodal Fashion Retrieval and Generation"
                                ],
                                [
                                    105,
                                    "TopViewRS: Vision-Language Models as Top-View Spatial Reasoners"
                                ],
                                [
                                    111,
                                    "TinyChart: Efficient Chart Understanding with Program-of-Thoughts Learning and Visual Token Merging"
                                ],
                                [
                                    113,
                                    "Enhancing Advanced Visual Reasoning Ability of Large Language Models"
                                ],
                                [
                                    119,
                                    "Tag-grounded Visual Instruction Tuning with Retrieval Augmentation"
                                ]
                            ],
                            "paper_ids": [
                                5,
                                43,
                                60,
                                66,
                                74,
                                88,
                                105,
                                111,
                                113,
                                119,
                                123,
                                143,
                                160,
                                166,
                                197,
                                236,
                                251,
                                253,
                                264,
                                286,
                                304,
                                311,
                                334,
                                350,
                                360,
                                366,
                                368,
                                372,
                                384,
                                386,
                                390,
                                407,
                                417,
                                433,
                                449,
                                450,
                                453,
                                459,
                                487,
                                494,
                                500,
                                504,
                                521,
                                527,
                                532,
                                555,
                                557,
                                594,
                                612,
                                647,
                                667,
                                689,
                                777,
                                789,
                                792,
                                797,
                                803,
                                806,
                                809,
                                820,
                                822,
                                832,
                                860,
                                863,
                                866,
                                880,
                                892,
                                894,
                                897,
                                921,
                                942,
                                946,
                                956,
                                971,
                                980,
                                988,
                                992,
                                997,
                                1027,
                                1041,
                                1055,
                                1061,
                                1069,
                                1070,
                                1071,
                                1085,
                                1091,
                                1132,
                                1152,
                                1153,
                                1157,
                                1162,
                                1166,
                                1170,
                                1185,
                                1186,
                                1190,
                                1215,
                                1246,
                                1249,
                                1256,
                                1267,
                                1269,
                                1289,
                                1295,
                                1310,
                                1317,
                                1320,
                                1332,
                                1360,
                                1394,
                                1401,
                                1406,
                                1408,
                                1417,
                                1419,
                                1424,
                                1427,
                                1460,
                                1464,
                                1490,
                                1508,
                                1519,
                                1521,
                                1527,
                                1529,
                                1534,
                                1576,
                                1589,
                                1597,
                                1616,
                                1638,
                                1667,
                                1696,
                                1714,
                                1734,
                                1788,
                                1801,
                                1812,
                                1820,
                                1827,
                                1873,
                                1903,
                                1911,
                                1914,
                                1947,
                                1952,
                                1954,
                                1975,
                                1983,
                                2004,
                                2029,
                                2045,
                                2049,
                                2072,
                                2083,
                                2087,
                                2095,
                                2113,
                                2115,
                                2148,
                                2204,
                                2209,
                                2216,
                                2222,
                                2226,
                                2232,
                                2273,
                                2283,
                                2350,
                                2369,
                                2376,
                                2380,
                                2419,
                                2473,
                                2511,
                                2516,
                                2518,
                                2536,
                                2544,
                                2565,
                                2591,
                                2600,
                                2618,
                                2620,
                                2626,
                                2634,
                                2635,
                                2677,
                                2713,
                                2735,
                                2755,
                                2769,
                                2800,
                                2803,
                                2810
                            ]
                        },
                        {
                            "label": "visual_language_models",
                            "description": "This cluster encompasses models that integrate visual and linguistic information to improve understanding and generation tasks across multimodal datasets.",
                            "level": 3,
                            "example_papers": [
                                [
                                    5,
                                    "ImageInWords: Unlocking Hyper-Detailed Image Descriptions"
                                ],
                                [
                                    43,
                                    "GeoGPT4V: Towards Geometric Multi-modal Large Language Models with Geometric Image Generation"
                                ],
                                [
                                    66,
                                    "EFUF: Efficient Fine-Grained Unlearning Framework for Mitigating Hallucinations in Multimodal Large Language Models"
                                ],
                                [
                                    88,
                                    "UniFashion: A Unified Vision-Language Model for Multimodal Fashion Retrieval and Generation"
                                ],
                                [
                                    111,
                                    "TinyChart: Efficient Chart Understanding with Program-of-Thoughts Learning and Visual Token Merging"
                                ],
                                [
                                    113,
                                    "Enhancing Advanced Visual Reasoning Ability of Large Language Models"
                                ],
                                [
                                    123,
                                    "Towards Difficulty-Agnostic Efficient Transfer Learning for Vision-Language Models"
                                ],
                                [
                                    143,
                                    "Can visual language models resolve textual ambiguity with visual cues? Let visual puns tell you!"
                                ],
                                [
                                    166,
                                    "With Ears to See and Eyes to Hear: Sound Symbolism Experiments with Multimodal Large Language Models"
                                ],
                                [
                                    253,
                                    "VIMI: Grounding Video Generation through Multi-modal Instruction"
                                ]
                            ],
                            "paper_ids": [
                                5,
                                43,
                                66,
                                88,
                                111,
                                113,
                                123,
                                143,
                                166,
                                253,
                                264,
                                290,
                                350,
                                384,
                                386,
                                417,
                                433,
                                453,
                                454,
                                555,
                                557,
                                632,
                                792,
                                796,
                                809,
                                832,
                                894,
                                897,
                                946,
                                956,
                                997,
                                1061,
                                1071,
                                1091,
                                1190,
                                1246,
                                1269,
                                1460,
                                1490,
                                1529,
                                1548,
                                1637,
                                1667,
                                1714,
                                1801,
                                1812,
                                1931,
                                1939,
                                1947,
                                1952,
                                2021,
                                2029,
                                2045,
                                2072,
                                2087,
                                2115,
                                2251,
                                2273,
                                2283,
                                2361,
                                2380,
                                2419,
                                2436,
                                2516,
                                2518
                            ]
                        },
                        {
                            "label": "video_retrieval",
                            "description": "This cluster specializes in retrieving relevant video content based on user queries, leveraging both visual and audio features to enhance search accuracy.",
                            "level": 3,
                            "example_papers": [
                                [
                                    126,
                                    "VideoScore: Building Automatic Metrics to Simulate Fine-grained Human Feedback for Video Generation"
                                ],
                                [
                                    253,
                                    "VIMI: Grounding Video Generation through Multi-modal Instruction"
                                ],
                                [
                                    453,
                                    "Efficient Vision-Language pre-training via domain-specific learning for human activities"
                                ],
                                [
                                    555,
                                    "Efficient Temporal Extrapolation of Multimodal Large Language Models with Temporal Grounding Bridge"
                                ],
                                [
                                    797,
                                    "ECIS-VQG: Generation of Entity-centric Information-seeking Questions from Videos"
                                ],
                                [
                                    897,
                                    "VideoCLIP-XL: Advancing Long Description Understanding for Video CLIP Models"
                                ],
                                [
                                    1085,
                                    "Video-Text Prompting for Weakly Supervised Spatio-Temporal Video Grounding"
                                ],
                                [
                                    1190,
                                    "Show and Guide: Instructional-Plan Grounded Vision and Language Model"
                                ],
                                [
                                    1360,
                                    "MERLIN: Multimodal Embedding Refinement via LLM-based Iterative Navigation for Text-Video Retrieval-Rerank Pipeline"
                                ],
                                [
                                    2380,
                                    "Grounding Partially-Defined Events in Multimodal Data"
                                ]
                            ],
                            "paper_ids": [
                                126,
                                253,
                                453,
                                555,
                                797,
                                897,
                                1085,
                                1190,
                                1360,
                                2380
                            ]
                        },
                        {
                            "label": "image_captioning",
                            "description": "This cluster involves generating descriptive captions for images by combining visual analysis with natural language processing techniques.",
                            "level": 3,
                            "example_papers": [
                                [
                                    5,
                                    "ImageInWords: Unlocking Hyper-Detailed Image Descriptions"
                                ],
                                [
                                    1152,
                                    "IFCap: Image-like Retrieval and Frequency-based Entity Filtering for Zero-shot Captioning"
                                ],
                                [
                                    1490,
                                    "Preserving Pre-trained Representation Space: On Effectiveness of Prefix-tuning for Large Multi-modal Models"
                                ],
                                [
                                    1653,
                                    "TROPE: TRaining-Free Object-Part Enhancement for Seamlessly Improving Fine-Grained Zero-Shot Image Captioning"
                                ],
                                [
                                    1822,
                                    "CapEEN: Image Captioning with Early Exits and Knowledge Distillation"
                                ]
                            ],
                            "paper_ids": [
                                5,
                                1152,
                                1490,
                                1653,
                                1822
                            ]
                        },
                        {
                            "label": "cross_modal_alignment",
                            "description": "This cluster focuses on aligning information across different modalities, ensuring that data from text, images, and audio can be effectively correlated and utilized.",
                            "level": 3,
                            "example_papers": [
                                [
                                    66,
                                    "EFUF: Efficient Fine-Grained Unlearning Framework for Mitigating Hallucinations in Multimodal Large Language Models"
                                ],
                                [
                                    286,
                                    "MaPPER: Multimodal Prior-guided Parameter Efficient Tuning for Referring Expression Comprehension"
                                ],
                                [
                                    459,
                                    "mDPO: Conditional Preference Optimization for Multimodal Large Language Models"
                                ],
                                [
                                    557,
                                    "MMoE: Enhancing Multimodal Models with Mixtures of Multimodal Interaction Experts"
                                ],
                                [
                                    667,
                                    "Multi-Level Cross-Modal Alignment for Speech Relation Extraction"
                                ],
                                [
                                    863,
                                    "FineCops-Ref: A new Dataset and Task for Fine-Grained Compositional Referring Expression Comprehension"
                                ],
                                [
                                    894,
                                    "MLLM-Protector: Ensuring MLLM's Safety without Hurting Performance"
                                ],
                                [
                                    944,
                                    "Community-Cross-Instruct: Unsupervised Instruction Generation for Aligning Large Language Models to Online Communities"
                                ],
                                [
                                    971,
                                    "Dual-oriented Disentangled Network with Counterfactual Intervention for Multimodal Intent Detection"
                                ],
                                [
                                    1091,
                                    "IntCoOp: Interpretability-Aware Vision-Language Prompt Tuning"
                                ]
                            ],
                            "paper_ids": [
                                66,
                                286,
                                459,
                                557,
                                667,
                                863,
                                894,
                                944,
                                971,
                                1091,
                                1132,
                                1152,
                                1186,
                                1190,
                                1269,
                                1527,
                                1667,
                                1772,
                                1873,
                                1894,
                                1921,
                                2072,
                                2087,
                                2113,
                                2115,
                                2222,
                                2380,
                                2755,
                                2810
                            ]
                        }
                    ]
                },
                {
                    "label": "semantic_search",
                    "description": "This cluster focuses on enhancing search capabilities by understanding the meaning behind queries and documents, utilizing techniques like semantic indexing and knowledge graphs.",
                    "level": 2,
                    "example_papers": [
                        [
                            35,
                            "Evaluating Readability and Faithfulness of Concept-based Explanations"
                        ],
                        [
                            44,
                            "DyVo: Dynamic Vocabularies for Learned Sparse Retrieval with Entities"
                        ],
                        [
                            48,
                            "Overcome Noise and Bias: Segmentation-Aided Multi-Granularity Denoising and Debiasing for Enhanced Quarduples Extraction in Dialogue"
                        ],
                        [
                            57,
                            "BlendFilter: Advancing Retrieval-Augmented Large Language Models via Query Generation Blending and Knowledge Filtering"
                        ],
                        [
                            60,
                            "Bridging Cultures in the Kitchen: A Framework and Benchmark for Cross-Cultural Recipe Retrieval"
                        ],
                        [
                            70,
                            "ChatRetriever: Adapting Large Language Models for Generalized and Robust Conversational Dense Retrieval"
                        ],
                        [
                            79,
                            "Large Language Models as Foundations for Next-Gen Dense Retrieval: A Comprehensive Empirical Assessment"
                        ],
                        [
                            80,
                            "A New Pipeline for Knowledge Graph Reasoning Enhanced by Large Language Models Without Fine-Tuning"
                        ],
                        [
                            120,
                            "GLaPE: Gold Label-agnostic Prompt Evaluation for Large Language Models"
                        ],
                        [
                            134,
                            "CHIQ: Contextual History Enhancement for Improving Query Rewriting in Conversational Search"
                        ]
                    ],
                    "paper_ids": [
                        35,
                        44,
                        48,
                        57,
                        60,
                        70,
                        79,
                        80,
                        120,
                        134,
                        160,
                        168,
                        171,
                        177,
                        198,
                        236,
                        308,
                        311,
                        320,
                        335,
                        349,
                        351,
                        352,
                        405,
                        406,
                        408,
                        430,
                        431,
                        450,
                        490,
                        494,
                        501,
                        504,
                        521,
                        527,
                        530,
                        533,
                        551,
                        575,
                        609,
                        635,
                        637,
                        647,
                        662,
                        686,
                        687,
                        691,
                        726,
                        735,
                        745,
                        746,
                        750,
                        777,
                        782,
                        803,
                        827,
                        831,
                        844,
                        895,
                        918,
                        923,
                        942,
                        947,
                        962,
                        968,
                        978,
                        992,
                        1012,
                        1022,
                        1055,
                        1064,
                        1070,
                        1088,
                        1108,
                        1139,
                        1162,
                        1170,
                        1178,
                        1215,
                        1219,
                        1229,
                        1232,
                        1241,
                        1260,
                        1267,
                        1289,
                        1308,
                        1310,
                        1320,
                        1321,
                        1330,
                        1332,
                        1336,
                        1342,
                        1345,
                        1365,
                        1369,
                        1385,
                        1392,
                        1397,
                        1401,
                        1406,
                        1408,
                        1409,
                        1419,
                        1424,
                        1427,
                        1428,
                        1432,
                        1445,
                        1464,
                        1487,
                        1494,
                        1508,
                        1509,
                        1529,
                        1550,
                        1569,
                        1579,
                        1586,
                        1589,
                        1601,
                        1602,
                        1603,
                        1607,
                        1636,
                        1655,
                        1683,
                        1694,
                        1720,
                        1727,
                        1734,
                        1764,
                        1772,
                        1829,
                        1848,
                        1882,
                        1892,
                        1895,
                        1903,
                        1904,
                        1905,
                        1914,
                        1916,
                        1921,
                        1942,
                        1962,
                        1968,
                        1970,
                        1973,
                        1981,
                        2004,
                        2033,
                        2039,
                        2041,
                        2053,
                        2055,
                        2068,
                        2083,
                        2113,
                        2124,
                        2132,
                        2134,
                        2160,
                        2178,
                        2204,
                        2207,
                        2215,
                        2216,
                        2240,
                        2251,
                        2253,
                        2277,
                        2281,
                        2283,
                        2288,
                        2290,
                        2361,
                        2376,
                        2378,
                        2420,
                        2433,
                        2445,
                        2467,
                        2480,
                        2496,
                        2510,
                        2543,
                        2548,
                        2565,
                        2618,
                        2625,
                        2626,
                        2629,
                        2630,
                        2634,
                        2635,
                        2637,
                        2672,
                        2677,
                        2713,
                        2735,
                        2772,
                        2792,
                        2794,
                        2800,
                        2802,
                        2811
                    ],
                    "children": [
                        {
                            "label": "semantic_indexing",
                            "description": "This cluster focuses on techniques and methodologies for indexing documents based on their semantic content, enhancing retrieval effectiveness by understanding the meaning behind the text.",
                            "level": 3,
                            "example_papers": [
                                [
                                    44,
                                    "DyVo: Dynamic Vocabularies for Learned Sparse Retrieval with Entities"
                                ],
                                [
                                    48,
                                    "Overcome Noise and Bias: Segmentation-Aided Multi-Granularity Denoising and Debiasing for Enhanced Quarduples Extraction in Dialogue"
                                ],
                                [
                                    57,
                                    "BlendFilter: Advancing Retrieval-Augmented Large Language Models via Query Generation Blending and Knowledge Filtering"
                                ],
                                [
                                    79,
                                    "Large Language Models as Foundations for Next-Gen Dense Retrieval: A Comprehensive Empirical Assessment"
                                ],
                                [
                                    134,
                                    "CHIQ: Contextual History Enhancement for Improving Query Rewriting in Conversational Search"
                                ],
                                [
                                    308,
                                    "Relevance Is a Guiding Light: Relevance-aware Adaptive Learning for End-to-end Task-oriented Dialogue System"
                                ],
                                [
                                    320,
                                    "REAR: A Relevance-Aware Retrieval-Augmented Framework for Open-Domain Question Answering"
                                ],
                                [
                                    335,
                                    "MTA4DPR: Multi-Teaching-Assistants Based Iterative Knowledge Distillation for Dense Passage Retrieval"
                                ],
                                [
                                    349,
                                    "SciPrompt: Knowledge-augmented Prompting for Fine-grained Categorization of Scientific Topics"
                                ],
                                [
                                    352,
                                    "Do You Know What You Are Talking About? Characterizing Query-Knowledge Relevance For Reliable Retrieval Augmented Generation"
                                ]
                            ],
                            "paper_ids": [
                                44,
                                48,
                                57,
                                79,
                                134,
                                308,
                                320,
                                335,
                                349,
                                352,
                                406,
                                450,
                                501,
                                527,
                                726,
                                745,
                                746,
                                750,
                                777,
                                782,
                                831,
                                844,
                                923,
                                968,
                                978,
                                992,
                                1055,
                                1064,
                                1088,
                                1232,
                                1241,
                                1267,
                                1289,
                                1308,
                                1310,
                                1320,
                                1332,
                                1342,
                                1365,
                                1369,
                                1406,
                                1408,
                                1419,
                                1424,
                                1445,
                                1464,
                                1487,
                                1508,
                                1529,
                                1550,
                                1586,
                                1589,
                                1602,
                                1727,
                                1734,
                                1905,
                                1916,
                                1962,
                                2033,
                                2039,
                                2055,
                                2068,
                                2083,
                                2113,
                                2124,
                                2216,
                                2240,
                                2251,
                                2253,
                                2277,
                                2281,
                                2283,
                                2376,
                                2420,
                                2445,
                                2548,
                                2565,
                                2618,
                                2626,
                                2672,
                                2677,
                                2713,
                                2792,
                                2811
                            ]
                        },
                        {
                            "label": "knowledge_graphs",
                            "description": "This cluster explores the use of knowledge graphs to improve search capabilities, enabling systems to understand relationships and context within data for more accurate retrieval.",
                            "level": 3,
                            "example_papers": [
                                [
                                    80,
                                    "A New Pipeline for Knowledge Graph Reasoning Enhanced by Large Language Models Without Fine-Tuning"
                                ],
                                [
                                    308,
                                    "Relevance Is a Guiding Light: Relevance-aware Adaptive Learning for End-to-end Task-oriented Dialogue System"
                                ],
                                [
                                    335,
                                    "MTA4DPR: Multi-Teaching-Assistants Based Iterative Knowledge Distillation for Dense Passage Retrieval"
                                ],
                                [
                                    431,
                                    "XplainLLM: A Knowledge-Augmented Dataset for Reliable Grounded Explanations in LLMs"
                                ],
                                [
                                    527,
                                    "Structure Guided Prompt: Instructing Large Language Model in Multi-Step Reasoning by Exploring Graph Structure of the Text"
                                ],
                                [
                                    746,
                                    "Grasping the Essentials: Tailoring Large Language Models for Zero-Shot Relation Extraction"
                                ],
                                [
                                    750,
                                    "Lifelong Knowledge Editing for LLMs with Retrieval-Augmented Continuous Prompt Learning"
                                ],
                                [
                                    831,
                                    "MoCoKGC: Momentum Contrast Entity Encoding for Knowledge Graph Completion"
                                ],
                                [
                                    918,
                                    "ATAP: Automatic Template-Augmented Commonsense Knowledge Graph Completion via Pre-Trained Language Models"
                                ],
                                [
                                    962,
                                    "Varying Sentence Representations via Condition-Specified Routers"
                                ]
                            ],
                            "paper_ids": [
                                80,
                                308,
                                335,
                                431,
                                527,
                                746,
                                750,
                                831,
                                918,
                                962,
                                978,
                                1022,
                                1178,
                                1232,
                                1260,
                                1267,
                                1320,
                                1342,
                                1408,
                                1409,
                                1487,
                                1529,
                                1589,
                                1655,
                                1734,
                                1892,
                                1905,
                                1921,
                                1942,
                                1970,
                                2033,
                                2039,
                                2055,
                                2113,
                                2240,
                                2253,
                                2277,
                                2290,
                                2433,
                                2548
                            ]
                        },
                        {
                            "label": "query_understanding",
                            "description": "This cluster emphasizes the interpretation and analysis of user queries to enhance search results, ensuring that the intent behind the queries is accurately captured.",
                            "level": 3,
                            "example_papers": [
                                [
                                    48,
                                    "Overcome Noise and Bias: Segmentation-Aided Multi-Granularity Denoising and Debiasing for Enhanced Quarduples Extraction in Dialogue"
                                ],
                                [
                                    57,
                                    "BlendFilter: Advancing Retrieval-Augmented Large Language Models via Query Generation Blending and Knowledge Filtering"
                                ],
                                [
                                    134,
                                    "CHIQ: Contextual History Enhancement for Improving Query Rewriting in Conversational Search"
                                ],
                                [
                                    308,
                                    "Relevance Is a Guiding Light: Relevance-aware Adaptive Learning for End-to-end Task-oriented Dialogue System"
                                ],
                                [
                                    335,
                                    "MTA4DPR: Multi-Teaching-Assistants Based Iterative Knowledge Distillation for Dense Passage Retrieval"
                                ],
                                [
                                    352,
                                    "Do You Know What You Are Talking About? Characterizing Query-Knowledge Relevance For Reliable Retrieval Augmented Generation"
                                ],
                                [
                                    745,
                                    "Adaptive Query Rewriting: Aligning Rewriters through Marginal Probability of Conversational Answers"
                                ],
                                [
                                    750,
                                    "Lifelong Knowledge Editing for LLMs with Retrieval-Augmented Continuous Prompt Learning"
                                ],
                                [
                                    782,
                                    "Where am I? Large Language Models Wandering between Semantics and Structures in Long Contexts"
                                ],
                                [
                                    803,
                                    "DC-Instruct: An Effective Framework for Generative Multi-intent Spoken Language Understanding"
                                ]
                            ],
                            "paper_ids": [
                                48,
                                57,
                                134,
                                308,
                                335,
                                352,
                                745,
                                750,
                                782,
                                803,
                                1022,
                                1139,
                                1162,
                                1215,
                                1232,
                                1336,
                                1365,
                                1397,
                                1401,
                                1424,
                                1428,
                                1487,
                                1529,
                                1569,
                                1579,
                                1586,
                                1589,
                                1602,
                                1720,
                                1892,
                                1904,
                                1916,
                                1942,
                                1970,
                                2039,
                                2068,
                                2113,
                                2207,
                                2253,
                                2277,
                                2290,
                                2376,
                                2445,
                                2548,
                                2565,
                                2713,
                                2735
                            ]
                        },
                        {
                            "label": "cross-lingual_retrieval",
                            "description": "This cluster investigates methods for retrieving information across different languages, focusing on bridging language barriers in semantic search.",
                            "level": 3,
                            "example_papers": [
                                [
                                    60,
                                    "Bridging Cultures in the Kitchen: A Framework and Benchmark for Cross-Cultural Recipe Retrieval"
                                ],
                                [
                                    308,
                                    "Relevance Is a Guiding Light: Relevance-aware Adaptive Learning for End-to-end Task-oriented Dialogue System"
                                ],
                                [
                                    735,
                                    "Language Concept Erasure for Language-invariant Dense Retrieval"
                                ],
                                [
                                    1401,
                                    "LARA: Linguistic-Adaptive Retrieval-Augmentation for Multi-Turn Intent Classification"
                                ],
                                [
                                    1487,
                                    "RAG-Studio: Towards In-Domain Adaptation of Retrieval Augmented Generation Through Self-Alignment"
                                ],
                                [
                                    1529,
                                    "EchoSight: Advancing Visual-Language Models with Wiki Knowledge"
                                ],
                                [
                                    1601,
                                    "MINERS: Multilingual Language Models as Semantic Retrievers"
                                ],
                                [
                                    1603,
                                    "McCrolin: Multi-consistency Cross-lingual Training for Retrieval Question Answering"
                                ],
                                [
                                    1772,
                                    "Instance-Level Dynamic LoRAs Composition for Cross-Task Generalization"
                                ],
                                [
                                    1829,
                                    "Cross-lingual Contextualized Phrase Retrieval"
                                ]
                            ],
                            "paper_ids": [
                                60,
                                308,
                                735,
                                1401,
                                1487,
                                1529,
                                1601,
                                1603,
                                1772,
                                1829,
                                1914,
                                1921,
                                1968,
                                2113,
                                2160,
                                2378,
                                2510,
                                2618,
                                2625,
                                2630,
                                2634,
                                2637,
                                2772,
                                2800,
                                2802
                            ]
                        },
                        {
                            "label": "semantic_textual_similarity",
                            "description": "This cluster examines techniques for measuring the similarity between texts based on their semantic meaning, facilitating more relevant search results.",
                            "level": 3,
                            "example_papers": [
                                [
                                    35,
                                    "Evaluating Readability and Faithfulness of Concept-based Explanations"
                                ],
                                [
                                    48,
                                    "Overcome Noise and Bias: Segmentation-Aided Multi-Granularity Denoising and Debiasing for Enhanced Quarduples Extraction in Dialogue"
                                ],
                                [
                                    57,
                                    "BlendFilter: Advancing Retrieval-Augmented Large Language Models via Query Generation Blending and Knowledge Filtering"
                                ],
                                [
                                    79,
                                    "Large Language Models as Foundations for Next-Gen Dense Retrieval: A Comprehensive Empirical Assessment"
                                ],
                                [
                                    80,
                                    "A New Pipeline for Knowledge Graph Reasoning Enhanced by Large Language Models Without Fine-Tuning"
                                ],
                                [
                                    120,
                                    "GLaPE: Gold Label-agnostic Prompt Evaluation for Large Language Models"
                                ],
                                [
                                    160,
                                    "MoDULA: Mixture of Domain-Specific and Universal LoRA for Multi-Task Learning"
                                ],
                                [
                                    168,
                                    "Understanding Higher-Order Correlations Among Semantic Components in Embeddings"
                                ],
                                [
                                    171,
                                    "Verification and Refinement of Natural Language Explanations through LLM-Symbolic Theorem Proving"
                                ],
                                [
                                    236,
                                    "Teaching Embodied Reinforcement Learning Agents: Informativeness and Diversity of Language Use"
                                ]
                            ],
                            "paper_ids": [
                                35,
                                48,
                                57,
                                79,
                                80,
                                120,
                                160,
                                168,
                                171,
                                236,
                                308,
                                320,
                                335,
                                351,
                                405,
                                408,
                                450,
                                494,
                                530,
                                533,
                                551,
                                575,
                                609,
                                635,
                                637,
                                647,
                                662,
                                687,
                                691,
                                735,
                                750,
                                803,
                                827,
                                844,
                                895,
                                918,
                                923,
                                942,
                                962,
                                1012,
                                1055,
                                1070,
                                1170,
                                1229,
                                1232,
                                1241,
                                1310,
                                1330,
                                1336,
                                1345,
                                1365,
                                1385,
                                1401,
                                1409,
                                1432,
                                1487,
                                1509,
                                1529,
                                1550,
                                1569,
                                1579,
                                1586,
                                1589,
                                1601,
                                1602,
                                1607,
                                1636,
                                1694,
                                1764,
                                1848,
                                1882,
                                1903,
                                1904,
                                1914,
                                1942,
                                1968,
                                1981,
                                2004,
                                2039,
                                2041,
                                2055,
                                2068,
                                2113,
                                2132,
                                2134,
                                2204,
                                2207,
                                2215,
                                2251,
                                2253,
                                2277,
                                2283,
                                2288,
                                2361,
                                2376,
                                2433,
                                2445,
                                2467,
                                2480,
                                2496,
                                2510,
                                2543,
                                2548,
                                2565,
                                2625,
                                2629,
                                2630,
                                2637,
                                2672,
                                2677,
                                2772,
                                2794,
                                2802
                            ]
                        }
                    ]
                },
                {
                    "label": "personalized_information_retrieval",
                    "description": "This cluster includes tasks that tailor information retrieval processes to individual user preferences and behaviors, improving the relevance of search results.",
                    "level": 2,
                    "example_papers": [
                        [
                            13,
                            "A Usage-centric Take on Intent Understanding in E-Commerce"
                        ],
                        [
                            60,
                            "Bridging Cultures in the Kitchen: A Framework and Benchmark for Cross-Cultural Recipe Retrieval"
                        ],
                        [
                            85,
                            "Mitigating Matthew Effect: Multi-Hypergraph Boosted Multi-Interest Self-Supervised Learning for Conversational Recommendation"
                        ],
                        [
                            280,
                            "Crafting Personalized Agents through Retrieval-Augmented Generation on Editable Memory Graphs"
                        ],
                        [
                            311,
                            "Investigating LLMs as Voting Assistants via Contextual Augmentation: A Case Study on the European Parliament Elections 2024"
                        ],
                        [
                            370,
                            "Personalized Pieces: Efficient Personalized Large Language Models through Collaborative Efforts"
                        ],
                        [
                            436,
                            "MORPHEUS: Modeling Role from Personalized Dialogue History by Exploring and Utilizing Latent Space"
                        ],
                        [
                            477,
                            "Stepwise Verification and Remediation of Student Reasoning Errors with Large Language Model Tutors"
                        ],
                        [
                            494,
                            "Revisiting Who's Harry Potter: Towards Targeted Unlearning from a Causal Intervention Perspective"
                        ],
                        [
                            504,
                            "AssistantBench: Can Web Agents Solve Realistic and Time-Consuming Tasks?"
                        ]
                    ],
                    "paper_ids": [
                        13,
                        60,
                        85,
                        280,
                        311,
                        370,
                        436,
                        477,
                        494,
                        504,
                        521,
                        580,
                        647,
                        652,
                        709,
                        777,
                        783,
                        992,
                        994,
                        1055,
                        1070,
                        1106,
                        1109,
                        1186,
                        1215,
                        1280,
                        1336,
                        1359,
                        1369,
                        1401,
                        1406,
                        1414,
                        1419,
                        1423,
                        1424,
                        1427,
                        1445,
                        1468,
                        1487,
                        1496,
                        1497,
                        1614,
                        1646,
                        1693,
                        1734,
                        1772,
                        1869,
                        1903,
                        2004,
                        2083,
                        2113,
                        2169,
                        2251,
                        2275,
                        2361,
                        2391,
                        2524,
                        2540,
                        2551,
                        2558,
                        2565,
                        2626,
                        2635,
                        2677,
                        2713,
                        2735,
                        2764,
                        2775,
                        2792
                    ],
                    "children": [
                        {
                            "label": "recommender_systems",
                            "description": "This cluster focuses on systems designed to suggest items or content to users based on their preferences and past behaviors.",
                            "level": 3,
                            "example_papers": [
                                [
                                    13,
                                    "A Usage-centric Take on Intent Understanding in E-Commerce"
                                ],
                                [
                                    85,
                                    "Mitigating Matthew Effect: Multi-Hypergraph Boosted Multi-Interest Self-Supervised Learning for Conversational Recommendation"
                                ],
                                [
                                    652,
                                    "Enhancing High-order Interaction Awareness in LLM-based Recommender Model"
                                ],
                                [
                                    777,
                                    "MAIR: A Massive Benchmark for Evaluating Instructed Retrieval"
                                ],
                                [
                                    994,
                                    "PepRec: Progressive Enhancement of Prompting for Recommendation"
                                ],
                                [
                                    1106,
                                    "Jump Starting Bandits with LLM-Generated Prior Knowledge"
                                ],
                                [
                                    1186,
                                    "I-AM-G: Interest Augmented Multimodal Generator for Item Personalization"
                                ],
                                [
                                    1336,
                                    "Centrality-aware Product Retrieval and Ranking"
                                ],
                                [
                                    1369,
                                    "Breaking the Hourglass Phenomenon of Residual Quantization: Enhancing the Upper Bound of Generative Retrieval"
                                ],
                                [
                                    1406,
                                    "DiAL : Diversity Aware Listwise Ranking for Query Auto-Complete"
                                ]
                            ],
                            "paper_ids": [
                                13,
                                85,
                                652,
                                777,
                                994,
                                1106,
                                1186,
                                1336,
                                1369,
                                1406,
                                1414,
                                1423,
                                1468,
                                1497,
                                1614,
                                1693,
                                1869,
                                2004,
                                2169,
                                2275,
                                2775
                            ]
                        },
                        {
                            "label": "user_modeling",
                            "description": "This cluster encompasses techniques for creating and updating user profiles that capture individual preferences and behaviors to enhance information retrieval.",
                            "level": 3,
                            "example_papers": [
                                [
                                    13,
                                    "A Usage-centric Take on Intent Understanding in E-Commerce"
                                ],
                                [
                                    280,
                                    "Crafting Personalized Agents through Retrieval-Augmented Generation on Editable Memory Graphs"
                                ],
                                [
                                    370,
                                    "Personalized Pieces: Efficient Personalized Large Language Models through Collaborative Efforts"
                                ],
                                [
                                    783,
                                    "KARL: Knowledge-Aware Retrieval and Representations aid Retention and Learning in Students"
                                ],
                                [
                                    1109,
                                    "Virtual Personas for Language Models via an Anthology of Backstories"
                                ],
                                [
                                    1186,
                                    "I-AM-G: Interest Augmented Multimodal Generator for Item Personalization"
                                ],
                                [
                                    1280,
                                    "Arxiv Copilot: A Self-Evolving and Efficient LLM System for Personalized Academic Assistance"
                                ],
                                [
                                    1336,
                                    "Centrality-aware Product Retrieval and Ranking"
                                ],
                                [
                                    1359,
                                    "BPID: A Benchmark for Personal Identity Deduplication"
                                ],
                                [
                                    1496,
                                    "BASES: Large-scale Web Search User Simulation with Large Language Model based Agents"
                                ]
                            ],
                            "paper_ids": [
                                13,
                                280,
                                370,
                                783,
                                1109,
                                1186,
                                1280,
                                1336,
                                1359,
                                1496,
                                2391,
                                2524,
                                2775
                            ]
                        },
                        {
                            "label": "conversational_recommendation",
                            "description": "This cluster includes tasks that involve providing personalized recommendations through conversational interfaces, enhancing user engagement and satisfaction.",
                            "level": 3,
                            "example_papers": [
                                [
                                    85,
                                    "Mitigating Matthew Effect: Multi-Hypergraph Boosted Multi-Interest Self-Supervised Learning for Conversational Recommendation"
                                ],
                                [
                                    436,
                                    "MORPHEUS: Modeling Role from Personalized Dialogue History by Exploring and Utilizing Latent Space"
                                ],
                                [
                                    580,
                                    "\"In-Dialogues We Learn\": Towards Personalized Dialogue Without Pre-defined Profiles through In-Dialogue Learning"
                                ],
                                [
                                    709,
                                    "TransferTOD: A Generalizable Chinese Multi-Domain Task-Oriented Dialogue System with Transfer Capabilities"
                                ],
                                [
                                    1401,
                                    "LARA: Linguistic-Adaptive Retrieval-Augmentation for Multi-Turn Intent Classification"
                                ],
                                [
                                    1406,
                                    "DiAL : Diversity Aware Listwise Ranking for Query Auto-Complete"
                                ],
                                [
                                    1427,
                                    "RAC: Retrieval-augmented Conversation Dataset for Open-domain Question Answering in Conversational Settings"
                                ],
                                [
                                    1646,
                                    "EDEN: Empathetic Dialogues for English Learning"
                                ],
                                [
                                    1693,
                                    "Beyond Persuasion: Towards Conversational Recommender System with Credible Explanations"
                                ],
                                [
                                    2275,
                                    "Experience as Source for Anticipation and Planning: Experiential Policy Learning for Target-driven Recommendation Dialogues"
                                ]
                            ],
                            "paper_ids": [
                                85,
                                436,
                                580,
                                709,
                                1401,
                                1406,
                                1427,
                                1646,
                                1693,
                                2275,
                                2565,
                                2775
                            ]
                        },
                        {
                            "label": "adaptive_feedback",
                            "description": "This cluster involves methods that adaptively gather user feedback to refine and improve the relevance of information retrieval systems.",
                            "level": 3,
                            "example_papers": [
                                [
                                    311,
                                    "Investigating LLMs as Voting Assistants via Contextual Augmentation: A Case Study on the European Parliament Elections 2024"
                                ],
                                [
                                    477,
                                    "Stepwise Verification and Remediation of Student Reasoning Errors with Large Language Model Tutors"
                                ],
                                [
                                    783,
                                    "KARL: Knowledge-Aware Retrieval and Representations aid Retention and Learning in Students"
                                ],
                                [
                                    1106,
                                    "Jump Starting Bandits with LLM-Generated Prior Knowledge"
                                ],
                                [
                                    1336,
                                    "Centrality-aware Product Retrieval and Ranking"
                                ],
                                [
                                    1369,
                                    "Breaking the Hourglass Phenomenon of Residual Quantization: Enhancing the Upper Bound of Generative Retrieval"
                                ],
                                [
                                    1406,
                                    "DiAL : Diversity Aware Listwise Ranking for Query Auto-Complete"
                                ],
                                [
                                    1646,
                                    "EDEN: Empathetic Dialogues for English Learning"
                                ],
                                [
                                    2524,
                                    "Leveraging a Cognitive Model to Measure Subjective Similarity of Human and GPT-4 Written Content"
                                ]
                            ],
                            "paper_ids": [
                                311,
                                477,
                                783,
                                1106,
                                1336,
                                1369,
                                1406,
                                1646,
                                2524
                            ]
                        },
                        {
                            "label": "personalized_language_models",
                            "description": "This cluster focuses on the development of language models that are tailored to individual users, improving the accuracy and relevance of generated content.",
                            "level": 3,
                            "example_papers": [
                                [
                                    60,
                                    "Bridging Cultures in the Kitchen: A Framework and Benchmark for Cross-Cultural Recipe Retrieval"
                                ],
                                [
                                    280,
                                    "Crafting Personalized Agents through Retrieval-Augmented Generation on Editable Memory Graphs"
                                ],
                                [
                                    311,
                                    "Investigating LLMs as Voting Assistants via Contextual Augmentation: A Case Study on the European Parliament Elections 2024"
                                ],
                                [
                                    370,
                                    "Personalized Pieces: Efficient Personalized Large Language Models through Collaborative Efforts"
                                ],
                                [
                                    436,
                                    "MORPHEUS: Modeling Role from Personalized Dialogue History by Exploring and Utilizing Latent Space"
                                ],
                                [
                                    477,
                                    "Stepwise Verification and Remediation of Student Reasoning Errors with Large Language Model Tutors"
                                ],
                                [
                                    494,
                                    "Revisiting Who's Harry Potter: Towards Targeted Unlearning from a Causal Intervention Perspective"
                                ],
                                [
                                    504,
                                    "AssistantBench: Can Web Agents Solve Realistic and Time-Consuming Tasks?"
                                ],
                                [
                                    521,
                                    "RuBLiMP: Russian Benchmark of Linguistic Minimal Pairs"
                                ],
                                [
                                    580,
                                    "\"In-Dialogues We Learn\": Towards Personalized Dialogue Without Pre-defined Profiles through In-Dialogue Learning"
                                ]
                            ],
                            "paper_ids": [
                                60,
                                280,
                                311,
                                370,
                                436,
                                477,
                                494,
                                504,
                                521,
                                580,
                                647,
                                709,
                                783,
                                992,
                                994,
                                1055,
                                1070,
                                1106,
                                1109,
                                1186,
                                1215,
                                1280,
                                1336,
                                1401,
                                1414,
                                1423,
                                1424,
                                1445,
                                1468,
                                1487,
                                1496,
                                1497,
                                1734,
                                1772,
                                1869,
                                1903,
                                2083,
                                2113,
                                2169,
                                2251,
                                2361,
                                2391,
                                2524,
                                2540,
                                2551,
                                2558,
                                2565,
                                2677,
                                2713,
                                2735
                            ]
                        }
                    ]
                },
                {
                    "label": "legal_information_retrieval",
                    "description": "This cluster focuses on tasks related to retrieving legal documents and information, including case law, statutes, and legal opinions based on user queries.",
                    "level": 2,
                    "example_papers": [
                        [
                            72,
                            "Learning Interpretable Legal Case Retrieval via Knowledge-Guided Case Reformulation"
                        ],
                        [
                            216,
                            "C3PA: An Open Dataset of Expert-Annotated and Regulation-Aware Privacy Policies to Enable Scalable Regulatory Compliance Audits"
                        ],
                        [
                            311,
                            "Investigating LLMs as Voting Assistants via Contextual Augmentation: A Case Study on the European Parliament Elections 2024"
                        ],
                        [
                            401,
                            "Enhancing Legal Case Retrieval via Scaling High-quality Synthetic Query-Candidate Pairs"
                        ],
                        [
                            428,
                            "More Than Catastrophic Forgetting: Integrating General Capabilities For Domain-Specific LLMs"
                        ],
                        [
                            494,
                            "Revisiting Who's Harry Potter: Towards Targeted Unlearning from a Causal Intervention Perspective"
                        ],
                        [
                            504,
                            "AssistantBench: Can Web Agents Solve Realistic and Time-Consuming Tasks?"
                        ],
                        [
                            521,
                            "RuBLiMP: Russian Benchmark of Linguistic Minimal Pairs"
                        ],
                        [
                            647,
                            "Red Teaming Language Models for Processing Contradictory Dialogues"
                        ],
                        [
                            777,
                            "MAIR: A Massive Benchmark for Evaluating Instructed Retrieval"
                        ]
                    ],
                    "paper_ids": [
                        72,
                        216,
                        311,
                        401,
                        428,
                        494,
                        504,
                        521,
                        647,
                        777,
                        843,
                        900,
                        992,
                        1055,
                        1070,
                        1215,
                        1401,
                        1419,
                        1424,
                        1640,
                        1772,
                        1879,
                        1885,
                        1891,
                        1903,
                        1995,
                        2071,
                        2083,
                        2113,
                        2138,
                        2251,
                        2302,
                        2357,
                        2361,
                        2553,
                        2565,
                        2626,
                        2638,
                        2640,
                        2641,
                        2643,
                        2644,
                        2645,
                        2648,
                        2652,
                        2654,
                        2657,
                        2659,
                        2664,
                        2670,
                        2677,
                        2719,
                        2792
                    ],
                    "children": [
                        {
                            "label": "case_law_retrieval",
                            "description": "This subtopic focuses on the retrieval of case law documents, enabling users to find relevant legal precedents based on specific queries.",
                            "level": 3,
                            "example_papers": [
                                [
                                    72,
                                    "Learning Interpretable Legal Case Retrieval via Knowledge-Guided Case Reformulation"
                                ],
                                [
                                    401,
                                    "Enhancing Legal Case Retrieval via Scaling High-quality Synthetic Query-Candidate Pairs"
                                ]
                            ],
                            "paper_ids": [
                                72,
                                401
                            ]
                        },
                        {
                            "label": "statute_retrieval",
                            "description": "This subtopic involves the retrieval of statutes and legislative texts, allowing users to access legal codes and regulations pertinent to their inquiries.",
                            "level": 3,
                            "example_papers": [
                                [
                                    2071,
                                    "STARD: A Chinese Statute Retrieval Dataset Derived from Real-life Queries by Non-professionals"
                                ]
                            ],
                            "paper_ids": [
                                2071
                            ]
                        },
                        {
                            "label": "legal_document_retrieval",
                            "description": "This subtopic encompasses the retrieval of various legal documents, including contracts, briefs, and opinions, tailored to user-defined search criteria.",
                            "level": 3,
                            "example_papers": [
                                [
                                    504,
                                    "AssistantBench: Can Web Agents Solve Realistic and Time-Consuming Tasks?"
                                ],
                                [
                                    992,
                                    "Unveiling and Consulting Core Experts in Retrieval-Augmented MoE-based LLMs"
                                ],
                                [
                                    1055,
                                    "Link, Synthesize, Retrieve: Universal Document Linking for Zero-Shot Information Retrieval"
                                ],
                                [
                                    1772,
                                    "Instance-Level Dynamic LoRAs Composition for Cross-Task Generalization"
                                ],
                                [
                                    1879,
                                    "HiCuLR: Hierarchical Curriculum Learning for Rhetorical Role Labeling of Legal Documents"
                                ],
                                [
                                    1995,
                                    "AgentsCourt: Building Judicial Decision-Making Agents with Court Debate Simulation and Legal Knowledge Augmentation"
                                ],
                                [
                                    2113,
                                    "MDCR: A Dataset for Multi-Document Conditional Reasoning"
                                ],
                                [
                                    2302,
                                    "H-LegalKI: A Hierarchical Legal Knowledge Integration Framework for Legal Community Question Answering"
                                ],
                                [
                                    2357,
                                    "CoCoHD: Congress Committee Hearing Dataset"
                                ],
                                [
                                    2553,
                                    "HyPA-RAG: A Hybrid Parameter Adaptive Retrieval-Augmented Generation System for AI Legal and Policy Applications"
                                ]
                            ],
                            "paper_ids": [
                                504,
                                992,
                                1055,
                                1772,
                                1879,
                                1995,
                                2113,
                                2302,
                                2357,
                                2553,
                                2565,
                                2638,
                                2640,
                                2641,
                                2643,
                                2645,
                                2648,
                                2652
                            ]
                        },
                        {
                            "label": "legal_reasoning",
                            "description": "This subtopic explores the application of legal reasoning techniques to enhance the retrieval and interpretation of legal information.",
                            "level": 3,
                            "example_papers": [
                                [
                                    311,
                                    "Investigating LLMs as Voting Assistants via Contextual Augmentation: A Case Study on the European Parliament Elections 2024"
                                ],
                                [
                                    428,
                                    "More Than Catastrophic Forgetting: Integrating General Capabilities For Domain-Specific LLMs"
                                ],
                                [
                                    647,
                                    "Red Teaming Language Models for Processing Contradictory Dialogues"
                                ],
                                [
                                    1215,
                                    "Do LLMs Plan Like Human Writers? Comparing Journalist Coverage of Press Releases with LLMs"
                                ],
                                [
                                    1640,
                                    "Divide and Conquer: Legal Concept-guided Criminal Court View Generation"
                                ],
                                [
                                    1885,
                                    "On Evaluating Explanation Utility for Human-AI Decision Making in NLP"
                                ],
                                [
                                    1891,
                                    "Can Large Language Models Grasp Legal Theories? Enhance Legal Reasoning with Insights from Multi-Agent Collaboration"
                                ],
                                [
                                    1995,
                                    "AgentsCourt: Building Judicial Decision-Making Agents with Court Debate Simulation and Legal Knowledge Augmentation"
                                ],
                                [
                                    2083,
                                    "From Complex to Simple: Enhancing Multi-Constraint Complex Instruction Following Ability of Large Language Models"
                                ],
                                [
                                    2113,
                                    "MDCR: A Dataset for Multi-Document Conditional Reasoning"
                                ]
                            ],
                            "paper_ids": [
                                311,
                                428,
                                647,
                                1215,
                                1640,
                                1885,
                                1891,
                                1995,
                                2083,
                                2113,
                                2302,
                                2361,
                                2553,
                                2640,
                                2641,
                                2643,
                                2654,
                                2657,
                                2659,
                                2664,
                                2670
                            ]
                        },
                        {
                            "label": "regulatory_compliance",
                            "description": "This subtopic addresses the retrieval of information related to regulatory compliance, helping users understand and adhere to legal requirements.",
                            "level": 3,
                            "example_papers": [
                                [
                                    216,
                                    "C3PA: An Open Dataset of Expert-Annotated and Regulation-Aware Privacy Policies to Enable Scalable Regulatory Compliance Audits"
                                ],
                                [
                                    2654,
                                    "LLMs to the Rescue: Explaining DSA Statements of Reason with Platform's Terms of Services"
                                ]
                            ],
                            "paper_ids": [
                                216,
                                2654
                            ]
                        }
                    ]
                },
                {
                    "label": "medical_information_retrieval",
                    "description": "This cluster encompasses tasks aimed at retrieving medical literature and patient information, facilitating access to relevant healthcare data based on specific queries.",
                    "level": 2,
                    "example_papers": [
                        [
                            279,
                            "An Unsupervised Approach to Achieve Supervised-Level Explainability in Healthcare Records"
                        ],
                        [
                            311,
                            "Investigating LLMs as Voting Assistants via Contextual Augmentation: A Case Study on the European Parliament Elections 2024"
                        ],
                        [
                            398,
                            "Generative Models for Automatic Medical Decision Rule Extraction from Text"
                        ],
                        [
                            417,
                            "Towards Injecting Medical Visual Knowledge into Multimodal LLMs at Scale"
                        ],
                        [
                            437,
                            "KnowledgeSG: Privacy-Preserving Synthetic Text Generation with Knowledge Distillation from Server"
                        ],
                        [
                            494,
                            "Revisiting Who's Harry Potter: Towards Targeted Unlearning from a Causal Intervention Perspective"
                        ],
                        [
                            499,
                            "Beyond Label Attention: Transparency in Language Models for Automated Medical Coding via Dictionary Learning"
                        ],
                        [
                            504,
                            "AssistantBench: Can Web Agents Solve Realistic and Time-Consuming Tasks?"
                        ],
                        [
                            521,
                            "RuBLiMP: Russian Benchmark of Linguistic Minimal Pairs"
                        ],
                        [
                            579,
                            "CARER - ClinicAl Reasoning-Enhanced Representation for Temporal Health Risk Prediction"
                        ]
                    ],
                    "paper_ids": [
                        279,
                        311,
                        398,
                        417,
                        437,
                        494,
                        499,
                        504,
                        521,
                        579,
                        590,
                        647,
                        719,
                        758,
                        777,
                        992,
                        1025,
                        1050,
                        1055,
                        1070,
                        1180,
                        1215,
                        1240,
                        1243,
                        1244,
                        1401,
                        1419,
                        1424,
                        1445,
                        1480,
                        1487,
                        1517,
                        1588,
                        1667,
                        1707,
                        1772,
                        1775,
                        1821,
                        1902,
                        1903,
                        1956,
                        1974,
                        2029,
                        2064,
                        2065,
                        2083,
                        2113,
                        2251,
                        2280,
                        2340,
                        2361,
                        2500,
                        2565,
                        2626,
                        2677,
                        2685,
                        2719,
                        2742,
                        2764,
                        2780,
                        2792
                    ],
                    "children": [
                        {
                            "label": "literature_search",
                            "description": "This subtopic focuses on the retrieval of relevant medical literature based on specific queries, facilitating access to published research and clinical guidelines.",
                            "level": 3
                        },
                        {
                            "label": "patient_information_retrieval",
                            "description": "This subtopic encompasses tasks aimed at retrieving patient-specific information from medical records and databases to support clinical decision-making.",
                            "level": 3,
                            "example_papers": [
                                [
                                    1480,
                                    "SMILE: Single-turn to Multi-turn Inclusive Language Expansion via ChatGPT for Mental Health Support"
                                ]
                            ],
                            "paper_ids": [
                                1480
                            ]
                        },
                        {
                            "label": "medical_text_analysis",
                            "description": "This subtopic involves the analysis of medical texts to extract meaningful information, identify trends, and support various healthcare applications.",
                            "level": 3,
                            "example_papers": [
                                [
                                    279,
                                    "An Unsupervised Approach to Achieve Supervised-Level Explainability in Healthcare Records"
                                ],
                                [
                                    398,
                                    "Generative Models for Automatic Medical Decision Rule Extraction from Text"
                                ],
                                [
                                    417,
                                    "Towards Injecting Medical Visual Knowledge into Multimodal LLMs at Scale"
                                ],
                                [
                                    437,
                                    "KnowledgeSG: Privacy-Preserving Synthetic Text Generation with Knowledge Distillation from Server"
                                ],
                                [
                                    499,
                                    "Beyond Label Attention: Transparency in Language Models for Automated Medical Coding via Dictionary Learning"
                                ],
                                [
                                    504,
                                    "AssistantBench: Can Web Agents Solve Realistic and Time-Consuming Tasks?"
                                ],
                                [
                                    521,
                                    "RuBLiMP: Russian Benchmark of Linguistic Minimal Pairs"
                                ],
                                [
                                    579,
                                    "CARER - ClinicAl Reasoning-Enhanced Representation for Temporal Health Risk Prediction"
                                ],
                                [
                                    647,
                                    "Red Teaming Language Models for Processing Contradictory Dialogues"
                                ],
                                [
                                    719,
                                    "SPEED++: A Multilingual Event Extraction Framework for Epidemic Prediction and Preparedness"
                                ]
                            ],
                            "paper_ids": [
                                279,
                                398,
                                417,
                                437,
                                499,
                                504,
                                521,
                                579,
                                647,
                                719,
                                758,
                                992,
                                1025,
                                1050,
                                1215,
                                1243,
                                1517,
                                1667,
                                1772,
                                1775,
                                1821,
                                1903,
                                1956,
                                1974,
                                2029,
                                2064,
                                2065,
                                2113,
                                2280,
                                2340,
                                2361,
                                2500,
                                2685,
                                2742,
                                2780
                            ]
                        },
                        {
                            "label": "medical_information_extraction",
                            "description": "This subtopic focuses on extracting structured information from unstructured medical texts, such as clinical notes and research articles, to enhance data usability.",
                            "level": 3,
                            "example_papers": [
                                [
                                    398,
                                    "Generative Models for Automatic Medical Decision Rule Extraction from Text"
                                ],
                                [
                                    417,
                                    "Towards Injecting Medical Visual Knowledge into Multimodal LLMs at Scale"
                                ],
                                [
                                    437,
                                    "KnowledgeSG: Privacy-Preserving Synthetic Text Generation with Knowledge Distillation from Server"
                                ],
                                [
                                    504,
                                    "AssistantBench: Can Web Agents Solve Realistic and Time-Consuming Tasks?"
                                ],
                                [
                                    521,
                                    "RuBLiMP: Russian Benchmark of Linguistic Minimal Pairs"
                                ],
                                [
                                    579,
                                    "CARER - ClinicAl Reasoning-Enhanced Representation for Temporal Health Risk Prediction"
                                ],
                                [
                                    647,
                                    "Red Teaming Language Models for Processing Contradictory Dialogues"
                                ],
                                [
                                    719,
                                    "SPEED++: A Multilingual Event Extraction Framework for Epidemic Prediction and Preparedness"
                                ],
                                [
                                    758,
                                    "Large Language Models Are Poor Clinical Decision-Makers: A Comprehensive Benchmark"
                                ],
                                [
                                    992,
                                    "Unveiling and Consulting Core Experts in Retrieval-Augmented MoE-based LLMs"
                                ]
                            ],
                            "paper_ids": [
                                398,
                                417,
                                437,
                                504,
                                521,
                                579,
                                647,
                                719,
                                758,
                                992,
                                1025,
                                1050,
                                1243,
                                1244,
                                1487,
                                1517,
                                1588,
                                1667,
                                1772,
                                1775,
                                1821,
                                1902,
                                1903,
                                1956,
                                1974,
                                2029,
                                2064,
                                2065,
                                2113,
                                2340,
                                2361,
                                2500,
                                2677,
                                2742,
                                2780
                            ]
                        },
                        {
                            "label": "automated_medical_coding",
                            "description": "This subtopic deals with the automatic assignment of medical codes to diagnoses and procedures based on retrieved medical information, streamlining billing and record-keeping.",
                            "level": 3,
                            "example_papers": [
                                [
                                    279,
                                    "An Unsupervised Approach to Achieve Supervised-Level Explainability in Healthcare Records"
                                ],
                                [
                                    499,
                                    "Beyond Label Attention: Transparency in Language Models for Automated Medical Coding via Dictionary Learning"
                                ],
                                [
                                    1244,
                                    "EHRAgent: Code Empowers Large Language Models for Few-shot Complex Tabular Reasoning on Electronic Health Records"
                                ]
                            ],
                            "paper_ids": [
                                279,
                                499,
                                1244
                            ]
                        }
                    ]
                },
                {
                    "label": "healthcare_information_retrieval",
                    "description": "This cluster involves retrieving healthcare-related information, including clinical guidelines and research articles, to support medical decision-making and patient care.",
                    "level": 2,
                    "example_papers": [
                        [
                            279,
                            "An Unsupervised Approach to Achieve Supervised-Level Explainability in Healthcare Records"
                        ],
                        [
                            311,
                            "Investigating LLMs as Voting Assistants via Contextual Augmentation: A Case Study on the European Parliament Elections 2024"
                        ],
                        [
                            437,
                            "KnowledgeSG: Privacy-Preserving Synthetic Text Generation with Knowledge Distillation from Server"
                        ],
                        [
                            494,
                            "Revisiting Who's Harry Potter: Towards Targeted Unlearning from a Causal Intervention Perspective"
                        ],
                        [
                            499,
                            "Beyond Label Attention: Transparency in Language Models for Automated Medical Coding via Dictionary Learning"
                        ],
                        [
                            504,
                            "AssistantBench: Can Web Agents Solve Realistic and Time-Consuming Tasks?"
                        ],
                        [
                            521,
                            "RuBLiMP: Russian Benchmark of Linguistic Minimal Pairs"
                        ],
                        [
                            579,
                            "CARER - ClinicAl Reasoning-Enhanced Representation for Temporal Health Risk Prediction"
                        ],
                        [
                            590,
                            "Roleplay-doh: Enabling Domain-Experts to Create LLM-simulated Patients via Eliciting and Adhering to Principles"
                        ],
                        [
                            647,
                            "Red Teaming Language Models for Processing Contradictory Dialogues"
                        ]
                    ],
                    "paper_ids": [
                        279,
                        311,
                        437,
                        494,
                        499,
                        504,
                        521,
                        579,
                        590,
                        647,
                        719,
                        777,
                        992,
                        1025,
                        1050,
                        1055,
                        1070,
                        1215,
                        1243,
                        1244,
                        1401,
                        1419,
                        1424,
                        1445,
                        1480,
                        1487,
                        1588,
                        1667,
                        1772,
                        1775,
                        1821,
                        1903,
                        1974,
                        2064,
                        2065,
                        2083,
                        2113,
                        2251,
                        2280,
                        2340,
                        2361,
                        2565,
                        2626,
                        2677,
                        2685,
                        2719,
                        2742,
                        2764,
                        2780,
                        2792
                    ],
                    "children": [
                        {
                            "label": "clinical_guidelines",
                            "description": "This subtopic focuses on the retrieval and application of clinical guidelines to support healthcare professionals in making informed medical decisions.",
                            "level": 3
                        },
                        {
                            "label": "clinical_guidelines_retrieval",
                            "description": "This area specializes in the techniques and methodologies for efficiently retrieving clinical guidelines from various healthcare databases.",
                            "level": 3,
                            "example_papers": [
                                [
                                    1775,
                                    "TriageAgent: Towards Better Multi-Agents Collaborations for Large Language Model-Based Clinical Triage"
                                ],
                                [
                                    2065,
                                    "MedCare: Advancing Medical LLMs through Decoupling Clinical Alignment and Knowledge Aggregation"
                                ],
                                [
                                    2764,
                                    "Personalized-ABA: Personalized Treatment Plan Generation for Applied Behavior Analysis using Natural Language Processing"
                                ]
                            ],
                            "paper_ids": [
                                1775,
                                2065,
                                2764
                            ]
                        },
                        {
                            "label": "medical_question_answering",
                            "description": "This subtopic involves systems designed to answer medical questions by retrieving relevant healthcare information from various sources.",
                            "level": 3,
                            "example_papers": [
                                [
                                    311,
                                    "Investigating LLMs as Voting Assistants via Contextual Augmentation: A Case Study on the European Parliament Elections 2024"
                                ],
                                [
                                    1025,
                                    "CasiMedicos-Arg: A Medical Question Answering Dataset Annotated with Explanatory Argumentative Structures"
                                ],
                                [
                                    1243,
                                    "MedAdapter: Efficient Test-Time Adaptation of Large Language Models Towards Medical Reasoning"
                                ],
                                [
                                    1244,
                                    "EHRAgent: Code Empowers Large Language Models for Few-shot Complex Tabular Reasoning on Electronic Health Records"
                                ],
                                [
                                    1445,
                                    "AI for Science in the Era of Large Language Models"
                                ],
                                [
                                    1487,
                                    "RAG-Studio: Towards In-Domain Adaptation of Retrieval Augmented Generation Through Self-Alignment"
                                ],
                                [
                                    1588,
                                    "Enhancing Healthcare LLM Trust with Atypical Presentations Recalibration"
                                ],
                                [
                                    1667,
                                    "Med-MoE: Mixture of Domain-Specific Experts for Lightweight Medical Vision-Language Models"
                                ],
                                [
                                    1772,
                                    "Instance-Level Dynamic LoRAs Composition for Cross-Task Generalization"
                                ],
                                [
                                    1775,
                                    "TriageAgent: Towards Better Multi-Agents Collaborations for Large Language Model-Based Clinical Triage"
                                ]
                            ],
                            "paper_ids": [
                                311,
                                1025,
                                1243,
                                1244,
                                1445,
                                1487,
                                1588,
                                1667,
                                1772,
                                1775,
                                2064,
                                2113,
                                2565
                            ]
                        },
                        {
                            "label": "epidemiological_data_extraction",
                            "description": "This cluster focuses on the extraction of epidemiological data from healthcare literature to inform public health decisions and research.",
                            "level": 3,
                            "example_papers": [
                                [
                                    504,
                                    "AssistantBench: Can Web Agents Solve Realistic and Time-Consuming Tasks?"
                                ],
                                [
                                    719,
                                    "SPEED++: A Multilingual Event Extraction Framework for Epidemic Prediction and Preparedness"
                                ],
                                [
                                    2742,
                                    "From Text to Maps: LLM-Driven Extraction and Geotagging of Epidemiological Data"
                                ]
                            ],
                            "paper_ids": [
                                504,
                                719,
                                2742
                            ]
                        },
                        {
                            "label": "explanation_methods_in_healthcare_information_retrieval",
                            "description": "This area explores methods for providing explanations and justifications for the retrieved healthcare information to enhance user understanding.",
                            "level": 3,
                            "example_papers": [
                                [
                                    279,
                                    "An Unsupervised Approach to Achieve Supervised-Level Explainability in Healthcare Records"
                                ],
                                [
                                    437,
                                    "KnowledgeSG: Privacy-Preserving Synthetic Text Generation with Knowledge Distillation from Server"
                                ],
                                [
                                    494,
                                    "Revisiting Who's Harry Potter: Towards Targeted Unlearning from a Causal Intervention Perspective"
                                ],
                                [
                                    499,
                                    "Beyond Label Attention: Transparency in Language Models for Automated Medical Coding via Dictionary Learning"
                                ],
                                [
                                    579,
                                    "CARER - ClinicAl Reasoning-Enhanced Representation for Temporal Health Risk Prediction"
                                ],
                                [
                                    590,
                                    "Roleplay-doh: Enabling Domain-Experts to Create LLM-simulated Patients via Eliciting and Adhering to Principles"
                                ],
                                [
                                    647,
                                    "Red Teaming Language Models for Processing Contradictory Dialogues"
                                ],
                                [
                                    992,
                                    "Unveiling and Consulting Core Experts in Retrieval-Augmented MoE-based LLMs"
                                ],
                                [
                                    1025,
                                    "CasiMedicos-Arg: A Medical Question Answering Dataset Annotated with Explanatory Argumentative Structures"
                                ],
                                [
                                    1050,
                                    "Fool Me Once? Contrasting Textual and Visual Explanations in a Clinical Decision-Support Setting"
                                ]
                            ],
                            "paper_ids": [
                                279,
                                437,
                                494,
                                499,
                                579,
                                590,
                                647,
                                992,
                                1025,
                                1050,
                                1055,
                                1070,
                                1215,
                                1401,
                                1419,
                                1424,
                                1480,
                                1821,
                                1903,
                                1974,
                                2113,
                                2251,
                                2340,
                                2677,
                                2685,
                                2719,
                                2764,
                                2780,
                                2792
                            ]
                        }
                    ]
                },
                {
                    "label": "temporal_information_retrieval",
                    "description": "This cluster focuses on tasks that involve retrieving information based on temporal aspects, such as event timelines and historical data relevant to user queries.",
                    "level": 2,
                    "example_papers": [
                        [
                            50,
                            "In-context Contrastive Learning for Event Causality Identification"
                        ],
                        [
                            85,
                            "Mitigating Matthew Effect: Multi-Hypergraph Boosted Multi-Interest Self-Supervised Learning for Conversational Recommendation"
                        ],
                        [
                            137,
                            "Direct Multi-Turn Preference Optimization for Language Agents"
                        ],
                        [
                            281,
                            "EVEDIT: Event-based Knowledge Editing for Deterministic Knowledge Propagation"
                        ],
                        [
                            311,
                            "Investigating LLMs as Voting Assistants via Contextual Augmentation: A Case Study on the European Parliament Elections 2024"
                        ],
                        [
                            321,
                            "Leave No Document Behind: Benchmarking Long-Context LLMs with Extended Multi-Doc QA"
                        ],
                        [
                            368,
                            "UOUO: Uncontextualized Uncommon Objects for Measuring Knowledge Horizons of Vision Language Models"
                        ],
                        [
                            413,
                            "Extending Context Window of Large Language Models from a Distributional Perspective"
                        ],
                        [
                            439,
                            "Unlocking the Future: Exploring Look-Ahead Planning Mechanistic Interpretability in Large Language Models"
                        ],
                        [
                            450,
                            "PARIKSHA: A Large-Scale Investigation of Human-LLM Evaluator Agreement on Multilingual and Multi-Cultural Data"
                        ]
                    ],
                    "paper_ids": [
                        50,
                        85,
                        137,
                        281,
                        311,
                        321,
                        368,
                        413,
                        439,
                        450,
                        487,
                        489,
                        494,
                        504,
                        521,
                        540,
                        555,
                        579,
                        589,
                        647,
                        700,
                        719,
                        721,
                        754,
                        761,
                        773,
                        777,
                        782,
                        921,
                        956,
                        980,
                        992,
                        1041,
                        1055,
                        1070,
                        1076,
                        1085,
                        1094,
                        1135,
                        1168,
                        1169,
                        1185,
                        1191,
                        1203,
                        1215,
                        1317,
                        1373,
                        1401,
                        1406,
                        1409,
                        1419,
                        1424,
                        1427,
                        1445,
                        1487,
                        1491,
                        1493,
                        1496,
                        1572,
                        1603,
                        1608,
                        1665,
                        1702,
                        1771,
                        1772,
                        1784,
                        1881,
                        1903,
                        1957,
                        1989,
                        2083,
                        2113,
                        2153,
                        2204,
                        2247,
                        2251,
                        2355,
                        2361,
                        2399,
                        2409,
                        2473,
                        2490,
                        2565,
                        2578,
                        2581,
                        2626,
                        2677,
                        2680,
                        2683,
                        2697,
                        2719,
                        2735,
                        2792,
                        2807,
                        2809,
                        2945
                    ],
                    "children": [
                        {
                            "label": "event_timeline_retrieval",
                            "description": "This subtopic focuses on retrieving comprehensive timelines of events based on user queries, allowing for a structured understanding of temporal sequences.",
                            "level": 3,
                            "example_papers": [
                                [
                                    281,
                                    "EVEDIT: Event-based Knowledge Editing for Deterministic Knowledge Propagation"
                                ],
                                [
                                    1493,
                                    "Temporal Cognitive Tree: A Hierarchical Modeling Approach for Event Temporal Relation Extraction"
                                ],
                                [
                                    1665,
                                    "When and Where Did it Happen? An Encoder-Decoder Model to Identify Scenario Context"
                                ],
                                [
                                    2399,
                                    "Remember This Event That Year? Assessing Temporal Information and Understanding in Large Language Models"
                                ]
                            ],
                            "paper_ids": [
                                281,
                                1493,
                                1665,
                                2399
                            ]
                        },
                        {
                            "label": "event_based_information_retrieval",
                            "description": "This area emphasizes the retrieval of information that is specifically tied to events, enhancing the relevance of search results in temporal contexts.",
                            "level": 3,
                            "example_papers": [
                                [
                                    50,
                                    "In-context Contrastive Learning for Event Causality Identification"
                                ],
                                [
                                    85,
                                    "Mitigating Matthew Effect: Multi-Hypergraph Boosted Multi-Interest Self-Supervised Learning for Conversational Recommendation"
                                ],
                                [
                                    281,
                                    "EVEDIT: Event-based Knowledge Editing for Deterministic Knowledge Propagation"
                                ],
                                [
                                    311,
                                    "Investigating LLMs as Voting Assistants via Contextual Augmentation: A Case Study on the European Parliament Elections 2024"
                                ],
                                [
                                    487,
                                    "MEANT: Multimodal Encoder for Antecedent Information"
                                ],
                                [
                                    489,
                                    "AGRaME: Any-Granularity Ranking with Multi-Vector Embeddings"
                                ],
                                [
                                    504,
                                    "AssistantBench: Can Web Agents Solve Realistic and Time-Consuming Tasks?"
                                ],
                                [
                                    521,
                                    "RuBLiMP: Russian Benchmark of Linguistic Minimal Pairs"
                                ],
                                [
                                    555,
                                    "Efficient Temporal Extrapolation of Multimodal Large Language Models with Temporal Grounding Bridge"
                                ],
                                [
                                    700,
                                    "Lifelong Event Detection via Optimal Transport"
                                ]
                            ],
                            "paper_ids": [
                                50,
                                85,
                                281,
                                311,
                                487,
                                489,
                                504,
                                521,
                                555,
                                700,
                                754,
                                761,
                                921,
                                956,
                                980,
                                1041,
                                1055,
                                1070,
                                1085,
                                1185,
                                1215,
                                1373,
                                1406,
                                1409,
                                1419,
                                1424,
                                1487,
                                1496,
                                1603,
                                1772,
                                2083,
                                2113,
                                2153,
                                2361,
                                2473,
                                2490,
                                2581,
                                2677,
                                2680,
                                2697,
                                2719,
                                2735,
                                2792,
                                2809,
                                2945
                            ]
                        },
                        {
                            "label": "temporal_knowledge_graph_reasoning",
                            "description": "This subtopic involves reasoning over temporal knowledge graphs to extract insights and relationships that are time-dependent.",
                            "level": 3,
                            "example_papers": [
                                [
                                    85,
                                    "Mitigating Matthew Effect: Multi-Hypergraph Boosted Multi-Interest Self-Supervised Learning for Conversational Recommendation"
                                ],
                                [
                                    921,
                                    "Multi-Level Information Retrieval Augmented Generation for Knowledge-based Visual Question Answering"
                                ],
                                [
                                    1409,
                                    "Knowledge-augmented Financial Market Analysis and Report Generation"
                                ],
                                [
                                    1487,
                                    "RAG-Studio: Towards In-Domain Adaptation of Retrieval Augmented Generation Through Self-Alignment"
                                ],
                                [
                                    1957,
                                    "SALMON: A Structure-Aware Language Model with logicality and densification strategy for Temporal Knowledge Graph Reasoning"
                                ],
                                [
                                    1989,
                                    "Natural Evolution-based Dual-Level Aggregation for Temporal Knowledge Graph Reasoning"
                                ],
                                [
                                    2113,
                                    "MDCR: A Dataset for Multi-Document Conditional Reasoning"
                                ],
                                [
                                    2409,
                                    "Narrative-of-Thought: Improving Temporal Reasoning of Large Language Models via Recounted Narratives"
                                ]
                            ],
                            "paper_ids": [
                                85,
                                921,
                                1409,
                                1487,
                                1957,
                                1989,
                                2113,
                                2409
                            ]
                        },
                        {
                            "label": "event_prediction",
                            "description": "This cluster deals with predicting future events based on historical data and trends, providing foresight into temporal developments.",
                            "level": 3,
                            "example_papers": [
                                [
                                    137,
                                    "Direct Multi-Turn Preference Optimization for Language Agents"
                                ],
                                [
                                    504,
                                    "AssistantBench: Can Web Agents Solve Realistic and Time-Consuming Tasks?"
                                ],
                                [
                                    700,
                                    "Lifelong Event Detection via Optimal Transport"
                                ],
                                [
                                    719,
                                    "SPEED++: A Multilingual Event Extraction Framework for Epidemic Prediction and Preparedness"
                                ],
                                [
                                    721,
                                    "UNICORN: A Unified Causal Video-Oriented Language-Modeling Framework for Temporal Video-Language Tasks"
                                ],
                                [
                                    1491,
                                    "What Would Happen Next? Predicting Consequences from An Event Causality Graph"
                                ],
                                [
                                    2113,
                                    "MDCR: A Dataset for Multi-Document Conditional Reasoning"
                                ],
                                [
                                    2355,
                                    "Large Language Models Know What To Say But Not When To Speak"
                                ],
                                [
                                    2490,
                                    "Transformer verbatim in-context retrieval across time and scale"
                                ]
                            ],
                            "paper_ids": [
                                137,
                                504,
                                700,
                                719,
                                721,
                                1491,
                                2113,
                                2355,
                                2490
                            ]
                        },
                        {
                            "label": "temporal_relation_classification",
                            "description": "This area focuses on classifying relationships between events in terms of their temporal connections, aiding in the understanding of event interactions over time.",
                            "level": 3,
                            "example_papers": [
                                [
                                    50,
                                    "In-context Contrastive Learning for Event Causality Identification"
                                ],
                                [
                                    311,
                                    "Investigating LLMs as Voting Assistants via Contextual Augmentation: A Case Study on the European Parliament Elections 2024"
                                ],
                                [
                                    413,
                                    "Extending Context Window of Large Language Models from a Distributional Perspective"
                                ],
                                [
                                    439,
                                    "Unlocking the Future: Exploring Look-Ahead Planning Mechanistic Interpretability in Large Language Models"
                                ],
                                [
                                    489,
                                    "AGRaME: Any-Granularity Ranking with Multi-Vector Embeddings"
                                ],
                                [
                                    494,
                                    "Revisiting Who's Harry Potter: Towards Targeted Unlearning from a Causal Intervention Perspective"
                                ],
                                [
                                    504,
                                    "AssistantBench: Can Web Agents Solve Realistic and Time-Consuming Tasks?"
                                ],
                                [
                                    521,
                                    "RuBLiMP: Russian Benchmark of Linguistic Minimal Pairs"
                                ],
                                [
                                    555,
                                    "Efficient Temporal Extrapolation of Multimodal Large Language Models with Temporal Grounding Bridge"
                                ],
                                [
                                    579,
                                    "CARER - ClinicAl Reasoning-Enhanced Representation for Temporal Health Risk Prediction"
                                ]
                            ],
                            "paper_ids": [
                                50,
                                311,
                                413,
                                439,
                                489,
                                494,
                                504,
                                521,
                                555,
                                579,
                                589,
                                647,
                                700,
                                719,
                                721,
                                754,
                                773,
                                980,
                                992,
                                1041,
                                1055,
                                1070,
                                1085,
                                1094,
                                1135,
                                1168,
                                1169,
                                1191,
                                1203,
                                1373,
                                1491,
                                1493,
                                1572,
                                1603,
                                1608,
                                1772,
                                1784,
                                1881,
                                1903,
                                2113,
                                2204,
                                2247,
                                2361,
                                2399,
                                2409,
                                2473,
                                2490,
                                2680,
                                2697,
                                2719,
                                2735,
                                2945
                            ]
                        }
                    ]
                },
                {
                    "label": "event_temporal_relation_extraction",
                    "description": "This cluster deals with extracting and retrieving information related to the temporal relationships between events, enhancing the understanding of chronological data.",
                    "level": 2,
                    "example_papers": [
                        [
                            50,
                            "In-context Contrastive Learning for Event Causality Identification"
                        ],
                        [
                            281,
                            "EVEDIT: Event-based Knowledge Editing for Deterministic Knowledge Propagation"
                        ],
                        [
                            311,
                            "Investigating LLMs as Voting Assistants via Contextual Augmentation: A Case Study on the European Parliament Elections 2024"
                        ],
                        [
                            450,
                            "PARIKSHA: A Large-Scale Investigation of Human-LLM Evaluator Agreement on Multilingual and Multi-Cultural Data"
                        ],
                        [
                            494,
                            "Revisiting Who's Harry Potter: Towards Targeted Unlearning from a Causal Intervention Perspective"
                        ],
                        [
                            504,
                            "AssistantBench: Can Web Agents Solve Realistic and Time-Consuming Tasks?"
                        ],
                        [
                            521,
                            "RuBLiMP: Russian Benchmark of Linguistic Minimal Pairs"
                        ],
                        [
                            589,
                            "LLMs Are Prone to Fallacies in Causal Inference"
                        ],
                        [
                            647,
                            "Red Teaming Language Models for Processing Contradictory Dialogues"
                        ],
                        [
                            672,
                            "Explicit, Implicit, and Scattered: Revisiting Event Extraction to Capture Complex Arguments"
                        ]
                    ],
                    "paper_ids": [
                        50,
                        281,
                        311,
                        450,
                        494,
                        504,
                        521,
                        589,
                        647,
                        672,
                        700,
                        719,
                        777,
                        862,
                        992,
                        1041,
                        1055,
                        1070,
                        1076,
                        1135,
                        1169,
                        1191,
                        1215,
                        1401,
                        1406,
                        1419,
                        1424,
                        1427,
                        1445,
                        1481,
                        1487,
                        1491,
                        1493,
                        1572,
                        1665,
                        1702,
                        1772,
                        1794,
                        1827,
                        1903,
                        1957,
                        1989,
                        2083,
                        2113,
                        2251,
                        2355,
                        2361,
                        2380,
                        2399,
                        2409,
                        2432,
                        2565,
                        2590,
                        2594,
                        2626,
                        2677,
                        2680,
                        2719,
                        2735,
                        2792,
                        2945,
                        2952
                    ],
                    "children": [
                        {
                            "label": "temporal_relation_extraction",
                            "description": "This subtopic focuses on the extraction of temporal relationships between events, identifying how events are related in time.",
                            "level": 3,
                            "example_papers": [
                                [
                                    50,
                                    "In-context Contrastive Learning for Event Causality Identification"
                                ],
                                [
                                    281,
                                    "EVEDIT: Event-based Knowledge Editing for Deterministic Knowledge Propagation"
                                ],
                                [
                                    311,
                                    "Investigating LLMs as Voting Assistants via Contextual Augmentation: A Case Study on the European Parliament Elections 2024"
                                ],
                                [
                                    521,
                                    "RuBLiMP: Russian Benchmark of Linguistic Minimal Pairs"
                                ],
                                [
                                    589,
                                    "LLMs Are Prone to Fallacies in Causal Inference"
                                ],
                                [
                                    700,
                                    "Lifelong Event Detection via Optimal Transport"
                                ],
                                [
                                    1076,
                                    "CaT-Bench: Benchmarking Language Model Understanding of Causal and Temporal Dependencies in Plans"
                                ],
                                [
                                    1135,
                                    "Will LLMs Replace the Encoder-Only Models in Temporal Relation Classification?"
                                ],
                                [
                                    1481,
                                    "DocEE-zh: A Fine-grained Benchmark for Chinese Document-level Event Extraction"
                                ],
                                [
                                    1491,
                                    "What Would Happen Next? Predicting Consequences from An Event Causality Graph"
                                ]
                            ],
                            "paper_ids": [
                                50,
                                281,
                                311,
                                521,
                                589,
                                700,
                                1076,
                                1135,
                                1481,
                                1491,
                                1493,
                                1572,
                                1665,
                                1702,
                                1827,
                                1957,
                                1989,
                                2355,
                                2380,
                                2399,
                                2409,
                                2432,
                                2590,
                                2594,
                                2677,
                                2680,
                                2945,
                                2952
                            ]
                        },
                        {
                            "label": "temporal_relation_extraction_evaluation",
                            "description": "This subtopic deals with the evaluation methodologies and metrics used to assess the performance of temporal relation extraction systems.",
                            "level": 3,
                            "example_papers": [
                                [
                                    504,
                                    "AssistantBench: Can Web Agents Solve Realistic and Time-Consuming Tasks?"
                                ]
                            ],
                            "paper_ids": [
                                504
                            ]
                        },
                        {
                            "label": "temporal_dependency_extraction",
                            "description": "This subtopic involves the extraction of dependencies that indicate the temporal order and relationships among events.",
                            "level": 3,
                            "example_papers": [
                                [
                                    647,
                                    "Red Teaming Language Models for Processing Contradictory Dialogues"
                                ],
                                [
                                    672,
                                    "Explicit, Implicit, and Scattered: Revisiting Event Extraction to Capture Complex Arguments"
                                ],
                                [
                                    862,
                                    "SRF: Enhancing Document-Level Relation Extraction with a Novel Secondary Reasoning Framework"
                                ],
                                [
                                    992,
                                    "Unveiling and Consulting Core Experts in Retrieval-Augmented MoE-based LLMs"
                                ],
                                [
                                    1041,
                                    "The Emergence of Compositional Languages in Multi-entity Referential Games: from Image to Graph Representations"
                                ],
                                [
                                    1076,
                                    "CaT-Bench: Benchmarking Language Model Understanding of Causal and Temporal Dependencies in Plans"
                                ],
                                [
                                    1772,
                                    "Instance-Level Dynamic LoRAs Composition for Cross-Task Generalization"
                                ],
                                [
                                    1903,
                                    "NeuroMax: Enhancing Neural Topic Modeling via Maximizing Mutual Information and Group Topic Regularization"
                                ],
                                [
                                    2113,
                                    "MDCR: A Dataset for Multi-Document Conditional Reasoning"
                                ],
                                [
                                    2380,
                                    "Grounding Partially-Defined Events in Multimodal Data"
                                ]
                            ],
                            "paper_ids": [
                                647,
                                672,
                                862,
                                992,
                                1041,
                                1076,
                                1772,
                                1903,
                                2113,
                                2380,
                                2719,
                                2735
                            ]
                        },
                        {
                            "label": "temporal_relation_prediction",
                            "description": "This subtopic is concerned with predicting future temporal relationships between events based on existing data.",
                            "level": 3
                        },
                        {
                            "label": "temporal_graph_generation",
                            "description": "This subtopic focuses on creating graphical representations of temporal relationships among events to visualize and analyze their interconnections.",
                            "level": 3
                        }
                    ]
                }
            ]
        },
        {
            "label": "question_answering",
            "description": "The task of automatically answering questions posed by humans in a natural language.",
            "level": 1,
            "example_papers": [
                [
                    4,
                    "Table Question Answering for Low-resourced Indic Languages"
                ],
                [
                    5,
                    "ImageInWords: Unlocking Hyper-Detailed Image Descriptions"
                ],
                [
                    13,
                    "A Usage-centric Take on Intent Understanding in E-Commerce"
                ],
                [
                    14,
                    "Fine-Tuning or Retrieval? Comparing Knowledge Injection in LLMs"
                ],
                [
                    15,
                    "Systematic Biases in LLM Simulations of Debates"
                ],
                [
                    17,
                    "Uncertainty in Language Models: Assessment through Rank-Calibration"
                ],
                [
                    19,
                    "Learning Planning-based Reasoning by Trajectories Collection and Process Reward Synthesizing"
                ],
                [
                    39,
                    "Tokenization Is More Than Compression"
                ],
                [
                    42,
                    "Parameter-Efficient Sparsity Crafting from Dense to Mixture-of-Experts for Instruction Tuning on General Tasks"
                ],
                [
                    43,
                    "GeoGPT4V: Towards Geometric Multi-modal Large Language Models with Geometric Image Generation"
                ]
            ],
            "paper_ids": [
                4,
                5,
                13,
                14,
                15,
                17,
                19,
                39,
                42,
                43,
                47,
                48,
                50,
                52,
                53,
                56,
                57,
                63,
                67,
                71,
                75,
                80,
                87,
                90,
                91,
                100,
                101,
                105,
                109,
                111,
                117,
                118,
                120,
                124,
                127,
                129,
                134,
                137,
                138,
                139,
                141,
                145,
                146,
                149,
                152,
                154,
                155,
                157,
                158,
                160,
                163,
                165,
                166,
                167,
                169,
                171,
                172,
                173,
                174,
                185,
                186,
                190,
                193,
                197,
                198,
                204,
                210,
                211,
                220,
                222,
                225,
                226,
                228,
                233,
                235,
                238,
                241,
                248,
                251,
                262,
                264,
                265,
                266,
                267,
                269,
                273,
                276,
                279,
                283,
                286,
                287,
                296,
                299,
                300,
                306,
                307,
                308,
                311,
                312,
                315,
                319,
                320,
                321,
                332,
                337,
                342,
                345,
                346,
                347,
                348,
                350,
                352,
                358,
                360,
                368,
                375,
                377,
                378,
                380,
                386,
                390,
                393,
                398,
                399,
                402,
                405,
                407,
                409,
                417,
                425,
                431,
                434,
                436,
                441,
                442,
                443,
                453,
                454,
                457,
                459,
                460,
                464,
                472,
                474,
                476,
                477,
                480,
                483,
                484,
                489,
                494,
                501,
                503,
                504,
                508,
                511,
                521,
                522,
                523,
                527,
                529,
                530,
                535,
                536,
                540,
                543,
                544,
                545,
                549,
                550,
                553,
                555,
                557,
                559,
                567,
                570,
                573,
                577,
                579,
                580,
                582,
                585,
                593,
                594,
                596,
                604,
                605,
                609,
                612,
                614,
                624,
                627,
                628,
                630,
                631,
                632,
                635,
                636,
                637,
                645,
                647,
                649,
                653,
                656,
                657,
                658,
                662,
                664,
                667,
                675,
                676,
                679,
                684,
                685,
                686,
                688,
                689,
                691,
                702,
                705,
                709,
                713,
                721,
                724,
                732,
                733,
                740,
                741,
                745,
                746,
                750,
                756,
                758,
                760,
                761,
                762,
                763,
                769,
                775,
                776,
                778,
                780,
                782,
                789,
                792,
                794,
                797,
                800,
                803,
                804,
                806,
                809,
                812,
                813,
                814,
                816,
                825,
                830,
                831,
                832,
                843,
                844,
                846,
                849,
                850,
                853,
                854,
                857,
                860,
                862,
                863,
                870,
                872,
                873,
                874,
                879,
                880,
                882,
                892,
                894,
                895,
                904,
                909,
                911,
                914,
                918,
                919,
                921,
                925,
                928,
                932,
                937,
                939,
                941,
                946,
                948,
                954,
                955,
                956,
                960,
                961,
                963,
                965,
                971,
                973,
                974,
                976,
                977,
                978,
                980,
                984,
                992,
                995,
                997,
                1003,
                1006,
                1017,
                1020,
                1022,
                1025,
                1027,
                1031,
                1035,
                1036,
                1041,
                1050,
                1051,
                1053,
                1058,
                1059,
                1061,
                1062,
                1069,
                1070,
                1071,
                1073,
                1076,
                1085,
                1095,
                1096,
                1099,
                1104,
                1109,
                1110,
                1111,
                1112,
                1113,
                1116,
                1118,
                1129,
                1135,
                1139,
                1140,
                1144,
                1145,
                1148,
                1150,
                1157,
                1159,
                1161,
                1162,
                1166,
                1170,
                1174,
                1178,
                1181,
                1190,
                1191,
                1192,
                1193,
                1195,
                1201,
                1203,
                1204,
                1208,
                1211,
                1219,
                1228,
                1230,
                1232,
                1235,
                1243,
                1244,
                1246,
                1248,
                1249,
                1250,
                1252,
                1254,
                1258,
                1260,
                1269,
                1277,
                1278,
                1280,
                1285,
                1288,
                1289,
                1293,
                1294,
                1308,
                1311,
                1312,
                1317,
                1325,
                1328,
                1332,
                1334,
                1337,
                1342,
                1344,
                1345,
                1346,
                1347,
                1357,
                1360,
                1368,
                1374,
                1375,
                1378,
                1379,
                1394,
                1396,
                1402,
                1404,
                1408,
                1417,
                1427,
                1430,
                1432,
                1433,
                1435,
                1439,
                1441,
                1443,
                1444,
                1445,
                1446,
                1450,
                1453,
                1457,
                1459,
                1460,
                1469,
                1472,
                1474,
                1477,
                1480,
                1481,
                1485,
                1487,
                1490,
                1491,
                1492,
                1493,
                1494,
                1498,
                1500,
                1503,
                1507,
                1509,
                1511,
                1514,
                1517,
                1519,
                1521,
                1522,
                1527,
                1529,
                1530,
                1532,
                1533,
                1534,
                1537,
                1538,
                1539,
                1540,
                1541,
                1547,
                1548,
                1550,
                1552,
                1553,
                1555,
                1556,
                1557,
                1559,
                1562,
                1563,
                1565,
                1567,
                1569,
                1571,
                1573,
                1576,
                1577,
                1579,
                1580,
                1581,
                1582,
                1586,
                1588,
                1591,
                1596,
                1597,
                1598,
                1599,
                1602,
                1603,
                1605,
                1607,
                1608,
                1609,
                1610,
                1613,
                1616,
                1618,
                1622,
                1625,
                1628,
                1636,
                1637,
                1638,
                1640,
                1641,
                1643,
                1646,
                1647,
                1651,
                1652,
                1653,
                1655,
                1659,
                1667,
                1674,
                1680,
                1685,
                1688,
                1690,
                1691,
                1693,
                1696,
                1699,
                1702,
                1707,
                1708,
                1710,
                1714,
                1724,
                1725,
                1727,
                1734,
                1737,
                1738,
                1739,
                1745,
                1746,
                1751,
                1752,
                1753,
                1755,
                1758,
                1759,
                1764,
                1767,
                1768,
                1769,
                1772,
                1775,
                1787,
                1788,
                1793,
                1796,
                1802,
                1805,
                1808,
                1809,
                1811,
                1812,
                1820,
                1830,
                1832,
                1836,
                1838,
                1843,
                1849,
                1854,
                1856,
                1858,
                1859,
                1860,
                1861,
                1873,
                1875,
                1876,
                1879,
                1882,
                1884,
                1888,
                1891,
                1892,
                1895,
                1900,
                1904,
                1905,
                1909,
                1918,
                1919,
                1921,
                1923,
                1927,
                1929,
                1933,
                1936,
                1938,
                1939,
                1941,
                1942,
                1946,
                1947,
                1950,
                1952,
                1954,
                1955,
                1957,
                1965,
                1966,
                1968,
                1970,
                1971,
                1973,
                1975,
                1989,
                1992,
                1994,
                1995,
                1997,
                1999,
                2002,
                2005,
                2008,
                2014,
                2015,
                2019,
                2021,
                2022,
                2033,
                2034,
                2035,
                2038,
                2039,
                2040,
                2041,
                2045,
                2048,
                2049,
                2051,
                2053,
                2063,
                2064,
                2065,
                2066,
                2068,
                2069,
                2083,
                2095,
                2098,
                2100,
                2109,
                2113,
                2115,
                2116,
                2130,
                2136,
                2139,
                2145,
                2150,
                2156,
                2161,
                2167,
                2168,
                2178,
                2184,
                2188,
                2192,
                2193,
                2196,
                2203,
                2205,
                2209,
                2215,
                2216,
                2222,
                2228,
                2231,
                2240,
                2243,
                2244,
                2245,
                2246,
                2247,
                2251,
                2254,
                2255,
                2266,
                2267,
                2272,
                2275,
                2277,
                2281,
                2288,
                2289,
                2290,
                2294,
                2295,
                2299,
                2302,
                2313,
                2317,
                2318,
                2325,
                2328,
                2329,
                2337,
                2340,
                2341,
                2342,
                2346,
                2350,
                2354,
                2356,
                2359,
                2361,
                2362,
                2365,
                2384,
                2386,
                2387,
                2391,
                2392,
                2394,
                2399,
                2407,
                2410,
                2412,
                2414,
                2419,
                2423,
                2426,
                2427,
                2429,
                2430,
                2431,
                2432,
                2433,
                2436,
                2443,
                2460,
                2462,
                2463,
                2467,
                2473,
                2480,
                2481,
                2482,
                2484,
                2488,
                2489,
                2493,
                2494,
                2496,
                2507,
                2508,
                2513,
                2516,
                2518,
                2522,
                2535,
                2542,
                2552,
                2553,
                2556,
                2565,
                2567,
                2594,
                2597,
                2599,
                2600,
                2604,
                2605,
                2625,
                2628,
                2635,
                2636,
                2637,
                2638,
                2640,
                2641,
                2642,
                2643,
                2644,
                2649,
                2651,
                2653,
                2659,
                2663,
                2670,
                2679,
                2680,
                2698,
                2713,
                2720,
                2721,
                2735,
                2738,
                2749,
                2752,
                2755,
                2764,
                2772,
                2775,
                2780,
                2799,
                2800,
                2809,
                2810,
                2948,
                2951
            ],
            "children": [
                {
                    "label": "retrieval_based_question_answering",
                    "description": "This cluster focuses on techniques that enhance question answering by retrieving relevant information from external sources or databases to provide accurate answers.",
                    "level": 2,
                    "example_papers": [
                        [
                            14,
                            "Fine-Tuning or Retrieval? Comparing Knowledge Injection in LLMs"
                        ],
                        [
                            57,
                            "BlendFilter: Advancing Retrieval-Augmented Large Language Models via Query Generation Blending and Knowledge Filtering"
                        ],
                        [
                            100,
                            "Triad: A Framework Leveraging a Multi-Role LLM-based Agent to Solve Knowledge Base Question Answering"
                        ],
                        [
                            198,
                            "EfficientRAG: Efficient Retriever for Multi-Hop Question Answering"
                        ],
                        [
                            241,
                            "I Could've Asked That: Reformulating Unanswerable Questions"
                        ],
                        [
                            248,
                            "RAG-QA Arena: Evaluating Domain Robustness for Long-form Retrieval Augmented Question Answering"
                        ],
                        [
                            265,
                            "DVD: Dynamic Contrastive Decoding for Knowledge Amplification in Multi-Document Question Answering"
                        ],
                        [
                            269,
                            "Retrieve-Plan-Generation: An Iterative Planning and Answering Framework for Knowledge-Intensive LLM Generation"
                        ],
                        [
                            320,
                            "REAR: A Relevance-Aware Retrieval-Augmented Framework for Open-Domain Question Answering"
                        ],
                        [
                            321,
                            "Leave No Document Behind: Benchmarking Long-Context LLMs with Extended Multi-Doc QA"
                        ]
                    ],
                    "paper_ids": [
                        14,
                        57,
                        100,
                        198,
                        241,
                        248,
                        265,
                        269,
                        320,
                        321,
                        337,
                        346,
                        352,
                        489,
                        501,
                        504,
                        609,
                        612,
                        624,
                        635,
                        745,
                        750,
                        761,
                        792,
                        812,
                        844,
                        862,
                        911,
                        921,
                        925,
                        980,
                        1022,
                        1070,
                        1139,
                        1170,
                        1178,
                        1193,
                        1195,
                        1235,
                        1250,
                        1277,
                        1280,
                        1289,
                        1332,
                        1360,
                        1375,
                        1394,
                        1427,
                        1432,
                        1435,
                        1444,
                        1450,
                        1487,
                        1517,
                        1541,
                        1565,
                        1567,
                        1577,
                        1579,
                        1582,
                        1596,
                        1597,
                        1598,
                        1602,
                        1603,
                        1607,
                        1725,
                        1727,
                        1892,
                        1895,
                        1905,
                        1942,
                        1946,
                        1970,
                        1973,
                        1992,
                        2039,
                        2053,
                        2068,
                        2113,
                        2116,
                        2136,
                        2145,
                        2178,
                        2205,
                        2277,
                        2384,
                        2473,
                        2552,
                        2553,
                        2565,
                        2567,
                        2625,
                        2636,
                        2637,
                        2663,
                        2713,
                        2800
                    ],
                    "children": [
                        {
                            "label": "retrieval_augmented_generation",
                            "description": "This subtopic focuses on enhancing question answering by integrating retrieval mechanisms with generative models to produce more accurate and contextually relevant answers.",
                            "level": 3,
                            "example_papers": [
                                [
                                    14,
                                    "Fine-Tuning or Retrieval? Comparing Knowledge Injection in LLMs"
                                ],
                                [
                                    57,
                                    "BlendFilter: Advancing Retrieval-Augmented Large Language Models via Query Generation Blending and Knowledge Filtering"
                                ],
                                [
                                    198,
                                    "EfficientRAG: Efficient Retriever for Multi-Hop Question Answering"
                                ],
                                [
                                    248,
                                    "RAG-QA Arena: Evaluating Domain Robustness for Long-form Retrieval Augmented Question Answering"
                                ],
                                [
                                    265,
                                    "DVD: Dynamic Contrastive Decoding for Knowledge Amplification in Multi-Document Question Answering"
                                ],
                                [
                                    269,
                                    "Retrieve-Plan-Generation: An Iterative Planning and Answering Framework for Knowledge-Intensive LLM Generation"
                                ],
                                [
                                    320,
                                    "REAR: A Relevance-Aware Retrieval-Augmented Framework for Open-Domain Question Answering"
                                ],
                                [
                                    346,
                                    "Model Internals-based Answer Attribution for Trustworthy Retrieval-Augmented Generation"
                                ],
                                [
                                    352,
                                    "Do You Know What You Are Talking About? Characterizing Query-Knowledge Relevance For Reliable Retrieval Augmented Generation"
                                ],
                                [
                                    489,
                                    "AGRaME: Any-Granularity Ranking with Multi-Vector Embeddings"
                                ]
                            ],
                            "paper_ids": [
                                14,
                                57,
                                198,
                                248,
                                265,
                                269,
                                320,
                                346,
                                352,
                                489,
                                501,
                                609,
                                612,
                                745,
                                750,
                                761,
                                812,
                                921,
                                980,
                                1070,
                                1193,
                                1195,
                                1235,
                                1250,
                                1277,
                                1289,
                                1332,
                                1360,
                                1375,
                                1394,
                                1427,
                                1432,
                                1487,
                                1517,
                                1541,
                                1579,
                                1582,
                                1598,
                                1607,
                                1725,
                                1895,
                                1905,
                                1942,
                                1973,
                                1992,
                                2039,
                                2053,
                                2068,
                                2136,
                                2145,
                                2178,
                                2205,
                                2277,
                                2473,
                                2553,
                                2567,
                                2625,
                                2637,
                                2663,
                                2713,
                                2800
                            ]
                        },
                        {
                            "label": "knowledge_integration",
                            "description": "This cluster emphasizes the incorporation of external knowledge sources into the question answering process to improve the accuracy and relevance of the responses.",
                            "level": 3,
                            "example_papers": [
                                [
                                    14,
                                    "Fine-Tuning or Retrieval? Comparing Knowledge Injection in LLMs"
                                ],
                                [
                                    57,
                                    "BlendFilter: Advancing Retrieval-Augmented Large Language Models via Query Generation Blending and Knowledge Filtering"
                                ],
                                [
                                    100,
                                    "Triad: A Framework Leveraging a Multi-Role LLM-based Agent to Solve Knowledge Base Question Answering"
                                ],
                                [
                                    265,
                                    "DVD: Dynamic Contrastive Decoding for Knowledge Amplification in Multi-Document Question Answering"
                                ],
                                [
                                    269,
                                    "Retrieve-Plan-Generation: An Iterative Planning and Answering Framework for Knowledge-Intensive LLM Generation"
                                ],
                                [
                                    320,
                                    "REAR: A Relevance-Aware Retrieval-Augmented Framework for Open-Domain Question Answering"
                                ],
                                [
                                    321,
                                    "Leave No Document Behind: Benchmarking Long-Context LLMs with Extended Multi-Doc QA"
                                ],
                                [
                                    612,
                                    "Large Language Models Know What is Key Visual Entity: An LLM-assisted Multimodal Retrieval for VQA"
                                ],
                                [
                                    624,
                                    "Unlocking Markets: A Multilingual Benchmark to Cross-Market Question Answering"
                                ],
                                [
                                    761,
                                    "DynamicER: Resolving Emerging Mentions to Dynamic Entities for RAG"
                                ]
                            ],
                            "paper_ids": [
                                14,
                                57,
                                100,
                                265,
                                269,
                                320,
                                321,
                                612,
                                624,
                                761,
                                844,
                                862,
                                911,
                                1022,
                                1178,
                                1195,
                                1235,
                                1250,
                                1280,
                                1444,
                                1450,
                                1541,
                                1565,
                                1577,
                                1602,
                                1603,
                                1892,
                                1905,
                                1942,
                                2039,
                                2053,
                                2113,
                                2116,
                                2277,
                                2384,
                                2552,
                                2567,
                                2636,
                                2637,
                                2663,
                                2713,
                                2800
                            ]
                        },
                        {
                            "label": "query_generation",
                            "description": "This subtopic deals with the techniques for generating effective queries that can retrieve the most relevant information from external databases for question answering.",
                            "level": 3,
                            "example_papers": [
                                [
                                    57,
                                    "BlendFilter: Advancing Retrieval-Augmented Large Language Models via Query Generation Blending and Knowledge Filtering"
                                ],
                                [
                                    241,
                                    "I Could've Asked That: Reformulating Unanswerable Questions"
                                ],
                                [
                                    1139,
                                    "You Make me Feel like a Natural Question: Training QA Systems on Transformed Trivia Questions"
                                ],
                                [
                                    2205,
                                    "Synthetic Multimodal Question Generation"
                                ],
                                [
                                    2565,
                                    "Improving Evidence Retrieval on Claim Verification Pipeline through Question Enrichment"
                                ],
                                [
                                    2663,
                                    "Empowering Air Travelers: A Chatbot for Canadian Air Passenger Rights"
                                ],
                                [
                                    2713,
                                    "Increasing the Difficulty of Automatically Generated Questions via Reinforcement Learning with Synthetic Preference for Cost-Effective Cultural Heritage Dataset Generation"
                                ]
                            ],
                            "paper_ids": [
                                57,
                                241,
                                1139,
                                2205,
                                2565,
                                2663,
                                2713
                            ]
                        },
                        {
                            "label": "efficient_retrieval",
                            "description": "This cluster focuses on optimizing retrieval methods to ensure that relevant information is accessed quickly and effectively during the question answering process.",
                            "level": 3,
                            "example_papers": [
                                [
                                    57,
                                    "BlendFilter: Advancing Retrieval-Augmented Large Language Models via Query Generation Blending and Knowledge Filtering"
                                ],
                                [
                                    198,
                                    "EfficientRAG: Efficient Retriever for Multi-Hop Question Answering"
                                ],
                                [
                                    321,
                                    "Leave No Document Behind: Benchmarking Long-Context LLMs with Extended Multi-Doc QA"
                                ],
                                [
                                    337,
                                    "CItruS: Chunked Instruction-aware State Eviction for Long Sequence Modeling"
                                ],
                                [
                                    504,
                                    "AssistantBench: Can Web Agents Solve Realistic and Time-Consuming Tasks?"
                                ],
                                [
                                    612,
                                    "Large Language Models Know What is Key Visual Entity: An LLM-assisted Multimodal Retrieval for VQA"
                                ],
                                [
                                    624,
                                    "Unlocking Markets: A Multilingual Benchmark to Cross-Market Question Answering"
                                ],
                                [
                                    635,
                                    "Improve Dense Passage Retrieval with Entailment Tuning"
                                ],
                                [
                                    750,
                                    "Lifelong Knowledge Editing for LLMs with Retrieval-Augmented Continuous Prompt Learning"
                                ],
                                [
                                    761,
                                    "DynamicER: Resolving Emerging Mentions to Dynamic Entities for RAG"
                                ]
                            ],
                            "paper_ids": [
                                57,
                                198,
                                321,
                                337,
                                504,
                                612,
                                624,
                                635,
                                750,
                                761,
                                792,
                                844,
                                921,
                                925,
                                980,
                                1170,
                                1178,
                                1280,
                                1332,
                                1435,
                                1517,
                                1567,
                                1596,
                                1597,
                                1602,
                                1603,
                                1727,
                                1970,
                                2113,
                                2277,
                                2553,
                                2565,
                                2567,
                                2625,
                                2636,
                                2637,
                                2663,
                                2713
                            ]
                        },
                        {
                            "label": "knowledge_graph_based_qa",
                            "description": "This subtopic explores the use of knowledge graphs to facilitate question answering by providing structured information that can be easily queried and interpreted.",
                            "level": 3,
                            "example_papers": [
                                [
                                    100,
                                    "Triad: A Framework Leveraging a Multi-Role LLM-based Agent to Solve Knowledge Base Question Answering"
                                ],
                                [
                                    321,
                                    "Leave No Document Behind: Benchmarking Long-Context LLMs with Extended Multi-Doc QA"
                                ],
                                [
                                    1022,
                                    "Generate-on-Graph: Treat LLM as both Agent and KG for Incomplete Knowledge Graph Question Answering"
                                ],
                                [
                                    1178,
                                    "Generative Subgraph Retrieval for Knowledge Graph-Grounded Dialog Generation"
                                ],
                                [
                                    1565,
                                    "DALK: Dynamic Co-Augmentation of LLMs and KG to answer Alzheimer's Disease Questions with Scientific Literature"
                                ],
                                [
                                    1905,
                                    "Learning to Plan for Retrieval-Augmented Large Language Models from Knowledge Graphs"
                                ],
                                [
                                    1942,
                                    "TRACE the Evidence: Constructing Knowledge-Grounded Reasoning Chains for Retrieval-Augmented Generation"
                                ],
                                [
                                    1970,
                                    "Question-guided Knowledge Graph Re-scoring and Injection for Knowledge Graph Question Answering"
                                ],
                                [
                                    2113,
                                    "MDCR: A Dataset for Multi-Document Conditional Reasoning"
                                ],
                                [
                                    2116,
                                    "A Framework of Knowledge Graph-Enhanced Large Language Model Based on Question Decomposition and Atomic Retrieval"
                                ]
                            ],
                            "paper_ids": [
                                100,
                                321,
                                1022,
                                1178,
                                1565,
                                1905,
                                1942,
                                1970,
                                2113,
                                2116,
                                2384,
                                2663,
                                2713
                            ]
                        }
                    ]
                },
                {
                    "label": "dialogue_systems",
                    "description": "This cluster encompasses systems designed to engage in conversation with users, facilitating question answering through interactive dialogue.",
                    "level": 2,
                    "example_papers": [
                        [
                            48,
                            "Overcome Noise and Bias: Segmentation-Aided Multi-Granularity Denoising and Debiasing for Enhanced Quarduples Extraction in Dialogue"
                        ],
                        [
                            134,
                            "CHIQ: Contextual History Enhancement for Improving Query Rewriting in Conversational Search"
                        ],
                        [
                            262,
                            "Bootstrapped Policy Learning for Task-oriented Dialogue through Goal Shaping"
                        ],
                        [
                            307,
                            "An LLM Feature-based Framework for Dialogue Constructiveness Assessment"
                        ],
                        [
                            308,
                            "Relevance Is a Guiding Light: Relevance-aware Adaptive Learning for End-to-end Task-oriented Dialogue System"
                        ],
                        [
                            319,
                            "Synergizing In-context Learning with Hints for End-to-end Task-oriented Dialog Systems"
                        ],
                        [
                            409,
                            "Incomplete Utterance Rewriting with Editing Operation Guidance and Utterance Augmentation"
                        ],
                        [
                            436,
                            "MORPHEUS: Modeling Role from Personalized Dialogue History by Exploring and Utilizing Latent Space"
                        ],
                        [
                            472,
                            "Unsupervised End-to-End Task-Oriented Dialogue with LLMs: The Power of the Noisy Channel"
                        ],
                        [
                            484,
                            "Zero-shot Cross-domain Dialogue State Tracking via Context-aware Auto-prompting and Instruction-following Contrastive Decoding"
                        ]
                    ],
                    "paper_ids": [
                        48,
                        134,
                        262,
                        307,
                        308,
                        319,
                        409,
                        436,
                        472,
                        484,
                        544,
                        553,
                        580,
                        627,
                        630,
                        647,
                        684,
                        709,
                        803,
                        880,
                        882,
                        963,
                        978,
                        1059,
                        1099,
                        1174,
                        1178,
                        1190,
                        1191,
                        1325,
                        1347,
                        1427,
                        1433,
                        1480,
                        1552,
                        1559,
                        1586,
                        1597,
                        1710,
                        1751,
                        1775,
                        1808,
                        1918,
                        1975,
                        1999,
                        2113,
                        2130,
                        2196,
                        2228,
                        2240,
                        2266,
                        2272,
                        2275,
                        2289,
                        2295,
                        2299,
                        2341,
                        2365,
                        2391,
                        2394,
                        2738,
                        2775,
                        2780
                    ],
                    "children": [
                        {
                            "label": "intent_detection",
                            "description": "This subtopic focuses on identifying user intentions within dialogues, enabling systems to understand and respond appropriately to user queries.",
                            "level": 3,
                            "example_papers": [
                                [
                                    1347,
                                    "Detecting Ambiguous Utterances in an Intelligent Assistant"
                                ],
                                [
                                    1433,
                                    "Intent Detection in the Age of LLMs"
                                ],
                                [
                                    1586,
                                    "A Coarse-to-Fine Prototype Learning Approach for Multi-Label Few-Shot Intent Detection"
                                ],
                                [
                                    2365,
                                    "A Pointer Network-based Approach for Joint Extraction and Detection of Multi-Label Multi-Class Intents"
                                ]
                            ],
                            "paper_ids": [
                                1347,
                                1433,
                                1586,
                                2365
                            ]
                        },
                        {
                            "label": "task-oriented_dialog_systems",
                            "description": "This subtopic encompasses dialogue systems specifically designed to assist users in completing specific tasks through structured interactions.",
                            "level": 3,
                            "example_papers": [
                                [
                                    48,
                                    "Overcome Noise and Bias: Segmentation-Aided Multi-Granularity Denoising and Debiasing for Enhanced Quarduples Extraction in Dialogue"
                                ],
                                [
                                    134,
                                    "CHIQ: Contextual History Enhancement for Improving Query Rewriting in Conversational Search"
                                ],
                                [
                                    262,
                                    "Bootstrapped Policy Learning for Task-oriented Dialogue through Goal Shaping"
                                ],
                                [
                                    308,
                                    "Relevance Is a Guiding Light: Relevance-aware Adaptive Learning for End-to-end Task-oriented Dialogue System"
                                ],
                                [
                                    319,
                                    "Synergizing In-context Learning with Hints for End-to-end Task-oriented Dialog Systems"
                                ],
                                [
                                    409,
                                    "Incomplete Utterance Rewriting with Editing Operation Guidance and Utterance Augmentation"
                                ],
                                [
                                    436,
                                    "MORPHEUS: Modeling Role from Personalized Dialogue History by Exploring and Utilizing Latent Space"
                                ],
                                [
                                    472,
                                    "Unsupervised End-to-End Task-Oriented Dialogue with LLMs: The Power of the Noisy Channel"
                                ],
                                [
                                    484,
                                    "Zero-shot Cross-domain Dialogue State Tracking via Context-aware Auto-prompting and Instruction-following Contrastive Decoding"
                                ],
                                [
                                    553,
                                    "Into the Unknown Unknowns: Engaged Human Learning through Participation in Language Model Agent Conversations"
                                ]
                            ],
                            "paper_ids": [
                                48,
                                134,
                                262,
                                308,
                                319,
                                409,
                                436,
                                472,
                                484,
                                553,
                                580,
                                630,
                                647,
                                684,
                                709,
                                803,
                                880,
                                963,
                                978,
                                1059,
                                1099,
                                1174,
                                1178,
                                1190,
                                1191,
                                1325,
                                1427,
                                1433,
                                1480,
                                1552,
                                1586,
                                1597,
                                1710,
                                1751,
                                1775,
                                1808,
                                1918,
                                1999,
                                2196,
                                2240,
                                2266,
                                2275,
                                2341,
                                2365,
                                2391,
                                2394,
                                2738,
                                2775,
                                2780
                            ]
                        },
                        {
                            "label": "personalized_dialogue_generation",
                            "description": "This subtopic involves generating dialogue responses that are tailored to individual user preferences and contexts, enhancing user engagement.",
                            "level": 3,
                            "example_papers": [
                                [
                                    436,
                                    "MORPHEUS: Modeling Role from Personalized Dialogue History by Exploring and Utilizing Latent Space"
                                ],
                                [
                                    580,
                                    "\"In-Dialogues We Learn\": Towards Personalized Dialogue Without Pre-defined Profiles through In-Dialogue Learning"
                                ],
                                [
                                    2272,
                                    "Active Listening: Personalized Question Generation in Open-Domain Social Conversation with User Model Based Prompting"
                                ],
                                [
                                    2299,
                                    "Capturing Minds, Not Just Words: Enhancing Role-Playing Language Models with Personality-Indicative Data"
                                ],
                                [
                                    2775,
                                    "Redefining Proactivity for Information Seeking Dialogue"
                                ]
                            ],
                            "paper_ids": [
                                436,
                                580,
                                2272,
                                2299,
                                2775
                            ]
                        },
                        {
                            "label": "dialogue_management",
                            "description": "This subtopic deals with the strategies and techniques for managing the flow of conversation in dialogue systems, ensuring coherent and contextually relevant interactions.",
                            "level": 3,
                            "example_papers": [
                                [
                                    647,
                                    "Red Teaming Language Models for Processing Contradictory Dialogues"
                                ],
                                [
                                    963,
                                    "Inductive-Deductive Strategy Reuse for Multi-Turn Instructional Dialogues"
                                ],
                                [
                                    978,
                                    "MP2D: An Automated Topic Shift Dialogue Generation Framework Leveraging Knowledge Graphs"
                                ],
                                [
                                    1059,
                                    "Unsupervised Extraction of Dialogue Policies from Conversations"
                                ],
                                [
                                    1178,
                                    "Generative Subgraph Retrieval for Knowledge Graph-Grounded Dialog Generation"
                                ],
                                [
                                    1191,
                                    "Beyond Turn-Based Interfaces: Synchronous LLMs as Full-Duplex Dialogue Agents"
                                ],
                                [
                                    1480,
                                    "SMILE: Single-turn to Multi-turn Inclusive Language Expansion via ChatGPT for Mental Health Support"
                                ],
                                [
                                    1597,
                                    "PSLM: Parallel Generation of Text and Speech with LLMs for Low-Latency Spoken Dialogue Systems"
                                ],
                                [
                                    1775,
                                    "TriageAgent: Towards Better Multi-Agents Collaborations for Large Language Model-Based Clinical Triage"
                                ],
                                [
                                    2196,
                                    "Securing Multi-turn Conversational Language Models From Distributed Backdoor Attacks"
                                ]
                            ],
                            "paper_ids": [
                                647,
                                963,
                                978,
                                1059,
                                1178,
                                1191,
                                1480,
                                1597,
                                1775,
                                2196,
                                2240,
                                2275,
                                2289,
                                2295,
                                2341,
                                2391
                            ]
                        },
                        {
                            "label": "evaluation_of_dialogue_systems",
                            "description": "This subtopic focuses on assessing the performance and effectiveness of dialogue systems through various evaluation metrics and methodologies.",
                            "level": 3,
                            "example_papers": [
                                [
                                    48,
                                    "Overcome Noise and Bias: Segmentation-Aided Multi-Granularity Denoising and Debiasing for Enhanced Quarduples Extraction in Dialogue"
                                ],
                                [
                                    307,
                                    "An LLM Feature-based Framework for Dialogue Constructiveness Assessment"
                                ],
                                [
                                    409,
                                    "Incomplete Utterance Rewriting with Editing Operation Guidance and Utterance Augmentation"
                                ],
                                [
                                    544,
                                    "Evaluating the Effectiveness of Large Language Models in Establishing Conversational Grounding"
                                ],
                                [
                                    553,
                                    "Into the Unknown Unknowns: Engaged Human Learning through Participation in Language Model Agent Conversations"
                                ],
                                [
                                    627,
                                    "Do LLMs suffer from Multi-Party Hangover? A Diagnostic Approach to Addressee Recognition and Response Selection in Conversations"
                                ],
                                [
                                    647,
                                    "Red Teaming Language Models for Processing Contradictory Dialogues"
                                ],
                                [
                                    684,
                                    "RA2FD: Distilling Faithfulness into Efficient Dialogue Systems"
                                ],
                                [
                                    803,
                                    "DC-Instruct: An Effective Framework for Generative Multi-intent Spoken Language Understanding"
                                ],
                                [
                                    880,
                                    "Global Reward to Local Rewards: Multimodal-Guided Decomposition for Improving Dialogue Agents"
                                ]
                            ],
                            "paper_ids": [
                                48,
                                307,
                                409,
                                544,
                                553,
                                627,
                                647,
                                684,
                                803,
                                880,
                                882,
                                1559,
                                1710,
                                1751,
                                1975,
                                2113,
                                2130,
                                2228,
                                2266,
                                2341,
                                2394,
                                2738,
                                2780
                            ]
                        }
                    ]
                },
                {
                    "label": "visual_question_answering",
                    "description": "This cluster involves methods that enable models to answer questions based on visual inputs, integrating image understanding with natural language processing.",
                    "level": 2,
                    "example_papers": [
                        [
                            5,
                            "ImageInWords: Unlocking Hyper-Detailed Image Descriptions"
                        ],
                        [
                            87,
                            "Exploring Union and Intersection of Visual Regions for Generating Questions, Answers, and Distractors"
                        ],
                        [
                            90,
                            "MAR: Matching-Augmented Reasoning for Enhancing Visual-based Entity Question Answering"
                        ],
                        [
                            109,
                            "Self-Bootstrapped Visual-Language Model for Knowledge Selection and Question Answering"
                        ],
                        [
                            111,
                            "TinyChart: Efficient Chart Understanding with Program-of-Thoughts Learning and Visual Token Merging"
                        ],
                        [
                            158,
                            "Does Object Grounding Really Reduce Hallucination of Large Vision-Language Models?"
                        ],
                        [
                            193,
                            "Pixology: Probing the Linguistic and Visual Capabilities of Pixel-based Language Models"
                        ],
                        [
                            210,
                            "Decompose and Compare Consistency: Measuring VLMs' Answer Reliability via Task-Decomposition Consistency Comparison"
                        ],
                        [
                            226,
                            "Empowering Large Language Model for Continual Video Question Answering with Collaborative Prompting"
                        ],
                        [
                            264,
                            "World to Code: Multi-modal Data Generation via Self-Instructed Compositional Captioning and Filtering"
                        ]
                    ],
                    "paper_ids": [
                        5,
                        87,
                        90,
                        109,
                        111,
                        158,
                        193,
                        210,
                        226,
                        264,
                        283,
                        286,
                        350,
                        368,
                        386,
                        390,
                        399,
                        417,
                        453,
                        454,
                        459,
                        536,
                        543,
                        555,
                        557,
                        612,
                        632,
                        740,
                        792,
                        797,
                        809,
                        832,
                        857,
                        863,
                        872,
                        894,
                        921,
                        946,
                        956,
                        961,
                        980,
                        997,
                        1027,
                        1041,
                        1058,
                        1061,
                        1062,
                        1071,
                        1085,
                        1099,
                        1116,
                        1118,
                        1150,
                        1190,
                        1208,
                        1246,
                        1248,
                        1249,
                        1269,
                        1293,
                        1402,
                        1460,
                        1490,
                        1514,
                        1519,
                        1529,
                        1530,
                        1534,
                        1548,
                        1553,
                        1605,
                        1608,
                        1622,
                        1637,
                        1653,
                        1667,
                        1691,
                        1714,
                        1758,
                        1788,
                        1812,
                        1830,
                        1888,
                        1929,
                        1933,
                        1939,
                        1947,
                        1952,
                        2021,
                        2040,
                        2045,
                        2095,
                        2113,
                        2115,
                        2150,
                        2156,
                        2205,
                        2216,
                        2222,
                        2419,
                        2431,
                        2436,
                        2460,
                        2516,
                        2518,
                        2755,
                        2810
                    ],
                    "children": [
                        {
                            "label": "image_understanding",
                            "description": "This cluster focuses on methods that enhance the understanding of images to facilitate answering questions related to visual content.",
                            "level": 3,
                            "example_papers": [
                                [
                                    5,
                                    "ImageInWords: Unlocking Hyper-Detailed Image Descriptions"
                                ],
                                [
                                    87,
                                    "Exploring Union and Intersection of Visual Regions for Generating Questions, Answers, and Distractors"
                                ],
                                [
                                    158,
                                    "Does Object Grounding Really Reduce Hallucination of Large Vision-Language Models?"
                                ],
                                [
                                    193,
                                    "Pixology: Probing the Linguistic and Visual Capabilities of Pixel-based Language Models"
                                ],
                                [
                                    368,
                                    "UOUO: Uncontextualized Uncommon Objects for Measuring Knowledge Horizons of Vision Language Models"
                                ],
                                [
                                    454,
                                    "Empowering Backbone Models for Visual Text Generation with Input Granularity Control and Glyph-Aware Training"
                                ],
                                [
                                    792,
                                    "Shaking Up VLMs: Comparing Transformers and Structured State Space Models for Vision & Language Modeling"
                                ],
                                [
                                    863,
                                    "FineCops-Ref: A new Dataset and Task for Fine-Grained Compositional Referring Expression Comprehension"
                                ],
                                [
                                    997,
                                    "Game on Tree: Visual Hallucination Mitigation via Coarse-to-Fine View Tree and Game Theory"
                                ],
                                [
                                    1071,
                                    "Multimodal Self-Instruct: Synthetic Abstract Image and Visual Reasoning Instruction Using Language Model"
                                ]
                            ],
                            "paper_ids": [
                                5,
                                87,
                                158,
                                193,
                                368,
                                454,
                                792,
                                863,
                                997,
                                1071,
                                1402,
                                1514,
                                1529,
                                1548,
                                1653,
                                1788,
                                1933,
                                1947,
                                1952,
                                2436,
                                2518
                            ]
                        },
                        {
                            "label": "visual_reasoning",
                            "description": "This cluster encompasses techniques that involve reasoning about visual information to derive answers to questions posed in natural language.",
                            "level": 3,
                            "example_papers": [
                                [
                                    87,
                                    "Exploring Union and Intersection of Visual Regions for Generating Questions, Answers, and Distractors"
                                ],
                                [
                                    90,
                                    "MAR: Matching-Augmented Reasoning for Enhancing Visual-based Entity Question Answering"
                                ],
                                [
                                    193,
                                    "Pixology: Probing the Linguistic and Visual Capabilities of Pixel-based Language Models"
                                ],
                                [
                                    210,
                                    "Decompose and Compare Consistency: Measuring VLMs' Answer Reliability via Task-Decomposition Consistency Comparison"
                                ],
                                [
                                    283,
                                    "From the Least to the Most: Building a Plug-and-Play Visual Reasoner via Data Synthesis"
                                ],
                                [
                                    350,
                                    "Distilling Knowledge from Text-to-Image Generative Models Improves Visio-Linguistic Reasoning in CLIP"
                                ],
                                [
                                    368,
                                    "UOUO: Uncontextualized Uncommon Objects for Measuring Knowledge Horizons of Vision Language Models"
                                ],
                                [
                                    390,
                                    "Beyond Embeddings: The Promise of Visual Table in Visual Reasoning"
                                ],
                                [
                                    399,
                                    "Encoding and Controlling Global Semantics for Long-form Video Question Answering"
                                ],
                                [
                                    536,
                                    "Attribute Diversity Determines the Systematicity Gap in VQA"
                                ]
                            ],
                            "paper_ids": [
                                87,
                                90,
                                193,
                                210,
                                283,
                                350,
                                368,
                                390,
                                399,
                                536,
                                612,
                                792,
                                809,
                                863,
                                872,
                                946,
                                997,
                                1041,
                                1058,
                                1071,
                                1116,
                                1150,
                                1190,
                                1246,
                                1529,
                                1530,
                                1548,
                                1553,
                                1637,
                                1653,
                                1691,
                                1758,
                                1788,
                                1929,
                                1933,
                                1952,
                                2021,
                                2113,
                                2115,
                                2419,
                                2431,
                                2436,
                                2518
                            ]
                        },
                        {
                            "label": "video_question_answering",
                            "description": "This cluster includes approaches that enable models to answer questions based on video inputs, integrating temporal dynamics with visual understanding.",
                            "level": 3,
                            "example_papers": [
                                [
                                    226,
                                    "Empowering Large Language Model for Continual Video Question Answering with Collaborative Prompting"
                                ],
                                [
                                    399,
                                    "Encoding and Controlling Global Semantics for Long-form Video Question Answering"
                                ],
                                [
                                    543,
                                    "TraveLER: A Modular Multi-LMM Agent Framework for Video Question-Answering"
                                ],
                                [
                                    555,
                                    "Efficient Temporal Extrapolation of Multimodal Large Language Models with Temporal Grounding Bridge"
                                ],
                                [
                                    797,
                                    "ECIS-VQG: Generation of Entity-centric Information-seeking Questions from Videos"
                                ],
                                [
                                    1058,
                                    "TV-TREES: Multimodal Entailment Trees for Neuro-Symbolic Video Reasoning"
                                ],
                                [
                                    1085,
                                    "Video-Text Prompting for Weakly Supervised Spatio-Temporal Video Grounding"
                                ],
                                [
                                    1208,
                                    "A Simple LLM Framework for Long-Range Video Question-Answering"
                                ],
                                [
                                    1248,
                                    "Training-free Deep Concept Injection Enables Language Models for Video Question Answering"
                                ],
                                [
                                    1605,
                                    "Learning Musical Representations for Music Performance Question Answering"
                                ]
                            ],
                            "paper_ids": [
                                226,
                                399,
                                543,
                                555,
                                797,
                                1058,
                                1085,
                                1208,
                                1248,
                                1605,
                                1608,
                                1622,
                                1812,
                                1830,
                                2095,
                                2222
                            ]
                        },
                        {
                            "label": "multimodal_question_answering",
                            "description": "This cluster involves methods that combine information from multiple modalities, such as text and images, to answer questions effectively.",
                            "level": 3,
                            "example_papers": [
                                [
                                    87,
                                    "Exploring Union and Intersection of Visual Regions for Generating Questions, Answers, and Distractors"
                                ],
                                [
                                    90,
                                    "MAR: Matching-Augmented Reasoning for Enhancing Visual-based Entity Question Answering"
                                ],
                                [
                                    109,
                                    "Self-Bootstrapped Visual-Language Model for Knowledge Selection and Question Answering"
                                ],
                                [
                                    111,
                                    "TinyChart: Efficient Chart Understanding with Program-of-Thoughts Learning and Visual Token Merging"
                                ],
                                [
                                    264,
                                    "World to Code: Multi-modal Data Generation via Self-Instructed Compositional Captioning and Filtering"
                                ],
                                [
                                    286,
                                    "MaPPER: Multimodal Prior-guided Parameter Efficient Tuning for Referring Expression Comprehension"
                                ],
                                [
                                    368,
                                    "UOUO: Uncontextualized Uncommon Objects for Measuring Knowledge Horizons of Vision Language Models"
                                ],
                                [
                                    386,
                                    "MMNeuron: Discovering Neuron-Level Domain-Specific Interpretation in Multimodal Large Language Model"
                                ],
                                [
                                    417,
                                    "Towards Injecting Medical Visual Knowledge into Multimodal LLMs at Scale"
                                ],
                                [
                                    454,
                                    "Empowering Backbone Models for Visual Text Generation with Input Granularity Control and Glyph-Aware Training"
                                ]
                            ],
                            "paper_ids": [
                                87,
                                90,
                                109,
                                111,
                                264,
                                286,
                                368,
                                386,
                                417,
                                454,
                                459,
                                555,
                                557,
                                612,
                                632,
                                740,
                                792,
                                809,
                                832,
                                872,
                                894,
                                921,
                                956,
                                980,
                                1027,
                                1058,
                                1061,
                                1062,
                                1099,
                                1116,
                                1150,
                                1190,
                                1246,
                                1249,
                                1269,
                                1293,
                                1490,
                                1514,
                                1519,
                                1529,
                                1530,
                                1534,
                                1553,
                                1605,
                                1667,
                                1691,
                                1714,
                                1788,
                                1812,
                                1888,
                                1929,
                                1933,
                                1952,
                                2040,
                                2045,
                                2095,
                                2113,
                                2115,
                                2156,
                                2205,
                                2216,
                                2222,
                                2419,
                                2431,
                                2436,
                                2460,
                                2516,
                                2755,
                                2810
                            ]
                        },
                        {
                            "label": "medical_visual_question_answering",
                            "description": "This cluster specializes in visual question answering techniques applied in medical contexts, focusing on interpreting medical images and related queries.",
                            "level": 3,
                            "example_papers": [
                                [
                                    417,
                                    "Towards Injecting Medical Visual Knowledge into Multimodal LLMs at Scale"
                                ],
                                [
                                    872,
                                    "ERVQA: A Dataset to Benchmark the Readiness of Large Vision Language Models in Hospital Environments"
                                ],
                                [
                                    961,
                                    "MedCoT: Medical Chain of Thought via Hierarchical Expert"
                                ],
                                [
                                    1118,
                                    "Self-Training Large Language and Vision Assistant for Medical Question Answering"
                                ],
                                [
                                    1667,
                                    "Med-MoE: Mixture of Domain-Specific Experts for Lightweight Medical Vision-Language Models"
                                ]
                            ],
                            "paper_ids": [
                                417,
                                872,
                                961,
                                1118,
                                1667
                            ]
                        }
                    ]
                },
                {
                    "label": "multilingual_question_answering",
                    "description": "This cluster addresses the challenges of answering questions in multiple languages, ensuring accessibility and usability across diverse linguistic backgrounds.",
                    "level": 2,
                    "example_papers": [
                        [
                            146,
                            "Seemingly Plausible Distractors in Multi-Hop Reasoning: Are Large Language Models Attentive Readers?"
                        ],
                        [
                            160,
                            "MoDULA: Mixture of Domain-Specific and Universal LoRA for Multi-Task Learning"
                        ],
                        [
                            185,
                            "Cross-lingual Transfer for Automatic Question Generation by Learning Interrogative Structures in Target Languages"
                        ],
                        [
                            235,
                            "When Is Multilinguality a Curse? Language Modeling for 250 High- and Low-Resource Languages"
                        ],
                        [
                            238,
                            "Teaching LLMs to Abstain across Languages via Multilingual Feedback"
                        ],
                        [
                            321,
                            "Leave No Document Behind: Benchmarking Long-Context LLMs with Extended Multi-Doc QA"
                        ],
                        [
                            407,
                            "Python is Not Always the Best Choice: Embracing Multilingual Program of Thoughts"
                        ],
                        [
                            441,
                            "An Empirical Study of Multilingual Reasoning Distillation for Question Answering"
                        ],
                        [
                            457,
                            "AdaSwitch: Adaptive Switching between Small and Large Agents for Effective Cloud-Local Collaborative Learning"
                        ],
                        [
                            504,
                            "AssistantBench: Can Web Agents Solve Realistic and Time-Consuming Tasks?"
                        ]
                    ],
                    "paper_ids": [
                        146,
                        160,
                        185,
                        235,
                        238,
                        321,
                        407,
                        441,
                        457,
                        504,
                        521,
                        527,
                        624,
                        637,
                        675,
                        769,
                        800,
                        932,
                        941,
                        1025,
                        1144,
                        1278,
                        1312,
                        1375,
                        1450,
                        1481,
                        1534,
                        1571,
                        1586,
                        1603,
                        1641,
                        1707,
                        1724,
                        1734,
                        1752,
                        1811,
                        1859,
                        1921,
                        1954,
                        1968,
                        2113,
                        2136,
                        2251,
                        2290,
                        2362,
                        2365,
                        2423,
                        2535,
                        2600,
                        2605,
                        2625,
                        2628,
                        2679,
                        2698,
                        2713,
                        2752,
                        2772,
                        2799,
                        2800
                    ],
                    "children": [
                        {
                            "label": "evaluation_and_performance",
                            "description": "This cluster focuses on the evaluation methodologies and performance metrics for multilingual question answering systems, including language model evaluation and assessing model performance across diverse languages.",
                            "level": 3,
                            "example_papers": [
                                [
                                    146,
                                    "Seemingly Plausible Distractors in Multi-Hop Reasoning: Are Large Language Models Attentive Readers?"
                                ],
                                [
                                    160,
                                    "MoDULA: Mixture of Domain-Specific and Universal LoRA for Multi-Task Learning"
                                ],
                                [
                                    321,
                                    "Leave No Document Behind: Benchmarking Long-Context LLMs with Extended Multi-Doc QA"
                                ],
                                [
                                    504,
                                    "AssistantBench: Can Web Agents Solve Realistic and Time-Consuming Tasks?"
                                ],
                                [
                                    932,
                                    "Investigating Large Language Models for Complex Word Identification in Multilingual and Multidomain Setups"
                                ],
                                [
                                    1571,
                                    "EconLogicQA: A Question-Answering Benchmark for Evaluating Large Language Models in Economic Sequential Reasoning"
                                ],
                                [
                                    1724,
                                    "QRMeM: Unleash the Length Limitation through Question then Reflection Memory Mechanism"
                                ],
                                [
                                    1859,
                                    "TurkishMMLU: Measuring Massive Multitask Language Understanding in Turkish"
                                ],
                                [
                                    2365,
                                    "A Pointer Network-based Approach for Joint Extraction and Detection of Multi-Label Multi-Class Intents"
                                ],
                                [
                                    2600,
                                    "MLissard: Multilingual Long and Simple Sequential Reasoning Benchmarks"
                                ]
                            ],
                            "paper_ids": [
                                146,
                                160,
                                321,
                                504,
                                932,
                                1571,
                                1724,
                                1859,
                                2365,
                                2600,
                                2605,
                                2625,
                                2698,
                                2752
                            ]
                        },
                        {
                            "label": "dataset_and_resource_development",
                            "description": "This cluster encompasses the creation and utilization of datasets and resources specifically designed for multilingual question answering, including dataset generation and language resources for low-resource languages.",
                            "level": 3,
                            "example_papers": [
                                [
                                    160,
                                    "MoDULA: Mixture of Domain-Specific and Universal LoRA for Multi-Task Learning"
                                ],
                                [
                                    185,
                                    "Cross-lingual Transfer for Automatic Question Generation by Learning Interrogative Structures in Target Languages"
                                ],
                                [
                                    235,
                                    "When Is Multilinguality a Curse? Language Modeling for 250 High- and Low-Resource Languages"
                                ],
                                [
                                    238,
                                    "Teaching LLMs to Abstain across Languages via Multilingual Feedback"
                                ],
                                [
                                    321,
                                    "Leave No Document Behind: Benchmarking Long-Context LLMs with Extended Multi-Doc QA"
                                ],
                                [
                                    504,
                                    "AssistantBench: Can Web Agents Solve Realistic and Time-Consuming Tasks?"
                                ],
                                [
                                    521,
                                    "RuBLiMP: Russian Benchmark of Linguistic Minimal Pairs"
                                ],
                                [
                                    624,
                                    "Unlocking Markets: A Multilingual Benchmark to Cross-Market Question Answering"
                                ],
                                [
                                    637,
                                    "TEMA: Token Embeddings Mapping for Enriching Low-Resource Language Models"
                                ],
                                [
                                    800,
                                    "ASL STEM Wiki: Dataset and Benchmark for Interpreting STEM Articles"
                                ]
                            ],
                            "paper_ids": [
                                160,
                                185,
                                235,
                                238,
                                321,
                                504,
                                521,
                                624,
                                637,
                                800,
                                1025,
                                1144,
                                1278,
                                1312,
                                1375,
                                1450,
                                1481,
                                1534,
                                1571,
                                1586,
                                1641,
                                1707,
                                1734,
                                1752,
                                1811,
                                1859,
                                1921,
                                1954,
                                1968,
                                2113,
                                2136,
                                2251,
                                2365,
                                2600,
                                2625,
                                2628,
                                2679,
                                2698,
                                2713,
                                2752,
                                2799,
                                2800
                            ]
                        },
                        {
                            "label": "cross_lingual_and_transfer_learning",
                            "description": "This cluster addresses techniques and methodologies related to cross-lingual transfer learning and adaptation, facilitating the application of models across different languages and domains.",
                            "level": 3,
                            "example_papers": [
                                [
                                    160,
                                    "MoDULA: Mixture of Domain-Specific and Universal LoRA for Multi-Task Learning"
                                ],
                                [
                                    185,
                                    "Cross-lingual Transfer for Automatic Question Generation by Learning Interrogative Structures in Target Languages"
                                ],
                                [
                                    235,
                                    "When Is Multilinguality a Curse? Language Modeling for 250 High- and Low-Resource Languages"
                                ],
                                [
                                    238,
                                    "Teaching LLMs to Abstain across Languages via Multilingual Feedback"
                                ],
                                [
                                    407,
                                    "Python is Not Always the Best Choice: Embracing Multilingual Program of Thoughts"
                                ],
                                [
                                    504,
                                    "AssistantBench: Can Web Agents Solve Realistic and Time-Consuming Tasks?"
                                ],
                                [
                                    624,
                                    "Unlocking Markets: A Multilingual Benchmark to Cross-Market Question Answering"
                                ],
                                [
                                    637,
                                    "TEMA: Token Embeddings Mapping for Enriching Low-Resource Language Models"
                                ],
                                [
                                    675,
                                    "TL-CL: Task And Language Incremental Continual Learning"
                                ],
                                [
                                    769,
                                    "Pre-training Cross-lingual Open Domain Question Answering with Large-scale Synthetic Supervision"
                                ]
                            ],
                            "paper_ids": [
                                160,
                                185,
                                235,
                                238,
                                407,
                                504,
                                624,
                                637,
                                675,
                                769,
                                1144,
                                1312,
                                1375,
                                1450,
                                1534,
                                1586,
                                1603,
                                1811,
                                1921,
                                1954,
                                2251,
                                2290,
                                2362,
                                2605,
                                2625,
                                2628,
                                2772,
                                2799,
                                2800
                            ]
                        },
                        {
                            "label": "multilingual_reasoning_and_understanding",
                            "description": "This cluster explores advanced reasoning techniques and understanding mechanisms in multilingual contexts, including multilingual reasoning distillation and multistep reasoning.",
                            "level": 3,
                            "example_papers": [
                                [
                                    146,
                                    "Seemingly Plausible Distractors in Multi-Hop Reasoning: Are Large Language Models Attentive Readers?"
                                ],
                                [
                                    160,
                                    "MoDULA: Mixture of Domain-Specific and Universal LoRA for Multi-Task Learning"
                                ],
                                [
                                    238,
                                    "Teaching LLMs to Abstain across Languages via Multilingual Feedback"
                                ],
                                [
                                    407,
                                    "Python is Not Always the Best Choice: Embracing Multilingual Program of Thoughts"
                                ],
                                [
                                    441,
                                    "An Empirical Study of Multilingual Reasoning Distillation for Question Answering"
                                ],
                                [
                                    504,
                                    "AssistantBench: Can Web Agents Solve Realistic and Time-Consuming Tasks?"
                                ],
                                [
                                    527,
                                    "Structure Guided Prompt: Instructing Large Language Model in Multi-Step Reasoning by Exploring Graph Structure of the Text"
                                ],
                                [
                                    624,
                                    "Unlocking Markets: A Multilingual Benchmark to Cross-Market Question Answering"
                                ],
                                [
                                    1025,
                                    "CasiMedicos-Arg: A Medical Question Answering Dataset Annotated with Explanatory Argumentative Structures"
                                ],
                                [
                                    1312,
                                    "Sailor: Open Language Models for South-East Asia"
                                ]
                            ],
                            "paper_ids": [
                                146,
                                160,
                                238,
                                407,
                                441,
                                504,
                                527,
                                624,
                                1025,
                                1312,
                                1450,
                                1707,
                                2251,
                                2290,
                                2362,
                                2423,
                                2625,
                                2628,
                                2772
                            ]
                        },
                        {
                            "label": "interactive_and_collaborative_learning",
                            "description": "This cluster investigates interactive and collaborative learning approaches in multilingual question answering, focusing on methods like cloud-local collaborative learning and interactive learning strategies.",
                            "level": 3,
                            "example_papers": [
                                [
                                    160,
                                    "MoDULA: Mixture of Domain-Specific and Universal LoRA for Multi-Task Learning"
                                ],
                                [
                                    457,
                                    "AdaSwitch: Adaptive Switching between Small and Large Agents for Effective Cloud-Local Collaborative Learning"
                                ],
                                [
                                    504,
                                    "AssistantBench: Can Web Agents Solve Realistic and Time-Consuming Tasks?"
                                ],
                                [
                                    1450,
                                    "General Collaborative Framework between Large Language Model and Experts for Universal Information Extraction"
                                ],
                                [
                                    2799,
                                    "AI-Tutor: Interactive Learning of Ancient Knowledge from Low-Resource Languages"
                                ]
                            ],
                            "paper_ids": [
                                160,
                                457,
                                504,
                                1450,
                                2799
                            ]
                        }
                    ]
                },
                {
                    "label": "explanation_generation",
                    "description": "This cluster focuses on generating explanations for answers provided by question answering systems, enhancing transparency and user understanding.",
                    "level": 2,
                    "example_papers": [
                        [
                            19,
                            "Learning Planning-based Reasoning by Trajectories Collection and Process Reward Synthesizing"
                        ],
                        [
                            124,
                            "Advancing Process Verification for Large Language Models via Tree-Based Preference Learning"
                        ],
                        [
                            127,
                            "LogicAsker: Evaluating and Improving the Logical Reasoning Ability of Large Language Models"
                        ],
                        [
                            167,
                            "KB-Plugin: A Plug-and-play Framework for Large Language Models to Induce Programs over Low-resourced Knowledge Bases"
                        ],
                        [
                            171,
                            "Verification and Refinement of Natural Language Explanations through LLM-Symbolic Theorem Proving"
                        ],
                        [
                            190,
                            "Neuron-Level Knowledge Attribution in Large Language Models"
                        ],
                        [
                            204,
                            "CoTKR: Chain-of-Thought Enhanced Knowledge Rewriting for Complex Knowledge Graph Question Answering"
                        ],
                        [
                            222,
                            "Advancing Large Language Model Attribution through Self-Improving"
                        ],
                        [
                            251,
                            "ARES: Alternating Reinforcement Learning and Supervised Fine-Tuning for Enhanced Multi-Modal Chain-of-Thought Reasoning Through Diverse AI Feedback"
                        ],
                        [
                            279,
                            "An Unsupervised Approach to Achieve Supervised-Level Explainability in Healthcare Records"
                        ]
                    ],
                    "paper_ids": [
                        19,
                        124,
                        127,
                        167,
                        171,
                        190,
                        204,
                        222,
                        251,
                        279,
                        332,
                        346,
                        431,
                        477,
                        522,
                        530,
                        582,
                        593,
                        604,
                        614,
                        647,
                        656,
                        685,
                        691,
                        705,
                        713,
                        733,
                        746,
                        756,
                        760,
                        816,
                        870,
                        874,
                        904,
                        919,
                        955,
                        977,
                        984,
                        1017,
                        1025,
                        1050,
                        1051,
                        1170,
                        1293,
                        1430,
                        1450,
                        1459,
                        1469,
                        1474,
                        1477,
                        1492,
                        1530,
                        1557,
                        1563,
                        1576,
                        1636,
                        1640,
                        1693,
                        1734,
                        1746,
                        1759,
                        1809,
                        1838,
                        1854,
                        1861,
                        1904,
                        1923,
                        1997,
                        2002,
                        2066,
                        2109,
                        2113,
                        2130,
                        2136,
                        2243,
                        2288,
                        2313,
                        2328,
                        2412,
                        2414,
                        2426,
                        2427,
                        2429,
                        2481,
                        2482,
                        2493,
                        2494,
                        2653,
                        2749,
                        2775,
                        2951
                    ],
                    "children": [
                        {
                            "label": "explanation_generation_for_qa",
                            "description": "This cluster focuses on generating explanations specifically tailored for answers provided by question answering systems, enhancing the clarity and understanding of the responses.",
                            "level": 3,
                            "example_papers": [
                                [
                                    124,
                                    "Advancing Process Verification for Large Language Models via Tree-Based Preference Learning"
                                ],
                                [
                                    167,
                                    "KB-Plugin: A Plug-and-play Framework for Large Language Models to Induce Programs over Low-resourced Knowledge Bases"
                                ],
                                [
                                    204,
                                    "CoTKR: Chain-of-Thought Enhanced Knowledge Rewriting for Complex Knowledge Graph Question Answering"
                                ],
                                [
                                    222,
                                    "Advancing Large Language Model Attribution through Self-Improving"
                                ],
                                [
                                    251,
                                    "ARES: Alternating Reinforcement Learning and Supervised Fine-Tuning for Enhanced Multi-Modal Chain-of-Thought Reasoning Through Diverse AI Feedback"
                                ],
                                [
                                    346,
                                    "Model Internals-based Answer Attribution for Trustworthy Retrieval-Augmented Generation"
                                ],
                                [
                                    431,
                                    "XplainLLM: A Knowledge-Augmented Dataset for Reliable Grounded Explanations in LLMs"
                                ],
                                [
                                    477,
                                    "Stepwise Verification and Remediation of Student Reasoning Errors with Large Language Model Tutors"
                                ],
                                [
                                    530,
                                    "Enhancing Systematic Decompositional Natural Language Inference Using Informal Logic"
                                ],
                                [
                                    582,
                                    "Enhancing Language Model Factuality via Activation-Based Confidence Calibration and Guided Decoding"
                                ]
                            ],
                            "paper_ids": [
                                124,
                                167,
                                204,
                                222,
                                251,
                                346,
                                431,
                                477,
                                530,
                                582,
                                593,
                                604,
                                614,
                                647,
                                656,
                                705,
                                713,
                                733,
                                756,
                                904,
                                955,
                                984,
                                1017,
                                1051,
                                1170,
                                1293,
                                1459,
                                1477,
                                1492,
                                1530,
                                1557,
                                1563,
                                1576,
                                1746,
                                1759,
                                1861,
                                1904,
                                1923,
                                1997,
                                2002,
                                2066,
                                2109,
                                2113,
                                2136,
                                2243,
                                2288,
                                2313,
                                2328,
                                2412,
                                2414,
                                2427,
                                2482,
                                2493,
                                2494,
                                2749,
                                2951
                            ]
                        },
                        {
                            "label": "evaluation_of_explanations",
                            "description": "This cluster encompasses methods and approaches for evaluating the quality and effectiveness of generated explanations in various contexts.",
                            "level": 3,
                            "example_papers": [
                                [
                                    124,
                                    "Advancing Process Verification for Large Language Models via Tree-Based Preference Learning"
                                ],
                                [
                                    127,
                                    "LogicAsker: Evaluating and Improving the Logical Reasoning Ability of Large Language Models"
                                ],
                                [
                                    171,
                                    "Verification and Refinement of Natural Language Explanations through LLM-Symbolic Theorem Proving"
                                ],
                                [
                                    431,
                                    "XplainLLM: A Knowledge-Augmented Dataset for Reliable Grounded Explanations in LLMs"
                                ],
                                [
                                    477,
                                    "Stepwise Verification and Remediation of Student Reasoning Errors with Large Language Model Tutors"
                                ],
                                [
                                    530,
                                    "Enhancing Systematic Decompositional Natural Language Inference Using Informal Logic"
                                ],
                                [
                                    733,
                                    "FAC^2E: Better Understanding Large Language Model Capabilities by Dissociating Language and Cognition"
                                ],
                                [
                                    1050,
                                    "Fool Me Once? Contrasting Textual and Visual Explanations in a Clinical Decision-Support Setting"
                                ],
                                [
                                    1170,
                                    "I love pineapple on pizza != I hate pineapple on pizza: Stance-Aware Sentence Transformers for Opinion Mining"
                                ],
                                [
                                    1576,
                                    "Faithful and Plausible Natural Language Explanations for Image Classification: A Pipeline Approach"
                                ]
                            ],
                            "paper_ids": [
                                124,
                                127,
                                171,
                                431,
                                477,
                                530,
                                733,
                                1050,
                                1170,
                                1576,
                                1904,
                                2066,
                                2113,
                                2130,
                                2243,
                                2288,
                                2482
                            ]
                        },
                        {
                            "label": "knowledge_attribution",
                            "description": "This cluster deals with the processes of attributing knowledge sources to generated explanations, ensuring that the reasoning behind answers is transparent and traceable.",
                            "level": 3,
                            "example_papers": [
                                [
                                    190,
                                    "Neuron-Level Knowledge Attribution in Large Language Models"
                                ],
                                [
                                    346,
                                    "Model Internals-based Answer Attribution for Trustworthy Retrieval-Augmented Generation"
                                ],
                                [
                                    431,
                                    "XplainLLM: A Knowledge-Augmented Dataset for Reliable Grounded Explanations in LLMs"
                                ],
                                [
                                    733,
                                    "FAC^2E: Better Understanding Large Language Model Capabilities by Dissociating Language and Cognition"
                                ],
                                [
                                    984,
                                    "Enhancing Post-Hoc Attributions in Long Document Comprehension via Coarse Grained Answer Decomposition"
                                ],
                                [
                                    1293,
                                    "MATSA: Multi-Agent Table Structure Attribution"
                                ],
                                [
                                    1459,
                                    "CoTAR: Chain-of-Thought Attribution Reasoning with Multi-level Granularity"
                                ],
                                [
                                    1576,
                                    "Faithful and Plausible Natural Language Explanations for Image Classification: A Pipeline Approach"
                                ],
                                [
                                    2482,
                                    "Wrapper Boxes for Faithful Attribution of Model Predictions to Training Data"
                                ]
                            ],
                            "paper_ids": [
                                190,
                                346,
                                431,
                                733,
                                984,
                                1293,
                                1459,
                                1576,
                                2482
                            ]
                        },
                        {
                            "label": "generating_explanations_for_reasoning_processes",
                            "description": "This cluster focuses on creating explanations that elucidate the reasoning processes behind decisions made by AI systems, enhancing interpretability.",
                            "level": 3,
                            "example_papers": [
                                [
                                    19,
                                    "Learning Planning-based Reasoning by Trajectories Collection and Process Reward Synthesizing"
                                ],
                                [
                                    124,
                                    "Advancing Process Verification for Large Language Models via Tree-Based Preference Learning"
                                ],
                                [
                                    127,
                                    "LogicAsker: Evaluating and Improving the Logical Reasoning Ability of Large Language Models"
                                ],
                                [
                                    171,
                                    "Verification and Refinement of Natural Language Explanations through LLM-Symbolic Theorem Proving"
                                ],
                                [
                                    222,
                                    "Advancing Large Language Model Attribution through Self-Improving"
                                ],
                                [
                                    332,
                                    "Teaching Small Language Models Reasoning through Counterfactual Distillation"
                                ],
                                [
                                    431,
                                    "XplainLLM: A Knowledge-Augmented Dataset for Reliable Grounded Explanations in LLMs"
                                ],
                                [
                                    477,
                                    "Stepwise Verification and Remediation of Student Reasoning Errors with Large Language Model Tutors"
                                ],
                                [
                                    530,
                                    "Enhancing Systematic Decompositional Natural Language Inference Using Informal Logic"
                                ],
                                [
                                    614,
                                    "Self-AMPLIFY: Improving Small Language Models with Self Post Hoc Explanations"
                                ]
                            ],
                            "paper_ids": [
                                19,
                                124,
                                127,
                                171,
                                222,
                                332,
                                431,
                                477,
                                530,
                                614,
                                647,
                                733,
                                816,
                                870,
                                874,
                                904,
                                919,
                                1170,
                                1492,
                                1576,
                                1636,
                                1838,
                                1904,
                                2066,
                                2113,
                                2243,
                                2288,
                                2313,
                                2328,
                                2482,
                                2951
                            ]
                        },
                        {
                            "label": "explanation_generation_for_specialized_domains",
                            "description": "This cluster targets the generation of explanations within specialized domains, such as healthcare or legal contexts, ensuring that the explanations are relevant and contextually appropriate.",
                            "level": 3,
                            "example_papers": [
                                [
                                    167,
                                    "KB-Plugin: A Plug-and-play Framework for Large Language Models to Induce Programs over Low-resourced Knowledge Bases"
                                ],
                                [
                                    171,
                                    "Verification and Refinement of Natural Language Explanations through LLM-Symbolic Theorem Proving"
                                ],
                                [
                                    279,
                                    "An Unsupervised Approach to Achieve Supervised-Level Explainability in Healthcare Records"
                                ],
                                [
                                    431,
                                    "XplainLLM: A Knowledge-Augmented Dataset for Reliable Grounded Explanations in LLMs"
                                ],
                                [
                                    522,
                                    "Text-Tuple-Table: Towards Information Integration in Text-to-Table Generation via Global Tuple Extraction"
                                ],
                                [
                                    614,
                                    "Self-AMPLIFY: Improving Small Language Models with Self Post Hoc Explanations"
                                ],
                                [
                                    656,
                                    "\"A good pun is its own reword\": Can Large Language Models Understand Puns?"
                                ],
                                [
                                    685,
                                    "Subjective Topic meets LLMs: Unleashing Comprehensive, Reflective and Creative Thinking through the Negation of Negation"
                                ],
                                [
                                    733,
                                    "FAC^2E: Better Understanding Large Language Model Capabilities by Dissociating Language and Cognition"
                                ],
                                [
                                    746,
                                    "Grasping the Essentials: Tailoring Large Language Models for Zero-Shot Relation Extraction"
                                ]
                            ],
                            "paper_ids": [
                                167,
                                171,
                                279,
                                431,
                                522,
                                614,
                                656,
                                685,
                                733,
                                746,
                                760,
                                977,
                                1025,
                                1050,
                                1051,
                                1170,
                                1430,
                                1469,
                                1474,
                                1477,
                                1557,
                                1576,
                                1640,
                                1693,
                                1734,
                                1854,
                                1861,
                                1904,
                                1997,
                                2002,
                                2066,
                                2113,
                                2243,
                                2288,
                                2412,
                                2426,
                                2429,
                                2481,
                                2482,
                                2653,
                                2749,
                                2951
                            ]
                        }
                    ]
                },
                {
                    "label": "in_context_question_answering",
                    "description": "This cluster focuses on techniques that leverage contextual information to enhance the accuracy and relevance of answers in question answering tasks.",
                    "level": 2,
                    "example_papers": [
                        [
                            13,
                            "A Usage-centric Take on Intent Understanding in E-Commerce"
                        ],
                        [
                            14,
                            "Fine-Tuning or Retrieval? Comparing Knowledge Injection in LLMs"
                        ],
                        [
                            15,
                            "Systematic Biases in LLM Simulations of Debates"
                        ],
                        [
                            17,
                            "Uncertainty in Language Models: Assessment through Rank-Calibration"
                        ],
                        [
                            19,
                            "Learning Planning-based Reasoning by Trajectories Collection and Process Reward Synthesizing"
                        ],
                        [
                            39,
                            "Tokenization Is More Than Compression"
                        ],
                        [
                            42,
                            "Parameter-Efficient Sparsity Crafting from Dense to Mixture-of-Experts for Instruction Tuning on General Tasks"
                        ],
                        [
                            47,
                            "Making Large Language Models Better Reasoners with Orchestrated Streaming Experiences"
                        ],
                        [
                            48,
                            "Overcome Noise and Bias: Segmentation-Aided Multi-Granularity Denoising and Debiasing for Enhanced Quarduples Extraction in Dialogue"
                        ],
                        [
                            50,
                            "In-context Contrastive Learning for Event Causality Identification"
                        ]
                    ],
                    "paper_ids": [
                        13,
                        14,
                        15,
                        17,
                        19,
                        39,
                        42,
                        47,
                        48,
                        50,
                        52,
                        63,
                        71,
                        75,
                        80,
                        91,
                        100,
                        101,
                        118,
                        120,
                        124,
                        127,
                        129,
                        134,
                        137,
                        139,
                        145,
                        146,
                        149,
                        154,
                        155,
                        163,
                        167,
                        172,
                        173,
                        174,
                        186,
                        204,
                        210,
                        211,
                        220,
                        222,
                        225,
                        228,
                        233,
                        238,
                        241,
                        251,
                        265,
                        266,
                        273,
                        276,
                        287,
                        296,
                        299,
                        300,
                        306,
                        307,
                        308,
                        311,
                        312,
                        315,
                        319,
                        320,
                        321,
                        332,
                        347,
                        348,
                        358,
                        360,
                        375,
                        380,
                        393,
                        398,
                        402,
                        405,
                        434,
                        442,
                        443,
                        457,
                        460,
                        464,
                        474,
                        476,
                        477,
                        483,
                        489,
                        494,
                        503,
                        504,
                        508,
                        511,
                        522,
                        527,
                        529,
                        530,
                        535,
                        540,
                        544,
                        545,
                        549,
                        553,
                        559,
                        567,
                        570,
                        573,
                        577,
                        579,
                        580,
                        582,
                        585,
                        593,
                        594,
                        596,
                        605,
                        614,
                        628,
                        631,
                        636,
                        649,
                        653,
                        657,
                        658,
                        662,
                        667,
                        676,
                        679,
                        684,
                        685,
                        686,
                        688,
                        689,
                        702,
                        705,
                        713,
                        724,
                        732,
                        733,
                        741,
                        746,
                        756,
                        761,
                        762,
                        776,
                        778,
                        780,
                        782,
                        792,
                        794,
                        803,
                        804,
                        806,
                        813,
                        814,
                        816,
                        830,
                        846,
                        849,
                        853,
                        854,
                        862,
                        870,
                        873,
                        874,
                        879,
                        882,
                        892,
                        904,
                        911,
                        914,
                        919,
                        925,
                        928,
                        939,
                        948,
                        954,
                        955,
                        960,
                        973,
                        974,
                        976,
                        977,
                        978,
                        980,
                        984,
                        992,
                        995,
                        1003,
                        1006,
                        1017,
                        1020,
                        1022,
                        1025,
                        1031,
                        1035,
                        1036,
                        1073,
                        1109,
                        1110,
                        1111,
                        1112,
                        1113,
                        1129,
                        1139,
                        1140,
                        1145,
                        1148,
                        1157,
                        1159,
                        1161,
                        1162,
                        1170,
                        1192,
                        1195,
                        1201,
                        1211,
                        1219,
                        1230,
                        1232,
                        1235,
                        1243,
                        1244,
                        1246,
                        1250,
                        1252,
                        1254,
                        1258,
                        1260,
                        1288,
                        1293,
                        1308,
                        1325,
                        1332,
                        1334,
                        1337,
                        1342,
                        1344,
                        1346,
                        1357,
                        1374,
                        1375,
                        1378,
                        1379,
                        1396,
                        1404,
                        1427,
                        1433,
                        1435,
                        1439,
                        1441,
                        1450,
                        1457,
                        1459,
                        1469,
                        1472,
                        1477,
                        1481,
                        1485,
                        1491,
                        1492,
                        1494,
                        1498,
                        1500,
                        1509,
                        1511,
                        1521,
                        1527,
                        1530,
                        1532,
                        1537,
                        1539,
                        1540,
                        1541,
                        1547,
                        1550,
                        1552,
                        1555,
                        1556,
                        1557,
                        1559,
                        1562,
                        1563,
                        1565,
                        1567,
                        1569,
                        1571,
                        1573,
                        1577,
                        1580,
                        1581,
                        1582,
                        1588,
                        1591,
                        1599,
                        1609,
                        1610,
                        1616,
                        1618,
                        1625,
                        1628,
                        1636,
                        1638,
                        1641,
                        1643,
                        1647,
                        1651,
                        1652,
                        1655,
                        1659,
                        1667,
                        1674,
                        1680,
                        1685,
                        1688,
                        1699,
                        1724,
                        1727,
                        1734,
                        1737,
                        1739,
                        1746,
                        1752,
                        1753,
                        1755,
                        1764,
                        1767,
                        1768,
                        1769,
                        1772,
                        1775,
                        1793,
                        1796,
                        1805,
                        1809,
                        1832,
                        1836,
                        1838,
                        1843,
                        1849,
                        1854,
                        1856,
                        1858,
                        1859,
                        1860,
                        1875,
                        1876,
                        1882,
                        1884,
                        1892,
                        1904,
                        1905,
                        1909,
                        1921,
                        1923,
                        1927,
                        1936,
                        1941,
                        1942,
                        1950,
                        1955,
                        1970,
                        1971,
                        1973,
                        1992,
                        1994,
                        1999,
                        2005,
                        2019,
                        2022,
                        2033,
                        2034,
                        2035,
                        2038,
                        2041,
                        2048,
                        2049,
                        2063,
                        2064,
                        2065,
                        2068,
                        2069,
                        2100,
                        2109,
                        2113,
                        2136,
                        2139,
                        2145,
                        2150,
                        2161,
                        2167,
                        2168,
                        2184,
                        2188,
                        2192,
                        2193,
                        2203,
                        2205,
                        2215,
                        2216,
                        2231,
                        2243,
                        2244,
                        2247,
                        2254,
                        2255,
                        2266,
                        2267,
                        2277,
                        2281,
                        2288,
                        2290,
                        2313,
                        2317,
                        2318,
                        2325,
                        2328,
                        2329,
                        2337,
                        2340,
                        2342,
                        2346,
                        2354,
                        2361,
                        2384,
                        2386,
                        2392,
                        2394,
                        2407,
                        2410,
                        2412,
                        2414,
                        2423,
                        2426,
                        2427,
                        2429,
                        2430,
                        2432,
                        2433,
                        2462,
                        2463,
                        2467,
                        2480,
                        2484,
                        2489,
                        2494,
                        2496,
                        2507,
                        2508,
                        2513,
                        2522,
                        2542,
                        2552,
                        2567,
                        2597,
                        2599,
                        2604,
                        2605,
                        2653,
                        2680,
                        2713,
                        2721,
                        2735,
                        2738,
                        2755,
                        2800
                    ],
                    "children": [
                        {
                            "label": "contextual_learning_techniques",
                            "description": "This cluster focuses on various learning techniques that utilize contextual information to improve the performance of question answering systems, including in-context learning, few-shot learning, and multi-task learning.",
                            "level": 3,
                            "example_papers": [
                                [
                                    50,
                                    "In-context Contrastive Learning for Event Causality Identification"
                                ],
                                [
                                    63,
                                    "A Survey on In-context Learning"
                                ],
                                [
                                    101,
                                    "MetaGPT: Merging Large Language Models Using Model Exclusive Task Arithmetic"
                                ],
                                [
                                    129,
                                    "FuseGen: PLM Fusion for Data-generation based Zero-shot Learning"
                                ],
                                [
                                    154,
                                    "Whispers that Shake Foundations: Analyzing and Mitigating False Premise Hallucinations in Large Language Models"
                                ],
                                [
                                    228,
                                    "Dancing in Chains: Reconciling Instruction Following and Faithfulness in Language Models"
                                ],
                                [
                                    296,
                                    "Induct-Learn: Short Phrase Prompting with Instruction Induction"
                                ],
                                [
                                    315,
                                    "Predicting Rewards Alongside Tokens: Non-disruptive Parameter Insertion for Efficient Inference Intervention in Large Language Model"
                                ],
                                [
                                    319,
                                    "Synergizing In-context Learning with Hints for End-to-end Task-oriented Dialog Systems"
                                ],
                                [
                                    358,
                                    "Focused Large Language Models are Stable Many-Shot Learners"
                                ]
                            ],
                            "paper_ids": [
                                50,
                                63,
                                101,
                                129,
                                154,
                                228,
                                296,
                                315,
                                319,
                                358,
                                405,
                                464,
                                494,
                                508,
                                511,
                                529,
                                559,
                                570,
                                573,
                                605,
                                614,
                                628,
                                662,
                                685,
                                686,
                                688,
                                713,
                                746,
                                761,
                                778,
                                794,
                                846,
                                892,
                                960,
                                974,
                                984,
                                995,
                                1140,
                                1145,
                                1157,
                                1293,
                                1374,
                                1433,
                                1509,
                                1511,
                                1521,
                                1609,
                                1628,
                                1652,
                                1685,
                                1764,
                                1767,
                                1768,
                                1772,
                                1849,
                                1884,
                                1950,
                                1973,
                                1999,
                                2109,
                                2136,
                                2188,
                                2215,
                                2216,
                                2317,
                                2346,
                                2361,
                                2384,
                                2386,
                                2394,
                                2407,
                                2410,
                                2414,
                                2462,
                                2542,
                                2755
                            ]
                        },
                        {
                            "label": "enhanced_reasoning_methods",
                            "description": "This cluster encompasses methods aimed at enhancing reasoning capabilities in question answering, such as multi-step reasoning, causal reasoning, and complex reasoning approaches.",
                            "level": 3,
                            "example_papers": [
                                [
                                    19,
                                    "Learning Planning-based Reasoning by Trajectories Collection and Process Reward Synthesizing"
                                ],
                                [
                                    47,
                                    "Making Large Language Models Better Reasoners with Orchestrated Streaming Experiences"
                                ],
                                [
                                    50,
                                    "In-context Contrastive Learning for Event Causality Identification"
                                ],
                                [
                                    80,
                                    "A New Pipeline for Knowledge Graph Reasoning Enhanced by Large Language Models Without Fine-Tuning"
                                ],
                                [
                                    124,
                                    "Advancing Process Verification for Large Language Models via Tree-Based Preference Learning"
                                ],
                                [
                                    127,
                                    "LogicAsker: Evaluating and Improving the Logical Reasoning Ability of Large Language Models"
                                ],
                                [
                                    146,
                                    "Seemingly Plausible Distractors in Multi-Hop Reasoning: Are Large Language Models Attentive Readers?"
                                ],
                                [
                                    204,
                                    "CoTKR: Chain-of-Thought Enhanced Knowledge Rewriting for Complex Knowledge Graph Question Answering"
                                ],
                                [
                                    220,
                                    "PTD-SQL: Partitioning and Targeted Drilling with LLMs in Text-to-SQL"
                                ],
                                [
                                    251,
                                    "ARES: Alternating Reinforcement Learning and Supervised Fine-Tuning for Enhanced Multi-Modal Chain-of-Thought Reasoning Through Diverse AI Feedback"
                                ]
                            ],
                            "paper_ids": [
                                19,
                                47,
                                50,
                                80,
                                124,
                                127,
                                146,
                                204,
                                220,
                                251,
                                266,
                                273,
                                300,
                                306,
                                312,
                                332,
                                360,
                                380,
                                393,
                                402,
                                457,
                                503,
                                527,
                                570,
                                579,
                                585,
                                628,
                                649,
                                653,
                                685,
                                780,
                                803,
                                806,
                                813,
                                816,
                                853,
                                862,
                                870,
                                874,
                                904,
                                911,
                                914,
                                919,
                                973,
                                976,
                                1022,
                                1110,
                                1159,
                                1162,
                                1192,
                                1211,
                                1232,
                                1244,
                                1246,
                                1252,
                                1334,
                                1459,
                                1477,
                                1492,
                                1537,
                                1556,
                                1562,
                                1573,
                                1581,
                                1610,
                                1647,
                                1652,
                                1659,
                                1674,
                                1699,
                                1753,
                                1775,
                                1809,
                                1838,
                                1875,
                                1892,
                                1909,
                                1936,
                                1942,
                                1999,
                                2019,
                                2033,
                                2035,
                                2049,
                                2063,
                                2069,
                                2113,
                                2145,
                                2161,
                                2167,
                                2277,
                                2290,
                                2318,
                                2328,
                                2354,
                                2412,
                                2414,
                                2423,
                                2426,
                                2427,
                                2432
                            ]
                        },
                        {
                            "label": "knowledge_utilization_strategies",
                            "description": "This cluster highlights strategies for effectively utilizing knowledge in question answering tasks, including knowledge distillation, knowledge injection, and knowledge graph reasoning.",
                            "level": 3,
                            "example_papers": [
                                [
                                    13,
                                    "A Usage-centric Take on Intent Understanding in E-Commerce"
                                ],
                                [
                                    14,
                                    "Fine-Tuning or Retrieval? Comparing Knowledge Injection in LLMs"
                                ],
                                [
                                    42,
                                    "Parameter-Efficient Sparsity Crafting from Dense to Mixture-of-Experts for Instruction Tuning on General Tasks"
                                ],
                                [
                                    80,
                                    "A New Pipeline for Knowledge Graph Reasoning Enhanced by Large Language Models Without Fine-Tuning"
                                ],
                                [
                                    100,
                                    "Triad: A Framework Leveraging a Multi-Role LLM-based Agent to Solve Knowledge Base Question Answering"
                                ],
                                [
                                    139,
                                    "In Search of the Long-Tail: Systematic Generation of Long-Tail Inferential Knowledge via Logical Rule Guided Search"
                                ],
                                [
                                    167,
                                    "KB-Plugin: A Plug-and-play Framework for Large Language Models to Induce Programs over Low-resourced Knowledge Bases"
                                ],
                                [
                                    204,
                                    "CoTKR: Chain-of-Thought Enhanced Knowledge Rewriting for Complex Knowledge Graph Question Answering"
                                ],
                                [
                                    211,
                                    "Learn to Refuse: Making Large Language Models More Controllable and Reliable through Knowledge Scope Limitation and Refusal Mechanism"
                                ],
                                [
                                    233,
                                    "When Context Leads but Parametric Memory Follows in Large Language Models"
                                ]
                            ],
                            "paper_ids": [
                                13,
                                14,
                                42,
                                80,
                                100,
                                139,
                                167,
                                204,
                                211,
                                233,
                                238,
                                265,
                                276,
                                287,
                                308,
                                320,
                                332,
                                348,
                                375,
                                393,
                                398,
                                443,
                                460,
                                476,
                                530,
                                540,
                                579,
                                593,
                                596,
                                684,
                                702,
                                732,
                                733,
                                762,
                                804,
                                849,
                                854,
                                862,
                                873,
                                879,
                                976,
                                978,
                                980,
                                992,
                                1017,
                                1022,
                                1025,
                                1035,
                                1036,
                                1073,
                                1129,
                                1161,
                                1195,
                                1201,
                                1232,
                                1235,
                                1243,
                                1244,
                                1250,
                                1258,
                                1260,
                                1342,
                                1346,
                                1375,
                                1379,
                                1404,
                                1427,
                                1435,
                                1439,
                                1441,
                                1450,
                                1472,
                                1481,
                                1485,
                                1491,
                                1530,
                                1537,
                                1539,
                                1541,
                                1552,
                                1555,
                                1565,
                                1591,
                                1616,
                                1625,
                                1636,
                                1638,
                                1655,
                                1667,
                                1724,
                                1734,
                                1755,
                                1775,
                                1793,
                                1796,
                                1854,
                                1859,
                                1860,
                                1892,
                                1905,
                                1923,
                                1942,
                                1970,
                                1973,
                                1999,
                                2048,
                                2049,
                                2063,
                                2065,
                                2100,
                                2145,
                                2247,
                                2277,
                                2290,
                                2329,
                                2384,
                                2394,
                                2414,
                                2432,
                                2433,
                                2467,
                                2484,
                                2494,
                                2496,
                                2513,
                                2522,
                                2653,
                                2713
                            ]
                        },
                        {
                            "label": "evaluation_and_improvement_approaches",
                            "description": "This cluster focuses on approaches for evaluating and improving the performance of question answering systems, including confidence calibration, evaluating language models, and assessing answer reliability.",
                            "level": 3,
                            "example_papers": [
                                [
                                    15,
                                    "Systematic Biases in LLM Simulations of Debates"
                                ],
                                [
                                    17,
                                    "Uncertainty in Language Models: Assessment through Rank-Calibration"
                                ],
                                [
                                    39,
                                    "Tokenization Is More Than Compression"
                                ],
                                [
                                    47,
                                    "Making Large Language Models Better Reasoners with Orchestrated Streaming Experiences"
                                ],
                                [
                                    48,
                                    "Overcome Noise and Bias: Segmentation-Aided Multi-Granularity Denoising and Debiasing for Enhanced Quarduples Extraction in Dialogue"
                                ],
                                [
                                    71,
                                    "Fairer Preferences Elicit Improved Human-Aligned Large Language Model Judgments"
                                ],
                                [
                                    91,
                                    "Can Large Language Models Always Solve Easy Problems if They Can Solve Harder Ones?"
                                ],
                                [
                                    101,
                                    "MetaGPT: Merging Large Language Models Using Model Exclusive Task Arithmetic"
                                ],
                                [
                                    120,
                                    "GLaPE: Gold Label-agnostic Prompt Evaluation for Large Language Models"
                                ],
                                [
                                    124,
                                    "Advancing Process Verification for Large Language Models via Tree-Based Preference Learning"
                                ]
                            ],
                            "paper_ids": [
                                15,
                                17,
                                39,
                                47,
                                48,
                                71,
                                91,
                                101,
                                120,
                                124,
                                127,
                                137,
                                139,
                                145,
                                146,
                                149,
                                163,
                                172,
                                173,
                                174,
                                186,
                                210,
                                211,
                                220,
                                222,
                                225,
                                228,
                                238,
                                251,
                                266,
                                273,
                                287,
                                299,
                                306,
                                307,
                                312,
                                320,
                                321,
                                347,
                                360,
                                380,
                                434,
                                442,
                                464,
                                474,
                                476,
                                477,
                                483,
                                504,
                                530,
                                535,
                                544,
                                545,
                                577,
                                582,
                                585,
                                596,
                                614,
                                631,
                                636,
                                653,
                                657,
                                676,
                                679,
                                724,
                                733,
                                741,
                                756,
                                762,
                                776,
                                778,
                                782,
                                792,
                                804,
                                806,
                                813,
                                814,
                                816,
                                830,
                                846,
                                853,
                                874,
                                879,
                                882,
                                904,
                                914,
                                928,
                                939,
                                948,
                                954,
                                955,
                                980,
                                1003,
                                1006,
                                1017,
                                1020,
                                1031,
                                1110,
                                1111,
                                1139,
                                1148,
                                1162,
                                1219,
                                1235,
                                1246,
                                1250,
                                1252,
                                1254,
                                1288,
                                1334,
                                1337,
                                1344,
                                1375,
                                1378,
                                1379,
                                1427,
                                1441,
                                1450,
                                1457,
                                1459,
                                1472,
                                1477,
                                1492,
                                1494,
                                1500,
                                1527,
                                1530,
                                1532,
                                1539,
                                1557,
                                1559,
                                1563,
                                1567,
                                1569,
                                1571,
                                1573,
                                1581,
                                1588,
                                1599,
                                1618,
                                1641,
                                1643,
                                1647,
                                1651,
                                1659,
                                1674,
                                1680,
                                1688,
                                1727,
                                1737,
                                1739,
                                1752,
                                1753,
                                1769,
                                1796,
                                1805,
                                1838,
                                1843,
                                1856,
                                1858,
                                1859,
                                1875,
                                1876,
                                1904,
                                1927,
                                1941,
                                1955,
                                1971,
                                1994,
                                2005,
                                2022,
                                2034,
                                2035,
                                2038,
                                2041,
                                2064,
                                2065,
                                2069,
                                2100,
                                2113,
                                2139,
                                2150,
                                2161,
                                2168,
                                2184,
                                2193,
                                2205,
                                2231,
                                2243,
                                2244,
                                2254,
                                2255,
                                2267,
                                2288,
                                2318,
                                2325,
                                2329,
                                2337,
                                2340,
                                2392,
                                2410,
                                2414,
                                2429,
                                2430,
                                2463,
                                2467,
                                2489,
                                2494,
                                2496,
                                2508,
                                2522,
                                2552,
                                2567,
                                2597,
                                2599,
                                2604,
                                2605,
                                2713,
                                2721,
                                2738
                            ]
                        },
                        {
                            "label": "contextual_information_integration",
                            "description": "This cluster emphasizes techniques for integrating contextual information into question answering processes, such as leveraging contextual information, contextual reasoning, and contextualized question representation.",
                            "level": 3,
                            "example_papers": [
                                [
                                    15,
                                    "Systematic Biases in LLM Simulations of Debates"
                                ],
                                [
                                    52,
                                    "Language Models Learn Rare Phenomena from Less Rare Phenomena: The Case of the Missing AANNs"
                                ],
                                [
                                    75,
                                    "QUDSELECT: Selective Decoding for Questions Under Discussion Parsing"
                                ],
                                [
                                    91,
                                    "Can Large Language Models Always Solve Easy Problems if They Can Solve Harder Ones?"
                                ],
                                [
                                    118,
                                    "Aligning Language Models to Explicitly Handle Ambiguity"
                                ],
                                [
                                    134,
                                    "CHIQ: Contextual History Enhancement for Improving Query Rewriting in Conversational Search"
                                ],
                                [
                                    137,
                                    "Direct Multi-Turn Preference Optimization for Language Agents"
                                ],
                                [
                                    155,
                                    "To Word Senses and Beyond: Inducing Concepts with Contextualized Language Models"
                                ],
                                [
                                    222,
                                    "Advancing Large Language Model Attribution through Self-Improving"
                                ],
                                [
                                    225,
                                    "PRompt Optimization in Multi-Step Tasks (PROMST): Integrating Human Feedback and Heuristic-based Sampling"
                                ]
                            ],
                            "paper_ids": [
                                15,
                                52,
                                75,
                                91,
                                118,
                                134,
                                137,
                                155,
                                222,
                                225,
                                233,
                                241,
                                307,
                                311,
                                321,
                                457,
                                483,
                                489,
                                504,
                                522,
                                544,
                                549,
                                553,
                                567,
                                580,
                                594,
                                658,
                                667,
                                679,
                                689,
                                705,
                                724,
                                756,
                                782,
                                792,
                                803,
                                911,
                                925,
                                955,
                                977,
                                980,
                                1020,
                                1109,
                                1112,
                                1113,
                                1170,
                                1192,
                                1230,
                                1258,
                                1308,
                                1325,
                                1332,
                                1342,
                                1396,
                                1441,
                                1457,
                                1469,
                                1491,
                                1494,
                                1498,
                                1540,
                                1547,
                                1550,
                                1557,
                                1559,
                                1563,
                                1569,
                                1571,
                                1577,
                                1580,
                                1582,
                                1641,
                                1643,
                                1651,
                                1655,
                                1667,
                                1699,
                                1724,
                                1727,
                                1746,
                                1752,
                                1832,
                                1836,
                                1882,
                                1904,
                                1921,
                                1992,
                                2034,
                                2068,
                                2188,
                                2192,
                                2203,
                                2205,
                                2243,
                                2266,
                                2281,
                                2288,
                                2313,
                                2325,
                                2342,
                                2414,
                                2427,
                                2480,
                                2507,
                                2552,
                                2567,
                                2605,
                                2653,
                                2735,
                                2800
                            ]
                        }
                    ]
                },
                {
                    "label": "commonsense_question_answering",
                    "description": "This cluster addresses the challenges of answering questions that require commonsense reasoning and understanding of everyday knowledge.",
                    "level": 2,
                    "example_papers": [
                        [
                            15,
                            "Systematic Biases in LLM Simulations of Debates"
                        ],
                        [
                            47,
                            "Making Large Language Models Better Reasoners with Orchestrated Streaming Experiences"
                        ],
                        [
                            138,
                            "Self-Refine Instruction-Tuning for Aligning Reasoning in Language Models"
                        ],
                        [
                            139,
                            "In Search of the Long-Tail: Systematic Generation of Long-Tail Inferential Knowledge via Logical Rule Guided Search"
                        ],
                        [
                            155,
                            "To Word Senses and Beyond: Inducing Concepts with Contextualized Language Models"
                        ],
                        [
                            166,
                            "With Ears to See and Eyes to Hear: Sound Symbolism Experiments with Multimodal Large Language Models"
                        ],
                        [
                            211,
                            "Learn to Refuse: Making Large Language Models More Controllable and Reliable through Knowledge Scope Limitation and Refusal Mechanism"
                        ],
                        [
                            238,
                            "Teaching LLMs to Abstain across Languages via Multilingual Feedback"
                        ],
                        [
                            287,
                            "Hierarchical Deconstruction of LLM Reasoning: A Graph-Based Framework for Analyzing Knowledge Utilization"
                        ],
                        [
                            312,
                            "Adaption-of-Thought: Learning Question Difficulty Improves Large Language Models for Reasoning"
                        ]
                    ],
                    "paper_ids": [
                        15,
                        47,
                        138,
                        139,
                        155,
                        166,
                        211,
                        238,
                        287,
                        312,
                        360,
                        377,
                        378,
                        483,
                        585,
                        649,
                        676,
                        685,
                        780,
                        804,
                        806,
                        825,
                        854,
                        909,
                        914,
                        918,
                        960,
                        1020,
                        1022,
                        1025,
                        1051,
                        1104,
                        1110,
                        1144,
                        1159,
                        1181,
                        1232,
                        1246,
                        1250,
                        1491,
                        1507,
                        1556,
                        1580,
                        1599,
                        1613,
                        1659,
                        1690,
                        1734,
                        1745,
                        1859,
                        1892,
                        1938,
                        1965,
                        2019,
                        2113,
                        2115,
                        2209,
                        2240,
                        2318,
                        2337,
                        2432,
                        2467,
                        2496,
                        2522,
                        2597,
                        2599
                    ],
                    "children": [
                        {
                            "label": "reasoning_evaluation",
                            "description": "This cluster focuses on evaluating the reasoning abilities of models, including their performance in logical, abstract, and causal reasoning tasks.",
                            "level": 3,
                            "example_papers": [
                                [
                                    138,
                                    "Self-Refine Instruction-Tuning for Aligning Reasoning in Language Models"
                                ],
                                [
                                    139,
                                    "In Search of the Long-Tail: Systematic Generation of Long-Tail Inferential Knowledge via Logical Rule Guided Search"
                                ],
                                [
                                    312,
                                    "Adaption-of-Thought: Learning Question Difficulty Improves Large Language Models for Reasoning"
                                ],
                                [
                                    360,
                                    "GAMA: A Large Audio-Language Model with Advanced Audio Understanding and Complex Reasoning Abilities"
                                ],
                                [
                                    585,
                                    "Belief Revision: The Adaptability of Large Language Models Reasoning"
                                ],
                                [
                                    649,
                                    "Reasoning or a Semblance of it? A Diagnostic Study of Transitive Reasoning in LLMs"
                                ],
                                [
                                    685,
                                    "Subjective Topic meets LLMs: Unleashing Comprehensive, Reflective and Creative Thinking through the Negation of Negation"
                                ],
                                [
                                    914,
                                    "Exploring the Compositional Deficiency of Large Language Models in Mathematical Reasoning Through Trap Problems"
                                ],
                                [
                                    1020,
                                    "A linguistically-motivated evaluation methodology for unraveling model's abilities in reading comprehension tasks"
                                ],
                                [
                                    1104,
                                    "Perceptions to Beliefs: Exploring Precursory Inferences for Theory of Mind in Large Language Models"
                                ]
                            ],
                            "paper_ids": [
                                138,
                                139,
                                312,
                                360,
                                585,
                                649,
                                685,
                                914,
                                1020,
                                1104,
                                1110,
                                1159,
                                1181,
                                1246,
                                1556,
                                1613,
                                1659,
                                1690,
                                1859,
                                1938,
                                2019,
                                2113,
                                2209,
                                2318,
                                2337,
                                2467,
                                2522,
                                2597,
                                2599
                            ]
                        },
                        {
                            "label": "knowledge_utilization",
                            "description": "This cluster addresses how models utilize knowledge, including knowledge representation, integration, and the ability to leverage external knowledge sources in commonsense reasoning.",
                            "level": 3,
                            "example_papers": [
                                [
                                    47,
                                    "Making Large Language Models Better Reasoners with Orchestrated Streaming Experiences"
                                ],
                                [
                                    155,
                                    "To Word Senses and Beyond: Inducing Concepts with Contextualized Language Models"
                                ],
                                [
                                    166,
                                    "With Ears to See and Eyes to Hear: Sound Symbolism Experiments with Multimodal Large Language Models"
                                ],
                                [
                                    287,
                                    "Hierarchical Deconstruction of LLM Reasoning: A Graph-Based Framework for Analyzing Knowledge Utilization"
                                ],
                                [
                                    377,
                                    "Right for Right Reasons: Large Language Models for Verifiable Commonsense Knowledge Graph Question Answering"
                                ],
                                [
                                    483,
                                    "Explaining and Improving Contrastive Decoding by Extrapolating the Probabilities of a Huge and Hypothetical LM"
                                ],
                                [
                                    676,
                                    "Medical Adaptation of Large Language and Vision-Language Models: Are We Making Progress?"
                                ],
                                [
                                    804,
                                    "KnowTuning: Knowledge-aware Fine-tuning for Large Language Models"
                                ],
                                [
                                    806,
                                    "Nash CoT: Multi-Path Inference with Preference Equilibrium"
                                ],
                                [
                                    825,
                                    "Commonsense Knowledge Editing Based on Free-Text in LLMs"
                                ]
                            ],
                            "paper_ids": [
                                47,
                                155,
                                166,
                                287,
                                377,
                                483,
                                676,
                                804,
                                806,
                                825,
                                854,
                                909,
                                918,
                                960,
                                1022,
                                1025,
                                1051,
                                1144,
                                1232,
                                1246,
                                1250,
                                1491,
                                1507,
                                1734,
                                1745,
                                1859,
                                1892,
                                1938,
                                1965,
                                2115,
                                2209,
                                2240,
                                2432,
                                2467,
                                2522
                            ]
                        },
                        {
                            "label": "improving_reasoning_ability",
                            "description": "This cluster encompasses methods and strategies aimed at enhancing the reasoning capabilities of language models, including techniques for controllability and reliability.",
                            "level": 3,
                            "example_papers": [
                                [
                                    47,
                                    "Making Large Language Models Better Reasoners with Orchestrated Streaming Experiences"
                                ],
                                [
                                    138,
                                    "Self-Refine Instruction-Tuning for Aligning Reasoning in Language Models"
                                ],
                                [
                                    155,
                                    "To Word Senses and Beyond: Inducing Concepts with Contextualized Language Models"
                                ],
                                [
                                    211,
                                    "Learn to Refuse: Making Large Language Models More Controllable and Reliable through Knowledge Scope Limitation and Refusal Mechanism"
                                ],
                                [
                                    238,
                                    "Teaching LLMs to Abstain across Languages via Multilingual Feedback"
                                ],
                                [
                                    287,
                                    "Hierarchical Deconstruction of LLM Reasoning: A Graph-Based Framework for Analyzing Knowledge Utilization"
                                ],
                                [
                                    312,
                                    "Adaption-of-Thought: Learning Question Difficulty Improves Large Language Models for Reasoning"
                                ],
                                [
                                    360,
                                    "GAMA: A Large Audio-Language Model with Advanced Audio Understanding and Complex Reasoning Abilities"
                                ],
                                [
                                    377,
                                    "Right for Right Reasons: Large Language Models for Verifiable Commonsense Knowledge Graph Question Answering"
                                ],
                                [
                                    378,
                                    "Verifiable, Debuggable, and Repairable Commonsense Logical Reasoning via LLM-based Theory Resolution"
                                ]
                            ],
                            "paper_ids": [
                                47,
                                138,
                                155,
                                211,
                                238,
                                287,
                                312,
                                360,
                                377,
                                378,
                                483,
                                585,
                                780,
                                804,
                                806,
                                825,
                                914,
                                918,
                                1022,
                                1051,
                                1104,
                                1159,
                                1232,
                                1250,
                                1507,
                                1556,
                                1580,
                                1892,
                                1938,
                                1965,
                                2115,
                                2318,
                                2496
                            ]
                        },
                        {
                            "label": "social_and_cultural_reasoning",
                            "description": "This cluster explores reasoning tasks that involve social prediction and culturally aware language models, focusing on how models understand and generate socially relevant responses.",
                            "level": 3,
                            "example_papers": [
                                [
                                    15,
                                    "Systematic Biases in LLM Simulations of Debates"
                                ],
                                [
                                    1144,
                                    "Can LLM Generate Culturally Relevant Commonsense QA Data? Case Study in Indonesian and Sundanese"
                                ],
                                [
                                    1599,
                                    "Are Large Language Models (LLMs) Good Social Predictors?"
                                ],
                                [
                                    1734,
                                    "CultureBank: An Online Community-Driven Knowledge Base Towards Culturally Aware Language Technologies"
                                ]
                            ],
                            "paper_ids": [
                                15,
                                1144,
                                1599,
                                1734
                            ]
                        },
                        {
                            "label": "evaluation_and_debugging",
                            "description": "This cluster is dedicated to the evaluation and debugging of commonsense reasoning models, including stress testing and long-tail evaluation to ensure robustness and reliability.",
                            "level": 3,
                            "example_papers": [
                                [
                                    15,
                                    "Systematic Biases in LLM Simulations of Debates"
                                ],
                                [
                                    377,
                                    "Right for Right Reasons: Large Language Models for Verifiable Commonsense Knowledge Graph Question Answering"
                                ],
                                [
                                    378,
                                    "Verifiable, Debuggable, and Repairable Commonsense Logical Reasoning via LLM-based Theory Resolution"
                                ],
                                [
                                    676,
                                    "Medical Adaptation of Large Language and Vision-Language Models: Are We Making Progress?"
                                ],
                                [
                                    780,
                                    "Hopping Too Late: Exploring the Limitations of Large Language Models on Multi-Hop Queries"
                                ],
                                [
                                    1020,
                                    "A linguistically-motivated evaluation methodology for unraveling model's abilities in reading comprehension tasks"
                                ],
                                [
                                    1025,
                                    "CasiMedicos-Arg: A Medical Question Answering Dataset Annotated with Explanatory Argumentative Structures"
                                ],
                                [
                                    1051,
                                    "Towards Faithful Knowledge Graph Explanation Through Deep Alignment in Commonsense Question Answering"
                                ],
                                [
                                    1104,
                                    "Perceptions to Beliefs: Exploring Precursory Inferences for Theory of Mind in Large Language Models"
                                ],
                                [
                                    1246,
                                    "CELLO: Causal Evaluation of Large Vision-Language Models"
                                ]
                            ],
                            "paper_ids": [
                                15,
                                377,
                                378,
                                676,
                                780,
                                1020,
                                1025,
                                1051,
                                1104,
                                1246,
                                1491,
                                1613,
                                1659,
                                1690,
                                1745,
                                1859,
                                2113,
                                2337,
                                2432,
                                2496,
                                2522,
                                2599
                            ]
                        }
                    ]
                },
                {
                    "label": "temporal_relation_question_answering",
                    "description": "This cluster involves methods for answering questions that pertain to temporal relationships and events, emphasizing the understanding of time in context.",
                    "level": 2,
                    "example_papers": [
                        [
                            360,
                            "GAMA: A Large Audio-Language Model with Advanced Audio Understanding and Complex Reasoning Abilities"
                        ],
                        [
                            393,
                            "TimeR^4 : Time-aware Retrieval-Augmented Large Language Models for Temporal Knowledge Graph Question Answering"
                        ],
                        [
                            555,
                            "Efficient Temporal Extrapolation of Multimodal Large Language Models with Temporal Grounding Bridge"
                        ],
                        [
                            579,
                            "CARER - ClinicAl Reasoning-Enhanced Representation for Temporal Health Risk Prediction"
                        ],
                        [
                            1076,
                            "CaT-Bench: Benchmarking Language Model Understanding of Causal and Temporal Dependencies in Plans"
                        ],
                        [
                            1135,
                            "Will LLMs Replace the Encoder-Only Models in Temporal Relation Classification?"
                        ],
                        [
                            1203,
                            "Evaluating Large Language Models on Time Series Feature Understanding: A Comprehensive Taxonomy and Benchmark"
                        ],
                        [
                            1491,
                            "What Would Happen Next? Predicting Consequences from An Event Causality Graph"
                        ],
                        [
                            1493,
                            "Temporal Cognitive Tree: A Hierarchical Modeling Approach for Event Temporal Relation Extraction"
                        ],
                        [
                            1571,
                            "EconLogicQA: A Question-Answering Benchmark for Evaluating Large Language Models in Economic Sequential Reasoning"
                        ]
                    ],
                    "paper_ids": [
                        360,
                        393,
                        555,
                        579,
                        1076,
                        1135,
                        1203,
                        1491,
                        1493,
                        1571,
                        1622,
                        1957,
                        1989,
                        2008,
                        2113,
                        2247,
                        2294,
                        2399
                    ]
                },
                {
                    "label": "free_form_question_answering",
                    "description": "This cluster encompasses approaches that allow for open-ended and flexible question answering, accommodating a wide range of question formats and types.",
                    "level": 2,
                    "example_papers": [
                        [
                            345,
                            "Boosting Scientific Concepts Understanding: Can Analogy from Teacher Models Empower Student Models?"
                        ],
                        [
                            360,
                            "GAMA: A Large Audio-Language Model with Advanced Audio Understanding and Complex Reasoning Abilities"
                        ],
                        [
                            483,
                            "Explaining and Improving Contrastive Decoding by Extrapolating the Probabilities of a Huge and Hypothetical LM"
                        ],
                        [
                            489,
                            "AGRaME: Any-Granularity Ranking with Multi-Vector Embeddings"
                        ],
                        [
                            676,
                            "Medical Adaptation of Large Language and Vision-Language Models: Are We Making Progress?"
                        ],
                        [
                            679,
                            "ControlMath: Controllable Data Generation Promotes Math Generalist Models"
                        ],
                        [
                            830,
                            "SparseGrad: A Selective Method for Efficient Fine-tuning of MLP Layers"
                        ],
                        [
                            873,
                            "Human-LLM Hybrid Text Answer Aggregation for Crowd Annotations"
                        ],
                        [
                            1139,
                            "You Make me Feel like a Natural Question: Training QA Systems on Transformed Trivia Questions"
                        ],
                        [
                            1166,
                            "TokenVerse: Towards Unifying Speech and NLP Tasks via Transducer-based ASR"
                        ]
                    ],
                    "paper_ids": [
                        345,
                        360,
                        483,
                        489,
                        676,
                        679,
                        830,
                        873,
                        1139,
                        1166,
                        1204,
                        1294,
                        1342,
                        1345,
                        1450,
                        1477,
                        1494,
                        1547,
                        1667,
                        1734,
                        1737,
                        1738,
                        1752,
                        1793,
                        1849,
                        1859,
                        1860,
                        1994,
                        2014,
                        2022,
                        2113,
                        2136,
                        2216,
                        2244,
                        2443,
                        2635
                    ]
                },
                {
                    "label": "legal_question_answering",
                    "description": "This cluster specializes in techniques for answering questions related to legal contexts, focusing on the interpretation and application of legal knowledge.",
                    "level": 2,
                    "example_papers": [
                        [
                            843,
                            "CopyBench: Measuring Literal and Non-Literal Reproduction of Copyright-Protected Text in Language Model Generation"
                        ],
                        [
                            1640,
                            "Divide and Conquer: Legal Concept-guided Criminal Court View Generation"
                        ],
                        [
                            1734,
                            "CultureBank: An Online Community-Driven Knowledge Base Towards Culturally Aware Language Technologies"
                        ],
                        [
                            1891,
                            "Can Large Language Models Grasp Legal Theories? Enhance Legal Reasoning with Insights from Multi-Agent Collaboration"
                        ],
                        [
                            1995,
                            "AgentsCourt: Building Judicial Decision-Making Agents with Court Debate Simulation and Legal Knowledge Augmentation"
                        ],
                        [
                            2113,
                            "MDCR: A Dataset for Multi-Document Conditional Reasoning"
                        ],
                        [
                            2302,
                            "H-LegalKI: A Hierarchical Legal Knowledge Integration Framework for Legal Community Question Answering"
                        ],
                        [
                            2553,
                            "HyPA-RAG: A Hybrid Parameter Adaptive Retrieval-Augmented Generation System for AI Legal and Policy Applications"
                        ],
                        [
                            2638,
                            "LeGen: Complex Information Extraction from Legal sentences using Generative Models"
                        ],
                        [
                            2640,
                            "Enhancing Legal Expertise in Large Language Models through Composite Model Integration: The Development and Evaluation of Law-Neo"
                        ]
                    ],
                    "paper_ids": [
                        843,
                        1640,
                        1734,
                        1891,
                        1995,
                        2113,
                        2302,
                        2553,
                        2638,
                        2640,
                        2641,
                        2642,
                        2643,
                        2644,
                        2649,
                        2651,
                        2653,
                        2659,
                        2663,
                        2670
                    ]
                }
            ]
        },
        {
            "label": "bias_detection",
            "description": "The process of identifying and mitigating biases in data and algorithms to ensure fairness and accuracy.",
            "level": 1,
            "example_papers": [
                [
                    5,
                    "ImageInWords: Unlocking Hyper-Detailed Image Descriptions"
                ],
                [
                    12,
                    "\"Thinking\" Fair and Slow: On the Efficacy of Structured Prompts for Debiasing Language Models"
                ],
                [
                    13,
                    "A Usage-centric Take on Intent Understanding in E-Commerce"
                ],
                [
                    15,
                    "Systematic Biases in LLM Simulations of Debates"
                ],
                [
                    16,
                    "Studying and Mitigating Biases in Sign Language Understanding Models"
                ],
                [
                    17,
                    "Uncertainty in Language Models: Assessment through Rank-Calibration"
                ],
                [
                    21,
                    "\"We Demand Justice!\": Towards Social Context Grounding of Political Texts"
                ],
                [
                    28,
                    "On the Influence of Gender and Race in Romantic Relationship Prediction from Large Language Models"
                ],
                [
                    30,
                    "On Fake News Detection with LLM Enhanced Semantics Mining"
                ],
                [
                    33,
                    "A Study of Nationality Bias in Names and Perplexity using Off-the-Shelf Affect-related Tweet Classifiers"
                ]
            ],
            "paper_ids": [
                5,
                12,
                13,
                15,
                16,
                17,
                21,
                28,
                30,
                33,
                38,
                39,
                40,
                42,
                48,
                52,
                53,
                56,
                59,
                67,
                71,
                76,
                81,
                84,
                96,
                114,
                141,
                155,
                156,
                163,
                165,
                166,
                169,
                186,
                193,
                194,
                225,
                227,
                235,
                242,
                252,
                255,
                258,
                271,
                273,
                276,
                279,
                286,
                299,
                300,
                307,
                315,
                323,
                326,
                332,
                342,
                343,
                353,
                362,
                376,
                378,
                383,
                384,
                400,
                402,
                407,
                409,
                411,
                412,
                424,
                425,
                426,
                436,
                454,
                460,
                470,
                475,
                480,
                482,
                493,
                494,
                507,
                508,
                509,
                511,
                515,
                520,
                521,
                523,
                525,
                529,
                530,
                531,
                545,
                549,
                557,
                564,
                573,
                574,
                584,
                585,
                589,
                594,
                605,
                611,
                613,
                614,
                619,
                620,
                622,
                628,
                631,
                637,
                641,
                644,
                656,
                658,
                662,
                664,
                670,
                678,
                679,
                689,
                691,
                693,
                695,
                702,
                706,
                712,
                723,
                729,
                732,
                733,
                741,
                746,
                749,
                760,
                763,
                768,
                775,
                776,
                779,
                781,
                784,
                793,
                800,
                803,
                808,
                809,
                811,
                819,
                825,
                828,
                843,
                845,
                846,
                849,
                867,
                868,
                871,
                877,
                883,
                885,
                894,
                895,
                903,
                909,
                914,
                917,
                930,
                932,
                941,
                944,
                948,
                949,
                950,
                951,
                953,
                954,
                965,
                977,
                981,
                985,
                989,
                993,
                1001,
                1006,
                1021,
                1027,
                1028,
                1033,
                1034,
                1035,
                1044,
                1053,
                1065,
                1069,
                1088,
                1089,
                1090,
                1095,
                1096,
                1097,
                1109,
                1112,
                1114,
                1129,
                1133,
                1134,
                1141,
                1143,
                1145,
                1149,
                1157,
                1159,
                1170,
                1171,
                1172,
                1173,
                1196,
                1199,
                1203,
                1206,
                1224,
                1228,
                1229,
                1230,
                1254,
                1255,
                1257,
                1259,
                1260,
                1278,
                1283,
                1308,
                1311,
                1333,
                1334,
                1335,
                1337,
                1344,
                1357,
                1359,
                1366,
                1374,
                1390,
                1400,
                1403,
                1417,
                1433,
                1438,
                1441,
                1443,
                1446,
                1450,
                1462,
                1472,
                1474,
                1481,
                1485,
                1493,
                1498,
                1502,
                1503,
                1505,
                1512,
                1527,
                1531,
                1532,
                1533,
                1539,
                1540,
                1542,
                1543,
                1555,
                1556,
                1566,
                1576,
                1585,
                1586,
                1599,
                1618,
                1619,
                1625,
                1630,
                1634,
                1636,
                1640,
                1645,
                1646,
                1651,
                1653,
                1659,
                1663,
                1688,
                1690,
                1691,
                1697,
                1701,
                1707,
                1717,
                1718,
                1722,
                1729,
                1734,
                1739,
                1742,
                1753,
                1755,
                1764,
                1767,
                1769,
                1777,
                1778,
                1781,
                1790,
                1796,
                1799,
                1802,
                1806,
                1812,
                1834,
                1843,
                1851,
                1852,
                1854,
                1858,
                1861,
                1866,
                1870,
                1875,
                1876,
                1879,
                1885,
                1909,
                1913,
                1930,
                1935,
                1936,
                1941,
                1952,
                1953,
                1957,
                1971,
                1975,
                1991,
                1997,
                2002,
                2005,
                2015,
                2017,
                2022,
                2034,
                2035,
                2038,
                2041,
                2047,
                2048,
                2056,
                2057,
                2064,
                2066,
                2075,
                2093,
                2096,
                2100,
                2118,
                2126,
                2138,
                2149,
                2158,
                2160,
                2184,
                2185,
                2187,
                2196,
                2215,
                2218,
                2219,
                2221,
                2225,
                2228,
                2229,
                2230,
                2231,
                2245,
                2260,
                2267,
                2284,
                2285,
                2287,
                2288,
                2289,
                2296,
                2308,
                2313,
                2314,
                2316,
                2317,
                2318,
                2329,
                2333,
                2336,
                2337,
                2340,
                2341,
                2356,
                2361,
                2370,
                2372,
                2374,
                2387,
                2406,
                2408,
                2412,
                2416,
                2417,
                2418,
                2429,
                2441,
                2443,
                2461,
                2467,
                2469,
                2472,
                2481,
                2482,
                2487,
                2488,
                2495,
                2505,
                2506,
                2513,
                2524,
                2535,
                2545,
                2548,
                2556,
                2600,
                2602,
                2609,
                2628,
                2630,
                2640,
                2643,
                2657,
                2670,
                2671,
                2679,
                2680,
                2685,
                2686,
                2698,
                2706,
                2719,
                2721,
                2726,
                2728,
                2730,
                2734,
                2737,
                2738,
                2740,
                2744,
                2746,
                2747,
                2749,
                2751,
                2752,
                2761,
                2764,
                2770,
                2772,
                2777,
                2778,
                2800,
                2802,
                2804,
                2806,
                2809,
                2810,
                2836,
                2948,
                2949
            ],
            "children": [
                {
                    "label": "algorithmic_bias",
                    "description": "The study and identification of biases that arise from algorithms, focusing on how these biases can affect decision-making processes and outcomes.",
                    "level": 2,
                    "example_papers": [
                        [
                            1691,
                            "A Robust Dual-debiasing VQA Model based on Counterfactual Causal Effect"
                        ]
                    ],
                    "paper_ids": [
                        1691
                    ]
                },
                {
                    "label": "bias_in_language_models",
                    "description": "The examination of biases present in language models, including how these biases manifest in generated text and their implications for fairness.",
                    "level": 2,
                    "example_papers": [
                        [
                            12,
                            "\"Thinking\" Fair and Slow: On the Efficacy of Structured Prompts for Debiasing Language Models"
                        ],
                        [
                            15,
                            "Systematic Biases in LLM Simulations of Debates"
                        ],
                        [
                            17,
                            "Uncertainty in Language Models: Assessment through Rank-Calibration"
                        ],
                        [
                            28,
                            "On the Influence of Gender and Race in Romantic Relationship Prediction from Large Language Models"
                        ],
                        [
                            33,
                            "A Study of Nationality Bias in Names and Perplexity using Off-the-Shelf Affect-related Tweet Classifiers"
                        ],
                        [
                            38,
                            "CoCoLoFa: A Dataset of News Comments with Common Logical Fallacies Written by LLM-Assisted Crowds"
                        ],
                        [
                            40,
                            "FLIRT: Feedback Loop In-context Red Teaming"
                        ],
                        [
                            52,
                            "Language Models Learn Rare Phenomena from Less Rare Phenomena: The Case of the Missing AANNs"
                        ],
                        [
                            53,
                            "Large Language Models for Data Annotation and Synthesis: A Survey"
                        ],
                        [
                            59,
                            "Eliminating Biased Length Reliance of Direct Preference Optimization via Down-Sampled KL Divergence"
                        ]
                    ],
                    "paper_ids": [
                        12,
                        15,
                        17,
                        28,
                        33,
                        38,
                        40,
                        52,
                        53,
                        59,
                        67,
                        71,
                        96,
                        114,
                        141,
                        156,
                        163,
                        165,
                        166,
                        193,
                        227,
                        235,
                        242,
                        252,
                        271,
                        276,
                        299,
                        342,
                        343,
                        353,
                        362,
                        376,
                        384,
                        400,
                        402,
                        411,
                        412,
                        426,
                        475,
                        482,
                        493,
                        494,
                        507,
                        515,
                        520,
                        521,
                        525,
                        529,
                        531,
                        545,
                        549,
                        573,
                        585,
                        589,
                        594,
                        605,
                        611,
                        613,
                        614,
                        619,
                        620,
                        628,
                        641,
                        656,
                        678,
                        702,
                        706,
                        712,
                        723,
                        729,
                        732,
                        733,
                        749,
                        760,
                        763,
                        768,
                        781,
                        793,
                        808,
                        811,
                        819,
                        825,
                        828,
                        843,
                        846,
                        849,
                        868,
                        877,
                        883,
                        885,
                        894,
                        895,
                        903,
                        914,
                        917,
                        932,
                        944,
                        948,
                        949,
                        950,
                        951,
                        977,
                        981,
                        985,
                        989,
                        1006,
                        1027,
                        1033,
                        1034,
                        1044,
                        1088,
                        1089,
                        1095,
                        1096,
                        1097,
                        1109,
                        1133,
                        1134,
                        1145,
                        1149,
                        1171,
                        1173,
                        1196,
                        1199,
                        1228,
                        1229,
                        1230,
                        1254,
                        1257,
                        1259,
                        1283,
                        1344,
                        1357,
                        1390,
                        1400,
                        1417,
                        1433,
                        1438,
                        1441,
                        1472,
                        1485,
                        1498,
                        1502,
                        1503,
                        1505,
                        1512,
                        1531,
                        1532,
                        1540,
                        1542,
                        1543,
                        1556,
                        1566,
                        1585,
                        1599,
                        1619,
                        1630,
                        1634,
                        1651,
                        1659,
                        1688,
                        1690,
                        1697,
                        1701,
                        1718,
                        1734,
                        1739,
                        1755,
                        1769,
                        1777,
                        1778,
                        1781,
                        1796,
                        1799,
                        1806,
                        1812,
                        1834,
                        1843,
                        1851,
                        1852,
                        1858,
                        1866,
                        1870,
                        1913,
                        1941,
                        1952,
                        1953,
                        1975,
                        1991,
                        1997,
                        2002,
                        2005,
                        2017,
                        2022,
                        2038,
                        2056,
                        2057,
                        2093,
                        2126,
                        2138,
                        2149,
                        2160,
                        2184,
                        2185,
                        2187,
                        2196,
                        2215,
                        2218,
                        2225,
                        2228,
                        2229,
                        2230,
                        2231,
                        2245,
                        2260,
                        2267,
                        2284,
                        2285,
                        2287,
                        2288,
                        2289,
                        2296,
                        2308,
                        2314,
                        2316,
                        2318,
                        2329,
                        2333,
                        2337,
                        2340,
                        2372,
                        2374,
                        2387,
                        2406,
                        2408,
                        2412,
                        2417,
                        2429,
                        2441,
                        2467,
                        2469,
                        2472,
                        2495,
                        2505,
                        2506,
                        2524,
                        2545,
                        2548,
                        2556,
                        2600,
                        2609,
                        2628,
                        2630,
                        2640,
                        2643,
                        2657,
                        2719,
                        2721,
                        2728,
                        2734,
                        2737,
                        2738,
                        2740,
                        2744,
                        2746,
                        2747,
                        2749,
                        2751,
                        2752,
                        2770,
                        2772,
                        2800,
                        2802,
                        2804
                    ],
                    "children": [
                        {
                            "label": "bias_manifestation",
                            "description": "This cluster focuses on the various ways biases manifest in language models, particularly in the generated text, and includes studies on bias manifestation in generated outputs.",
                            "level": 3,
                            "example_papers": [
                                [
                                    15,
                                    "Systematic Biases in LLM Simulations of Debates"
                                ],
                                [
                                    33,
                                    "A Study of Nationality Bias in Names and Perplexity using Off-the-Shelf Affect-related Tweet Classifiers"
                                ],
                                [
                                    40,
                                    "FLIRT: Feedback Loop In-context Red Teaming"
                                ],
                                [
                                    156,
                                    "ASETF: A Novel Method for Jailbreak Attack on LLMs through Translate Suffix Embeddings"
                                ],
                                [
                                    242,
                                    "STOP! Benchmarking Large Language Models with Sensitivity Testing on Offensive Progressions"
                                ],
                                [
                                    252,
                                    "Order of Magnitude Speedups for LLM Membership Inference"
                                ],
                                [
                                    271,
                                    "A Peek into Token Bias: Large Language Models Are Not Yet Genuine Reasoners"
                                ],
                                [
                                    353,
                                    "On the Reliability of Psychological Scales on Large Language Models"
                                ],
                                [
                                    362,
                                    "ChatGPT Doesn't Trust Chargers Fans: Guardrail Sensitivity in Context"
                                ],
                                [
                                    376,
                                    "Reconstruct Your Previous Conversations! Comprehensively Investigating Privacy Leakage Risks in Conversations with GPT Models"
                                ]
                            ],
                            "paper_ids": [
                                15,
                                33,
                                40,
                                156,
                                242,
                                252,
                                271,
                                353,
                                362,
                                376,
                                400,
                                411,
                                426,
                                482,
                                493,
                                515,
                                520,
                                529,
                                531,
                                589,
                                613,
                                641,
                                678,
                                706,
                                749,
                                768,
                                843,
                                849,
                                883,
                                885,
                                894,
                                903,
                                917,
                                949,
                                951,
                                981,
                                989,
                                1033,
                                1034,
                                1088,
                                1097,
                                1133,
                                1173,
                                1229,
                                1283,
                                1542,
                                1543,
                                1566,
                                1585,
                                1619,
                                1634,
                                1651,
                                1659,
                                1697,
                                1701,
                                1718,
                                1755,
                                1777,
                                1778,
                                1799,
                                1806,
                                1851,
                                1852,
                                1866,
                                1870,
                                1913,
                                2017,
                                2184,
                                2196,
                                2228,
                                2229,
                                2260,
                                2284,
                                2287,
                                2296,
                                2308,
                                2314,
                                2374,
                                2417,
                                2441,
                                2505,
                                2524,
                                2609,
                                2630,
                                2719,
                                2728,
                                2734,
                                2740,
                                2744,
                                2751,
                                2772,
                                2802
                            ]
                        },
                        {
                            "label": "bias_implications",
                            "description": "This cluster examines the implications of biases present in language models, including their impact on fairness and societal consequences.",
                            "level": 3,
                            "example_papers": [
                                [
                                    15,
                                    "Systematic Biases in LLM Simulations of Debates"
                                ],
                                [
                                    227,
                                    "Dissecting Fine-Tuning Unlearning in Large Language Models"
                                ],
                                [
                                    235,
                                    "When Is Multilinguality a Curse? Language Modeling for 250 High- and Low-Resource Languages"
                                ],
                                [
                                    362,
                                    "ChatGPT Doesn't Trust Chargers Fans: Guardrail Sensitivity in Context"
                                ],
                                [
                                    426,
                                    "Is LLM-as-a-Judge Robust? Investigating Universal Adversarial Attacks on Zero-shot LLM Assessment"
                                ],
                                [
                                    482,
                                    "Perceptions of Linguistic Uncertainty by Language Models and Humans"
                                ],
                                [
                                    493,
                                    "\"Flex Tape Can't Fix That\": Bias and Misinformation in Edited Language Models"
                                ],
                                [
                                    507,
                                    "On the Relationship between Truth and Political Bias in Language Models"
                                ],
                                [
                                    706,
                                    "\"Global is Good, Local is Bad?\": Understanding Brand Bias in LLMs"
                                ],
                                [
                                    723,
                                    "OATH-Frames: Characterizing Online Attitudes Towards Homelessness with LLM Assistants"
                                ]
                            ],
                            "paper_ids": [
                                15,
                                227,
                                235,
                                362,
                                426,
                                482,
                                493,
                                507,
                                706,
                                723,
                                749,
                                811,
                                883,
                                885,
                                949,
                                951,
                                981,
                                985,
                                1033,
                                1034,
                                1089,
                                1133,
                                1173,
                                1199,
                                1229,
                                1542,
                                1566,
                                1634,
                                1697,
                                1701,
                                1777,
                                1806,
                                1851,
                                1852,
                                2038,
                                2260,
                                2267,
                                2314,
                                2333,
                                2408,
                                2719,
                                2728,
                                2740,
                                2770,
                                2772
                            ]
                        },
                        {
                            "label": "debiasing_methods",
                            "description": "This cluster encompasses various methods and techniques aimed at reducing or mitigating biases in language models, including approaches to debiasing and calibration.",
                            "level": 3,
                            "example_papers": [
                                [
                                    12,
                                    "\"Thinking\" Fair and Slow: On the Efficacy of Structured Prompts for Debiasing Language Models"
                                ],
                                [
                                    59,
                                    "Eliminating Biased Length Reliance of Direct Preference Optimization via Down-Sampled KL Divergence"
                                ],
                                [
                                    67,
                                    "Rethinking Pruning Large Language Models: Benefits and Pitfalls of Reconstruction Error Minimization"
                                ],
                                [
                                    71,
                                    "Fairer Preferences Elicit Improved Human-Aligned Large Language Model Judgments"
                                ],
                                [
                                    96,
                                    "Predicate Debiasing in Vision-Language Models Integration for Scene Graph Generation Enhancement"
                                ],
                                [
                                    114,
                                    "CMD: a framework for Context-aware Model self-Detoxification"
                                ],
                                [
                                    156,
                                    "ASETF: A Novel Method for Jailbreak Attack on LLMs through Translate Suffix Embeddings"
                                ],
                                [
                                    163,
                                    "Alignment-Enhanced Decoding: Defending Jailbreaks via Token-Level Adaptive Refining of Probability Distributions"
                                ],
                                [
                                    227,
                                    "Dissecting Fine-Tuning Unlearning in Large Language Models"
                                ],
                                [
                                    242,
                                    "STOP! Benchmarking Large Language Models with Sensitivity Testing on Offensive Progressions"
                                ]
                            ],
                            "paper_ids": [
                                12,
                                59,
                                67,
                                71,
                                96,
                                114,
                                156,
                                163,
                                227,
                                242,
                                276,
                                299,
                                342,
                                402,
                                411,
                                475,
                                494,
                                515,
                                520,
                                525,
                                549,
                                573,
                                594,
                                605,
                                611,
                                614,
                                619,
                                620,
                                628,
                                702,
                                733,
                                760,
                                768,
                                781,
                                808,
                                828,
                                846,
                                877,
                                917,
                                948,
                                950,
                                981,
                                1006,
                                1027,
                                1044,
                                1109,
                                1134,
                                1149,
                                1171,
                                1199,
                                1254,
                                1257,
                                1259,
                                1357,
                                1390,
                                1400,
                                1438,
                                1472,
                                1485,
                                1502,
                                1503,
                                1531,
                                1532,
                                1540,
                                1556,
                                1634,
                                1688,
                                1734,
                                1739,
                                1781,
                                1834,
                                1843,
                                1991,
                                1997,
                                2002,
                                2022,
                                2056,
                                2093,
                                2184,
                                2185,
                                2187,
                                2225,
                                2229,
                                2230,
                                2245,
                                2288,
                                2296,
                                2329,
                                2340,
                                2372,
                                2495,
                                2545,
                                2548,
                                2628,
                                2630,
                                2640,
                                2738,
                                2740,
                                2749,
                                2770
                            ]
                        },
                        {
                            "label": "evaluation_of_bias",
                            "description": "This cluster is dedicated to the assessment and evaluation of biases in language models, focusing on methodologies for measuring and analyzing bias levels.",
                            "level": 3,
                            "example_papers": [
                                [
                                    38,
                                    "CoCoLoFa: A Dataset of News Comments with Common Logical Fallacies Written by LLM-Assisted Crowds"
                                ],
                                [
                                    193,
                                    "Pixology: Probing the Linguistic and Visual Capabilities of Pixel-based Language Models"
                                ],
                                [
                                    235,
                                    "When Is Multilinguality a Curse? Language Modeling for 250 High- and Low-Resource Languages"
                                ],
                                [
                                    242,
                                    "STOP! Benchmarking Large Language Models with Sensitivity Testing on Offensive Progressions"
                                ],
                                [
                                    271,
                                    "A Peek into Token Bias: Large Language Models Are Not Yet Genuine Reasoners"
                                ],
                                [
                                    299,
                                    "Pretraining Data Detection for Large Language Models: A Divergence-based Calibration Method"
                                ],
                                [
                                    353,
                                    "On the Reliability of Psychological Scales on Large Language Models"
                                ],
                                [
                                    521,
                                    "RuBLiMP: Russian Benchmark of Linguistic Minimal Pairs"
                                ],
                                [
                                    525,
                                    "Reverse-Engineering the Reader"
                                ],
                                [
                                    531,
                                    "Susu Box or Piggy Bank: Assessing Cultural Commonsense Knowledge between Ghana and the US"
                                ]
                            ],
                            "paper_ids": [
                                38,
                                193,
                                235,
                                242,
                                271,
                                299,
                                353,
                                521,
                                525,
                                531,
                                545,
                                549,
                                585,
                                656,
                                732,
                                733,
                                763,
                                768,
                                793,
                                846,
                                849,
                                883,
                                895,
                                903,
                                948,
                                977,
                                981,
                                989,
                                1088,
                                1095,
                                1096,
                                1097,
                                1145,
                                1230,
                                1257,
                                1283,
                                1344,
                                1390,
                                1433,
                                1472,
                                1503,
                                1531,
                                1532,
                                1540,
                                1542,
                                1566,
                                1599,
                                1619,
                                1634,
                                1651,
                                1690,
                                1701,
                                1718,
                                1734,
                                1769,
                                1778,
                                1799,
                                1812,
                                1843,
                                1858,
                                1866,
                                1952,
                                1975,
                                2005,
                                2056,
                                2149,
                                2228,
                                2260,
                                2288,
                                2316,
                                2318,
                                2333,
                                2337,
                                2340,
                                2374,
                                2467,
                                2469,
                                2472,
                                2506,
                                2524,
                                2600,
                                2628,
                                2630,
                                2643,
                                2657,
                                2719,
                                2721,
                                2728,
                                2740,
                                2747,
                                2749,
                                2772,
                                2800,
                                2802,
                                2804
                            ]
                        },
                        {
                            "label": "specific_bias_types",
                            "description": "This cluster investigates specific types of biases, such as gender, cultural, and political biases, within language models and their effects on generated content.",
                            "level": 3,
                            "example_papers": [
                                [
                                    15,
                                    "Systematic Biases in LLM Simulations of Debates"
                                ],
                                [
                                    28,
                                    "On the Influence of Gender and Race in Romantic Relationship Prediction from Large Language Models"
                                ],
                                [
                                    52,
                                    "Language Models Learn Rare Phenomena from Less Rare Phenomena: The Case of the Missing AANNs"
                                ],
                                [
                                    166,
                                    "With Ears to See and Eyes to Hear: Sound Symbolism Experiments with Multimodal Large Language Models"
                                ],
                                [
                                    193,
                                    "Pixology: Probing the Linguistic and Visual Capabilities of Pixel-based Language Models"
                                ],
                                [
                                    242,
                                    "STOP! Benchmarking Large Language Models with Sensitivity Testing on Offensive Progressions"
                                ],
                                [
                                    271,
                                    "A Peek into Token Bias: Large Language Models Are Not Yet Genuine Reasoners"
                                ],
                                [
                                    343,
                                    "Mitigating Frequency Bias and Anisotropy in Language Model Pre-Training with Syntactic Smoothing"
                                ],
                                [
                                    362,
                                    "ChatGPT Doesn't Trust Chargers Fans: Guardrail Sensitivity in Context"
                                ],
                                [
                                    412,
                                    "\"You Gotta be a Doctor, Lin\" : An Investigation of Name-Based Bias of Large Language Models in Employment Recommendations"
                                ]
                            ],
                            "paper_ids": [
                                15,
                                28,
                                52,
                                166,
                                193,
                                242,
                                271,
                                343,
                                362,
                                412,
                                482,
                                493,
                                507,
                                521,
                                613,
                                706,
                                712,
                                749,
                                793,
                                819,
                                849,
                                868,
                                914,
                                951,
                                977,
                                981,
                                985,
                                1033,
                                1088,
                                1089,
                                1097,
                                1133,
                                1173,
                                1196,
                                1230,
                                1505,
                                1512,
                                1599,
                                1619,
                                1630,
                                1634,
                                1697,
                                1701,
                                1718,
                                1777,
                                1778,
                                1806,
                                1852,
                                1952,
                                1953,
                                1975,
                                1991,
                                2017,
                                2057,
                                2126,
                                2149,
                                2218,
                                2260,
                                2285,
                                2314,
                                2316,
                                2318,
                                2333,
                                2337,
                                2374,
                                2406,
                                2469,
                                2472,
                                2495,
                                2506,
                                2609,
                                2643,
                                2719,
                                2737,
                                2740,
                                2746,
                                2747,
                                2751,
                                2800
                            ]
                        }
                    ]
                },
                {
                    "label": "fairness_in_data",
                    "description": "The assessment of data quality and representation to ensure that datasets used in machine learning are fair and do not propagate existing biases.",
                    "level": 2,
                    "example_papers": [
                        [
                            186,
                            "ScalingFilter: Assessing Data Quality through Inverse Utilization of Scaling Laws"
                        ],
                        [
                            235,
                            "When Is Multilinguality a Curse? Language Modeling for 250 High- and Low-Resource Languages"
                        ],
                        [
                            383,
                            "Locating Information Gaps and Narrative Inconsistencies Across Languages: A Case Study of LGBT People Portrayals on Wikipedia"
                        ],
                        [
                            460,
                            "Data Advisor: Dynamic Data Curation for Safety Alignment of Large Language Models"
                        ],
                        [
                            564,
                            "Optimizing Language Models with Fair and Stable Reward Composition in Reinforcement Learning"
                        ],
                        [
                            670,
                            "The Multilingual Alignment Prism: Aligning Global and Local Preferences to Reduce Harm"
                        ],
                        [
                            679,
                            "ControlMath: Controllable Data Generation Promotes Math Generalist Models"
                        ],
                        [
                            693,
                            "Enhancing Data Quality through Simple De-duplication: Navigating Responsible Computational Social Science Research"
                        ],
                        [
                            776,
                            "How Do Your Code LLMs perform? Empowering Code Instruction Tuning with Really Good Data"
                        ],
                        [
                            1224,
                            "FairFlow: Mitigating Dataset Biases through Undecided Learning for Natural Language Understanding"
                        ]
                    ],
                    "paper_ids": [
                        186,
                        235,
                        383,
                        460,
                        564,
                        670,
                        679,
                        693,
                        776,
                        1224,
                        1230,
                        1462,
                        1645,
                        2126,
                        2219,
                        2340,
                        2387,
                        2706,
                        2726,
                        2730,
                        2761,
                        2778
                    ]
                },
                {
                    "label": "bias_mitigation",
                    "description": "The development and implementation of strategies aimed at reducing or eliminating biases in data and algorithms to promote fairness.",
                    "level": 2,
                    "example_papers": [
                        [
                            12,
                            "\"Thinking\" Fair and Slow: On the Efficacy of Structured Prompts for Debiasing Language Models"
                        ],
                        [
                            15,
                            "Systematic Biases in LLM Simulations of Debates"
                        ],
                        [
                            16,
                            "Studying and Mitigating Biases in Sign Language Understanding Models"
                        ],
                        [
                            21,
                            "\"We Demand Justice!\": Towards Social Context Grounding of Political Texts"
                        ],
                        [
                            30,
                            "On Fake News Detection with LLM Enhanced Semantics Mining"
                        ],
                        [
                            33,
                            "A Study of Nationality Bias in Names and Perplexity using Off-the-Shelf Affect-related Tweet Classifiers"
                        ],
                        [
                            39,
                            "Tokenization Is More Than Compression"
                        ],
                        [
                            40,
                            "FLIRT: Feedback Loop In-context Red Teaming"
                        ],
                        [
                            48,
                            "Overcome Noise and Bias: Segmentation-Aided Multi-Granularity Denoising and Debiasing for Enhanced Quarduples Extraction in Dialogue"
                        ],
                        [
                            53,
                            "Large Language Models for Data Annotation and Synthesis: A Survey"
                        ]
                    ],
                    "paper_ids": [
                        12,
                        15,
                        16,
                        21,
                        30,
                        33,
                        39,
                        40,
                        48,
                        53,
                        56,
                        59,
                        67,
                        71,
                        76,
                        81,
                        84,
                        96,
                        114,
                        155,
                        156,
                        163,
                        186,
                        193,
                        194,
                        225,
                        227,
                        242,
                        252,
                        255,
                        258,
                        273,
                        276,
                        279,
                        286,
                        299,
                        300,
                        307,
                        315,
                        323,
                        326,
                        332,
                        343,
                        353,
                        362,
                        376,
                        378,
                        383,
                        384,
                        407,
                        409,
                        411,
                        424,
                        426,
                        436,
                        454,
                        460,
                        470,
                        475,
                        480,
                        482,
                        493,
                        494,
                        507,
                        508,
                        509,
                        511,
                        515,
                        520,
                        530,
                        557,
                        564,
                        573,
                        574,
                        584,
                        585,
                        589,
                        605,
                        611,
                        613,
                        614,
                        619,
                        620,
                        622,
                        631,
                        637,
                        644,
                        658,
                        662,
                        664,
                        670,
                        678,
                        679,
                        689,
                        691,
                        693,
                        695,
                        702,
                        706,
                        729,
                        733,
                        741,
                        746,
                        749,
                        760,
                        768,
                        775,
                        776,
                        779,
                        781,
                        784,
                        793,
                        803,
                        808,
                        809,
                        811,
                        828,
                        845,
                        849,
                        867,
                        868,
                        871,
                        877,
                        883,
                        894,
                        903,
                        909,
                        914,
                        917,
                        944,
                        948,
                        950,
                        951,
                        953,
                        954,
                        965,
                        977,
                        981,
                        985,
                        989,
                        993,
                        1001,
                        1006,
                        1021,
                        1028,
                        1033,
                        1035,
                        1044,
                        1053,
                        1065,
                        1069,
                        1088,
                        1089,
                        1090,
                        1096,
                        1097,
                        1109,
                        1112,
                        1114,
                        1133,
                        1134,
                        1141,
                        1143,
                        1149,
                        1157,
                        1170,
                        1171,
                        1172,
                        1173,
                        1199,
                        1206,
                        1224,
                        1229,
                        1254,
                        1257,
                        1259,
                        1260,
                        1283,
                        1308,
                        1333,
                        1334,
                        1335,
                        1344,
                        1357,
                        1359,
                        1366,
                        1374,
                        1390,
                        1403,
                        1438,
                        1441,
                        1450,
                        1462,
                        1474,
                        1481,
                        1493,
                        1502,
                        1503,
                        1527,
                        1531,
                        1532,
                        1539,
                        1540,
                        1542,
                        1555,
                        1556,
                        1566,
                        1576,
                        1585,
                        1586,
                        1599,
                        1618,
                        1630,
                        1634,
                        1636,
                        1640,
                        1645,
                        1651,
                        1653,
                        1659,
                        1663,
                        1690,
                        1691,
                        1697,
                        1718,
                        1722,
                        1729,
                        1739,
                        1742,
                        1753,
                        1755,
                        1764,
                        1767,
                        1777,
                        1778,
                        1781,
                        1790,
                        1799,
                        1806,
                        1834,
                        1851,
                        1852,
                        1854,
                        1858,
                        1861,
                        1866,
                        1870,
                        1875,
                        1876,
                        1885,
                        1909,
                        1913,
                        1930,
                        1935,
                        1936,
                        1941,
                        1953,
                        1957,
                        1971,
                        1991,
                        2002,
                        2015,
                        2017,
                        2022,
                        2034,
                        2035,
                        2038,
                        2041,
                        2047,
                        2056,
                        2066,
                        2075,
                        2093,
                        2096,
                        2118,
                        2126,
                        2158,
                        2184,
                        2185,
                        2187,
                        2196,
                        2218,
                        2219,
                        2221,
                        2225,
                        2229,
                        2230,
                        2245,
                        2285,
                        2287,
                        2288,
                        2289,
                        2296,
                        2308,
                        2313,
                        2314,
                        2316,
                        2317,
                        2318,
                        2329,
                        2333,
                        2336,
                        2340,
                        2341,
                        2361,
                        2370,
                        2372,
                        2374,
                        2387,
                        2406,
                        2408,
                        2416,
                        2417,
                        2429,
                        2441,
                        2443,
                        2472,
                        2481,
                        2482,
                        2487,
                        2495,
                        2506,
                        2524,
                        2545,
                        2548,
                        2556,
                        2602,
                        2630,
                        2640,
                        2643,
                        2670,
                        2671,
                        2680,
                        2686,
                        2706,
                        2719,
                        2726,
                        2728,
                        2730,
                        2734,
                        2738,
                        2740,
                        2749,
                        2751,
                        2761,
                        2770,
                        2777,
                        2778,
                        2800,
                        2802,
                        2809,
                        2810,
                        2836,
                        2949
                    ],
                    "children": [
                        {
                            "label": "bias_reduction",
                            "description": "Strategies and methods focused on reducing the presence and impact of biases in algorithms and datasets.",
                            "level": 3,
                            "example_papers": [
                                [
                                    16,
                                    "Studying and Mitigating Biases in Sign Language Understanding Models"
                                ],
                                [
                                    21,
                                    "\"We Demand Justice!\": Towards Social Context Grounding of Political Texts"
                                ],
                                [
                                    30,
                                    "On Fake News Detection with LLM Enhanced Semantics Mining"
                                ],
                                [
                                    39,
                                    "Tokenization Is More Than Compression"
                                ],
                                [
                                    48,
                                    "Overcome Noise and Bias: Segmentation-Aided Multi-Granularity Denoising and Debiasing for Enhanced Quarduples Extraction in Dialogue"
                                ],
                                [
                                    56,
                                    "RoseLoRA: Row and Column-wise Sparse Low-rank Adaptation of Pre-trained Language Model for Knowledge Editing and Fine-tuning"
                                ],
                                [
                                    59,
                                    "Eliminating Biased Length Reliance of Direct Preference Optimization via Down-Sampled KL Divergence"
                                ],
                                [
                                    67,
                                    "Rethinking Pruning Large Language Models: Benefits and Pitfalls of Reconstruction Error Minimization"
                                ],
                                [
                                    71,
                                    "Fairer Preferences Elicit Improved Human-Aligned Large Language Model Judgments"
                                ],
                                [
                                    76,
                                    "Mitigating Language Bias of LMMs in Social Intelligence Understanding with Virtual Counterfactual Calibration"
                                ]
                            ],
                            "paper_ids": [
                                16,
                                21,
                                30,
                                39,
                                48,
                                56,
                                59,
                                67,
                                71,
                                76,
                                81,
                                84,
                                114,
                                155,
                                163,
                                225,
                                227,
                                255,
                                258,
                                273,
                                276,
                                279,
                                286,
                                299,
                                307,
                                315,
                                323,
                                332,
                                343,
                                353,
                                407,
                                411,
                                424,
                                436,
                                454,
                                460,
                                470,
                                475,
                                480,
                                494,
                                511,
                                515,
                                520,
                                557,
                                564,
                                574,
                                584,
                                585,
                                605,
                                611,
                                614,
                                620,
                                622,
                                631,
                                637,
                                644,
                                658,
                                670,
                                679,
                                689,
                                691,
                                693,
                                695,
                                702,
                                729,
                                733,
                                741,
                                749,
                                760,
                                768,
                                775,
                                776,
                                779,
                                781,
                                784,
                                793,
                                803,
                                808,
                                809,
                                849,
                                867,
                                868,
                                871,
                                877,
                                883,
                                894,
                                914,
                                917,
                                944,
                                948,
                                950,
                                953,
                                954,
                                989,
                                993,
                                1028,
                                1035,
                                1044,
                                1053,
                                1069,
                                1090,
                                1096,
                                1109,
                                1114,
                                1134,
                                1143,
                                1149,
                                1157,
                                1170,
                                1171,
                                1199,
                                1224,
                                1254,
                                1257,
                                1259,
                                1308,
                                1333,
                                1334,
                                1335,
                                1359,
                                1366,
                                1374,
                                1390,
                                1403,
                                1441,
                                1450,
                                1493,
                                1502,
                                1503,
                                1531,
                                1539,
                                1540,
                                1542,
                                1555,
                                1556,
                                1576,
                                1586,
                                1630,
                                1634,
                                1636,
                                1640,
                                1645,
                                1651,
                                1653,
                                1663,
                                1691,
                                1697,
                                1739,
                                1753,
                                1755,
                                1764,
                                1781,
                                1790,
                                1806,
                                1834,
                                1861,
                                1875,
                                1876,
                                1909,
                                1913,
                                1935,
                                1936,
                                1941,
                                1971,
                                1991,
                                2002,
                                2017,
                                2022,
                                2034,
                                2035,
                                2041,
                                2047,
                                2066,
                                2075,
                                2093,
                                2096,
                                2118,
                                2184,
                                2185,
                                2187,
                                2219,
                                2221,
                                2229,
                                2230,
                                2285,
                                2287,
                                2288,
                                2289,
                                2296,
                                2313,
                                2314,
                                2317,
                                2329,
                                2340,
                                2341,
                                2361,
                                2372,
                                2387,
                                2406,
                                2408,
                                2429,
                                2441,
                                2443,
                                2481,
                                2482,
                                2487,
                                2495,
                                2524,
                                2545,
                                2630,
                                2686,
                                2706,
                                2726,
                                2730,
                                2734,
                                2738,
                                2740,
                                2749,
                                2770,
                                2777
                            ]
                        },
                        {
                            "label": "debiasing",
                            "description": "Techniques aimed at correcting or removing biases from models and their outputs to ensure fairness.",
                            "level": 3,
                            "example_papers": [
                                [
                                    12,
                                    "\"Thinking\" Fair and Slow: On the Efficacy of Structured Prompts for Debiasing Language Models"
                                ],
                                [
                                    21,
                                    "\"We Demand Justice!\": Towards Social Context Grounding of Political Texts"
                                ],
                                [
                                    48,
                                    "Overcome Noise and Bias: Segmentation-Aided Multi-Granularity Denoising and Debiasing for Enhanced Quarduples Extraction in Dialogue"
                                ],
                                [
                                    59,
                                    "Eliminating Biased Length Reliance of Direct Preference Optimization via Down-Sampled KL Divergence"
                                ],
                                [
                                    71,
                                    "Fairer Preferences Elicit Improved Human-Aligned Large Language Model Judgments"
                                ],
                                [
                                    76,
                                    "Mitigating Language Bias of LMMs in Social Intelligence Understanding with Virtual Counterfactual Calibration"
                                ],
                                [
                                    96,
                                    "Predicate Debiasing in Vision-Language Models Integration for Scene Graph Generation Enhancement"
                                ],
                                [
                                    114,
                                    "CMD: a framework for Context-aware Model self-Detoxification"
                                ],
                                [
                                    163,
                                    "Alignment-Enhanced Decoding: Defending Jailbreaks via Token-Level Adaptive Refining of Probability Distributions"
                                ],
                                [
                                    315,
                                    "Predicting Rewards Alongside Tokens: Non-disruptive Parameter Insertion for Efficient Inference Intervention in Large Language Model"
                                ]
                            ],
                            "paper_ids": [
                                12,
                                21,
                                48,
                                59,
                                71,
                                76,
                                96,
                                114,
                                163,
                                315,
                                378,
                                411,
                                475,
                                480,
                                494,
                                508,
                                511,
                                515,
                                574,
                                611,
                                619,
                                622,
                                729,
                                749,
                                781,
                                809,
                                828,
                                894,
                                917,
                                993,
                                1044,
                                1069,
                                1090,
                                1109,
                                1170,
                                1171,
                                1224,
                                1335,
                                1390,
                                1438,
                                1502,
                                1503,
                                1531,
                                1576,
                                1640,
                                1691,
                                1739,
                                1790,
                                1806,
                                1991,
                                2047,
                                2096,
                                2118,
                                2126,
                                2185,
                                2187,
                                2221,
                                2225,
                                2229,
                                2230,
                                2372,
                                2408,
                                2429,
                                2482,
                                2495,
                                2548,
                                2630,
                                2726,
                                2730,
                                2740
                            ]
                        },
                        {
                            "label": "data_preprocessing",
                            "description": "Methods applied to data before model training to identify and mitigate biases inherent in the dataset.",
                            "level": 3,
                            "example_papers": [
                                [
                                    16,
                                    "Studying and Mitigating Biases in Sign Language Understanding Models"
                                ],
                                [
                                    39,
                                    "Tokenization Is More Than Compression"
                                ],
                                [
                                    59,
                                    "Eliminating Biased Length Reliance of Direct Preference Optimization via Down-Sampled KL Divergence"
                                ],
                                [
                                    114,
                                    "CMD: a framework for Context-aware Model self-Detoxification"
                                ],
                                [
                                    163,
                                    "Alignment-Enhanced Decoding: Defending Jailbreaks via Token-Level Adaptive Refining of Probability Distributions"
                                ],
                                [
                                    276,
                                    "KidLM: Advancing Language Models for Children - Early Insights and Future Directions"
                                ],
                                [
                                    411,
                                    "Aligning Large Language Models with Diverse Political Viewpoints"
                                ],
                                [
                                    436,
                                    "MORPHEUS: Modeling Role from Personalized Dialogue History by Exploring and Utilizing Latent Space"
                                ],
                                [
                                    460,
                                    "Data Advisor: Dynamic Data Curation for Safety Alignment of Large Language Models"
                                ],
                                [
                                    470,
                                    "Resampled Datasets Are Not Enough: Mitigating Societal Bias Beyond Single Attributes"
                                ]
                            ],
                            "paper_ids": [
                                16,
                                39,
                                59,
                                114,
                                163,
                                276,
                                411,
                                436,
                                460,
                                470,
                                480,
                                494,
                                511,
                                574,
                                622,
                                644,
                                664,
                                679,
                                729,
                                741,
                                776,
                                779,
                                781,
                                809,
                                894,
                                954,
                                993,
                                1053,
                                1069,
                                1109,
                                1359,
                                1474,
                                1539,
                                1576,
                                1640,
                                1739,
                                1806,
                                2022,
                                2118,
                                2218,
                                2230,
                                2313,
                                2341,
                                2429,
                                2482,
                                2706,
                                2726,
                                2809,
                                2810
                            ]
                        },
                        {
                            "label": "bias_evaluation",
                            "description": "Assessment techniques used to measure and analyze the extent of bias present in algorithms and their predictions.",
                            "level": 3,
                            "example_papers": [
                                [
                                    15,
                                    "Systematic Biases in LLM Simulations of Debates"
                                ],
                                [
                                    16,
                                    "Studying and Mitigating Biases in Sign Language Understanding Models"
                                ],
                                [
                                    33,
                                    "A Study of Nationality Bias in Names and Perplexity using Off-the-Shelf Affect-related Tweet Classifiers"
                                ],
                                [
                                    40,
                                    "FLIRT: Feedback Loop In-context Red Teaming"
                                ],
                                [
                                    59,
                                    "Eliminating Biased Length Reliance of Direct Preference Optimization via Down-Sampled KL Divergence"
                                ],
                                [
                                    71,
                                    "Fairer Preferences Elicit Improved Human-Aligned Large Language Model Judgments"
                                ],
                                [
                                    76,
                                    "Mitigating Language Bias of LMMs in Social Intelligence Understanding with Virtual Counterfactual Calibration"
                                ],
                                [
                                    81,
                                    "Towards Tool Use Alignment of Large Language Models"
                                ],
                                [
                                    84,
                                    "Controllable Preference Optimization: Toward Controllable Multi-Objective Alignment"
                                ],
                                [
                                    114,
                                    "CMD: a framework for Context-aware Model self-Detoxification"
                                ]
                            ],
                            "paper_ids": [
                                15,
                                16,
                                33,
                                40,
                                59,
                                71,
                                76,
                                81,
                                84,
                                114,
                                163,
                                186,
                                194,
                                242,
                                252,
                                255,
                                258,
                                276,
                                299,
                                323,
                                362,
                                376,
                                383,
                                384,
                                407,
                                424,
                                426,
                                470,
                                480,
                                482,
                                493,
                                494,
                                507,
                                511,
                                574,
                                584,
                                585,
                                589,
                                613,
                                620,
                                631,
                                670,
                                678,
                                689,
                                693,
                                695,
                                706,
                                729,
                                749,
                                768,
                                781,
                                784,
                                793,
                                809,
                                811,
                                845,
                                849,
                                868,
                                883,
                                894,
                                903,
                                914,
                                917,
                                944,
                                948,
                                950,
                                951,
                                953,
                                977,
                                981,
                                985,
                                989,
                                993,
                                1021,
                                1033,
                                1069,
                                1088,
                                1089,
                                1090,
                                1096,
                                1097,
                                1109,
                                1112,
                                1114,
                                1133,
                                1134,
                                1141,
                                1171,
                                1172,
                                1173,
                                1199,
                                1206,
                                1229,
                                1257,
                                1283,
                                1333,
                                1366,
                                1403,
                                1441,
                                1462,
                                1527,
                                1531,
                                1532,
                                1542,
                                1566,
                                1576,
                                1585,
                                1599,
                                1630,
                                1640,
                                1651,
                                1659,
                                1663,
                                1690,
                                1697,
                                1718,
                                1722,
                                1729,
                                1739,
                                1742,
                                1777,
                                1778,
                                1781,
                                1790,
                                1799,
                                1806,
                                1851,
                                1852,
                                1854,
                                1858,
                                1870,
                                1875,
                                1885,
                                1913,
                                1930,
                                1941,
                                1953,
                                1991,
                                2034,
                                2038,
                                2041,
                                2056,
                                2066,
                                2075,
                                2093,
                                2096,
                                2118,
                                2158,
                                2185,
                                2196,
                                2219,
                                2221,
                                2287,
                                2289,
                                2308,
                                2314,
                                2316,
                                2318,
                                2329,
                                2333,
                                2336,
                                2340,
                                2361,
                                2374,
                                2387,
                                2416,
                                2429,
                                2441,
                                2472,
                                2495,
                                2506,
                                2602,
                                2630,
                                2643,
                                2686,
                                2719,
                                2726,
                                2728,
                                2730,
                                2740,
                                2751,
                                2761,
                                2770,
                                2777,
                                2778,
                                2800,
                                2802,
                                2836,
                                2949
                            ]
                        },
                        {
                            "label": "bias_quantification",
                            "description": "Approaches for quantifying the level of bias in data and algorithms to facilitate targeted mitigation efforts.",
                            "level": 3,
                            "example_papers": [
                                [
                                    15,
                                    "Systematic Biases in LLM Simulations of Debates"
                                ],
                                [
                                    30,
                                    "On Fake News Detection with LLM Enhanced Semantics Mining"
                                ],
                                [
                                    33,
                                    "A Study of Nationality Bias in Names and Perplexity using Off-the-Shelf Affect-related Tweet Classifiers"
                                ],
                                [
                                    40,
                                    "FLIRT: Feedback Loop In-context Red Teaming"
                                ],
                                [
                                    56,
                                    "RoseLoRA: Row and Column-wise Sparse Low-rank Adaptation of Pre-trained Language Model for Knowledge Editing and Fine-tuning"
                                ],
                                [
                                    59,
                                    "Eliminating Biased Length Reliance of Direct Preference Optimization via Down-Sampled KL Divergence"
                                ],
                                [
                                    67,
                                    "Rethinking Pruning Large Language Models: Benefits and Pitfalls of Reconstruction Error Minimization"
                                ],
                                [
                                    81,
                                    "Towards Tool Use Alignment of Large Language Models"
                                ],
                                [
                                    84,
                                    "Controllable Preference Optimization: Toward Controllable Multi-Objective Alignment"
                                ],
                                [
                                    114,
                                    "CMD: a framework for Context-aware Model self-Detoxification"
                                ]
                            ],
                            "paper_ids": [
                                15,
                                30,
                                33,
                                40,
                                56,
                                59,
                                67,
                                81,
                                84,
                                114,
                                155,
                                163,
                                186,
                                193,
                                194,
                                225,
                                227,
                                242,
                                252,
                                255,
                                258,
                                273,
                                279,
                                307,
                                332,
                                343,
                                353,
                                362,
                                376,
                                383,
                                384,
                                407,
                                424,
                                426,
                                454,
                                480,
                                482,
                                493,
                                494,
                                507,
                                509,
                                511,
                                520,
                                557,
                                573,
                                574,
                                589,
                                613,
                                614,
                                637,
                                658,
                                678,
                                689,
                                691,
                                693,
                                702,
                                706,
                                729,
                                733,
                                760,
                                768,
                                775,
                                781,
                                784,
                                803,
                                808,
                                809,
                                811,
                                845,
                                849,
                                867,
                                871,
                                877,
                                894,
                                903,
                                909,
                                914,
                                951,
                                953,
                                977,
                                981,
                                985,
                                989,
                                993,
                                1001,
                                1021,
                                1028,
                                1033,
                                1035,
                                1069,
                                1088,
                                1089,
                                1097,
                                1109,
                                1112,
                                1114,
                                1133,
                                1134,
                                1141,
                                1149,
                                1157,
                                1172,
                                1173,
                                1199,
                                1206,
                                1229,
                                1254,
                                1257,
                                1259,
                                1283,
                                1308,
                                1333,
                                1334,
                                1374,
                                1441,
                                1450,
                                1462,
                                1493,
                                1531,
                                1532,
                                1540,
                                1542,
                                1556,
                                1566,
                                1576,
                                1585,
                                1586,
                                1599,
                                1630,
                                1634,
                                1636,
                                1640,
                                1645,
                                1651,
                                1653,
                                1659,
                                1690,
                                1697,
                                1718,
                                1722,
                                1729,
                                1739,
                                1742,
                                1753,
                                1764,
                                1777,
                                1778,
                                1781,
                                1799,
                                1806,
                                1834,
                                1851,
                                1852,
                                1854,
                                1858,
                                1861,
                                1870,
                                1876,
                                1885,
                                1909,
                                1913,
                                1930,
                                1935,
                                1936,
                                1941,
                                1953,
                                1971,
                                1991,
                                2002,
                                2017,
                                2034,
                                2035,
                                2038,
                                2056,
                                2075,
                                2118,
                                2158,
                                2184,
                                2196,
                                2219,
                                2285,
                                2288,
                                2289,
                                2296,
                                2308,
                                2316,
                                2317,
                                2318,
                                2333,
                                2336,
                                2340,
                                2374,
                                2406,
                                2416,
                                2429,
                                2441,
                                2443,
                                2472,
                                2481,
                                2495,
                                2506,
                                2524,
                                2545,
                                2602,
                                2643,
                                2671,
                                2686,
                                2719,
                                2726,
                                2728,
                                2734,
                                2738,
                                2740,
                                2749,
                                2751,
                                2761,
                                2770,
                                2777,
                                2778,
                                2800,
                                2802,
                                2949
                            ]
                        }
                    ]
                },
                {
                    "label": "fairness_evaluation",
                    "description": "The process of evaluating the fairness of algorithms and models, ensuring that they perform equitably across different demographic groups.",
                    "level": 2,
                    "example_papers": [
                        [
                            12,
                            "\"Thinking\" Fair and Slow: On the Efficacy of Structured Prompts for Debiasing Language Models"
                        ],
                        [
                            21,
                            "\"We Demand Justice!\": Towards Social Context Grounding of Political Texts"
                        ],
                        [
                            30,
                            "On Fake News Detection with LLM Enhanced Semantics Mining"
                        ],
                        [
                            48,
                            "Overcome Noise and Bias: Segmentation-Aided Multi-Granularity Denoising and Debiasing for Enhanced Quarduples Extraction in Dialogue"
                        ],
                        [
                            71,
                            "Fairer Preferences Elicit Improved Human-Aligned Large Language Model Judgments"
                        ],
                        [
                            81,
                            "Towards Tool Use Alignment of Large Language Models"
                        ],
                        [
                            84,
                            "Controllable Preference Optimization: Toward Controllable Multi-Objective Alignment"
                        ],
                        [
                            155,
                            "To Word Senses and Beyond: Inducing Concepts with Contextualized Language Models"
                        ],
                        [
                            194,
                            "GoldCoin: Grounding Large Language Models in Privacy Laws via Contextual Integrity Theory"
                        ],
                        [
                            225,
                            "PRompt Optimization in Multi-Step Tasks (PROMST): Integrating Human Feedback and Heuristic-based Sampling"
                        ]
                    ],
                    "paper_ids": [
                        12,
                        21,
                        30,
                        48,
                        71,
                        81,
                        84,
                        155,
                        194,
                        225,
                        242,
                        255,
                        258,
                        273,
                        300,
                        323,
                        326,
                        342,
                        407,
                        424,
                        436,
                        493,
                        509,
                        521,
                        531,
                        557,
                        622,
                        656,
                        678,
                        706,
                        732,
                        763,
                        811,
                        846,
                        871,
                        895,
                        909,
                        948,
                        953,
                        954,
                        1021,
                        1028,
                        1065,
                        1069,
                        1088,
                        1090,
                        1114,
                        1141,
                        1170,
                        1172,
                        1203,
                        1206,
                        1228,
                        1333,
                        1335,
                        1337,
                        1366,
                        1403,
                        1446,
                        1481,
                        1531,
                        1566,
                        1690,
                        1717,
                        1718,
                        1722,
                        1729,
                        1734,
                        1742,
                        1769,
                        1790,
                        1802,
                        1812,
                        1854,
                        1858,
                        1885,
                        1913,
                        1930,
                        1952,
                        1975,
                        2005,
                        2041,
                        2057,
                        2066,
                        2075,
                        2260,
                        2333,
                        2336,
                        2337,
                        2370,
                        2374,
                        2387,
                        2408,
                        2416,
                        2461,
                        2472,
                        2482,
                        2487,
                        2524,
                        2600,
                        2602,
                        2628,
                        2630,
                        2643,
                        2657,
                        2670,
                        2671,
                        2680,
                        2686,
                        2730,
                        2744,
                        2747,
                        2777
                    ],
                    "children": [
                        {
                            "label": "evaluation_methods",
                            "description": "This subtopic focuses on various methodologies and approaches used to assess the fairness of algorithms and models across different demographic groups.",
                            "level": 3,
                            "example_papers": [
                                [
                                    225,
                                    "PRompt Optimization in Multi-Step Tasks (PROMST): Integrating Human Feedback and Heuristic-based Sampling"
                                ],
                                [
                                    242,
                                    "STOP! Benchmarking Large Language Models with Sensitivity Testing on Offensive Progressions"
                                ],
                                [
                                    258,
                                    "Leveraging Conflicts in Social Media Posts: Unintended Offense Dataset"
                                ],
                                [
                                    493,
                                    "\"Flex Tape Can't Fix That\": Bias and Misinformation in Edited Language Models"
                                ],
                                [
                                    509,
                                    "Statistical Uncertainty in Word Embeddings: GloVe-V"
                                ],
                                [
                                    521,
                                    "RuBLiMP: Russian Benchmark of Linguistic Minimal Pairs"
                                ],
                                [
                                    656,
                                    "\"A good pun is its own reword\": Can Large Language Models Understand Puns?"
                                ],
                                [
                                    678,
                                    "Do LLMs Overcome Shortcut Learning? An Evaluation of Shortcut Challenges in Large Language Models"
                                ],
                                [
                                    763,
                                    "A Systematic Survey and Critical Review on Evaluating Large Language Models: Challenges, Limitations, and Recommendations"
                                ],
                                [
                                    895,
                                    "Leveraging Large Language Models for NLG Evaluation: Advances and Challenges"
                                ]
                            ],
                            "paper_ids": [
                                225,
                                242,
                                258,
                                493,
                                509,
                                521,
                                656,
                                678,
                                763,
                                895,
                                948,
                                954,
                                1021,
                                1172,
                                1203,
                                1337,
                                1366,
                                1403,
                                1446,
                                1531,
                                1717,
                                1742,
                                1769,
                                1802,
                                1812,
                                1854,
                                1858,
                                1885,
                                1952,
                                1975,
                                2005,
                                2041,
                                2416,
                                2461,
                                2600,
                                2602,
                                2657,
                                2680,
                                2744,
                                2777
                            ]
                        },
                        {
                            "label": "bias_amplification",
                            "description": "This subtopic examines the phenomenon where algorithms exacerbate existing biases in data, leading to unfair outcomes for certain demographic groups.",
                            "level": 3,
                            "example_papers": [
                                [
                                    242,
                                    "STOP! Benchmarking Large Language Models with Sensitivity Testing on Offensive Progressions"
                                ],
                                [
                                    407,
                                    "Python is Not Always the Best Choice: Embracing Multilingual Program of Thoughts"
                                ],
                                [
                                    493,
                                    "\"Flex Tape Can't Fix That\": Bias and Misinformation in Edited Language Models"
                                ],
                                [
                                    678,
                                    "Do LLMs Overcome Shortcut Learning? An Evaluation of Shortcut Challenges in Large Language Models"
                                ],
                                [
                                    706,
                                    "\"Global is Good, Local is Bad?\": Understanding Brand Bias in LLMs"
                                ],
                                [
                                    811,
                                    "Social Bias Probing: Fairness Benchmarking for Language Models"
                                ],
                                [
                                    1088,
                                    "Discovering Biases in Information Retrieval Models Using Relevance Thesaurus as Global Explanation"
                                ],
                                [
                                    1090,
                                    "DISCERN: Decoding Systematic Errors in Natural Language for Text Classifiers"
                                ],
                                [
                                    1172,
                                    "ArMeme: Propagandistic Content in Arabic Memes"
                                ],
                                [
                                    1718,
                                    "Evaluating Moral Beliefs across LLMs through a Pluralistic Framework"
                                ]
                            ],
                            "paper_ids": [
                                242,
                                407,
                                493,
                                678,
                                706,
                                811,
                                1088,
                                1090,
                                1172,
                                1718,
                                1930,
                                2057,
                                2075,
                                2333,
                                2336,
                                2416,
                                2602,
                                2630,
                                2747,
                                2777
                            ]
                        },
                        {
                            "label": "algorithmic_fairness_evaluation",
                            "description": "This subtopic involves the assessment of algorithms specifically designed to ensure fairness in their decision-making processes.",
                            "level": 3,
                            "example_papers": [
                                [
                                    12,
                                    "\"Thinking\" Fair and Slow: On the Efficacy of Structured Prompts for Debiasing Language Models"
                                ],
                                [
                                    21,
                                    "\"We Demand Justice!\": Towards Social Context Grounding of Political Texts"
                                ],
                                [
                                    30,
                                    "On Fake News Detection with LLM Enhanced Semantics Mining"
                                ],
                                [
                                    48,
                                    "Overcome Noise and Bias: Segmentation-Aided Multi-Granularity Denoising and Debiasing for Enhanced Quarduples Extraction in Dialogue"
                                ],
                                [
                                    71,
                                    "Fairer Preferences Elicit Improved Human-Aligned Large Language Model Judgments"
                                ],
                                [
                                    81,
                                    "Towards Tool Use Alignment of Large Language Models"
                                ],
                                [
                                    155,
                                    "To Word Senses and Beyond: Inducing Concepts with Contextualized Language Models"
                                ],
                                [
                                    194,
                                    "GoldCoin: Grounding Large Language Models in Privacy Laws via Contextual Integrity Theory"
                                ],
                                [
                                    255,
                                    "Deciphering Rumors: A Multi-Task Learning Approach with Intent-aware Hierarchical Contrastive Learning"
                                ],
                                [
                                    273,
                                    "MuMath-Code: Combining Tool-Use Large Language Models with Multi-perspective Data Augmentation for Mathematical Reasoning"
                                ]
                            ],
                            "paper_ids": [
                                12,
                                21,
                                30,
                                48,
                                71,
                                81,
                                155,
                                194,
                                255,
                                273,
                                323,
                                326,
                                342,
                                407,
                                424,
                                436,
                                531,
                                622,
                                678,
                                732,
                                811,
                                846,
                                871,
                                909,
                                1028,
                                1065,
                                1090,
                                1114,
                                1141,
                                1170,
                                1333,
                                1335,
                                1481,
                                1531,
                                1566,
                                1690,
                                1718,
                                1722,
                                1729,
                                1734,
                                1742,
                                1790,
                                1854,
                                1913,
                                1930,
                                2066,
                                2075,
                                2260,
                                2333,
                                2337,
                                2387,
                                2408,
                                2461,
                                2472,
                                2482,
                                2524,
                                2602,
                                2643,
                                2657,
                                2670,
                                2671,
                                2686,
                                2730,
                                2747
                            ]
                        },
                        {
                            "label": "bias_evaluation_metrics",
                            "description": "This subtopic covers the metrics and criteria used to quantitatively measure bias in algorithms and models.",
                            "level": 3,
                            "example_papers": [
                                [
                                    48,
                                    "Overcome Noise and Bias: Segmentation-Aided Multi-Granularity Denoising and Debiasing for Enhanced Quarduples Extraction in Dialogue"
                                ],
                                [
                                    71,
                                    "Fairer Preferences Elicit Improved Human-Aligned Large Language Model Judgments"
                                ],
                                [
                                    194,
                                    "GoldCoin: Grounding Large Language Models in Privacy Laws via Contextual Integrity Theory"
                                ],
                                [
                                    258,
                                    "Leveraging Conflicts in Social Media Posts: Unintended Offense Dataset"
                                ],
                                [
                                    323,
                                    "Thinking Outside of the Differential Privacy Box: A Case Study in Text Privatization with Language Model Prompting"
                                ],
                                [
                                    342,
                                    "SaySelf: Teaching LLMs to Express Confidence with Self-Reflective Rationales"
                                ],
                                [
                                    424,
                                    "Strategic Demonstration Selection for Improved Fairness in LLM In-Context Learning"
                                ],
                                [
                                    531,
                                    "Susu Box or Piggy Bank: Assessing Cultural Commonsense Knowledge between Ghana and the US"
                                ],
                                [
                                    678,
                                    "Do LLMs Overcome Shortcut Learning? An Evaluation of Shortcut Challenges in Large Language Models"
                                ],
                                [
                                    811,
                                    "Social Bias Probing: Fairness Benchmarking for Language Models"
                                ]
                            ],
                            "paper_ids": [
                                48,
                                71,
                                194,
                                258,
                                323,
                                342,
                                424,
                                531,
                                678,
                                811,
                                871,
                                1028,
                                1065,
                                1088,
                                1090,
                                1206,
                                1335,
                                1531,
                                1566,
                                1718,
                                1722,
                                1742,
                                1913,
                                2260,
                                2333,
                                2337,
                                2461,
                                2472,
                                2482,
                                2524,
                                2602,
                                2671,
                                2686,
                                2744,
                                2747
                            ]
                        },
                        {
                            "label": "algorithmic_bias_evaluation",
                            "description": "This subtopic focuses on the evaluation of biases inherent in algorithms, assessing their impact on fairness and equity.",
                            "level": 3,
                            "example_papers": [
                                [
                                    242,
                                    "STOP! Benchmarking Large Language Models with Sensitivity Testing on Offensive Progressions"
                                ],
                                [
                                    342,
                                    "SaySelf: Teaching LLMs to Express Confidence with Self-Reflective Rationales"
                                ],
                                [
                                    678,
                                    "Do LLMs Overcome Shortcut Learning? An Evaluation of Shortcut Challenges in Large Language Models"
                                ],
                                [
                                    706,
                                    "\"Global is Good, Local is Bad?\": Understanding Brand Bias in LLMs"
                                ],
                                [
                                    811,
                                    "Social Bias Probing: Fairness Benchmarking for Language Models"
                                ],
                                [
                                    1088,
                                    "Discovering Biases in Information Retrieval Models Using Relevance Thesaurus as Global Explanation"
                                ],
                                [
                                    1206,
                                    "Metrics for What, Metrics for Whom: Assessing Actionability of Bias Evaluation Metrics in NLP"
                                ],
                                [
                                    2057,
                                    "BiasDora: Exploring Hidden Biased Associations in Vision-Language Models"
                                ],
                                [
                                    2336,
                                    "Modeling Gender and Dialect Bias in Automatic Speech Recognition"
                                ],
                                [
                                    2374,
                                    "Evaluating Gender Bias of LLMs in Making Morality Judgements"
                                ]
                            ],
                            "paper_ids": [
                                242,
                                342,
                                678,
                                706,
                                811,
                                1088,
                                1206,
                                2057,
                                2336,
                                2374,
                                2602,
                                2630,
                                2744,
                                2777
                            ]
                        }
                    ]
                }
            ]
        },
        {
            "label": "fact_checking",
            "description": "The task of verifying the factual accuracy of statements or claims made in various contexts.",
            "level": 1,
            "example_papers": [
                [
                    2,
                    "FIZZ: Factual Inconsistency Detection by Zoom-in Summary and Zoom-out Document"
                ],
                [
                    5,
                    "ImageInWords: Unlocking Hyper-Detailed Image Descriptions"
                ],
                [
                    13,
                    "A Usage-centric Take on Intent Understanding in E-Commerce"
                ],
                [
                    14,
                    "Fine-Tuning or Retrieval? Comparing Knowledge Injection in LLMs"
                ],
                [
                    17,
                    "Uncertainty in Language Models: Assessment through Rank-Calibration"
                ],
                [
                    30,
                    "On Fake News Detection with LLM Enhanced Semantics Mining"
                ],
                [
                    38,
                    "CoCoLoFa: A Dataset of News Comments with Common Logical Fallacies Written by LLM-Assisted Crowds"
                ],
                [
                    39,
                    "Tokenization Is More Than Compression"
                ],
                [
                    40,
                    "FLIRT: Feedback Loop In-context Red Teaming"
                ],
                [
                    42,
                    "Parameter-Efficient Sparsity Crafting from Dense to Mixture-of-Experts for Instruction Tuning on General Tasks"
                ]
            ],
            "paper_ids": [
                2,
                5,
                13,
                14,
                17,
                30,
                38,
                39,
                40,
                42,
                52,
                53,
                56,
                61,
                67,
                81,
                84,
                95,
                102,
                112,
                114,
                115,
                127,
                141,
                151,
                154,
                155,
                156,
                163,
                165,
                166,
                169,
                186,
                193,
                194,
                216,
                225,
                227,
                235,
                246,
                252,
                254,
                255,
                271,
                273,
                276,
                279,
                281,
                286,
                298,
                299,
                300,
                307,
                313,
                315,
                323,
                332,
                342,
                349,
                363,
                376,
                377,
                378,
                383,
                394,
                400,
                402,
                407,
                409,
                411,
                419,
                424,
                425,
                426,
                436,
                443,
                446,
                447,
                454,
                460,
                468,
                469,
                480,
                482,
                483,
                486,
                493,
                494,
                498,
                507,
                508,
                511,
                512,
                521,
                523,
                525,
                526,
                529,
                530,
                531,
                545,
                549,
                557,
                568,
                573,
                582,
                585,
                589,
                594,
                605,
                614,
                621,
                628,
                631,
                637,
                641,
                656,
                658,
                662,
                664,
                674,
                678,
                679,
                689,
                691,
                693,
                702,
                705,
                719,
                727,
                729,
                732,
                733,
                741,
                746,
                760,
                763,
                768,
                775,
                776,
                793,
                800,
                803,
                804,
                808,
                809,
                817,
                825,
                836,
                842,
                843,
                845,
                846,
                849,
                886,
                893,
                894,
                895,
                904,
                909,
                910,
                914,
                917,
                930,
                932,
                933,
                941,
                944,
                947,
                948,
                951,
                953,
                954,
                955,
                965,
                977,
                985,
                989,
                993,
                1006,
                1011,
                1021,
                1027,
                1033,
                1035,
                1053,
                1065,
                1069,
                1087,
                1089,
                1095,
                1096,
                1109,
                1112,
                1129,
                1134,
                1141,
                1145,
                1146,
                1149,
                1157,
                1159,
                1170,
                1172,
                1199,
                1203,
                1228,
                1229,
                1230,
                1242,
                1254,
                1257,
                1259,
                1260,
                1271,
                1277,
                1278,
                1290,
                1293,
                1299,
                1308,
                1311,
                1321,
                1334,
                1337,
                1344,
                1357,
                1358,
                1359,
                1366,
                1367,
                1374,
                1391,
                1403,
                1416,
                1417,
                1433,
                1438,
                1441,
                1443,
                1446,
                1450,
                1457,
                1467,
                1472,
                1474,
                1481,
                1485,
                1493,
                1498,
                1502,
                1507,
                1527,
                1531,
                1532,
                1533,
                1539,
                1540,
                1542,
                1543,
                1555,
                1556,
                1566,
                1576,
                1585,
                1586,
                1599,
                1618,
                1625,
                1634,
                1636,
                1637,
                1640,
                1646,
                1649,
                1650,
                1651,
                1653,
                1656,
                1659,
                1661,
                1662,
                1663,
                1688,
                1690,
                1706,
                1707,
                1708,
                1717,
                1718,
                1721,
                1722,
                1729,
                1734,
                1736,
                1739,
                1742,
                1753,
                1764,
                1767,
                1769,
                1780,
                1781,
                1796,
                1799,
                1802,
                1812,
                1834,
                1843,
                1854,
                1858,
                1861,
                1870,
                1874,
                1875,
                1876,
                1879,
                1885,
                1907,
                1909,
                1912,
                1917,
                1935,
                1936,
                1941,
                1952,
                1957,
                1961,
                1963,
                1965,
                1971,
                1975,
                1995,
                1997,
                1998,
                2002,
                2003,
                2005,
                2015,
                2022,
                2034,
                2035,
                2041,
                2048,
                2056,
                2059,
                2064,
                2066,
                2075,
                2094,
                2097,
                2100,
                2104,
                2113,
                2118,
                2138,
                2158,
                2160,
                2162,
                2176,
                2182,
                2184,
                2189,
                2196,
                2210,
                2215,
                2217,
                2218,
                2225,
                2228,
                2231,
                2241,
                2245,
                2267,
                2276,
                2284,
                2285,
                2287,
                2288,
                2289,
                2290,
                2296,
                2303,
                2308,
                2313,
                2316,
                2317,
                2318,
                2329,
                2337,
                2340,
                2341,
                2356,
                2361,
                2370,
                2372,
                2387,
                2401,
                2408,
                2412,
                2416,
                2429,
                2437,
                2443,
                2444,
                2449,
                2461,
                2467,
                2469,
                2472,
                2481,
                2482,
                2487,
                2488,
                2506,
                2513,
                2535,
                2548,
                2554,
                2556,
                2560,
                2561,
                2562,
                2563,
                2564,
                2565,
                2566,
                2567,
                2568,
                2569,
                2570,
                2571,
                2572,
                2573,
                2574,
                2575,
                2576,
                2577,
                2579,
                2582,
                2583,
                2584,
                2585,
                2586,
                2587,
                2600,
                2602,
                2628,
                2640,
                2641,
                2643,
                2657,
                2660,
                2666,
                2667,
                2670,
                2671,
                2679,
                2680,
                2686,
                2698,
                2721,
                2725,
                2730,
                2743,
                2749,
                2752,
                2764,
                2772,
                2800,
                2802,
                2805,
                2806,
                2809,
                2810,
                2948,
                2949
            ],
            "children": [
                {
                    "label": "automated_fact_checking",
                    "description": "This cluster focuses on the development and application of automated systems and algorithms designed to verify the accuracy of claims and statements without human intervention.",
                    "level": 2,
                    "example_papers": [
                        [
                            2,
                            "FIZZ: Factual Inconsistency Detection by Zoom-in Summary and Zoom-out Document"
                        ],
                        [
                            61,
                            "RULE: Reliable Multimodal RAG for Factuality in Medical Vision Language Models"
                        ],
                        [
                            102,
                            "Event Causality Identification with Synthetic Control"
                        ],
                        [
                            112,
                            "Do We Need Language-Specific Fact-Checking Models? The Case of Chinese"
                        ],
                        [
                            151,
                            "Knowledge Verification to Nip Hallucination in the Bud"
                        ],
                        [
                            186,
                            "ScalingFilter: Assessing Data Quality through Inverse Utilization of Scaling Laws"
                        ],
                        [
                            225,
                            "PRompt Optimization in Multi-Step Tasks (PROMST): Integrating Human Feedback and Heuristic-based Sampling"
                        ],
                        [
                            246,
                            "An Analysis of Multilingual FActScore"
                        ],
                        [
                            254,
                            "F^2RL: Factuality and Faithfulness Reinforcement Learning Framework for Claim-Guided Evidence-Supported Counterspeech Generation"
                        ],
                        [
                            273,
                            "MuMath-Code: Combining Tool-Use Large Language Models with Multi-perspective Data Augmentation for Mathematical Reasoning"
                        ]
                    ],
                    "paper_ids": [
                        2,
                        61,
                        102,
                        112,
                        151,
                        186,
                        225,
                        246,
                        254,
                        273,
                        281,
                        298,
                        307,
                        313,
                        315,
                        332,
                        342,
                        349,
                        378,
                        383,
                        402,
                        409,
                        424,
                        446,
                        460,
                        468,
                        483,
                        486,
                        494,
                        498,
                        508,
                        525,
                        526,
                        568,
                        582,
                        614,
                        621,
                        674,
                        702,
                        727,
                        729,
                        732,
                        733,
                        793,
                        803,
                        804,
                        825,
                        842,
                        843,
                        845,
                        886,
                        893,
                        904,
                        910,
                        914,
                        947,
                        948,
                        954,
                        1087,
                        1134,
                        1157,
                        1170,
                        1199,
                        1242,
                        1259,
                        1277,
                        1290,
                        1293,
                        1299,
                        1337,
                        1358,
                        1416,
                        1433,
                        1438,
                        1457,
                        1467,
                        1498,
                        1502,
                        1507,
                        1531,
                        1576,
                        1618,
                        1637,
                        1640,
                        1651,
                        1656,
                        1659,
                        1661,
                        1662,
                        1729,
                        1753,
                        1769,
                        1780,
                        1834,
                        1858,
                        1875,
                        1876,
                        1885,
                        1917,
                        1935,
                        1936,
                        1963,
                        1998,
                        2003,
                        2034,
                        2041,
                        2097,
                        2113,
                        2118,
                        2158,
                        2162,
                        2176,
                        2182,
                        2210,
                        2217,
                        2231,
                        2276,
                        2284,
                        2285,
                        2287,
                        2288,
                        2290,
                        2296,
                        2303,
                        2308,
                        2313,
                        2316,
                        2317,
                        2372,
                        2401,
                        2412,
                        2437,
                        2444,
                        2467,
                        2482,
                        2554,
                        2560,
                        2561,
                        2562,
                        2563,
                        2564,
                        2566,
                        2567,
                        2568,
                        2569,
                        2570,
                        2571,
                        2572,
                        2573,
                        2574,
                        2575,
                        2576,
                        2579,
                        2582,
                        2583,
                        2584,
                        2585,
                        2586,
                        2587,
                        2640,
                        2641,
                        2643,
                        2657,
                        2666,
                        2667,
                        2686,
                        2725
                    ],
                    "children": [
                        {
                            "label": "fact_verification",
                            "description": "This cluster focuses on the methodologies and algorithms specifically designed for verifying the truthfulness of claims and statements.",
                            "level": 3,
                            "example_papers": [
                                [
                                    151,
                                    "Knowledge Verification to Nip Hallucination in the Bud"
                                ],
                                [
                                    378,
                                    "Verifiable, Debuggable, and Repairable Commonsense Logical Reasoning via LLM-based Theory Resolution"
                                ],
                                [
                                    383,
                                    "Locating Information Gaps and Narrative Inconsistencies Across Languages: A Case Study of LGBT People Portrayals on Wikipedia"
                                ],
                                [
                                    424,
                                    "Strategic Demonstration Selection for Improved Fairness in LLM In-Context Learning"
                                ],
                                [
                                    446,
                                    "ECON: On the Detection and Resolution of Evidence Conflicts"
                                ],
                                [
                                    468,
                                    "Towards Verifiable Text Generation with Evolving Memory and Self-Reflection"
                                ],
                                [
                                    526,
                                    "Synchronous Faithfulness Monitoring for Trustworthy Retrieval-Augmented Generation"
                                ],
                                [
                                    674,
                                    "Unknown Claims: Generation of Fact-Checking Training Examples from Unstructured and Structured Data"
                                ],
                                [
                                    732,
                                    "A Bayesian Approach to Harnessing the Power of LLMs in Authorship Attribution"
                                ],
                                [
                                    843,
                                    "CopyBench: Measuring Literal and Non-Literal Reproduction of Copyright-Protected Text in Language Model Generation"
                                ]
                            ],
                            "paper_ids": [
                                151,
                                378,
                                383,
                                424,
                                446,
                                468,
                                526,
                                674,
                                732,
                                843,
                                845,
                                904,
                                947,
                                954,
                                1134,
                                1170,
                                1299,
                                1457,
                                1651,
                                1659,
                                1729,
                                1769,
                                1834,
                                1875,
                                1917,
                                1963,
                                2118,
                                2182,
                                2210,
                                2290,
                                2303,
                                2308,
                                2372,
                                2437,
                                2554,
                                2561,
                                2563,
                                2566,
                                2567,
                                2571,
                                2572,
                                2574,
                                2576,
                                2582,
                                2587,
                                2641,
                                2667,
                                2686
                            ]
                        },
                        {
                            "label": "fact_checking_techniques",
                            "description": "This cluster encompasses various techniques employed in the automated fact-checking process to assess the validity of information.",
                            "level": 3,
                            "example_papers": [
                                [
                                    61,
                                    "RULE: Reliable Multimodal RAG for Factuality in Medical Vision Language Models"
                                ],
                                [
                                    102,
                                    "Event Causality Identification with Synthetic Control"
                                ],
                                [
                                    112,
                                    "Do We Need Language-Specific Fact-Checking Models? The Case of Chinese"
                                ],
                                [
                                    151,
                                    "Knowledge Verification to Nip Hallucination in the Bud"
                                ],
                                [
                                    186,
                                    "ScalingFilter: Assessing Data Quality through Inverse Utilization of Scaling Laws"
                                ],
                                [
                                    225,
                                    "PRompt Optimization in Multi-Step Tasks (PROMST): Integrating Human Feedback and Heuristic-based Sampling"
                                ],
                                [
                                    246,
                                    "An Analysis of Multilingual FActScore"
                                ],
                                [
                                    273,
                                    "MuMath-Code: Combining Tool-Use Large Language Models with Multi-perspective Data Augmentation for Mathematical Reasoning"
                                ],
                                [
                                    281,
                                    "EVEDIT: Event-based Knowledge Editing for Deterministic Knowledge Propagation"
                                ],
                                [
                                    298,
                                    "LUQ: Long-text Uncertainty Quantification for LLMs"
                                ]
                            ],
                            "paper_ids": [
                                61,
                                102,
                                112,
                                151,
                                186,
                                225,
                                246,
                                273,
                                281,
                                298,
                                307,
                                313,
                                315,
                                332,
                                342,
                                349,
                                378,
                                402,
                                409,
                                424,
                                446,
                                460,
                                468,
                                483,
                                486,
                                494,
                                498,
                                525,
                                526,
                                568,
                                582,
                                621,
                                727,
                                729,
                                732,
                                793,
                                803,
                                804,
                                845,
                                886,
                                904,
                                914,
                                947,
                                954,
                                1087,
                                1134,
                                1157,
                                1170,
                                1199,
                                1242,
                                1259,
                                1299,
                                1416,
                                1433,
                                1438,
                                1457,
                                1502,
                                1507,
                                1531,
                                1618,
                                1637,
                                1651,
                                1659,
                                1661,
                                1729,
                                1753,
                                1780,
                                1834,
                                1858,
                                1875,
                                1885,
                                1917,
                                1935,
                                1936,
                                1963,
                                1998,
                                2003,
                                2034,
                                2097,
                                2118,
                                2162,
                                2182,
                                2210,
                                2231,
                                2285,
                                2287,
                                2290,
                                2296,
                                2303,
                                2308,
                                2313,
                                2316,
                                2317,
                                2372,
                                2401,
                                2412,
                                2444,
                                2482,
                                2561,
                                2562,
                                2564,
                                2568,
                                2569,
                                2572,
                                2573,
                                2575,
                                2576,
                                2579,
                                2583,
                                2584,
                                2585,
                                2586,
                                2587,
                                2667,
                                2686,
                                2725
                            ]
                        },
                        {
                            "label": "factuality_assessment",
                            "description": "This cluster is dedicated to evaluating the factual accuracy of statements and claims using automated systems.",
                            "level": 3,
                            "example_papers": [
                                [
                                    2,
                                    "FIZZ: Factual Inconsistency Detection by Zoom-in Summary and Zoom-out Document"
                                ],
                                [
                                    61,
                                    "RULE: Reliable Multimodal RAG for Factuality in Medical Vision Language Models"
                                ],
                                [
                                    112,
                                    "Do We Need Language-Specific Fact-Checking Models? The Case of Chinese"
                                ],
                                [
                                    151,
                                    "Knowledge Verification to Nip Hallucination in the Bud"
                                ],
                                [
                                    186,
                                    "ScalingFilter: Assessing Data Quality through Inverse Utilization of Scaling Laws"
                                ],
                                [
                                    246,
                                    "An Analysis of Multilingual FActScore"
                                ],
                                [
                                    254,
                                    "F^2RL: Factuality and Faithfulness Reinforcement Learning Framework for Claim-Guided Evidence-Supported Counterspeech Generation"
                                ],
                                [
                                    281,
                                    "EVEDIT: Event-based Knowledge Editing for Deterministic Knowledge Propagation"
                                ],
                                [
                                    298,
                                    "LUQ: Long-text Uncertainty Quantification for LLMs"
                                ],
                                [
                                    307,
                                    "An LLM Feature-based Framework for Dialogue Constructiveness Assessment"
                                ]
                            ],
                            "paper_ids": [
                                2,
                                61,
                                112,
                                151,
                                186,
                                246,
                                254,
                                281,
                                298,
                                307,
                                313,
                                332,
                                349,
                                383,
                                402,
                                409,
                                446,
                                460,
                                468,
                                483,
                                486,
                                494,
                                525,
                                526,
                                582,
                                727,
                                732,
                                733,
                                793,
                                803,
                                804,
                                842,
                                845,
                                886,
                                893,
                                904,
                                910,
                                914,
                                947,
                                948,
                                1087,
                                1134,
                                1157,
                                1170,
                                1199,
                                1242,
                                1259,
                                1290,
                                1299,
                                1337,
                                1358,
                                1416,
                                1433,
                                1457,
                                1467,
                                1498,
                                1507,
                                1531,
                                1637,
                                1651,
                                1661,
                                1662,
                                1729,
                                1769,
                                1834,
                                1858,
                                1875,
                                1885,
                                1917,
                                1935,
                                1936,
                                1998,
                                2003,
                                2034,
                                2097,
                                2113,
                                2118,
                                2158,
                                2162,
                                2176,
                                2210,
                                2217,
                                2231,
                                2276,
                                2284,
                                2285,
                                2287,
                                2288,
                                2290,
                                2296,
                                2303,
                                2372,
                                2401,
                                2412,
                                2444,
                                2467,
                                2561,
                                2568,
                                2572,
                                2573,
                                2576,
                                2579,
                                2583,
                                2587,
                                2666,
                                2686
                            ]
                        },
                        {
                            "label": "fact_checking_systems",
                            "description": "This cluster involves the development and implementation of comprehensive systems that automate the fact-checking process.",
                            "level": 3,
                            "example_papers": [
                                [
                                    2,
                                    "FIZZ: Factual Inconsistency Detection by Zoom-in Summary and Zoom-out Document"
                                ],
                                [
                                    112,
                                    "Do We Need Language-Specific Fact-Checking Models? The Case of Chinese"
                                ],
                                [
                                    151,
                                    "Knowledge Verification to Nip Hallucination in the Bud"
                                ],
                                [
                                    225,
                                    "PRompt Optimization in Multi-Step Tasks (PROMST): Integrating Human Feedback and Heuristic-based Sampling"
                                ],
                                [
                                    246,
                                    "An Analysis of Multilingual FActScore"
                                ],
                                [
                                    254,
                                    "F^2RL: Factuality and Faithfulness Reinforcement Learning Framework for Claim-Guided Evidence-Supported Counterspeech Generation"
                                ],
                                [
                                    313,
                                    "LogicST: A Logical Self-Training Framework for Document-Level Relation Extraction with Incomplete Annotations"
                                ],
                                [
                                    349,
                                    "SciPrompt: Knowledge-augmented Prompting for Fine-grained Categorization of Scientific Topics"
                                ],
                                [
                                    402,
                                    "Does Large Language Model Contain Task-Specific Neurons?"
                                ],
                                [
                                    446,
                                    "ECON: On the Detection and Resolution of Evidence Conflicts"
                                ]
                            ],
                            "paper_ids": [
                                2,
                                112,
                                151,
                                225,
                                246,
                                254,
                                313,
                                349,
                                402,
                                446,
                                460,
                                468,
                                486,
                                494,
                                498,
                                526,
                                621,
                                674,
                                727,
                                732,
                                793,
                                804,
                                842,
                                845,
                                886,
                                893,
                                904,
                                910,
                                947,
                                948,
                                1134,
                                1157,
                                1170,
                                1199,
                                1242,
                                1277,
                                1290,
                                1293,
                                1299,
                                1337,
                                1358,
                                1416,
                                1438,
                                1457,
                                1507,
                                1531,
                                1637,
                                1640,
                                1729,
                                1780,
                                1834,
                                1858,
                                1875,
                                1876,
                                1917,
                                1936,
                                2034,
                                2041,
                                2097,
                                2113,
                                2118,
                                2162,
                                2210,
                                2276,
                                2290,
                                2296,
                                2303,
                                2317,
                                2372,
                                2401,
                                2412,
                                2437,
                                2444,
                                2554,
                                2560,
                                2561,
                                2562,
                                2563,
                                2564,
                                2567,
                                2568,
                                2569,
                                2570,
                                2571,
                                2572,
                                2573,
                                2574,
                                2575,
                                2576,
                                2584,
                                2585,
                                2587,
                                2640,
                                2643,
                                2666,
                                2686
                            ]
                        },
                        {
                            "label": "explainable_fact_checking",
                            "description": "This cluster emphasizes the creation of transparent and interpretable automated fact-checking methods that provide understandable justifications for their conclusions.",
                            "level": 3,
                            "example_papers": [
                                [
                                    2,
                                    "FIZZ: Factual Inconsistency Detection by Zoom-in Summary and Zoom-out Document"
                                ],
                                [
                                    102,
                                    "Event Causality Identification with Synthetic Control"
                                ],
                                [
                                    281,
                                    "EVEDIT: Event-based Knowledge Editing for Deterministic Knowledge Propagation"
                                ],
                                [
                                    307,
                                    "An LLM Feature-based Framework for Dialogue Constructiveness Assessment"
                                ],
                                [
                                    342,
                                    "SaySelf: Teaching LLMs to Express Confidence with Self-Reflective Rationales"
                                ],
                                [
                                    446,
                                    "ECON: On the Detection and Resolution of Evidence Conflicts"
                                ],
                                [
                                    494,
                                    "Revisiting Who's Harry Potter: Towards Targeted Unlearning from a Causal Intervention Perspective"
                                ],
                                [
                                    568,
                                    "Atomic Inference for NLI with Generated Facts as Atoms"
                                ],
                                [
                                    614,
                                    "Self-AMPLIFY: Improving Small Language Models with Self Post Hoc Explanations"
                                ],
                                [
                                    621,
                                    "Integrating Argumentation and Hate-Speech-based Techniques for Countering Misinformation"
                                ]
                            ],
                            "paper_ids": [
                                2,
                                102,
                                281,
                                307,
                                342,
                                446,
                                494,
                                568,
                                614,
                                621,
                                729,
                                732,
                                733,
                                845,
                                904,
                                910,
                                914,
                                947,
                                1134,
                                1170,
                                1242,
                                1277,
                                1293,
                                1299,
                                1457,
                                1467,
                                1576,
                                1640,
                                1651,
                                1656,
                                1729,
                                1834,
                                1885,
                                2118,
                                2182,
                                2210,
                                2316,
                                2372,
                                2482,
                                2561,
                                2576,
                                2579,
                                2582,
                                2585,
                                2643,
                                2657,
                                2686
                            ]
                        }
                    ]
                },
                {
                    "label": "claim_verification",
                    "description": "This cluster encompasses methods and techniques specifically aimed at verifying the truthfulness of individual claims made in various contexts.",
                    "level": 2,
                    "example_papers": [
                        [
                            255,
                            "Deciphering Rumors: A Multi-Task Learning Approach with Intent-aware Hierarchical Contrastive Learning"
                        ],
                        [
                            377,
                            "Right for Right Reasons: Large Language Models for Verifiable Commonsense Knowledge Graph Question Answering"
                        ],
                        [
                            378,
                            "Verifiable, Debuggable, and Repairable Commonsense Logical Reasoning via LLM-based Theory Resolution"
                        ],
                        [
                            411,
                            "Aligning Large Language Models with Diverse Political Viewpoints"
                        ],
                        [
                            468,
                            "Towards Verifiable Text Generation with Evolving Memory and Self-Reflection"
                        ],
                        [
                            469,
                            "Pelican: Correcting Hallucination in Vision-LLMs via Claim Decomposition and Program of Thought Verification"
                        ],
                        [
                            482,
                            "Perceptions of Linguistic Uncertainty by Language Models and Humans"
                        ],
                        [
                            498,
                            "MiniCheck: Efficient Fact-Checking of LLMs on Grounding Documents"
                        ],
                        [
                            530,
                            "Enhancing Systematic Decompositional Natural Language Inference Using Informal Logic"
                        ],
                        [
                            568,
                            "Atomic Inference for NLI with Generated Facts as Atoms"
                        ]
                    ],
                    "paper_ids": [
                        255,
                        377,
                        378,
                        411,
                        468,
                        469,
                        482,
                        498,
                        530,
                        568,
                        674,
                        729,
                        793,
                        817,
                        886,
                        904,
                        947,
                        953,
                        955,
                        1053,
                        1134,
                        1149,
                        1170,
                        1242,
                        1277,
                        1290,
                        1299,
                        1367,
                        1472,
                        1640,
                        1659,
                        1661,
                        1742,
                        1769,
                        1834,
                        1885,
                        1917,
                        1961,
                        1998,
                        2003,
                        2160,
                        2182,
                        2210,
                        2241,
                        2276,
                        2284,
                        2288,
                        2372,
                        2437,
                        2467,
                        2560,
                        2561,
                        2562,
                        2563,
                        2564,
                        2565,
                        2567,
                        2569,
                        2571,
                        2572,
                        2573,
                        2576,
                        2577,
                        2579,
                        2582,
                        2585,
                        2587,
                        2657,
                        2686
                    ],
                    "children": [
                        {
                            "label": "verification_techniques",
                            "description": "This cluster encompasses various methods and techniques specifically designed for the verification of claims, including automated and manual approaches.",
                            "level": 3,
                            "example_papers": [
                                [
                                    255,
                                    "Deciphering Rumors: A Multi-Task Learning Approach with Intent-aware Hierarchical Contrastive Learning"
                                ],
                                [
                                    377,
                                    "Right for Right Reasons: Large Language Models for Verifiable Commonsense Knowledge Graph Question Answering"
                                ],
                                [
                                    378,
                                    "Verifiable, Debuggable, and Repairable Commonsense Logical Reasoning via LLM-based Theory Resolution"
                                ],
                                [
                                    468,
                                    "Towards Verifiable Text Generation with Evolving Memory and Self-Reflection"
                                ],
                                [
                                    469,
                                    "Pelican: Correcting Hallucination in Vision-LLMs via Claim Decomposition and Program of Thought Verification"
                                ],
                                [
                                    482,
                                    "Perceptions of Linguistic Uncertainty by Language Models and Humans"
                                ],
                                [
                                    530,
                                    "Enhancing Systematic Decompositional Natural Language Inference Using Informal Logic"
                                ],
                                [
                                    568,
                                    "Atomic Inference for NLI with Generated Facts as Atoms"
                                ],
                                [
                                    729,
                                    "Boosting Logical Fallacy Reasoning in LLMs via Logical Structure Tree"
                                ],
                                [
                                    793,
                                    "Are LLMs Good Zero-Shot Fallacy Classifiers?"
                                ]
                            ],
                            "paper_ids": [
                                255,
                                377,
                                378,
                                468,
                                469,
                                482,
                                530,
                                568,
                                729,
                                793,
                                817,
                                904,
                                947,
                                953,
                                955,
                                1053,
                                1134,
                                1149,
                                1170,
                                1242,
                                1277,
                                1367,
                                1472,
                                1640,
                                1659,
                                1661,
                                1742,
                                1769,
                                1834,
                                1885,
                                1961,
                                2003,
                                2160,
                                2182,
                                2241,
                                2276,
                                2284,
                                2288,
                                2372,
                                2437,
                                2560,
                                2561,
                                2562,
                                2563,
                                2564,
                                2565,
                                2567,
                                2569,
                                2571,
                                2572,
                                2576,
                                2577,
                                2579,
                                2582,
                                2585,
                                2587,
                                2686
                            ]
                        },
                        {
                            "label": "evidence_verification",
                            "description": "This cluster focuses on the assessment and validation of evidence presented in support of claims, ensuring its reliability and relevance.",
                            "level": 3,
                            "example_papers": [
                                [
                                    255,
                                    "Deciphering Rumors: A Multi-Task Learning Approach with Intent-aware Hierarchical Contrastive Learning"
                                ],
                                [
                                    469,
                                    "Pelican: Correcting Hallucination in Vision-LLMs via Claim Decomposition and Program of Thought Verification"
                                ],
                                [
                                    482,
                                    "Perceptions of Linguistic Uncertainty by Language Models and Humans"
                                ],
                                [
                                    530,
                                    "Enhancing Systematic Decompositional Natural Language Inference Using Informal Logic"
                                ],
                                [
                                    904,
                                    "Rationale-Aware Answer Verification by Pairwise Self-Evaluation"
                                ],
                                [
                                    955,
                                    "Adaptive Question Answering: Enhancing Language Model Proficiency for Addressing Knowledge Conflicts with Source Citations"
                                ],
                                [
                                    1659,
                                    "Self-contradictory reasoning evaluation and detection"
                                ],
                                [
                                    1742,
                                    "Rater Cohesion and Quality from a Vicarious Perspective"
                                ],
                                [
                                    1834,
                                    "Wrong-of-Thought: An Integrated Reasoning Framework with Multi-Perspective Verification and Wrong Information"
                                ],
                                [
                                    1885,
                                    "On Evaluating Explanation Utility for Human-AI Decision Making in NLP"
                                ]
                            ],
                            "paper_ids": [
                                255,
                                469,
                                482,
                                530,
                                904,
                                955,
                                1659,
                                1742,
                                1834,
                                1885,
                                1961,
                                2182,
                                2241,
                                2560,
                                2561,
                                2565
                            ]
                        },
                        {
                            "label": "explainable_verification",
                            "description": "This cluster includes approaches that aim to provide transparent and understandable explanations for the verification process of claims.",
                            "level": 3,
                            "example_papers": [
                                [
                                    255,
                                    "Deciphering Rumors: A Multi-Task Learning Approach with Intent-aware Hierarchical Contrastive Learning"
                                ],
                                [
                                    469,
                                    "Pelican: Correcting Hallucination in Vision-LLMs via Claim Decomposition and Program of Thought Verification"
                                ],
                                [
                                    482,
                                    "Perceptions of Linguistic Uncertainty by Language Models and Humans"
                                ],
                                [
                                    817,
                                    "FinDVer: Explainable Claim Verification over Long and Hybrid-content Financial Documents"
                                ],
                                [
                                    904,
                                    "Rationale-Aware Answer Verification by Pairwise Self-Evaluation"
                                ],
                                [
                                    1299,
                                    "ClaimLens: Automated, Explainable Fact-Checking on Voting Claims Using Frame-Semantics"
                                ],
                                [
                                    1472,
                                    "Can Large Language Models Identify Authorship?"
                                ],
                                [
                                    1640,
                                    "Divide and Conquer: Legal Concept-guided Criminal Court View Generation"
                                ],
                                [
                                    1742,
                                    "Rater Cohesion and Quality from a Vicarious Perspective"
                                ],
                                [
                                    1834,
                                    "Wrong-of-Thought: An Integrated Reasoning Framework with Multi-Perspective Verification and Wrong Information"
                                ]
                            ],
                            "paper_ids": [
                                255,
                                469,
                                482,
                                817,
                                904,
                                1299,
                                1472,
                                1640,
                                1742,
                                1834,
                                1885,
                                2182,
                                2241,
                                2288,
                                2561,
                                2579,
                                2582,
                                2657
                            ]
                        },
                        {
                            "label": "fact_checking_methods",
                            "description": "This cluster covers diverse methodologies employed in the fact-checking process, including both traditional and innovative techniques.",
                            "level": 3,
                            "example_papers": [
                                [
                                    255,
                                    "Deciphering Rumors: A Multi-Task Learning Approach with Intent-aware Hierarchical Contrastive Learning"
                                ],
                                [
                                    377,
                                    "Right for Right Reasons: Large Language Models for Verifiable Commonsense Knowledge Graph Question Answering"
                                ],
                                [
                                    411,
                                    "Aligning Large Language Models with Diverse Political Viewpoints"
                                ],
                                [
                                    469,
                                    "Pelican: Correcting Hallucination in Vision-LLMs via Claim Decomposition and Program of Thought Verification"
                                ],
                                [
                                    482,
                                    "Perceptions of Linguistic Uncertainty by Language Models and Humans"
                                ],
                                [
                                    498,
                                    "MiniCheck: Efficient Fact-Checking of LLMs on Grounding Documents"
                                ],
                                [
                                    568,
                                    "Atomic Inference for NLI with Generated Facts as Atoms"
                                ],
                                [
                                    674,
                                    "Unknown Claims: Generation of Fact-Checking Training Examples from Unstructured and Structured Data"
                                ],
                                [
                                    793,
                                    "Are LLMs Good Zero-Shot Fallacy Classifiers?"
                                ],
                                [
                                    886,
                                    "Temporally Consistent Factuality Probing for Large Language Models"
                                ]
                            ],
                            "paper_ids": [
                                255,
                                377,
                                411,
                                469,
                                482,
                                498,
                                568,
                                674,
                                793,
                                886,
                                904,
                                947,
                                953,
                                955,
                                1134,
                                1149,
                                1170,
                                1242,
                                1277,
                                1290,
                                1299,
                                1640,
                                1661,
                                1742,
                                1834,
                                1885,
                                1917,
                                1961,
                                2003,
                                2182,
                                2210,
                                2241,
                                2276,
                                2284,
                                2437,
                                2560,
                                2561,
                                2562,
                                2563,
                                2564,
                                2565,
                                2567,
                                2569,
                                2571,
                                2572,
                                2573,
                                2576,
                                2579,
                                2582,
                                2585,
                                2686
                            ]
                        }
                    ]
                },
                {
                    "label": "misinformation_detection",
                    "description": "This cluster is dedicated to identifying and analyzing false or misleading information across different media and platforms.",
                    "level": 2,
                    "example_papers": [
                        [
                            30,
                            "On Fake News Detection with LLM Enhanced Semantics Mining"
                        ],
                        [
                            38,
                            "CoCoLoFa: A Dataset of News Comments with Common Logical Fallacies Written by LLM-Assisted Crowds"
                        ],
                        [
                            40,
                            "FLIRT: Feedback Loop In-context Red Teaming"
                        ],
                        [
                            67,
                            "Rethinking Pruning Large Language Models: Benefits and Pitfalls of Reconstruction Error Minimization"
                        ],
                        [
                            95,
                            "Glue pizza and eat rocks - Exploiting Vulnerabilities in Retrieval-Augmented Generative Models"
                        ],
                        [
                            114,
                            "CMD: a framework for Context-aware Model self-Detoxification"
                        ],
                        [
                            156,
                            "ASETF: A Novel Method for Jailbreak Attack on LLMs through Translate Suffix Embeddings"
                        ],
                        [
                            193,
                            "Pixology: Probing the Linguistic and Visual Capabilities of Pixel-based Language Models"
                        ],
                        [
                            194,
                            "GoldCoin: Grounding Large Language Models in Privacy Laws via Contextual Integrity Theory"
                        ],
                        [
                            246,
                            "An Analysis of Multilingual FActScore"
                        ]
                    ],
                    "paper_ids": [
                        30,
                        38,
                        40,
                        67,
                        95,
                        114,
                        156,
                        193,
                        194,
                        246,
                        252,
                        255,
                        276,
                        299,
                        307,
                        323,
                        376,
                        446,
                        447,
                        454,
                        480,
                        482,
                        483,
                        486,
                        493,
                        507,
                        512,
                        531,
                        549,
                        557,
                        568,
                        585,
                        589,
                        621,
                        656,
                        691,
                        719,
                        729,
                        793,
                        845,
                        894,
                        895,
                        917,
                        944,
                        951,
                        977,
                        989,
                        1006,
                        1089,
                        1112,
                        1134,
                        1141,
                        1157,
                        1172,
                        1199,
                        1228,
                        1230,
                        1242,
                        1257,
                        1259,
                        1357,
                        1366,
                        1374,
                        1391,
                        1433,
                        1532,
                        1542,
                        1543,
                        1555,
                        1637,
                        1651,
                        1656,
                        1721,
                        1769,
                        1781,
                        1799,
                        1834,
                        1870,
                        1907,
                        1961,
                        2003,
                        2005,
                        2022,
                        2059,
                        2075,
                        2158,
                        2182,
                        2189,
                        2196,
                        2210,
                        2218,
                        2225,
                        2228,
                        2284,
                        2288,
                        2296,
                        2308,
                        2316,
                        2337,
                        2340,
                        2370,
                        2416,
                        2437,
                        2467,
                        2482,
                        2563,
                        2579,
                        2582,
                        2585,
                        2600,
                        2602,
                        2641,
                        2657,
                        2666,
                        2667,
                        2671,
                        2686,
                        2730,
                        2743,
                        2800,
                        2802,
                        2805,
                        2806,
                        2810,
                        2949
                    ],
                    "children": [
                        {
                            "label": "fake_news_detection",
                            "description": "This subtopic focuses on identifying and analyzing false news articles and reports that spread misinformation across various media platforms.",
                            "level": 3,
                            "example_papers": [
                                [
                                    30,
                                    "On Fake News Detection with LLM Enhanced Semantics Mining"
                                ],
                                [
                                    1907,
                                    "Multilingual Fine-Grained News Headline Hallucination Detection"
                                ],
                                [
                                    2563,
                                    "RAG-Fusion Based Information Retrieval for Fact-Checking"
                                ],
                                [
                                    2585,
                                    "RAGAR, Your Falsehood Radar: RAG-Augmented Reasoning for Political Fact-Checking using Multimodal Large Language Models"
                                ]
                            ],
                            "paper_ids": [
                                30,
                                1907,
                                2563,
                                2585
                            ]
                        },
                        {
                            "label": "rumor_detection",
                            "description": "This subtopic is dedicated to detecting and analyzing unverified information or rumors that may contribute to the spread of misinformation.",
                            "level": 3,
                            "example_papers": [
                                [
                                    255,
                                    "Deciphering Rumors: A Multi-Task Learning Approach with Intent-aware Hierarchical Contrastive Learning"
                                ],
                                [
                                    621,
                                    "Integrating Argumentation and Hate-Speech-based Techniques for Countering Misinformation"
                                ],
                                [
                                    2585,
                                    "RAGAR, Your Falsehood Radar: RAG-Augmented Reasoning for Political Fact-Checking using Multimodal Large Language Models"
                                ]
                            ],
                            "paper_ids": [
                                255,
                                621,
                                2585
                            ]
                        },
                        {
                            "label": "propaganda_detection",
                            "description": "This subtopic involves identifying and analyzing biased or misleading information intended to promote a particular political agenda or viewpoint.",
                            "level": 3,
                            "example_papers": [
                                [
                                    1172,
                                    "ArMeme: Propagandistic Content in Arabic Memes"
                                ],
                                [
                                    2296,
                                    "Large Language Models for Propaganda Span Annotation"
                                ]
                            ],
                            "paper_ids": [
                                1172,
                                2296
                            ]
                        },
                        {
                            "label": "toxicity_detection",
                            "description": "This subtopic focuses on identifying harmful or toxic content that may contribute to misinformation and negatively impact public discourse.",
                            "level": 3,
                            "example_papers": [
                                [
                                    114,
                                    "CMD: a framework for Context-aware Model self-Detoxification"
                                ],
                                [
                                    917,
                                    "Intrinsic Self-correction for Enhanced Morality: An Analysis of Internal Mechanisms and the Superficial Hypothesis"
                                ],
                                [
                                    1089,
                                    "Adaptable Moral Stances of Large Language Models on Sexist Content: Implications for Society and Gender Discourse"
                                ],
                                [
                                    1799,
                                    "Can LLMs Recognize Toxicity? A Structured Investigation Framework and Toxicity Metric"
                                ],
                                [
                                    2210,
                                    "How to Train Your Fact Verifier: Knowledge Transfer with Multimodal Open Models"
                                ],
                                [
                                    2225,
                                    "Attribute Controlled Fine-tuning for Large Language Models: A Case Study on Detoxification"
                                ],
                                [
                                    2416,
                                    "ToxiCraft: A Novel Framework for Synthetic Generation of Harmful Information"
                                ]
                            ],
                            "paper_ids": [
                                114,
                                917,
                                1089,
                                1799,
                                2210,
                                2225,
                                2416
                            ]
                        },
                        {
                            "label": "visual_misinformation_detection",
                            "description": "This subtopic is dedicated to detecting misleading or false information presented through visual media, including images and videos.",
                            "level": 3,
                            "example_papers": [
                                [
                                    447,
                                    "\"Image, Tell me your story!\" Predicting the original meta-context of visual misinformation"
                                ],
                                [
                                    454,
                                    "Empowering Backbone Models for Visual Text Generation with Input Granularity Control and Glyph-Aware Training"
                                ],
                                [
                                    512,
                                    "The Factuality Tax of Diversity-Intervened Text-to-Image Generation: Benchmark and Fact-Augmented Intervention"
                                ],
                                [
                                    894,
                                    "MLLM-Protector: Ensuring MLLM's Safety without Hurting Performance"
                                ],
                                [
                                    1242,
                                    "M3D: MultiModal MultiDocument Fine-Grained Inconsistency Detection"
                                ],
                                [
                                    2059,
                                    "Multimodal Misinformation Detection by Learning from Synthetic Data with Multimodal LLMs"
                                ],
                                [
                                    2075,
                                    "Seeing Through VisualBERT: A Causal Adventure on Memetic Landscapes"
                                ],
                                [
                                    2585,
                                    "RAGAR, Your Falsehood Radar: RAG-Augmented Reasoning for Political Fact-Checking using Multimodal Large Language Models"
                                ],
                                [
                                    2810,
                                    "ARMADA: Attribute-Based Multimodal Data Augmentation"
                                ]
                            ],
                            "paper_ids": [
                                447,
                                454,
                                512,
                                894,
                                1242,
                                2059,
                                2075,
                                2585,
                                2810
                            ]
                        },
                        {
                            "label": "adversarial_attack_detection",
                            "description": "This subtopic focuses on identifying and mitigating adversarial attacks that aim to manipulate machine learning models and their outputs.",
                            "level": 3,
                            "example_papers": [
                                [
                                    40,
                                    "FLIRT: Feedback Loop In-context Red Teaming"
                                ],
                                [
                                    95,
                                    "Glue pizza and eat rocks - Exploiting Vulnerabilities in Retrieval-Augmented Generative Models"
                                ],
                                [
                                    156,
                                    "ASETF: A Novel Method for Jailbreak Attack on LLMs through Translate Suffix Embeddings"
                                ],
                                [
                                    480,
                                    "The Best Defense is Attack: Repairing Semantics in Textual Adversarial Examples"
                                ],
                                [
                                    894,
                                    "MLLM-Protector: Ensuring MLLM's Safety without Hurting Performance"
                                ],
                                [
                                    951,
                                    "How Susceptible are Large Language Models to Ideological Manipulation?"
                                ],
                                [
                                    1366,
                                    "KorSmishing Explainer: A Korean-centric LLM-based Framework for Smishing Detection and Explanation Generation"
                                ],
                                [
                                    1834,
                                    "Wrong-of-Thought: An Integrated Reasoning Framework with Multi-Perspective Verification and Wrong Information"
                                ],
                                [
                                    2003,
                                    "How Entangled is Factuality and Deception in German?"
                                ],
                                [
                                    2196,
                                    "Securing Multi-turn Conversational Language Models From Distributed Backdoor Attacks"
                                ]
                            ],
                            "paper_ids": [
                                40,
                                95,
                                156,
                                480,
                                894,
                                951,
                                1366,
                                1834,
                                2003,
                                2196
                            ]
                        },
                        {
                            "label": "misinformation_spread_detection",
                            "description": "This subtopic is dedicated to detecting and analyzing the mechanisms and patterns through which misinformation spreads across various platforms.",
                            "level": 3,
                            "example_papers": [
                                [
                                    38,
                                    "CoCoLoFa: A Dataset of News Comments with Common Logical Fallacies Written by LLM-Assisted Crowds"
                                ],
                                [
                                    193,
                                    "Pixology: Probing the Linguistic and Visual Capabilities of Pixel-based Language Models"
                                ],
                                [
                                    246,
                                    "An Analysis of Multilingual FActScore"
                                ],
                                [
                                    299,
                                    "Pretraining Data Detection for Large Language Models: A Divergence-based Calibration Method"
                                ],
                                [
                                    307,
                                    "An LLM Feature-based Framework for Dialogue Constructiveness Assessment"
                                ],
                                [
                                    323,
                                    "Thinking Outside of the Differential Privacy Box: A Case Study in Text Privatization with Language Model Prompting"
                                ],
                                [
                                    446,
                                    "ECON: On the Detection and Resolution of Evidence Conflicts"
                                ],
                                [
                                    482,
                                    "Perceptions of Linguistic Uncertainty by Language Models and Humans"
                                ],
                                [
                                    483,
                                    "Explaining and Improving Contrastive Decoding by Extrapolating the Probabilities of a Huge and Hypothetical LM"
                                ],
                                [
                                    486,
                                    "MisinfoEval: Generative AI in the Era of \"Alternative Facts\""
                                ]
                            ],
                            "paper_ids": [
                                38,
                                193,
                                246,
                                299,
                                307,
                                323,
                                446,
                                482,
                                483,
                                486,
                                493,
                                512,
                                568,
                                621,
                                656,
                                691,
                                719,
                                729,
                                793,
                                845,
                                895,
                                951,
                                989,
                                1089,
                                1134,
                                1141,
                                1157,
                                1199,
                                1230,
                                1242,
                                1257,
                                1259,
                                1357,
                                1366,
                                1374,
                                1532,
                                1543,
                                1555,
                                1656,
                                1721,
                                1769,
                                1834,
                                1870,
                                1907,
                                1961,
                                2003,
                                2005,
                                2022,
                                2059,
                                2158,
                                2182,
                                2210,
                                2218,
                                2288,
                                2296,
                                2308,
                                2316,
                                2337,
                                2340,
                                2416,
                                2437,
                                2482,
                                2563,
                                2579,
                                2582,
                                2585,
                                2600,
                                2602,
                                2671,
                                2686,
                                2730,
                                2800,
                                2802,
                                2806
                            ]
                        },
                        {
                            "label": "privacy_violation_detection",
                            "description": "This subtopic involves identifying instances of privacy violations that may arise from the misuse of personal data in the context of misinformation.",
                            "level": 3,
                            "example_papers": [
                                [
                                    194,
                                    "GoldCoin: Grounding Large Language Models in Privacy Laws via Contextual Integrity Theory"
                                ],
                                [
                                    252,
                                    "Order of Magnitude Speedups for LLM Membership Inference"
                                ],
                                [
                                    323,
                                    "Thinking Outside of the Differential Privacy Box: A Case Study in Text Privatization with Language Model Prompting"
                                ],
                                [
                                    376,
                                    "Reconstruct Your Previous Conversations! Comprehensively Investigating Privacy Leakage Risks in Conversations with GPT Models"
                                ],
                                [
                                    1089,
                                    "Adaptable Moral Stances of Large Language Models on Sexist Content: Implications for Society and Gender Discourse"
                                ],
                                [
                                    2340,
                                    "Evaluating Differentially Private Synthetic Data Generation in High-Stakes Domains"
                                ]
                            ],
                            "paper_ids": [
                                194,
                                252,
                                323,
                                376,
                                1089,
                                2340
                            ]
                        },
                        {
                            "label": "legal_misinformation_detection",
                            "description": "This subtopic focuses on identifying and analyzing misinformation that pertains to legal matters and its implications on public understanding.",
                            "level": 3,
                            "example_papers": [
                                [
                                    1089,
                                    "Adaptable Moral Stances of Large Language Models on Sexist Content: Implications for Society and Gender Discourse"
                                ],
                                [
                                    2370,
                                    "Misinformation with Legal Consequences (MisLC): A New Task Towards Harnessing Societal Harm of Misinformation"
                                ],
                                [
                                    2579,
                                    "Improving Explainable Fact-Checking via Sentence-Level Factual Reasoning"
                                ],
                                [
                                    2641,
                                    "uOttawa at LegalLens-2024: Transformer-based Classification Experiments"
                                ],
                                [
                                    2666,
                                    "Semantists at LegalLens-2024: Data-efficient Training of LLM's for Legal Violation Identification"
                                ],
                                [
                                    2667,
                                    "LegalLens Shared Task 2024: Legal Violation Identification in Unstructured Text"
                                ],
                                [
                                    2730,
                                    "Towards Explainable Multi-Label Text Classification: A Multi-Task Rationalisation Framework for Identifying Indicators of Forced Labour"
                                ]
                            ],
                            "paper_ids": [
                                1089,
                                2370,
                                2579,
                                2641,
                                2666,
                                2667,
                                2730
                            ]
                        },
                        {
                            "label": "health_advice_detection",
                            "description": "This subtopic is dedicated to detecting misleading or false health advice that can contribute to the spread of misinformation in health-related contexts.",
                            "level": 3,
                            "example_papers": [
                                [
                                    486,
                                    "MisinfoEval: Generative AI in the Era of \"Alternative Facts\""
                                ],
                                [
                                    719,
                                    "SPEED++: A Multilingual Event Extraction Framework for Epidemic Prediction and Preparedness"
                                ],
                                [
                                    1089,
                                    "Adaptable Moral Stances of Large Language Models on Sexist Content: Implications for Society and Gender Discourse"
                                ],
                                [
                                    1391,
                                    "Don't be my Doctor! Recognizing Healthcare Advice in Large Language Models"
                                ],
                                [
                                    2582,
                                    "AMREx: AMR for Explainable Fact Verification"
                                ]
                            ],
                            "paper_ids": [
                                486,
                                719,
                                1089,
                                1391,
                                2582
                            ]
                        }
                    ]
                },
                {
                    "label": "evidence_retrieval",
                    "description": "This cluster involves techniques for efficiently retrieving relevant evidence and data to support or refute claims during the fact-checking process.",
                    "level": 2,
                    "example_papers": [
                        [
                            14,
                            "Fine-Tuning or Retrieval? Comparing Knowledge Injection in LLMs"
                        ],
                        [
                            30,
                            "On Fake News Detection with LLM Enhanced Semantics Mining"
                        ],
                        [
                            53,
                            "Large Language Models for Data Annotation and Synthesis: A Survey"
                        ],
                        [
                            61,
                            "RULE: Reliable Multimodal RAG for Factuality in Medical Vision Language Models"
                        ],
                        [
                            112,
                            "Do We Need Language-Specific Fact-Checking Models? The Case of Chinese"
                        ],
                        [
                            141,
                            "Backward Lens: Projecting Language Model Gradients into the Vocabulary Space"
                        ],
                        [
                            155,
                            "To Word Senses and Beyond: Inducing Concepts with Contextualized Language Models"
                        ],
                        [
                            193,
                            "Pixology: Probing the Linguistic and Visual Capabilities of Pixel-based Language Models"
                        ],
                        [
                            194,
                            "GoldCoin: Grounding Large Language Models in Privacy Laws via Contextual Integrity Theory"
                        ],
                        [
                            254,
                            "F^2RL: Factuality and Faithfulness Reinforcement Learning Framework for Claim-Guided Evidence-Supported Counterspeech Generation"
                        ]
                    ],
                    "paper_ids": [
                        14,
                        30,
                        53,
                        61,
                        112,
                        141,
                        155,
                        193,
                        194,
                        254,
                        279,
                        281,
                        299,
                        323,
                        349,
                        383,
                        407,
                        411,
                        419,
                        447,
                        454,
                        460,
                        468,
                        498,
                        521,
                        530,
                        531,
                        549,
                        568,
                        585,
                        637,
                        664,
                        674,
                        679,
                        691,
                        719,
                        733,
                        776,
                        804,
                        817,
                        843,
                        849,
                        895,
                        944,
                        955,
                        1109,
                        1145,
                        1149,
                        1172,
                        1203,
                        1229,
                        1242,
                        1277,
                        1293,
                        1450,
                        1457,
                        1474,
                        1481,
                        1507,
                        1542,
                        1556,
                        1625,
                        1637,
                        1640,
                        1662,
                        1769,
                        1780,
                        1874,
                        1879,
                        1909,
                        1936,
                        1963,
                        1971,
                        1995,
                        1998,
                        2035,
                        2064,
                        2113,
                        2118,
                        2158,
                        2160,
                        2162,
                        2182,
                        2217,
                        2241,
                        2276,
                        2284,
                        2288,
                        2313,
                        2372,
                        2467,
                        2560,
                        2561,
                        2562,
                        2563,
                        2564,
                        2565,
                        2567,
                        2569,
                        2570,
                        2571,
                        2572,
                        2573,
                        2574,
                        2576,
                        2579,
                        2584,
                        2585,
                        2587,
                        2600,
                        2640,
                        2657,
                        2671,
                        2686,
                        2698,
                        2730,
                        2800,
                        2809
                    ],
                    "children": [
                        {
                            "label": "efficient_evidence_retrieval",
                            "description": "This subtopic focuses on techniques and methodologies aimed at enhancing the efficiency of retrieving relevant evidence to support or refute claims in the fact-checking process.",
                            "level": 3,
                            "example_papers": [
                                [
                                    14,
                                    "Fine-Tuning or Retrieval? Comparing Knowledge Injection in LLMs"
                                ],
                                [
                                    30,
                                    "On Fake News Detection with LLM Enhanced Semantics Mining"
                                ],
                                [
                                    112,
                                    "Do We Need Language-Specific Fact-Checking Models? The Case of Chinese"
                                ],
                                [
                                    194,
                                    "GoldCoin: Grounding Large Language Models in Privacy Laws via Contextual Integrity Theory"
                                ],
                                [
                                    279,
                                    "An Unsupervised Approach to Achieve Supervised-Level Explainability in Healthcare Records"
                                ],
                                [
                                    281,
                                    "EVEDIT: Event-based Knowledge Editing for Deterministic Knowledge Propagation"
                                ],
                                [
                                    299,
                                    "Pretraining Data Detection for Large Language Models: A Divergence-based Calibration Method"
                                ],
                                [
                                    323,
                                    "Thinking Outside of the Differential Privacy Box: A Case Study in Text Privatization with Language Model Prompting"
                                ],
                                [
                                    349,
                                    "SciPrompt: Knowledge-augmented Prompting for Fine-grained Categorization of Scientific Topics"
                                ],
                                [
                                    383,
                                    "Locating Information Gaps and Narrative Inconsistencies Across Languages: A Case Study of LGBT People Portrayals on Wikipedia"
                                ]
                            ],
                            "paper_ids": [
                                14,
                                30,
                                112,
                                194,
                                279,
                                281,
                                299,
                                323,
                                349,
                                383,
                                407,
                                447,
                                460,
                                468,
                                498,
                                521,
                                568,
                                585,
                                637,
                                664,
                                674,
                                679,
                                691,
                                719,
                                733,
                                776,
                                944,
                                1145,
                                1450,
                                1507,
                                1625,
                                1780,
                                1874,
                                1879,
                                1963,
                                1971,
                                1995,
                                2064,
                                2160,
                                2162,
                                2288,
                                2313,
                                2372,
                                2560,
                                2562,
                                2563,
                                2564,
                                2565,
                                2569,
                                2570,
                                2571,
                                2572,
                                2573,
                                2574,
                                2576,
                                2584,
                                2585,
                                2587,
                                2640,
                                2686,
                                2698,
                                2800,
                                2809
                            ]
                        },
                        {
                            "label": "reliable_evidence_retrieval",
                            "description": "This cluster emphasizes the development of methods that ensure the retrieval of trustworthy and credible evidence during fact-checking activities.",
                            "level": 3,
                            "example_papers": [
                                [
                                    14,
                                    "Fine-Tuning or Retrieval? Comparing Knowledge Injection in LLMs"
                                ],
                                [
                                    30,
                                    "On Fake News Detection with LLM Enhanced Semantics Mining"
                                ],
                                [
                                    61,
                                    "RULE: Reliable Multimodal RAG for Factuality in Medical Vision Language Models"
                                ],
                                [
                                    112,
                                    "Do We Need Language-Specific Fact-Checking Models? The Case of Chinese"
                                ],
                                [
                                    281,
                                    "EVEDIT: Event-based Knowledge Editing for Deterministic Knowledge Propagation"
                                ],
                                [
                                    323,
                                    "Thinking Outside of the Differential Privacy Box: A Case Study in Text Privatization with Language Model Prompting"
                                ],
                                [
                                    383,
                                    "Locating Information Gaps and Narrative Inconsistencies Across Languages: A Case Study of LGBT People Portrayals on Wikipedia"
                                ],
                                [
                                    419,
                                    "Unveiling Factual Recall Behaviors of Large Language Models through Knowledge Neurons"
                                ],
                                [
                                    447,
                                    "\"Image, Tell me your story!\" Predicting the original meta-context of visual misinformation"
                                ],
                                [
                                    521,
                                    "RuBLiMP: Russian Benchmark of Linguistic Minimal Pairs"
                                ]
                            ],
                            "paper_ids": [
                                14,
                                30,
                                61,
                                112,
                                281,
                                323,
                                383,
                                419,
                                447,
                                521,
                                585,
                                1109,
                                1172,
                                1277,
                                1450,
                                1769,
                                1780,
                                1874,
                                1995,
                                1998,
                                2118,
                                2217,
                                2276,
                                2467,
                                2560,
                                2567,
                                2569,
                                2573,
                                2574,
                                2579,
                                2584,
                                2585,
                                2640,
                                2657,
                                2671,
                                2730,
                                2800
                            ]
                        },
                        {
                            "label": "multi_hop_evidence_retrieval",
                            "description": "This subtopic involves strategies for retrieving evidence that requires multiple reasoning steps or connections to substantiate claims effectively.",
                            "level": 3,
                            "example_papers": [
                                [
                                    30,
                                    "On Fake News Detection with LLM Enhanced Semantics Mining"
                                ],
                                [
                                    281,
                                    "EVEDIT: Event-based Knowledge Editing for Deterministic Knowledge Propagation"
                                ],
                                [
                                    323,
                                    "Thinking Outside of the Differential Privacy Box: A Case Study in Text Privatization with Language Model Prompting"
                                ],
                                [
                                    407,
                                    "Python is Not Always the Best Choice: Embracing Multilingual Program of Thoughts"
                                ],
                                [
                                    419,
                                    "Unveiling Factual Recall Behaviors of Large Language Models through Knowledge Neurons"
                                ],
                                [
                                    447,
                                    "\"Image, Tell me your story!\" Predicting the original meta-context of visual misinformation"
                                ],
                                [
                                    521,
                                    "RuBLiMP: Russian Benchmark of Linguistic Minimal Pairs"
                                ],
                                [
                                    585,
                                    "Belief Revision: The Adaptability of Large Language Models Reasoning"
                                ],
                                [
                                    719,
                                    "SPEED++: A Multilingual Event Extraction Framework for Epidemic Prediction and Preparedness"
                                ],
                                [
                                    955,
                                    "Adaptive Question Answering: Enhancing Language Model Proficiency for Addressing Knowledge Conflicts with Source Citations"
                                ]
                            ],
                            "paper_ids": [
                                30,
                                281,
                                323,
                                407,
                                419,
                                447,
                                521,
                                585,
                                719,
                                955,
                                1242,
                                1457,
                                1909,
                                1936,
                                1995,
                                2113,
                                2182,
                                2560,
                                2561,
                                2567,
                                2574,
                                2576,
                                2584,
                                2585,
                                2600,
                                2800
                            ]
                        },
                        {
                            "label": "claim_guided_evidence_retrieval",
                            "description": "This area explores approaches that utilize specific claims to guide the retrieval of pertinent evidence, enhancing the relevance of the information gathered.",
                            "level": 3,
                            "example_papers": [
                                [
                                    30,
                                    "On Fake News Detection with LLM Enhanced Semantics Mining"
                                ],
                                [
                                    254,
                                    "F^2RL: Factuality and Faithfulness Reinforcement Learning Framework for Claim-Guided Evidence-Supported Counterspeech Generation"
                                ],
                                [
                                    281,
                                    "EVEDIT: Event-based Knowledge Editing for Deterministic Knowledge Propagation"
                                ],
                                [
                                    323,
                                    "Thinking Outside of the Differential Privacy Box: A Case Study in Text Privatization with Language Model Prompting"
                                ],
                                [
                                    447,
                                    "\"Image, Tell me your story!\" Predicting the original meta-context of visual misinformation"
                                ],
                                [
                                    521,
                                    "RuBLiMP: Russian Benchmark of Linguistic Minimal Pairs"
                                ],
                                [
                                    585,
                                    "Belief Revision: The Adaptability of Large Language Models Reasoning"
                                ],
                                [
                                    719,
                                    "SPEED++: A Multilingual Event Extraction Framework for Epidemic Prediction and Preparedness"
                                ],
                                [
                                    817,
                                    "FinDVer: Explainable Claim Verification over Long and Hybrid-content Financial Documents"
                                ],
                                [
                                    955,
                                    "Adaptive Question Answering: Enhancing Language Model Proficiency for Addressing Knowledge Conflicts with Source Citations"
                                ]
                            ],
                            "paper_ids": [
                                30,
                                254,
                                281,
                                323,
                                447,
                                521,
                                585,
                                719,
                                817,
                                955,
                                1242,
                                1457,
                                1995,
                                2241,
                                2560,
                                2562,
                                2563,
                                2564,
                                2565,
                                2570,
                                2571,
                                2572,
                                2573,
                                2574,
                                2576,
                                2584,
                                2585,
                                2730,
                                2800
                            ]
                        },
                        {
                            "label": "structured_evidence_retrieval",
                            "description": "This cluster focuses on the organization and retrieval of evidence in a structured manner, facilitating easier access and analysis during the fact-checking process.",
                            "level": 3,
                            "example_papers": [
                                [
                                    30,
                                    "On Fake News Detection with LLM Enhanced Semantics Mining"
                                ],
                                [
                                    112,
                                    "Do We Need Language-Specific Fact-Checking Models? The Case of Chinese"
                                ],
                                [
                                    155,
                                    "To Word Senses and Beyond: Inducing Concepts with Contextualized Language Models"
                                ],
                                [
                                    281,
                                    "EVEDIT: Event-based Knowledge Editing for Deterministic Knowledge Propagation"
                                ],
                                [
                                    323,
                                    "Thinking Outside of the Differential Privacy Box: A Case Study in Text Privatization with Language Model Prompting"
                                ],
                                [
                                    447,
                                    "\"Image, Tell me your story!\" Predicting the original meta-context of visual misinformation"
                                ],
                                [
                                    521,
                                    "RuBLiMP: Russian Benchmark of Linguistic Minimal Pairs"
                                ],
                                [
                                    530,
                                    "Enhancing Systematic Decompositional Natural Language Inference Using Informal Logic"
                                ],
                                [
                                    549,
                                    "Can Transformers Learn n-gram Language Models?"
                                ],
                                [
                                    585,
                                    "Belief Revision: The Adaptability of Large Language Models Reasoning"
                                ]
                            ],
                            "paper_ids": [
                                30,
                                112,
                                155,
                                281,
                                323,
                                447,
                                521,
                                530,
                                549,
                                585,
                                719,
                                895,
                                1203,
                                1293,
                                1450,
                                1474,
                                1481,
                                1556,
                                1640,
                                1874,
                                1995,
                                2035,
                                2113,
                                2118,
                                2241,
                                2276,
                                2560,
                                2570,
                                2574,
                                2584,
                                2585,
                                2640,
                                2800
                            ]
                        }
                    ]
                },
                {
                    "label": "hallucination_detection",
                    "description": "This cluster focuses on identifying instances where language models generate false or misleading information that does not correspond to real-world facts.",
                    "level": 2,
                    "example_papers": [
                        [
                            38,
                            "CoCoLoFa: A Dataset of News Comments with Common Logical Fallacies Written by LLM-Assisted Crowds"
                        ],
                        [
                            40,
                            "FLIRT: Feedback Loop In-context Red Teaming"
                        ],
                        [
                            115,
                            "Embedding and Gradient Say Wrong: A White-Box Method for Hallucination Detection"
                        ],
                        [
                            127,
                            "LogicAsker: Evaluating and Improving the Logical Reasoning Ability of Large Language Models"
                        ],
                        [
                            151,
                            "Knowledge Verification to Nip Hallucination in the Bud"
                        ],
                        [
                            154,
                            "Whispers that Shake Foundations: Analyzing and Mitigating False Premise Hallucinations in Large Language Models"
                        ],
                        [
                            156,
                            "ASETF: A Novel Method for Jailbreak Attack on LLMs through Translate Suffix Embeddings"
                        ],
                        [
                            163,
                            "Alignment-Enhanced Decoding: Defending Jailbreaks via Token-Level Adaptive Refining of Probability Distributions"
                        ],
                        [
                            194,
                            "GoldCoin: Grounding Large Language Models in Privacy Laws via Contextual Integrity Theory"
                        ],
                        [
                            227,
                            "Dissecting Fine-Tuning Unlearning in Large Language Models"
                        ]
                    ],
                    "paper_ids": [
                        38,
                        40,
                        115,
                        127,
                        151,
                        154,
                        156,
                        163,
                        194,
                        227,
                        254,
                        271,
                        363,
                        376,
                        377,
                        378,
                        394,
                        400,
                        426,
                        443,
                        468,
                        469,
                        480,
                        493,
                        494,
                        507,
                        512,
                        526,
                        529,
                        568,
                        573,
                        589,
                        628,
                        641,
                        678,
                        705,
                        729,
                        760,
                        793,
                        808,
                        836,
                        886,
                        895,
                        904,
                        910,
                        917,
                        933,
                        989,
                        1011,
                        1033,
                        1089,
                        1134,
                        1141,
                        1146,
                        1242,
                        1271,
                        1277,
                        1290,
                        1321,
                        1344,
                        1366,
                        1391,
                        1416,
                        1472,
                        1566,
                        1599,
                        1637,
                        1650,
                        1661,
                        1663,
                        1706,
                        1708,
                        1736,
                        1739,
                        1769,
                        1799,
                        1834,
                        1861,
                        1870,
                        1907,
                        1912,
                        1975,
                        1997,
                        2002,
                        2005,
                        2056,
                        2075,
                        2094,
                        2182,
                        2184,
                        2284,
                        2288,
                        2318,
                        2329,
                        2337,
                        2401,
                        2416,
                        2429,
                        2444,
                        2449,
                        2461,
                        2467,
                        2548,
                        2579,
                        2657,
                        2660,
                        2686,
                        2721,
                        2749,
                        2806
                    ],
                    "children": [
                        {
                            "label": "hallucination_detection_methods",
                            "description": "This cluster focuses on various techniques and methodologies developed for detecting hallucinations in language models, including both traditional and innovative approaches.",
                            "level": 3,
                            "example_papers": [
                                [
                                    38,
                                    "CoCoLoFa: A Dataset of News Comments with Common Logical Fallacies Written by LLM-Assisted Crowds"
                                ],
                                [
                                    40,
                                    "FLIRT: Feedback Loop In-context Red Teaming"
                                ],
                                [
                                    115,
                                    "Embedding and Gradient Say Wrong: A White-Box Method for Hallucination Detection"
                                ],
                                [
                                    154,
                                    "Whispers that Shake Foundations: Analyzing and Mitigating False Premise Hallucinations in Large Language Models"
                                ],
                                [
                                    156,
                                    "ASETF: A Novel Method for Jailbreak Attack on LLMs through Translate Suffix Embeddings"
                                ],
                                [
                                    271,
                                    "A Peek into Token Bias: Large Language Models Are Not Yet Genuine Reasoners"
                                ],
                                [
                                    376,
                                    "Reconstruct Your Previous Conversations! Comprehensively Investigating Privacy Leakage Risks in Conversations with GPT Models"
                                ],
                                [
                                    394,
                                    "Knowledge-Centric Hallucination Detection"
                                ],
                                [
                                    400,
                                    "Towards Understanding Jailbreak Attacks in LLMs: A Representation Space Analysis"
                                ],
                                [
                                    426,
                                    "Is LLM-as-a-Judge Robust? Investigating Universal Adversarial Attacks on Zero-shot LLM Assessment"
                                ]
                            ],
                            "paper_ids": [
                                38,
                                40,
                                115,
                                154,
                                156,
                                271,
                                376,
                                394,
                                400,
                                426,
                                443,
                                469,
                                480,
                                493,
                                507,
                                526,
                                529,
                                589,
                                641,
                                793,
                                808,
                                836,
                                886,
                                910,
                                989,
                                1011,
                                1033,
                                1146,
                                1271,
                                1321,
                                1391,
                                1416,
                                1637,
                                1650,
                                1661,
                                1708,
                                1736,
                                1870,
                                1907,
                                1912,
                                1975,
                                2056,
                                2075,
                                2094,
                                2182,
                                2184,
                                2288,
                                2318,
                                2329,
                                2416,
                                2660,
                                2686,
                                2721
                            ]
                        },
                        {
                            "label": "factuality_evaluation",
                            "description": "This cluster encompasses methods and metrics used to assess the factual accuracy of information generated by language models, ensuring that outputs align with real-world facts.",
                            "level": 3,
                            "example_papers": [
                                [
                                    254,
                                    "F^2RL: Factuality and Faithfulness Reinforcement Learning Framework for Claim-Guided Evidence-Supported Counterspeech Generation"
                                ],
                                [
                                    271,
                                    "A Peek into Token Bias: Large Language Models Are Not Yet Genuine Reasoners"
                                ],
                                [
                                    363,
                                    "Personas as a Way to Model Truthfulness in Language Models"
                                ],
                                [
                                    394,
                                    "Knowledge-Centric Hallucination Detection"
                                ],
                                [
                                    468,
                                    "Towards Verifiable Text Generation with Evolving Memory and Self-Reflection"
                                ],
                                [
                                    493,
                                    "\"Flex Tape Can't Fix That\": Bias and Misinformation in Edited Language Models"
                                ],
                                [
                                    507,
                                    "On the Relationship between Truth and Political Bias in Language Models"
                                ],
                                [
                                    512,
                                    "The Factuality Tax of Diversity-Intervened Text-to-Image Generation: Benchmark and Fact-Augmented Intervention"
                                ],
                                [
                                    526,
                                    "Synchronous Faithfulness Monitoring for Trustworthy Retrieval-Augmented Generation"
                                ],
                                [
                                    589,
                                    "LLMs Are Prone to Fallacies in Causal Inference"
                                ]
                            ],
                            "paper_ids": [
                                254,
                                271,
                                363,
                                394,
                                468,
                                493,
                                507,
                                512,
                                526,
                                589,
                                678,
                                705,
                                793,
                                836,
                                886,
                                895,
                                904,
                                910,
                                1011,
                                1134,
                                1141,
                                1146,
                                1242,
                                1277,
                                1290,
                                1344,
                                1416,
                                1599,
                                1637,
                                1661,
                                1736,
                                1769,
                                1975,
                                2005,
                                2056,
                                2182,
                                2284,
                                2337,
                                2401,
                                2416,
                                2444,
                                2449,
                                2461,
                                2467,
                                2579,
                                2686,
                                2806
                            ]
                        },
                        {
                            "label": "hallucination_mitigation",
                            "description": "This cluster addresses strategies and techniques aimed at reducing the occurrence of hallucinations in language models, enhancing their reliability and trustworthiness.",
                            "level": 3,
                            "example_papers": [
                                [
                                    151,
                                    "Knowledge Verification to Nip Hallucination in the Bud"
                                ],
                                [
                                    154,
                                    "Whispers that Shake Foundations: Analyzing and Mitigating False Premise Hallucinations in Large Language Models"
                                ],
                                [
                                    163,
                                    "Alignment-Enhanced Decoding: Defending Jailbreaks via Token-Level Adaptive Refining of Probability Distributions"
                                ],
                                [
                                    227,
                                    "Dissecting Fine-Tuning Unlearning in Large Language Models"
                                ],
                                [
                                    254,
                                    "F^2RL: Factuality and Faithfulness Reinforcement Learning Framework for Claim-Guided Evidence-Supported Counterspeech Generation"
                                ],
                                [
                                    271,
                                    "A Peek into Token Bias: Large Language Models Are Not Yet Genuine Reasoners"
                                ],
                                [
                                    363,
                                    "Personas as a Way to Model Truthfulness in Language Models"
                                ],
                                [
                                    377,
                                    "Right for Right Reasons: Large Language Models for Verifiable Commonsense Knowledge Graph Question Answering"
                                ],
                                [
                                    378,
                                    "Verifiable, Debuggable, and Repairable Commonsense Logical Reasoning via LLM-based Theory Resolution"
                                ],
                                [
                                    426,
                                    "Is LLM-as-a-Judge Robust? Investigating Universal Adversarial Attacks on Zero-shot LLM Assessment"
                                ]
                            ],
                            "paper_ids": [
                                151,
                                154,
                                163,
                                227,
                                254,
                                271,
                                363,
                                377,
                                378,
                                426,
                                443,
                                468,
                                469,
                                480,
                                493,
                                494,
                                507,
                                512,
                                526,
                                568,
                                573,
                                628,
                                678,
                                705,
                                729,
                                760,
                                793,
                                895,
                                904,
                                910,
                                917,
                                933,
                                989,
                                1011,
                                1033,
                                1089,
                                1134,
                                1146,
                                1271,
                                1277,
                                1344,
                                1391,
                                1416,
                                1599,
                                1637,
                                1650,
                                1663,
                                1706,
                                1739,
                                1799,
                                1834,
                                1907,
                                1912,
                                2056,
                                2094,
                                2182,
                                2184,
                                2284,
                                2318,
                                2329,
                                2337,
                                2401,
                                2444,
                                2548
                            ]
                        },
                        {
                            "label": "knowledge_verification",
                            "description": "This cluster involves the processes and tools used to verify the knowledge and information presented by language models, ensuring that it is accurate and credible.",
                            "level": 3,
                            "example_papers": [
                                [
                                    151,
                                    "Knowledge Verification to Nip Hallucination in the Bud"
                                ],
                                [
                                    271,
                                    "A Peek into Token Bias: Large Language Models Are Not Yet Genuine Reasoners"
                                ],
                                [
                                    377,
                                    "Right for Right Reasons: Large Language Models for Verifiable Commonsense Knowledge Graph Question Answering"
                                ],
                                [
                                    378,
                                    "Verifiable, Debuggable, and Repairable Commonsense Logical Reasoning via LLM-based Theory Resolution"
                                ],
                                [
                                    443,
                                    "Does Fine-Tuning LLMs on New Knowledge Encourage Hallucinations?"
                                ],
                                [
                                    468,
                                    "Towards Verifiable Text Generation with Evolving Memory and Self-Reflection"
                                ],
                                [
                                    493,
                                    "\"Flex Tape Can't Fix That\": Bias and Misinformation in Edited Language Models"
                                ],
                                [
                                    507,
                                    "On the Relationship between Truth and Political Bias in Language Models"
                                ],
                                [
                                    526,
                                    "Synchronous Faithfulness Monitoring for Trustworthy Retrieval-Augmented Generation"
                                ],
                                [
                                    793,
                                    "Are LLMs Good Zero-Shot Fallacy Classifiers?"
                                ]
                            ],
                            "paper_ids": [
                                151,
                                271,
                                377,
                                378,
                                443,
                                468,
                                493,
                                507,
                                526,
                                793,
                                910,
                                1011,
                                1141,
                                1146,
                                1271,
                                1277,
                                1416,
                                1472,
                                1599,
                                1637,
                                1769,
                                1834,
                                2056,
                                2182,
                                2284,
                                2337,
                                2449,
                                2548,
                                2806
                            ]
                        },
                        {
                            "label": "explanation_methods",
                            "description": "This cluster focuses on the development of explanation techniques that help elucidate the reasoning behind language model outputs, particularly in the context of hallucinations.",
                            "level": 3,
                            "example_papers": [
                                [
                                    127,
                                    "LogicAsker: Evaluating and Improving the Logical Reasoning Ability of Large Language Models"
                                ],
                                [
                                    271,
                                    "A Peek into Token Bias: Large Language Models Are Not Yet Genuine Reasoners"
                                ],
                                [
                                    363,
                                    "Personas as a Way to Model Truthfulness in Language Models"
                                ],
                                [
                                    493,
                                    "\"Flex Tape Can't Fix That\": Bias and Misinformation in Edited Language Models"
                                ],
                                [
                                    494,
                                    "Revisiting Who's Harry Potter: Towards Targeted Unlearning from a Causal Intervention Perspective"
                                ],
                                [
                                    507,
                                    "On the Relationship between Truth and Political Bias in Language Models"
                                ],
                                [
                                    526,
                                    "Synchronous Faithfulness Monitoring for Trustworthy Retrieval-Augmented Generation"
                                ],
                                [
                                    568,
                                    "Atomic Inference for NLI with Generated Facts as Atoms"
                                ],
                                [
                                    793,
                                    "Are LLMs Good Zero-Shot Fallacy Classifiers?"
                                ],
                                [
                                    910,
                                    "Finding Blind Spots in Evaluator LLMs with Interpretable Checklists"
                                ]
                            ],
                            "paper_ids": [
                                127,
                                271,
                                363,
                                493,
                                494,
                                507,
                                526,
                                568,
                                793,
                                910,
                                1011,
                                1089,
                                1146,
                                1242,
                                1277,
                                1366,
                                1472,
                                1637,
                                1861,
                                1997,
                                2002,
                                2056,
                                2075,
                                2182,
                                2288,
                                2461,
                                2579,
                                2657,
                                2749
                            ]
                        }
                    ]
                }
            ]
        },
        {
            "label": "hate_speech_detection",
            "description": "The task of identifying and classifying speech that incites violence or prejudicial action against a particular group.",
            "level": 1,
            "example_papers": [
                [
                    5,
                    "ImageInWords: Unlocking Hyper-Detailed Image Descriptions"
                ],
                [
                    9,
                    "Hateful Word in Context Classification"
                ],
                [
                    10,
                    "Eyes Don't Lie: Subjective Hate Annotation and Detection with Gaze"
                ],
                [
                    13,
                    "A Usage-centric Take on Intent Understanding in E-Commerce"
                ],
                [
                    17,
                    "Uncertainty in Language Models: Assessment through Rank-Calibration"
                ],
                [
                    33,
                    "A Study of Nationality Bias in Names and Perplexity using Off-the-Shelf Affect-related Tweet Classifiers"
                ],
                [
                    38,
                    "CoCoLoFa: A Dataset of News Comments with Common Logical Fallacies Written by LLM-Assisted Crowds"
                ],
                [
                    39,
                    "Tokenization Is More Than Compression"
                ],
                [
                    40,
                    "FLIRT: Feedback Loop In-context Red Teaming"
                ],
                [
                    42,
                    "Parameter-Efficient Sparsity Crafting from Dense to Mixture-of-Experts for Instruction Tuning on General Tasks"
                ]
            ],
            "paper_ids": [
                5,
                9,
                10,
                13,
                17,
                33,
                38,
                39,
                40,
                42,
                52,
                53,
                56,
                67,
                81,
                84,
                114,
                131,
                135,
                141,
                155,
                156,
                163,
                165,
                166,
                169,
                186,
                193,
                194,
                200,
                225,
                235,
                242,
                252,
                254,
                258,
                259,
                273,
                276,
                279,
                286,
                299,
                300,
                307,
                315,
                323,
                332,
                342,
                344,
                376,
                402,
                407,
                409,
                425,
                426,
                436,
                444,
                454,
                460,
                475,
                480,
                483,
                508,
                511,
                515,
                521,
                523,
                525,
                529,
                530,
                531,
                545,
                549,
                557,
                573,
                585,
                594,
                605,
                613,
                614,
                621,
                628,
                631,
                637,
                641,
                656,
                658,
                662,
                664,
                679,
                689,
                691,
                702,
                719,
                729,
                732,
                733,
                741,
                746,
                760,
                763,
                775,
                776,
                800,
                803,
                808,
                809,
                825,
                843,
                845,
                846,
                847,
                849,
                885,
                894,
                895,
                909,
                914,
                917,
                930,
                932,
                941,
                944,
                948,
                951,
                954,
                958,
                965,
                977,
                993,
                1006,
                1018,
                1021,
                1027,
                1028,
                1033,
                1035,
                1053,
                1065,
                1069,
                1089,
                1095,
                1096,
                1098,
                1109,
                1112,
                1129,
                1133,
                1134,
                1145,
                1149,
                1157,
                1159,
                1165,
                1170,
                1172,
                1173,
                1199,
                1203,
                1220,
                1225,
                1228,
                1230,
                1233,
                1254,
                1257,
                1259,
                1260,
                1278,
                1282,
                1308,
                1311,
                1334,
                1337,
                1344,
                1357,
                1359,
                1366,
                1374,
                1403,
                1417,
                1433,
                1438,
                1441,
                1442,
                1443,
                1446,
                1450,
                1472,
                1474,
                1481,
                1485,
                1493,
                1498,
                1502,
                1527,
                1532,
                1533,
                1539,
                1540,
                1542,
                1555,
                1556,
                1576,
                1585,
                1586,
                1599,
                1618,
                1625,
                1634,
                1636,
                1640,
                1646,
                1651,
                1653,
                1659,
                1663,
                1688,
                1690,
                1700,
                1707,
                1717,
                1722,
                1734,
                1739,
                1742,
                1753,
                1764,
                1767,
                1769,
                1781,
                1789,
                1790,
                1796,
                1799,
                1802,
                1812,
                1843,
                1852,
                1854,
                1858,
                1861,
                1870,
                1875,
                1876,
                1879,
                1885,
                1896,
                1909,
                1935,
                1936,
                1941,
                1952,
                1957,
                1971,
                1975,
                1997,
                2002,
                2005,
                2015,
                2022,
                2034,
                2035,
                2041,
                2048,
                2056,
                2064,
                2066,
                2075,
                2100,
                2138,
                2160,
                2184,
                2196,
                2215,
                2225,
                2228,
                2230,
                2231,
                2245,
                2267,
                2285,
                2287,
                2288,
                2289,
                2296,
                2313,
                2316,
                2317,
                2318,
                2329,
                2337,
                2340,
                2341,
                2356,
                2361,
                2377,
                2387,
                2412,
                2416,
                2429,
                2443,
                2467,
                2472,
                2481,
                2482,
                2488,
                2506,
                2513,
                2521,
                2535,
                2556,
                2600,
                2602,
                2628,
                2640,
                2641,
                2643,
                2657,
                2670,
                2671,
                2679,
                2680,
                2698,
                2721,
                2724,
                2730,
                2733,
                2741,
                2749,
                2752,
                2764,
                2772,
                2802,
                2809,
                2810,
                2948,
                2949
            ],
            "children": [
                {
                    "label": "hate_speech_classification",
                    "description": "The task of categorizing instances of hate speech into predefined classes based on their content and context.",
                    "level": 2,
                    "example_papers": [
                        [
                            9,
                            "Hateful Word in Context Classification"
                        ],
                        [
                            10,
                            "Eyes Don't Lie: Subjective Hate Annotation and Detection with Gaze"
                        ],
                        [
                            33,
                            "A Study of Nationality Bias in Names and Perplexity using Off-the-Shelf Affect-related Tweet Classifiers"
                        ],
                        [
                            131,
                            "Oddballs and Misfits: Detecting Implicit Abuse in Which Identity Groups are Depicted as Deviating from the Norm"
                        ],
                        [
                            135,
                            "Towards Low-Resource Harmful Meme Detection with LMM Agents"
                        ],
                        [
                            200,
                            "Is Safer Better? The Impact of Guardrails on the Argumentative Strength of LLMs in Hate Speech Countering"
                        ],
                        [
                            242,
                            "STOP! Benchmarking Large Language Models with Sensitivity Testing on Offensive Progressions"
                        ],
                        [
                            254,
                            "F^2RL: Factuality and Faithfulness Reinforcement Learning Framework for Claim-Guided Evidence-Supported Counterspeech Generation"
                        ],
                        [
                            258,
                            "Leveraging Conflicts in Social Media Posts: Unintended Offense Dataset"
                        ],
                        [
                            344,
                            "ToxiCloakCN: Evaluating Robustness of Offensive Language Detection in Chinese with Cloaking Perturbations"
                        ]
                    ],
                    "paper_ids": [
                        9,
                        10,
                        33,
                        131,
                        135,
                        200,
                        242,
                        254,
                        258,
                        344,
                        444,
                        483,
                        613,
                        614,
                        621,
                        637,
                        691,
                        885,
                        951,
                        958,
                        1018,
                        1089,
                        1098,
                        1133,
                        1165,
                        1170,
                        1172,
                        1199,
                        1220,
                        1225,
                        1233,
                        1282,
                        1366,
                        1442,
                        1502,
                        1555,
                        1640,
                        1700,
                        1789,
                        1790,
                        1852,
                        1858,
                        1971,
                        2056,
                        2075,
                        2160,
                        2296,
                        2316,
                        2317,
                        2341,
                        2377,
                        2416,
                        2521,
                        2600,
                        2724,
                        2741,
                        2949
                    ],
                    "children": [
                        {
                            "label": "hate_detection",
                            "description": "The task of identifying and categorizing instances of hate speech based on their content, focusing on the explicit expressions of hate.",
                            "level": 3,
                            "example_papers": [
                                [
                                    9,
                                    "Hateful Word in Context Classification"
                                ],
                                [
                                    10,
                                    "Eyes Don't Lie: Subjective Hate Annotation and Detection with Gaze"
                                ],
                                [
                                    33,
                                    "A Study of Nationality Bias in Names and Perplexity using Off-the-Shelf Affect-related Tweet Classifiers"
                                ],
                                [
                                    344,
                                    "ToxiCloakCN: Evaluating Robustness of Offensive Language Detection in Chinese with Cloaking Perturbations"
                                ],
                                [
                                    444,
                                    "Bridging Modalities: Enhancing Cross-Modality Hate Speech Detection with Few-Shot In-Context Learning"
                                ],
                                [
                                    885,
                                    "Hate Personified: Investigating the role of LLMs in content moderation"
                                ],
                                [
                                    1018,
                                    "Please note that I'm just an AI: Analysis of Behavior Patterns of LLMs in (Non-)offensive Speech Identification"
                                ],
                                [
                                    1098,
                                    "Delving into Qualitative Implications of Synthetic Data for Hate Speech Detection"
                                ],
                                [
                                    1165,
                                    "PREDICT: Multi-Agent-based Debate Simulation for Generalized Hate Speech Detection"
                                ],
                                [
                                    1220,
                                    "Accurate and Data-Efficient Toxicity Prediction when Annotators Disagree"
                                ]
                            ],
                            "paper_ids": [
                                9,
                                10,
                                33,
                                344,
                                444,
                                885,
                                1018,
                                1098,
                                1165,
                                1220,
                                1852,
                                2075,
                                2341,
                                2416
                            ]
                        },
                        {
                            "label": "implicit_abuse_detection",
                            "description": "The task of recognizing and classifying subtle or implicit forms of hate speech that may not be overtly aggressive but still convey harmful sentiments.",
                            "level": 3,
                            "example_papers": [
                                [
                                    131,
                                    "Oddballs and Misfits: Detecting Implicit Abuse in Which Identity Groups are Depicted as Deviating from the Norm"
                                ],
                                [
                                    258,
                                    "Leveraging Conflicts in Social Media Posts: Unintended Offense Dataset"
                                ],
                                [
                                    1852,
                                    "PclGPT: A Large Language Model for Patronizing and Condescending Language Detection"
                                ]
                            ],
                            "paper_ids": [
                                131,
                                258,
                                1852
                            ]
                        },
                        {
                            "label": "bias_in_hate_speech_models",
                            "description": "The examination and classification of biases present in models used for hate speech detection, assessing how these biases affect the outcomes of hate speech classification.",
                            "level": 3,
                            "example_papers": [
                                [
                                    33,
                                    "A Study of Nationality Bias in Names and Perplexity using Off-the-Shelf Affect-related Tweet Classifiers"
                                ],
                                [
                                    242,
                                    "STOP! Benchmarking Large Language Models with Sensitivity Testing on Offensive Progressions"
                                ],
                                [
                                    613,
                                    "Towards Probing Speech-Specific Risks in Large Multimodal Models: A Taxonomy, Benchmark, and Insights"
                                ],
                                [
                                    951,
                                    "How Susceptible are Large Language Models to Ideological Manipulation?"
                                ],
                                [
                                    1133,
                                    "\"They are uncultured\": Unveiling Covert Harms and Social Threats in LLM Generated Conversations"
                                ],
                                [
                                    1790,
                                    "Giving Control Back to Models: Enabling Offensive Language Detection Models to Autonomously Identify and Mitigate Biases"
                                ],
                                [
                                    1852,
                                    "PclGPT: A Large Language Model for Patronizing and Condescending Language Detection"
                                ]
                            ],
                            "paper_ids": [
                                33,
                                242,
                                613,
                                951,
                                1133,
                                1790,
                                1852
                            ]
                        },
                        {
                            "label": "hate_speech_mitigation",
                            "description": "The task of developing strategies and methods to reduce the prevalence and impact of hate speech in various contexts, focusing on intervention techniques.",
                            "level": 3,
                            "example_papers": [
                                [
                                    135,
                                    "Towards Low-Resource Harmful Meme Detection with LMM Agents"
                                ],
                                [
                                    200,
                                    "Is Safer Better? The Impact of Guardrails on the Argumentative Strength of LLMs in Hate Speech Countering"
                                ],
                                [
                                    242,
                                    "STOP! Benchmarking Large Language Models with Sensitivity Testing on Offensive Progressions"
                                ],
                                [
                                    254,
                                    "F^2RL: Factuality and Faithfulness Reinforcement Learning Framework for Claim-Guided Evidence-Supported Counterspeech Generation"
                                ],
                                [
                                    344,
                                    "ToxiCloakCN: Evaluating Robustness of Offensive Language Detection in Chinese with Cloaking Perturbations"
                                ],
                                [
                                    444,
                                    "Bridging Modalities: Enhancing Cross-Modality Hate Speech Detection with Few-Shot In-Context Learning"
                                ],
                                [
                                    483,
                                    "Explaining and Improving Contrastive Decoding by Extrapolating the Probabilities of a Huge and Hypothetical LM"
                                ],
                                [
                                    621,
                                    "Integrating Argumentation and Hate-Speech-based Techniques for Countering Misinformation"
                                ],
                                [
                                    637,
                                    "TEMA: Token Embeddings Mapping for Enriching Low-Resource Language Models"
                                ],
                                [
                                    885,
                                    "Hate Personified: Investigating the role of LLMs in content moderation"
                                ]
                            ],
                            "paper_ids": [
                                135,
                                200,
                                242,
                                254,
                                344,
                                444,
                                483,
                                621,
                                637,
                                885,
                                951,
                                1089,
                                1133,
                                1165,
                                1172,
                                1199,
                                1225,
                                1233,
                                1282,
                                1442,
                                1502,
                                1555,
                                1700,
                                1789,
                                1790,
                                1852,
                                1971,
                                2056,
                                2316,
                                2317,
                                2377,
                                2521,
                                2600,
                                2741,
                                2949
                            ]
                        },
                        {
                            "label": "explainable_hate_speech_detection",
                            "description": "The task of creating models for hate speech detection that provide interpretable and understandable explanations for their classifications, enhancing transparency.",
                            "level": 3,
                            "example_papers": [
                                [
                                    10,
                                    "Eyes Don't Lie: Subjective Hate Annotation and Detection with Gaze"
                                ],
                                [
                                    614,
                                    "Self-AMPLIFY: Improving Small Language Models with Self Post Hoc Explanations"
                                ],
                                [
                                    691,
                                    "Latent Concept-based Explanation of NLP Models"
                                ],
                                [
                                    1089,
                                    "Adaptable Moral Stances of Large Language Models on Sexist Content: Implications for Society and Gender Discourse"
                                ],
                                [
                                    1366,
                                    "KorSmishing Explainer: A Korean-centric LLM-based Framework for Smishing Detection and Explanation Generation"
                                ],
                                [
                                    1700,
                                    "Recent Advances in Online Hate Speech Moderation: Multimodality and the Role of Large Models"
                                ],
                                [
                                    1789,
                                    "HateCOT: An Explanation-Enhanced Dataset for Generalizable Offensive Speech Detection via Large Language Models"
                                ],
                                [
                                    1852,
                                    "PclGPT: A Large Language Model for Patronizing and Condescending Language Detection"
                                ],
                                [
                                    2316,
                                    "LLMs for Generating and Evaluating Counterfactuals: A Comprehensive Study"
                                ],
                                [
                                    2741,
                                    "Explainable Identification of Hate Speech towards Islam using Graph Neural Networks"
                                ]
                            ],
                            "paper_ids": [
                                10,
                                614,
                                691,
                                1089,
                                1366,
                                1700,
                                1789,
                                1852,
                                2316,
                                2741
                            ]
                        }
                    ]
                },
                {
                    "label": "counterspeech_generation",
                    "description": "The process of creating responses or narratives that counteract hate speech and promote positive dialogue.",
                    "level": 2,
                    "example_papers": [
                        [
                            200,
                            "Is Safer Better? The Impact of Guardrails on the Argumentative Strength of LLMs in Hate Speech Countering"
                        ],
                        [
                            254,
                            "F^2RL: Factuality and Faithfulness Reinforcement Learning Framework for Claim-Guided Evidence-Supported Counterspeech Generation"
                        ],
                        [
                            259,
                            "Outcome-Constrained Large Language Models for Countering Hate Speech"
                        ],
                        [
                            621,
                            "Integrating Argumentation and Hate-Speech-based Techniques for Countering Misinformation"
                        ],
                        [
                            1442,
                            "Countering Hateful and Offensive Speech Online - Open Challenges"
                        ],
                        [
                            1896,
                            "Contextualized Graph Representations for Generating Counter-Narratives against Hate Speech"
                        ],
                        [
                            2005,
                            "A LLM-based Ranking Method for the Evaluation of Automatic Counter-Narrative Generation"
                        ],
                        [
                            2377,
                            "LLM generated responses to mitigate the impact of hate speech"
                        ],
                        [
                            2521,
                            "CrowdCounter: A benchmark type-specific multi-target counterspeech dataset"
                        ]
                    ],
                    "paper_ids": [
                        200,
                        254,
                        259,
                        621,
                        1442,
                        1896,
                        2005,
                        2377,
                        2521
                    ]
                },
                {
                    "label": "misogyny_detection",
                    "description": "The identification and classification of speech that expresses hatred or prejudice against women.",
                    "level": 2,
                    "example_papers": [
                        [
                            1089,
                            "Adaptable Moral Stances of Large Language Models on Sexist Content: Implications for Society and Gender Discourse"
                        ],
                        [
                            1173,
                            "Language is Scary when Over-Analyzed: Unpacking Implied Misogynistic Reasoning with Argumentation Theory-Driven Prompts"
                        ],
                        [
                            1233,
                            "M3Hop-CoT: Misogynous Meme Identification with Multimodal Multi-hop Chain-of-Thought"
                        ]
                    ],
                    "paper_ids": [
                        1089,
                        1173,
                        1233
                    ]
                },
                {
                    "label": "cross-cultural_offensiveness_detection",
                    "description": "The task of detecting offensive language that varies in meaning and impact across different cultural contexts.",
                    "level": 2,
                    "example_papers": [
                        [
                            885,
                            "Hate Personified: Investigating the role of LLMs in content moderation"
                        ],
                        [
                            1028,
                            "D3CODE: Disentangling Disagreements in Data across Cultures on Offensiveness Detection and Evaluation"
                        ],
                        [
                            1089,
                            "Adaptable Moral Stances of Large Language Models on Sexist Content: Implications for Society and Gender Discourse"
                        ],
                        [
                            2772,
                            "Should We Respect LLMs? A Cross-Lingual Study on the Influence of Prompt Politeness on LLM Performance"
                        ]
                    ],
                    "paper_ids": [
                        885,
                        1028,
                        1089,
                        2772
                    ]
                },
                {
                    "label": "toxic_content_mitigation",
                    "description": "Strategies and methods aimed at reducing the prevalence and impact of toxic language in online communications.",
                    "level": 2,
                    "example_papers": [
                        [
                            114,
                            "CMD: a framework for Context-aware Model self-Detoxification"
                        ],
                        [
                            163,
                            "Alignment-Enhanced Decoding: Defending Jailbreaks via Token-Level Adaptive Refining of Probability Distributions"
                        ],
                        [
                            186,
                            "ScalingFilter: Assessing Data Quality through Inverse Utilization of Scaling Laws"
                        ],
                        [
                            242,
                            "STOP! Benchmarking Large Language Models with Sensitivity Testing on Offensive Progressions"
                        ],
                        [
                            460,
                            "Data Advisor: Dynamic Data Curation for Safety Alignment of Large Language Models"
                        ],
                        [
                            475,
                            "Walking in Others' Shoes: How Perspective-Taking Guides Large Language Models in Reducing Toxicity and Bias"
                        ],
                        [
                            760,
                            "Householder Pseudo-Rotation: A Novel Approach to Activation Editing in LLMs with Direction-Magnitude Perspective"
                        ],
                        [
                            847,
                            "XDetox: Text Detoxification with Token-Level Toxicity Explanations"
                        ],
                        [
                            885,
                            "Hate Personified: Investigating the role of LLMs in content moderation"
                        ],
                        [
                            1065,
                            "DetoxLLM: A Framework for Detoxification with Explanations"
                        ]
                    ],
                    "paper_ids": [
                        114,
                        163,
                        186,
                        242,
                        460,
                        475,
                        760,
                        847,
                        885,
                        1065,
                        1089,
                        1442,
                        1700,
                        1789,
                        1799,
                        2230,
                        2285,
                        2377,
                        2416
                    ]
                },
                {
                    "label": "backdoor_attack_detection",
                    "description": "The task of identifying and mitigating backdoor attacks in machine learning models, particularly in the context of hate speech detection.",
                    "level": 2,
                    "example_papers": [
                        [
                            40,
                            "FLIRT: Feedback Loop In-context Red Teaming"
                        ],
                        [
                            156,
                            "ASETF: A Novel Method for Jailbreak Attack on LLMs through Translate Suffix Embeddings"
                        ],
                        [
                            242,
                            "STOP! Benchmarking Large Language Models with Sensitivity Testing on Offensive Progressions"
                        ],
                        [
                            299,
                            "Pretraining Data Detection for Large Language Models: A Divergence-based Calibration Method"
                        ],
                        [
                            426,
                            "Is LLM-as-a-Judge Robust? Investigating Universal Adversarial Attacks on Zero-shot LLM Assessment"
                        ],
                        [
                            641,
                            "Universal Vulnerabilities in Large Language Models: Backdoor Attacks for In-context Learning"
                        ],
                        [
                            1033,
                            "Jailbreaking LLMs with Arabic Transliteration and Arabizi"
                        ],
                        [
                            1739,
                            "Defending Large Language Models Against Jailbreak Attacks via Layer-specific Editing"
                        ],
                        [
                            1781,
                            "PKAD: Pretrained Knowledge is All You Need to Detect and Mitigate Textual Backdoor Attacks"
                        ],
                        [
                            2196,
                            "Securing Multi-turn Conversational Language Models From Distributed Backdoor Attacks"
                        ]
                    ],
                    "paper_ids": [
                        40,
                        156,
                        242,
                        299,
                        426,
                        641,
                        1033,
                        1739,
                        1781,
                        2196
                    ]
                },
                {
                    "label": "multi-task_hate_speech_learning",
                    "description": "The approach of simultaneously training models to perform multiple related tasks in the domain of hate speech detection and classification.",
                    "level": 2,
                    "example_papers": [
                        [
                            10,
                            "Eyes Don't Lie: Subjective Hate Annotation and Detection with Gaze"
                        ],
                        [
                            242,
                            "STOP! Benchmarking Large Language Models with Sensitivity Testing on Offensive Progressions"
                        ],
                        [
                            332,
                            "Teaching Small Language Models Reasoning through Counterfactual Distillation"
                        ],
                        [
                            407,
                            "Python is Not Always the Best Choice: Embracing Multilingual Program of Thoughts"
                        ],
                        [
                            409,
                            "Incomplete Utterance Rewriting with Editing Operation Guidance and Utterance Augmentation"
                        ],
                        [
                            444,
                            "Bridging Modalities: Enhancing Cross-Modality Hate Speech Detection with Few-Shot In-Context Learning"
                        ],
                        [
                            803,
                            "DC-Instruct: An Effective Framework for Generative Multi-intent Spoken Language Understanding"
                        ],
                        [
                            846,
                            "Layer by Layer: Uncovering Where Multi-Task Learning Happens in Instruction-Tuned Large Language Models"
                        ],
                        [
                            1053,
                            "Argument Relation Classification through Discourse Markers and Adversarial Training"
                        ],
                        [
                            1165,
                            "PREDICT: Multi-Agent-based Debate Simulation for Generalized Hate Speech Detection"
                        ]
                    ],
                    "paper_ids": [
                        10,
                        242,
                        332,
                        407,
                        409,
                        444,
                        803,
                        846,
                        1053,
                        1165,
                        1450,
                        1625,
                        1700,
                        1764,
                        1789,
                        1935,
                        1936,
                        2035,
                        2288,
                        2316,
                        2361,
                        2724,
                        2730,
                        2741
                    ]
                },
                {
                    "label": "legal_outcome_hate_speech_prediction",
                    "description": "The task of predicting legal outcomes related to hate speech incidents based on various contextual and textual features.",
                    "level": 2,
                    "example_papers": [
                        [
                            242,
                            "STOP! Benchmarking Large Language Models with Sensitivity Testing on Offensive Progressions"
                        ],
                        [
                            2640,
                            "Enhancing Legal Expertise in Large Language Models through Composite Model Integration: The Development and Evaluation of Law-Neo"
                        ],
                        [
                            2657,
                            "Comparative Study of Explainability Methods for Legal Outcome Prediction"
                        ],
                        [
                            2670,
                            "Towards Supporting Legal Argumentation with NLP: Is More Data Really All You Need?"
                        ]
                    ],
                    "paper_ids": [
                        242,
                        2640,
                        2657,
                        2670
                    ]
                }
            ]
        }
    ]
}