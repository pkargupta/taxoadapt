{
    "label": "natural_language_processing",
    "description": null,
    "level": 0,
    "source": "initial",
    "example_papers": [
        [
            0,
            "Generative Knowledge Graph Construction: A Review"
        ],
        [
            1,
            "CDConv: A Benchmark for Contradiction Detection in Chinese Conversations"
        ],
        [
            5,
            "Backdoor Attacks in Federated Learning by Rare Embeddings and Gradient Ensembling"
        ],
        [
            6,
            "Generating Natural Language Proofs with Verifier-Guided Search"
        ],
        [
            7,
            "Toward Unifying Text Segmentation and Long Document Summarization"
        ],
        [
            8,
            "The Geometry of Multilingual Language Model Representations"
        ],
        [
            9,
            "Improving Complex Knowledge Base Question Answering via Question-to-Action and Question-to-Question Alignment"
        ],
        [
            10,
            "PAIR: Prompt-Aware margIn Ranking for Counselor Reflection Scoring in Motivational Interviewing"
        ],
        [
            13,
            "Interpreting Language Models with Contrastive Explanations"
        ],
        [
            14,
            "RankGen: Improving text generation with Large Ranking Models"
        ]
    ],
    "paper_ids": [
        0,
        1,
        5,
        6,
        7,
        8,
        9,
        10,
        13,
        14,
        15,
        16,
        17,
        18,
        19,
        21,
        22,
        24,
        25,
        26,
        27,
        28,
        31,
        35,
        36,
        37,
        38,
        39,
        40,
        41,
        44,
        46,
        48,
        50,
        55,
        60,
        61,
        62,
        63,
        68,
        69,
        71,
        73,
        74,
        75,
        78,
        79,
        81,
        83,
        85,
        87,
        88,
        90,
        92,
        94,
        96,
        98,
        99,
        100,
        103,
        105,
        109,
        114,
        115,
        116,
        117,
        118,
        119,
        120,
        121,
        122,
        123,
        125,
        127,
        128,
        129,
        130,
        131,
        132,
        133,
        134,
        135,
        136,
        137,
        138,
        140,
        141,
        142,
        143,
        145,
        146,
        147,
        149,
        152,
        153,
        154,
        155,
        157,
        164,
        165,
        166,
        167,
        168,
        169,
        171,
        172,
        174,
        177,
        178,
        184,
        187,
        188,
        190,
        191,
        194,
        200,
        201,
        204,
        207,
        210,
        214,
        215,
        216,
        219,
        223,
        224,
        227,
        228,
        229,
        232,
        233,
        235,
        236,
        237,
        238,
        244,
        246,
        247,
        248,
        249,
        250,
        251,
        252,
        254,
        255,
        257,
        260,
        261,
        262,
        266,
        268,
        275,
        276,
        282,
        286,
        289,
        291,
        292,
        293,
        296,
        297,
        298,
        299,
        300,
        304,
        307,
        308,
        309,
        310,
        313,
        314,
        316,
        318,
        319,
        322,
        324,
        325,
        326,
        329,
        332,
        333,
        334,
        336,
        338,
        339,
        340,
        346,
        347,
        349,
        356,
        364,
        365,
        369,
        371,
        372,
        373,
        375,
        377,
        379,
        382,
        385,
        386,
        388,
        389,
        391,
        392,
        394,
        396,
        398,
        399,
        404,
        405,
        408,
        410,
        413,
        414,
        415,
        417,
        419,
        420,
        424,
        425,
        428,
        432,
        437,
        439,
        442,
        444,
        449,
        450,
        452,
        455,
        456,
        457,
        462,
        463,
        468,
        469,
        471,
        472,
        475,
        476,
        477,
        478,
        479,
        481,
        483,
        488,
        489,
        491,
        492,
        493,
        494,
        495,
        496,
        498,
        499,
        500,
        502,
        505,
        506,
        509,
        510,
        512,
        515,
        517,
        520,
        524,
        525,
        530,
        531,
        532,
        533,
        534,
        538,
        539,
        541,
        545,
        546,
        551,
        554,
        556,
        563,
        565,
        568,
        569,
        570,
        579,
        587,
        588,
        590,
        591,
        592,
        593,
        594,
        595,
        597,
        600,
        601,
        603,
        606,
        608,
        612,
        613,
        614,
        615,
        616,
        617,
        618,
        619,
        620,
        621,
        622,
        623,
        624,
        625,
        626,
        627,
        628,
        629,
        630,
        631,
        634,
        635,
        636,
        639,
        640,
        641,
        642,
        643,
        644,
        645,
        648,
        650,
        652,
        653,
        654,
        656,
        657,
        658,
        661,
        662,
        664,
        665,
        666,
        668,
        669,
        670,
        671,
        672,
        673,
        674,
        675,
        676,
        677,
        681,
        683,
        685,
        687,
        688,
        696,
        697,
        698,
        699,
        700,
        702,
        704,
        709,
        710,
        711,
        713,
        714,
        717,
        720,
        723,
        724,
        725,
        726,
        729,
        730,
        731,
        732,
        735,
        736,
        737,
        738,
        742,
        743,
        744,
        745,
        747,
        748,
        750,
        751,
        752,
        753,
        754,
        756,
        757,
        758,
        759,
        760,
        761,
        766,
        767,
        768,
        769,
        770,
        771,
        773,
        774,
        775,
        776,
        778,
        782,
        783,
        784,
        786,
        788,
        789,
        790,
        792,
        793,
        794,
        795,
        796,
        797,
        802,
        803,
        805,
        806,
        808,
        810,
        811,
        812,
        813,
        814,
        815,
        816,
        817,
        819,
        820,
        821,
        822,
        826
    ],
    "children": [
        {
            "label": "benchmarking",
            "description": "Benchmarking involves the systematic comparison of different models or algorithms on standardized datasets to evaluate their performance and identify strengths and weaknesses.",
            "level": 1,
            "source": "initial",
            "example_papers": [
                [
                    1,
                    "CDConv: A Benchmark for Contradiction Detection in Chinese Conversations"
                ],
                [
                    7,
                    "Toward Unifying Text Segmentation and Long Document Summarization"
                ],
                [
                    10,
                    "PAIR: Prompt-Aware margIn Ranking for Counselor Reflection Scoring in Motivational Interviewing"
                ],
                [
                    37,
                    "Abstract Visual Reasoning with Tangram Shapes"
                ],
                [
                    38,
                    "UnifiedSKG: Unifying and Multi-Tasking Structured Knowledge Grounding with Text-to-Text Language Models"
                ],
                [
                    40,
                    "When Can Transformers Ground and Compose: Insights from Compositional Generalization Benchmarks"
                ],
                [
                    41,
                    "Generative Language Models for Paragraph-Level Question Generation"
                ],
                [
                    44,
                    "Crossmodal-3600: A Massively Multilingual Multimodal Evaluation Dataset"
                ],
                [
                    62,
                    "M2D2: A Massively Multi-Domain Language Modeling Dataset"
                ],
                [
                    68,
                    "Multilingual Relation Classification via Efficient and Effective Prompting"
                ]
            ],
            "paper_ids": [
                1,
                7,
                10,
                37,
                38,
                40,
                41,
                44,
                62,
                68,
                74,
                87,
                88,
                90,
                92,
                109,
                116,
                121,
                127,
                128,
                129,
                131,
                137,
                147,
                153,
                155,
                171,
                187,
                190,
                201,
                210,
                228,
                248,
                249,
                250,
                252,
                260,
                266,
                286,
                291,
                300,
                304,
                309,
                314,
                319,
                325,
                333,
                334,
                339,
                346,
                347,
                356,
                365,
                373,
                375,
                379,
                389,
                391,
                394,
                410,
                414,
                415,
                417,
                420,
                425,
                468,
                469,
                475,
                476,
                493,
                510,
                525,
                530,
                531,
                554,
                568,
                570,
                579,
                592,
                593,
                597,
                614,
                621,
                630,
                635,
                639,
                640,
                652,
                653,
                658,
                661,
                668,
                669,
                672,
                676,
                677,
                685,
                697,
                699,
                702,
                710,
                723,
                726,
                732,
                735,
                743,
                747,
                748,
                750,
                754,
                768,
                770,
                773,
                774,
                783,
                784,
                786,
                790,
                792,
                794,
                795,
                810,
                822
            ],
            "children": [
                {
                    "label": "benchmarking_techniques",
                    "description": "This cluster focuses on various methodologies and approaches used for benchmarking models and algorithms in natural language processing.",
                    "level": 2,
                    "source": "depth",
                    "example_papers": [
                        [
                            1,
                            "CDConv: A Benchmark for Contradiction Detection in Chinese Conversations"
                        ],
                        [
                            7,
                            "Toward Unifying Text Segmentation and Long Document Summarization"
                        ],
                        [
                            10,
                            "PAIR: Prompt-Aware margIn Ranking for Counselor Reflection Scoring in Motivational Interviewing"
                        ],
                        [
                            37,
                            "Abstract Visual Reasoning with Tangram Shapes"
                        ],
                        [
                            38,
                            "UnifiedSKG: Unifying and Multi-Tasking Structured Knowledge Grounding with Text-to-Text Language Models"
                        ],
                        [
                            40,
                            "When Can Transformers Ground and Compose: Insights from Compositional Generalization Benchmarks"
                        ],
                        [
                            41,
                            "Generative Language Models for Paragraph-Level Question Generation"
                        ],
                        [
                            44,
                            "Crossmodal-3600: A Massively Multilingual Multimodal Evaluation Dataset"
                        ],
                        [
                            74,
                            "SQuALITY: Building a Long-Document Summarization Dataset the Hard Way"
                        ],
                        [
                            87,
                            "How well can Text-to-Image Generative Models understand Ethical Natural Language Interventions?"
                        ]
                    ],
                    "paper_ids": [
                        1,
                        7,
                        10,
                        37,
                        38,
                        40,
                        41,
                        44,
                        74,
                        87,
                        88,
                        90,
                        92,
                        109,
                        116,
                        121,
                        127,
                        128,
                        129,
                        131,
                        137,
                        147,
                        153,
                        187,
                        190,
                        201,
                        210,
                        248,
                        249,
                        250,
                        252,
                        286,
                        291,
                        300,
                        304,
                        309,
                        319,
                        325,
                        333,
                        334,
                        339,
                        346,
                        347,
                        356,
                        365,
                        373,
                        379,
                        391,
                        394,
                        410,
                        414,
                        415,
                        417,
                        420,
                        468,
                        469,
                        475,
                        476,
                        493,
                        510,
                        525,
                        531,
                        554,
                        568,
                        570,
                        579,
                        592,
                        593,
                        597,
                        614,
                        621,
                        630,
                        635,
                        639,
                        640,
                        653,
                        658,
                        661,
                        668,
                        672,
                        676,
                        677,
                        685,
                        697,
                        702,
                        726,
                        732,
                        743,
                        747,
                        750,
                        770,
                        773,
                        774,
                        783,
                        784,
                        786,
                        792,
                        795,
                        810,
                        822
                    ]
                },
                {
                    "label": "cross-lingual_benchmarking",
                    "description": "This cluster encompasses benchmarking methods that evaluate models across different languages and linguistic contexts.",
                    "level": 2,
                    "source": "depth",
                    "example_papers": [
                        [
                            44,
                            "Crossmodal-3600: A Massively Multilingual Multimodal Evaluation Dataset"
                        ],
                        [
                            131,
                            "GeoMLAMA: Geo-Diverse Commonsense Probing on Multilingual Pre-Trained Language Models"
                        ],
                        [
                            137,
                            "Stanceosaurus: Classifying Stance Towards Multicultural Misinformation"
                        ],
                        [
                            201,
                            "Multi-level Distillation of Semantic Knowledge for Pre-training Multilingual Language Model"
                        ],
                        [
                            525,
                            "ClidSum: A Benchmark Dataset for Cross-Lingual Dialogue Summarization"
                        ],
                        [
                            531,
                            "DivEMT: Neural Machine Translation Post-Editing Effort Across Typologically Diverse Languages"
                        ],
                        [
                            570,
                            "SMaLL-100: Introducing Shallow Multilingual Machine Translation Model for Low-Resource Languages"
                        ],
                        [
                            672,
                            "Label-aware Multi-level Contrastive Learning for Cross-lingual Spoken Language Understanding"
                        ],
                        [
                            735,
                            "Don't Stop Fine-Tuning: On Training Regimes for Few-Shot Cross-Lingual Transfer with Multilingual Language Models"
                        ],
                        [
                            754,
                            "IndicXNLI: Evaluating Multilingual Inference for Indian Languages"
                        ]
                    ],
                    "paper_ids": [
                        44,
                        131,
                        137,
                        201,
                        525,
                        531,
                        570,
                        672,
                        735,
                        754
                    ]
                },
                {
                    "label": "robustness_evaluation",
                    "description": "This cluster includes methods aimed at assessing the robustness and reliability of models under various conditions.",
                    "level": 2,
                    "source": "depth",
                    "example_papers": [
                        [
                            44,
                            "Crossmodal-3600: A Massively Multilingual Multimodal Evaluation Dataset"
                        ],
                        [
                            131,
                            "GeoMLAMA: Geo-Diverse Commonsense Probing on Multilingual Pre-Trained Language Models"
                        ],
                        [
                            137,
                            "Stanceosaurus: Classifying Stance Towards Multicultural Misinformation"
                        ],
                        [
                            171,
                            "How Far are We from Robust Long Abstractive Summarization?"
                        ],
                        [
                            266,
                            "ProsocialDialog: A Prosocial Backbone for Conversational Agents"
                        ],
                        [
                            347,
                            "RuCoLA: Russian Corpus of Linguistic Acceptability"
                        ],
                        [
                            530,
                            "DuQM: A Chinese Dataset of Linguistically Perturbed Natural Questions for Evaluating the Robustness of Question Matching Models"
                        ],
                        [
                            570,
                            "SMaLL-100: Introducing Shallow Multilingual Machine Translation Model for Low-Resource Languages"
                        ],
                        [
                            652,
                            "RobustLR: A Diagnostic Benchmark for Evaluating Logical Robustness of Deductive Reasoners"
                        ],
                        [
                            669,
                            "CRIPP-VQA: Counterfactual Reasoning about Implicit Physical Properties via Video Question Answering"
                        ]
                    ],
                    "paper_ids": [
                        44,
                        131,
                        137,
                        171,
                        266,
                        347,
                        530,
                        570,
                        652,
                        669,
                        770
                    ]
                },
                {
                    "label": "domain_adaptation_benchmarking",
                    "description": "This cluster focuses on benchmarking techniques specifically designed for evaluating model performance in different domains.",
                    "level": 2,
                    "source": "depth",
                    "example_papers": [
                        [
                            41,
                            "Generative Language Models for Paragraph-Level Question Generation"
                        ],
                        [
                            62,
                            "M2D2: A Massively Multi-Domain Language Modeling Dataset"
                        ],
                        [
                            131,
                            "GeoMLAMA: Geo-Diverse Commonsense Probing on Multilingual Pre-Trained Language Models"
                        ],
                        [
                            137,
                            "Stanceosaurus: Classifying Stance Towards Multicultural Misinformation"
                        ],
                        [
                            147,
                            "When FLUE Meets FLANG: Benchmarks and Large Pretrained Language Model for Financial Domain"
                        ],
                        [
                            260,
                            "Mixed-effects transformers for hierarchical adaptation"
                        ],
                        [
                            291,
                            "A Second Wave of UD Hebrew Treebanking and Cross-Domain Parsing"
                        ],
                        [
                            356,
                            "DuReader-Retrieval: A Large-scale Chinese Benchmark for Passage Retrieval from Web Search Engine"
                        ],
                        [
                            389,
                            "BioReader: a Retrieval-Enhanced Text-to-Text Transformer for Biomedical Literature"
                        ],
                        [
                            425,
                            "Factorizing Content and Budget Decisions in Abstractive Summarization of Long Documents"
                        ]
                    ],
                    "paper_ids": [
                        41,
                        62,
                        131,
                        137,
                        147,
                        260,
                        291,
                        356,
                        389,
                        425,
                        748
                    ]
                },
                {
                    "label": "few-shot_benchmarking",
                    "description": "This cluster covers benchmarking methods that evaluate model performance in few-shot learning scenarios.",
                    "level": 2,
                    "source": "depth",
                    "example_papers": [
                        [
                            68,
                            "Multilingual Relation Classification via Efficient and Effective Prompting"
                        ],
                        [
                            129,
                            "Large language models are few-shot clinical information extractors"
                        ],
                        [
                            131,
                            "GeoMLAMA: Geo-Diverse Commonsense Probing on Multilingual Pre-Trained Language Models"
                        ],
                        [
                            147,
                            "When FLUE Meets FLANG: Benchmarks and Large Pretrained Language Model for Financial Domain"
                        ],
                        [
                            735,
                            "Don't Stop Fine-Tuning: On Training Regimes for Few-Shot Cross-Lingual Transfer with Multilingual Language Models"
                        ],
                        [
                            750,
                            "FETA: A Benchmark for Few-Sample Task Transfer in Open-Domain Dialogue"
                        ]
                    ],
                    "paper_ids": [
                        68,
                        129,
                        131,
                        147,
                        735,
                        750
                    ]
                }
            ]
        },
        {
            "label": "comparative_studies",
            "description": "Comparative studies assess the performance of various natural language processing methods against each other, providing insights into their relative effectiveness and applicability in different contexts.",
            "level": 1,
            "source": "initial",
            "example_papers": [
                [
                    1,
                    "CDConv: A Benchmark for Contradiction Detection in Chinese Conversations"
                ],
                [
                    6,
                    "Generating Natural Language Proofs with Verifier-Guided Search"
                ],
                [
                    7,
                    "Toward Unifying Text Segmentation and Long Document Summarization"
                ],
                [
                    8,
                    "The Geometry of Multilingual Language Model Representations"
                ],
                [
                    9,
                    "Improving Complex Knowledge Base Question Answering via Question-to-Action and Question-to-Question Alignment"
                ],
                [
                    10,
                    "PAIR: Prompt-Aware margIn Ranking for Counselor Reflection Scoring in Motivational Interviewing"
                ],
                [
                    13,
                    "Interpreting Language Models with Contrastive Explanations"
                ],
                [
                    15,
                    "Learning a Grammar Inducer from Massive Uncurated Instructional Videos"
                ],
                [
                    17,
                    "Estimating Soft Labels for Out-of-Domain Intent Detection"
                ],
                [
                    18,
                    "Multi-VQG: Generating Engaging Questions for Multiple Images"
                ]
            ],
            "paper_ids": [
                1,
                6,
                7,
                8,
                9,
                10,
                13,
                15,
                17,
                18,
                21,
                26,
                27,
                37,
                38,
                40,
                41,
                44,
                50,
                55,
                60,
                61,
                62,
                63,
                68,
                69,
                71,
                73,
                75,
                78,
                81,
                83,
                85,
                87,
                88,
                90,
                92,
                94,
                96,
                99,
                100,
                109,
                115,
                116,
                117,
                118,
                119,
                125,
                127,
                128,
                129,
                132,
                135,
                136,
                137,
                140,
                141,
                142,
                145,
                146,
                149,
                152,
                155,
                157,
                164,
                165,
                166,
                167,
                168,
                169,
                178,
                187,
                191,
                194,
                201,
                204,
                210,
                215,
                216,
                223,
                227,
                228,
                229,
                232,
                233,
                235,
                237,
                246,
                247,
                248,
                249,
                250,
                251,
                252,
                254,
                255,
                257,
                260,
                262,
                266,
                268,
                276,
                282,
                286,
                291,
                293,
                296,
                297,
                298,
                299,
                300,
                304,
                307,
                310,
                313,
                314,
                316,
                318,
                325,
                326,
                333,
                336,
                338,
                339,
                340,
                347,
                349,
                365,
                369,
                371,
                375,
                379,
                389,
                392,
                396,
                399,
                405,
                410,
                414,
                415,
                420,
                425,
                428,
                432,
                437,
                444,
                449,
                450,
                455,
                456,
                457,
                469,
                472,
                475,
                476,
                479,
                483,
                488,
                489,
                491,
                492,
                493,
                494,
                495,
                496,
                498,
                499,
                500,
                502,
                505,
                509,
                510,
                512,
                515,
                525,
                530,
                531,
                532,
                533,
                534,
                538,
                539,
                545,
                551,
                554,
                568,
                570,
                579,
                593,
                597,
                600,
                601,
                603,
                606,
                608,
                613,
                614,
                615,
                616,
                618,
                619,
                620,
                621,
                623,
                628,
                629,
                630,
                634,
                635,
                636,
                639,
                640,
                641,
                642,
                643,
                644,
                645,
                653,
                657,
                658,
                661,
                664,
                668,
                669,
                670,
                673,
                675,
                676,
                677,
                681,
                683,
                688,
                696,
                697,
                699,
                709,
                710,
                711,
                713,
                720,
                723,
                724,
                725,
                726,
                729,
                732,
                735,
                738,
                743,
                744,
                745,
                747,
                748,
                751,
                753,
                754,
                758,
                759,
                760,
                768,
                770,
                771,
                775,
                782,
                783,
                786,
                788,
                789,
                790,
                792,
                793,
                794,
                795,
                797,
                803,
                810,
                811,
                812,
                813,
                816,
                817,
                819,
                821,
                822
            ],
            "children": [
                {
                    "label": "comparative_performance_studies",
                    "description": "This cluster focuses on studies that compare the performance of various NLP models and techniques across different tasks and datasets.",
                    "level": 2,
                    "source": "depth",
                    "example_papers": [
                        [
                            6,
                            "Generating Natural Language Proofs with Verifier-Guided Search"
                        ],
                        [
                            8,
                            "The Geometry of Multilingual Language Model Representations"
                        ],
                        [
                            15,
                            "Learning a Grammar Inducer from Massive Uncurated Instructional Videos"
                        ],
                        [
                            17,
                            "Estimating Soft Labels for Out-of-Domain Intent Detection"
                        ],
                        [
                            21,
                            "Prompting for Multimodal Hateful Meme Classification"
                        ],
                        [
                            27,
                            "Sentence-Incremental Neural Coreference Resolution"
                        ],
                        [
                            40,
                            "When Can Transformers Ground and Compose: Insights from Compositional Generalization Benchmarks"
                        ],
                        [
                            41,
                            "Generative Language Models for Paragraph-Level Question Generation"
                        ],
                        [
                            44,
                            "Crossmodal-3600: A Massively Multilingual Multimodal Evaluation Dataset"
                        ],
                        [
                            50,
                            "DocInfer: Document-level Natural Language Inference using Optimal Evidence Selection"
                        ]
                    ],
                    "paper_ids": [
                        6,
                        8,
                        15,
                        17,
                        21,
                        27,
                        40,
                        41,
                        44,
                        50,
                        55,
                        60,
                        61,
                        62,
                        63,
                        68,
                        69,
                        71,
                        75,
                        87,
                        90,
                        94,
                        99,
                        100,
                        109,
                        115,
                        118,
                        119,
                        125,
                        127,
                        128,
                        129,
                        132,
                        135,
                        140,
                        141,
                        152,
                        157,
                        166,
                        167,
                        169,
                        178,
                        187,
                        191,
                        204,
                        210,
                        216,
                        223,
                        229,
                        233,
                        246,
                        248,
                        250,
                        254,
                        255,
                        257,
                        262,
                        282,
                        286,
                        293,
                        296,
                        297,
                        299,
                        300,
                        304,
                        313,
                        314,
                        318,
                        325,
                        333,
                        338,
                        339,
                        365,
                        369,
                        371,
                        375,
                        379,
                        389,
                        399,
                        410,
                        414,
                        415,
                        425,
                        428,
                        432,
                        444,
                        449,
                        450,
                        455,
                        457,
                        469,
                        472,
                        475,
                        479,
                        489,
                        491,
                        492,
                        495,
                        498,
                        500,
                        502,
                        515,
                        525,
                        530,
                        531,
                        539,
                        545,
                        554,
                        568,
                        570,
                        579,
                        597,
                        600,
                        601,
                        608,
                        613,
                        614,
                        615,
                        618,
                        620,
                        621,
                        623,
                        628,
                        629,
                        635,
                        639,
                        642,
                        643,
                        644,
                        653,
                        657,
                        658,
                        668,
                        670,
                        673,
                        675,
                        676,
                        683,
                        696,
                        697,
                        711,
                        725,
                        726,
                        729,
                        732,
                        735,
                        738,
                        743,
                        747,
                        748,
                        753,
                        754,
                        759,
                        771,
                        782,
                        783,
                        786,
                        788,
                        789,
                        792,
                        793,
                        794,
                        797,
                        803,
                        813,
                        822
                    ]
                },
                {
                    "label": "cross-lingual_transfer_evaluation",
                    "description": "This cluster encompasses evaluations that assess the effectiveness of models in cross-lingual transfer scenarios.",
                    "level": 2,
                    "source": "depth",
                    "example_papers": [
                        [
                            44,
                            "Crossmodal-3600: A Massively Multilingual Multimodal Evaluation Dataset"
                        ],
                        [
                            100,
                            "A Multilingual Perspective Towards the Evaluation of Attribution Methods in Natural Language Inference"
                        ],
                        [
                            166,
                            "Training Dynamics for Curriculum Learning: A Study on Monolingual and Cross-lingual NLU"
                        ],
                        [
                            169,
                            "Calibrating Zero-shot Cross-lingual (Un-)structured Predictions"
                        ],
                        [
                            201,
                            "Multi-level Distillation of Semantic Knowledge for Pre-training Multilingual Language Model"
                        ],
                        [
                            232,
                            "Language Contamination Helps Explains the Cross-lingual Capabilities of English Pretrained Models"
                        ],
                        [
                            297,
                            "MasakhaNER 2.0: Africa-centric Transfer Learning for Named Entity Recognition"
                        ],
                        [
                            399,
                            "Toward the Limitation of Code-Switching in Cross-Lingual Transfer"
                        ],
                        [
                            432,
                            "Retrofitting Multilingual Sentence Embeddings with Abstract Meaning Representation"
                        ],
                        [
                            502,
                            "Subword Evenness (SuE) as a Predictor of Cross-lingual Transfer to Low-resource Languages"
                        ]
                    ],
                    "paper_ids": [
                        44,
                        100,
                        166,
                        169,
                        201,
                        232,
                        297,
                        399,
                        432,
                        502,
                        510,
                        512,
                        525,
                        551,
                        615,
                        620,
                        629,
                        688,
                        697,
                        735,
                        743,
                        789,
                        821
                    ]
                },
                {
                    "label": "comparative_analysis",
                    "description": "This cluster includes studies that perform comparative analyses of different NLP methods, focusing on their strengths and weaknesses.",
                    "level": 2,
                    "source": "depth",
                    "example_papers": [
                        [
                            1,
                            "CDConv: A Benchmark for Contradiction Detection in Chinese Conversations"
                        ],
                        [
                            7,
                            "Toward Unifying Text Segmentation and Long Document Summarization"
                        ],
                        [
                            8,
                            "The Geometry of Multilingual Language Model Representations"
                        ],
                        [
                            9,
                            "Improving Complex Knowledge Base Question Answering via Question-to-Action and Question-to-Question Alignment"
                        ],
                        [
                            10,
                            "PAIR: Prompt-Aware margIn Ranking for Counselor Reflection Scoring in Motivational Interviewing"
                        ],
                        [
                            13,
                            "Interpreting Language Models with Contrastive Explanations"
                        ],
                        [
                            18,
                            "Multi-VQG: Generating Engaging Questions for Multiple Images"
                        ],
                        [
                            26,
                            "What Makes Instruction Learning Hard? An Investigation and a New Challenge in a Synthetic Environment"
                        ],
                        [
                            37,
                            "Abstract Visual Reasoning with Tangram Shapes"
                        ],
                        [
                            38,
                            "UnifiedSKG: Unifying and Multi-Tasking Structured Knowledge Grounding with Text-to-Text Language Models"
                        ]
                    ],
                    "paper_ids": [
                        1,
                        7,
                        8,
                        9,
                        10,
                        13,
                        18,
                        26,
                        37,
                        38,
                        63,
                        73,
                        78,
                        81,
                        83,
                        85,
                        88,
                        92,
                        96,
                        100,
                        115,
                        117,
                        125,
                        128,
                        132,
                        136,
                        137,
                        142,
                        145,
                        146,
                        149,
                        152,
                        155,
                        157,
                        164,
                        165,
                        167,
                        168,
                        169,
                        194,
                        215,
                        227,
                        228,
                        229,
                        233,
                        235,
                        237,
                        246,
                        247,
                        249,
                        251,
                        252,
                        260,
                        266,
                        268,
                        276,
                        291,
                        296,
                        298,
                        307,
                        310,
                        313,
                        316,
                        325,
                        326,
                        336,
                        340,
                        347,
                        349,
                        379,
                        392,
                        396,
                        405,
                        420,
                        437,
                        450,
                        456,
                        457,
                        475,
                        476,
                        483,
                        488,
                        493,
                        494,
                        496,
                        499,
                        505,
                        509,
                        531,
                        532,
                        533,
                        534,
                        538,
                        551,
                        570,
                        603,
                        606,
                        616,
                        618,
                        619,
                        630,
                        634,
                        636,
                        640,
                        641,
                        661,
                        664,
                        669,
                        673,
                        675,
                        677,
                        681,
                        699,
                        709,
                        710,
                        713,
                        720,
                        724,
                        744,
                        745,
                        747,
                        748,
                        751,
                        753,
                        758,
                        759,
                        760,
                        768,
                        770,
                        775,
                        790,
                        795,
                        810,
                        811,
                        812,
                        816,
                        817,
                        819
                    ]
                },
                {
                    "label": "fairness_evaluation",
                    "description": "This cluster is dedicated to evaluating the fairness of NLP models and techniques through comparative studies.",
                    "level": 2,
                    "source": "depth",
                    "example_papers": [
                        [
                            9,
                            "Improving Complex Knowledge Base Question Answering via Question-to-Action and Question-to-Question Alignment"
                        ],
                        [
                            100,
                            "A Multilingual Perspective Towards the Evaluation of Attribution Methods in Natural Language Inference"
                        ],
                        [
                            532,
                            "Bridging Fairness and Environmental Sustainability in Natural Language Processing"
                        ],
                        [
                            645,
                            "Perturbation Augmentation for Fairer NLP"
                        ]
                    ],
                    "paper_ids": [
                        9,
                        100,
                        532,
                        645
                    ]
                }
            ]
        },
        {
            "label": "error_analysis",
            "description": "Error analysis focuses on identifying and categorizing the types of errors made by NLP models, helping researchers understand limitations and areas for improvement.",
            "level": 1,
            "source": "initial",
            "example_papers": [
                [
                    13,
                    "Interpreting Language Models with Contrastive Explanations"
                ],
                [
                    22,
                    "Certified Error Control of Candidate Set Pruning for Two-Stage Relevance Ranking"
                ],
                [
                    24,
                    "Robustness of Fusion-based Multimodal Classifiers to Cross-Modal Content Dilutions"
                ],
                [
                    26,
                    "What Makes Instruction Learning Hard? An Investigation and a New Challenge in a Synthetic Environment"
                ],
                [
                    28,
                    "SNaC: Coherence Error Detection for Narrative Summarization"
                ],
                [
                    40,
                    "When Can Transformers Ground and Compose: Insights from Compositional Generalization Benchmarks"
                ],
                [
                    61,
                    "How Large Language Models are Transforming Machine-Paraphrase Plagiarism"
                ],
                [
                    63,
                    "``Will You Find These Shortcuts?'' A Protocol for Evaluating the Faithfulness of Input Salience Methods for Text Classification"
                ],
                [
                    83,
                    "Tracing Semantic Variation in Slang"
                ],
                [
                    98,
                    "Extracted BERT Model Leaks More Information than You Think!"
                ]
            ],
            "paper_ids": [
                13,
                22,
                24,
                26,
                28,
                40,
                61,
                63,
                83,
                98,
                99,
                109,
                114,
                115,
                118,
                120,
                123,
                127,
                132,
                136,
                137,
                138,
                142,
                145,
                149,
                154,
                169,
                172,
                174,
                177,
                214,
                224,
                228,
                229,
                237,
                244,
                247,
                250,
                266,
                289,
                292,
                296,
                313,
                324,
                336,
                347,
                369,
                375,
                379,
                385,
                396,
                398,
                404,
                437,
                450,
                475,
                483,
                491,
                500,
                524,
                530,
                532,
                538,
                541,
                545,
                579,
                591,
                593,
                595,
                597,
                616,
                617,
                618,
                622,
                623,
                628,
                640,
                645,
                652,
                661,
                664,
                665,
                666,
                671,
                676,
                677,
                699,
                700,
                710,
                711,
                724,
                730,
                742,
                752,
                758,
                759,
                767,
                769,
                770,
                776,
                784,
                788,
                792,
                796,
                808,
                811,
                812,
                814,
                815,
                820,
                826
            ],
            "children": [
                {
                    "label": "bias_analysis",
                    "description": "Bias analysis focuses on identifying and mitigating biases present in NLP models, ensuring fairness and equity in model predictions.",
                    "level": 2,
                    "source": "depth",
                    "example_papers": [
                        [
                            132,
                            "The (Undesired) Attenuation of Human Biases by Multilinguality"
                        ],
                        [
                            138,
                            "Gendered Mental Health Stigma in Masked Language Models"
                        ],
                        [
                            244,
                            "BERTScore is Unfair: On Social Bias in Language Model-Based Metrics for text generation"
                        ],
                        [
                            532,
                            "Bridging Fairness and Environmental Sustainability in Natural Language Processing"
                        ],
                        [
                            591,
                            "Does Your Model Classify Entities Reasonably? Diagnosing and Mitigating Spurious Correlations in Entity Typing"
                        ],
                        [
                            645,
                            "Perturbation Augmentation for Fairer NLP"
                        ],
                        [
                            776,
                            "Mitigating Spurious Correlation in Natural Language Understanding with Counterfactual Inference"
                        ]
                    ],
                    "paper_ids": [
                        132,
                        138,
                        244,
                        532,
                        591,
                        645,
                        776
                    ]
                },
                {
                    "label": "error_characterization",
                    "description": "Error characterization involves categorizing and understanding the types of errors made by NLP models to improve their performance.",
                    "level": 2,
                    "source": "depth",
                    "example_papers": [
                        [
                            40,
                            "When Can Transformers Ground and Compose: Insights from Compositional Generalization Benchmarks"
                        ],
                        [
                            127,
                            "AfroLID: A Neural Language Identification Tool for African Languages"
                        ],
                        [
                            169,
                            "Calibrating Zero-shot Cross-lingual (Un-)structured Predictions"
                        ],
                        [
                            172,
                            "Measuring Context-Word Biases in Lexical Semantic Datasets"
                        ],
                        [
                            214,
                            "Robots-Dont-Cry: Understanding Falsely Anthropomorphic Utterances in Dialog Systems"
                        ],
                        [
                            237,
                            "That's the Wrong Lung! Evaluating and Improving the Interpretability of Unsupervised Multimodal Encoders for Medical Data"
                        ],
                        [
                            475,
                            "FigMemes: A Dataset for Figurative Language Identification in Politically-Opinionated Memes"
                        ],
                        [
                            530,
                            "DuQM: A Chinese Dataset of Linguistically Perturbed Natural Questions for Evaluating the Robustness of Question Matching Models"
                        ],
                        [
                            617,
                            "Detecting Label Errors by Using Pre-Trained Language Models"
                        ],
                        [
                            724,
                            "Looking at the Overlooked: An Analysis on the Word-Overlap Bias in Natural Language Inference"
                        ]
                    ],
                    "paper_ids": [
                        40,
                        127,
                        169,
                        172,
                        214,
                        237,
                        475,
                        530,
                        617,
                        724,
                        730,
                        752,
                        759,
                        826
                    ]
                },
                {
                    "label": "model_evaluation",
                    "description": "Model evaluation encompasses various methods for assessing the overall performance and limitations of NLP models.",
                    "level": 2,
                    "source": "depth",
                    "example_papers": [
                        [
                            63,
                            "``Will You Find These Shortcuts?'' A Protocol for Evaluating the Faithfulness of Input Salience Methods for Text Classification"
                        ],
                        [
                            169,
                            "Calibrating Zero-shot Cross-lingual (Un-)structured Predictions"
                        ],
                        [
                            237,
                            "That's the Wrong Lung! Evaluating and Improving the Interpretability of Unsupervised Multimodal Encoders for Medical Data"
                        ],
                        [
                            379,
                            "Rethinking the Authorship Verification Experimental Setups"
                        ],
                        [
                            385,
                            "Questioning the Validity of Summarization Datasets and Improving Their Factual Consistency"
                        ],
                        [
                            475,
                            "FigMemes: A Dataset for Figurative Language Identification in Politically-Opinionated Memes"
                        ],
                        [
                            530,
                            "DuQM: A Chinese Dataset of Linguistically Perturbed Natural Questions for Evaluating the Robustness of Question Matching Models"
                        ],
                        [
                            814,
                            "Model Criticism for Long-Form text generation"
                        ],
                        [
                            826,
                            "Digging Errors in NMT: Evaluating and Understanding Model Errors from Partial Hypothesis Space"
                        ]
                    ],
                    "paper_ids": [
                        63,
                        169,
                        237,
                        379,
                        385,
                        475,
                        530,
                        814,
                        826
                    ]
                },
                {
                    "label": "error_analysis_method",
                    "description": "Error analysis methods focus on specific techniques and frameworks for conducting error analysis in NLP models.",
                    "level": 2,
                    "source": "depth",
                    "example_papers": [
                        [
                            13,
                            "Interpreting Language Models with Contrastive Explanations"
                        ],
                        [
                            22,
                            "Certified Error Control of Candidate Set Pruning for Two-Stage Relevance Ranking"
                        ],
                        [
                            26,
                            "What Makes Instruction Learning Hard? An Investigation and a New Challenge in a Synthetic Environment"
                        ],
                        [
                            28,
                            "SNaC: Coherence Error Detection for Narrative Summarization"
                        ],
                        [
                            40,
                            "When Can Transformers Ground and Compose: Insights from Compositional Generalization Benchmarks"
                        ],
                        [
                            61,
                            "How Large Language Models are Transforming Machine-Paraphrase Plagiarism"
                        ],
                        [
                            63,
                            "``Will You Find These Shortcuts?'' A Protocol for Evaluating the Faithfulness of Input Salience Methods for Text Classification"
                        ],
                        [
                            83,
                            "Tracing Semantic Variation in Slang"
                        ],
                        [
                            99,
                            "Do Vision-and-Language Transformers Learn Grounded Predicate-Noun Dependencies?"
                        ],
                        [
                            109,
                            "Unbiased and Efficient Sampling of Dependency Trees"
                        ]
                    ],
                    "paper_ids": [
                        13,
                        22,
                        26,
                        28,
                        40,
                        61,
                        63,
                        83,
                        99,
                        109,
                        114,
                        115,
                        120,
                        123,
                        136,
                        137,
                        142,
                        145,
                        149,
                        154,
                        172,
                        174,
                        177,
                        228,
                        229,
                        250,
                        266,
                        292,
                        296,
                        313,
                        324,
                        336,
                        347,
                        375,
                        379,
                        385,
                        398,
                        404,
                        437,
                        450,
                        483,
                        491,
                        500,
                        538,
                        541,
                        545,
                        579,
                        593,
                        595,
                        597,
                        616,
                        617,
                        618,
                        622,
                        623,
                        628,
                        640,
                        645,
                        661,
                        664,
                        666,
                        671,
                        676,
                        677,
                        699,
                        710,
                        711,
                        724,
                        730,
                        742,
                        752,
                        758,
                        759,
                        767,
                        769,
                        770,
                        776,
                        784,
                        788,
                        792,
                        796,
                        808,
                        811,
                        812,
                        814,
                        815,
                        820,
                        826
                    ]
                }
            ]
        },
        {
            "label": "user_studies",
            "description": "User studies evaluate the usability and effectiveness of NLP applications by gathering feedback from end-users, which can inform design and development decisions.",
            "level": 1,
            "source": "initial",
            "example_papers": [
                [
                    79,
                    "Affective Idiosyncratic Responses to Music"
                ],
                [
                    133,
                    "Entailer: Answering Questions with Faithful and Truthful Chains of Reasoning"
                ],
                [
                    214,
                    "Robots-Dont-Cry: Understanding Falsely Anthropomorphic Utterances in Dialog Systems"
                ],
                [
                    483,
                    "Let the CAT out of the bag: Contrastive Attributed explanations for Text"
                ],
                [
                    593,
                    "POQue: Asking Participant-specific Outcome Questions for a Deeper Understanding of Complex Events"
                ],
                [
                    643,
                    "Towards Teachable Reasoning Systems: Using a Dynamic Memory of User Feedback for Continual System Improvement"
                ],
                [
                    717,
                    "Evaluating the Knowledge Dependency of Questions"
                ]
            ],
            "paper_ids": [
                79,
                133,
                214,
                483,
                593,
                643,
                717
            ]
        },
        {
            "label": "proposed_evaluation_metrics",
            "description": "Proposed evaluation metrics involve the introduction of new quantitative measures to assess the performance of NLP models, aiming to provide more nuanced insights than traditional metrics.",
            "level": 1,
            "source": "initial",
            "example_papers": [
                [
                    10,
                    "PAIR: Prompt-Aware margIn Ranking for Counselor Reflection Scoring in Motivational Interviewing"
                ],
                [
                    13,
                    "Interpreting Language Models with Contrastive Explanations"
                ],
                [
                    14,
                    "RankGen: Improving text generation with Large Ranking Models"
                ],
                [
                    16,
                    "Normalized Contrastive Learning for Text-Video Retrieval"
                ],
                [
                    19,
                    "Tomayto, Tomahto. Beyond Token-level Answer Equivalence for Question Answering Evaluation"
                ],
                [
                    25,
                    "Translation between Molecules and Natural Language"
                ],
                [
                    26,
                    "What Makes Instruction Learning Hard? An Investigation and a New Challenge in a Synthetic Environment"
                ],
                [
                    28,
                    "SNaC: Coherence Error Detection for Narrative Summarization"
                ],
                [
                    31,
                    "Guiding Neural Entity Alignment with Compatibility"
                ],
                [
                    35,
                    "Aligning Recommendation and Conversation via Dual Imitation"
                ]
            ],
            "paper_ids": [
                10,
                13,
                14,
                16,
                19,
                25,
                26,
                28,
                31,
                35,
                36,
                37,
                39,
                46,
                48,
                61,
                63,
                69,
                81,
                85,
                100,
                103,
                105,
                120,
                122,
                127,
                129,
                130,
                132,
                134,
                137,
                140,
                141,
                143,
                147,
                152,
                154,
                155,
                157,
                166,
                169,
                171,
                172,
                177,
                184,
                191,
                200,
                204,
                207,
                219,
                224,
                227,
                228,
                236,
                238,
                244,
                248,
                250,
                251,
                261,
                266,
                268,
                275,
                276,
                282,
                289,
                293,
                307,
                308,
                319,
                322,
                324,
                326,
                329,
                332,
                334,
                347,
                364,
                371,
                372,
                375,
                377,
                379,
                385,
                386,
                388,
                391,
                392,
                405,
                408,
                415,
                417,
                419,
                420,
                424,
                432,
                439,
                442,
                444,
                452,
                456,
                462,
                463,
                468,
                471,
                472,
                475,
                477,
                478,
                479,
                481,
                483,
                494,
                502,
                505,
                506,
                515,
                517,
                520,
                530,
                541,
                546,
                556,
                563,
                565,
                587,
                588,
                590,
                591,
                592,
                593,
                594,
                595,
                597,
                600,
                601,
                603,
                606,
                612,
                617,
                622,
                624,
                625,
                626,
                627,
                628,
                629,
                631,
                634,
                640,
                645,
                648,
                650,
                653,
                654,
                656,
                657,
                661,
                662,
                666,
                669,
                671,
                673,
                674,
                676,
                677,
                687,
                698,
                699,
                700,
                704,
                710,
                713,
                714,
                717,
                730,
                731,
                736,
                737,
                742,
                752,
                753,
                756,
                757,
                761,
                766,
                770,
                771,
                773,
                776,
                778,
                790,
                792,
                802,
                805,
                806,
                810,
                812,
                813,
                814,
                815,
                816,
                819,
                826
            ],
            "children": [
                {
                    "label": "novel_evaluation_metrics",
                    "description": "This cluster focuses on the introduction of new evaluation metrics designed to enhance the assessment of NLP models beyond traditional methods.",
                    "level": 2,
                    "source": "depth",
                    "example_papers": [
                        [
                            10,
                            "PAIR: Prompt-Aware margIn Ranking for Counselor Reflection Scoring in Motivational Interviewing"
                        ],
                        [
                            13,
                            "Interpreting Language Models with Contrastive Explanations"
                        ],
                        [
                            14,
                            "RankGen: Improving text generation with Large Ranking Models"
                        ],
                        [
                            16,
                            "Normalized Contrastive Learning for Text-Video Retrieval"
                        ],
                        [
                            19,
                            "Tomayto, Tomahto. Beyond Token-level Answer Equivalence for Question Answering Evaluation"
                        ],
                        [
                            25,
                            "Translation between Molecules and Natural Language"
                        ],
                        [
                            26,
                            "What Makes Instruction Learning Hard? An Investigation and a New Challenge in a Synthetic Environment"
                        ],
                        [
                            28,
                            "SNaC: Coherence Error Detection for Narrative Summarization"
                        ],
                        [
                            31,
                            "Guiding Neural Entity Alignment with Compatibility"
                        ],
                        [
                            35,
                            "Aligning Recommendation and Conversation via Dual Imitation"
                        ]
                    ],
                    "paper_ids": [
                        10,
                        13,
                        14,
                        16,
                        19,
                        25,
                        26,
                        28,
                        31,
                        35,
                        36,
                        37,
                        39,
                        46,
                        48,
                        61,
                        63,
                        69,
                        81,
                        85,
                        100,
                        103,
                        105,
                        120,
                        122,
                        127,
                        129,
                        130,
                        132,
                        134,
                        137,
                        140,
                        141,
                        143,
                        147,
                        152,
                        154,
                        157,
                        166,
                        169,
                        171,
                        172,
                        177,
                        184,
                        204,
                        207,
                        219,
                        224,
                        227,
                        228,
                        236,
                        238,
                        244,
                        248,
                        250,
                        251,
                        261,
                        266,
                        268,
                        275,
                        276,
                        282,
                        289,
                        293,
                        307,
                        308,
                        319,
                        322,
                        324,
                        326,
                        329,
                        332,
                        334,
                        347,
                        364,
                        371,
                        372,
                        375,
                        377,
                        379,
                        385,
                        386,
                        388,
                        391,
                        392,
                        405,
                        408,
                        415,
                        417,
                        419,
                        420,
                        424,
                        432,
                        439,
                        442,
                        444,
                        452,
                        456,
                        462,
                        463,
                        468,
                        471,
                        472,
                        475,
                        477,
                        478,
                        479,
                        481,
                        483,
                        494,
                        502,
                        505,
                        506,
                        515,
                        517,
                        520,
                        530,
                        541,
                        546,
                        556,
                        563,
                        565,
                        587,
                        588,
                        590,
                        592,
                        593,
                        594,
                        595,
                        597,
                        600,
                        601,
                        603,
                        606,
                        612,
                        617,
                        622,
                        624,
                        625,
                        626,
                        627,
                        628,
                        629,
                        631,
                        634,
                        640,
                        645,
                        648,
                        650,
                        653,
                        656,
                        657,
                        661,
                        662,
                        666,
                        669,
                        671,
                        673,
                        674,
                        676,
                        677,
                        687,
                        698,
                        699,
                        700,
                        704,
                        710,
                        713,
                        714,
                        717,
                        730,
                        731,
                        736,
                        737,
                        742,
                        753,
                        756,
                        757,
                        761,
                        766,
                        770,
                        771,
                        773,
                        776,
                        778,
                        790,
                        792,
                        802,
                        805,
                        806,
                        810,
                        812,
                        813,
                        814,
                        815,
                        816,
                        819,
                        826
                    ]
                },
                {
                    "label": "interpretability_metrics",
                    "description": "This cluster encompasses metrics aimed at evaluating the interpretability of NLP models and their outputs.",
                    "level": 2,
                    "source": "depth",
                    "example_papers": [
                        [
                            13,
                            "Interpreting Language Models with Contrastive Explanations"
                        ],
                        [
                            250,
                            "Logical Reasoning with Span-Level Predictions for Interpretable and Robust NLI Models"
                        ]
                    ],
                    "paper_ids": [
                        13,
                        250
                    ]
                },
                {
                    "label": "cross-modal_embedding_based_metrics",
                    "description": "This cluster includes metrics that evaluate models based on cross-modal embeddings, assessing their performance across different data modalities.",
                    "level": 2,
                    "source": "depth",
                    "example_papers": [
                        [
                            25,
                            "Translation between Molecules and Natural Language"
                        ]
                    ],
                    "paper_ids": [
                        25
                    ]
                },
                {
                    "label": "quality_estimation",
                    "description": "This cluster focuses on metrics that estimate the quality of generated outputs in NLP tasks.",
                    "level": 2,
                    "source": "depth",
                    "example_papers": [
                        [
                            244,
                            "BERTScore is Unfair: On Social Bias in Language Model-Based Metrics for text generation"
                        ],
                        [
                            329,
                            "Competency-Aware Neural Machine Translation: Can Machine Translation Know its Own Translation Quality?"
                        ],
                        [
                            766,
                            "PreQuEL: Quality Estimation of Machine Translation Outputs in Advance"
                        ]
                    ],
                    "paper_ids": [
                        244,
                        329,
                        766
                    ]
                },
                {
                    "label": "reference-free_evaluation_metrics",
                    "description": "This cluster includes metrics that evaluate NLP models without relying on reference outputs, providing a more flexible assessment approach.",
                    "level": 2,
                    "source": "depth",
                    "example_papers": [
                        [
                            100,
                            "A Multilingual Perspective Towards the Evaluation of Attribution Methods in Natural Language Inference"
                        ],
                        [
                            200,
                            "Opinion Summarization by Weak-Supervision from Mix-structured Data"
                        ],
                        [
                            204,
                            "Revisiting Pre-trained Language Models and their Evaluation for Arabic Natural Language Processing"
                        ],
                        [
                            207,
                            "On the Evaluation Metrics for Paraphrase Generation"
                        ],
                        [
                            219,
                            "FineD-Eval: Fine-grained Automatic Dialogue-Level Evaluation"
                        ],
                        [
                            244,
                            "BERTScore is Unfair: On Social Bias in Language Model-Based Metrics for text generation"
                        ],
                        [
                            308,
                            "Context Matters for Image Descriptions for Accessibility: Challenges for Referenceless Evaluation Metrics"
                        ],
                        [
                            329,
                            "Competency-Aware Neural Machine Translation: Can Machine Translation Know its Own Translation Quality?"
                        ],
                        [
                            405,
                            "The Authenticity Gap in Human Evaluation"
                        ],
                        [
                            654,
                            "Referee: Reference-Free Sentence Summarization with Sharper Controllability through Symbolic Knowledge Distillation"
                        ]
                    ],
                    "paper_ids": [
                        100,
                        200,
                        204,
                        207,
                        219,
                        244,
                        308,
                        329,
                        405,
                        654,
                        731,
                        752
                    ]
                }
            ]
        }
    ]
}